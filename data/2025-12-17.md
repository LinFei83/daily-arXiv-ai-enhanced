<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 37]
- [cs.CV](#cs.CV) [Total: 113]
- [cs.CL](#cs.CL) [Total: 32]
- [cs.RO](#cs.RO) [Total: 22]
- [eess.SY](#eess.SY) [Total: 15]
- [eess.IV](#eess.IV) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records](https://arxiv.org/abs/2512.13700)
*Mitchell A. Klusty,Elizabeth C. Solie,Caroline N. Leach,W. Vaiden Logan,Lynnet E. Richey,John C. Gensel,David P. Szczykutowicz,Bryan C. McLellan,Emily B. Collier,Samuel E. Armstrong,V. K. Cody Bumgardner*

Main category: cs.AI

TL;DR: 该论文提出了一个安全的、模块化的框架，利用本地部署的大语言模型（LLM）和检索增强生成（RAG）技术，从临床笔记中自动提取结构化特征，以减轻人工病历审查的负担并提高数据捕获的一致性。


<details>
  <summary>Details</summary>
Motivation: 人工病历审查是临床研究中极其耗时且资源密集的部分，需要专家从非结构化的电子健康记录（EHR）叙述中提取复杂信息。

Method: 开发了一个安全的、模块化的框架，该框架利用部署在机构批准的、符合HIPAA标准的计算基础设施上的本地LLM。该系统将RAG和LLM的结构化响应方法集成到一个广泛可部署和可扩展的容器中，以实现多样化临床领域的特征提取。

Result: 在评估中，该框架在与专家标注数据集进行比较时，对大量患者笔记中存在的多种医学特征实现了高精度，并识别出了一些在人工审查中遗漏的标注错误。

Conclusion: 该框架展示了LLM系统通过自动化提取来减轻人工病历审查负担、提高数据捕获一致性并加速临床研究的潜力。

Abstract: Manual chart review remains an extremely time-consuming and resource-intensive component of clinical research, requiring experts to extract often complex information from unstructured electronic health record (EHR) narratives. We present a secure, modular framework for automated structured feature extraction from clinical notes leveraging locally deployed large language models (LLMs) on institutionally approved, Health Insurance Portability and Accountability Act (HIPPA)-compliant compute infrastructure. This system integrates retrieval augmented generation (RAG) and structured response methods of LLMs into a widely deployable and scalable container to provide feature extraction for diverse clinical domains. In evaluation, the framework achieved high accuracy across multiple medical characteristics present in large bodies of patient notes when compared against an expert-annotated dataset and identified several annotation errors missed in manual review. This framework demonstrates the potential of LLM systems to reduce the burden of manual chart review through automated extraction and increase consistency in data capture, accelerating clinical research.

</details>


### [2] [Blind Radio Mapping via Spatially Regularized Bayesian Trajectory Inference](https://arxiv.org/abs/2512.13701)
*Zheng Xing,Junting Chen*

Main category: cs.AI

TL;DR: 本文提出了一种盲无线电地图构建框架，通过MIMO-OFDM信道测量，无需位置标签即可推断用户轨迹，并有效构建无线电地图。


<details>
  <summary>Details</summary>
Motivation: 传统的无线电地图构建方法需要大量的、昂贵的且在实际场景中不切实际的位置标记数据。

Method: 该研究首先证明了在准镜面环境模型下，非视距(NLOS)信道状态信息(CSI)具有空间连续性，并导出了与物理距离成比例的CSI-距离度量。针对泊松分布AP部署中的直线轨迹，理论上证明了定位误差的克拉默-劳下界(CRLB)渐近消失。在此基础上，开发了一个空间正则化的贝叶斯推理框架，联合估计信道特征、区分视距(LOS)/NLOS条件并恢复用户轨迹。

Result: 在射线追踪数据集上的实验表明，平均定位误差为0.68米，波束图重建误差为3.3%。

Conclusion: 所提出的盲映射方法在无需位置标签的情况下，能够有效进行无线电地图构建，并实现了高精度的定位和波束图重建。

Abstract: Radio maps enable intelligent wireless applications by capturing the spatial distribution of channel characteristics. However, conventional construction methods demand extensive location-labeled data, which are costly and impractical in many real-world scenarios. This paper presents a blind radio map construction framework that infers user trajectories from indoor multiple-input multiple-output (MIMO)-Orthogonal Frequency-Division Multiplexing (OFDM) channel measurements without relying on location labels. It first proves that channel state information (CSI) under non-line-of-sight (NLOS) exhibits spatial continuity under a quasi-specular environmental model, allowing the derivation of a CSI-distance metric that is proportional to the corresponding physical distance. For rectilinear trajectories in Poisson-distributed access point (AP) deployments, it is shown that the Cramer-Rao Lower Bound (CRLB) of localization error vanishes asymptotically, even under poor angular resolution. Building on these theoretical results, a spatially regularized Bayesian inference framework is developed that jointly estimates channel features, distinguishes line-of-sight (LOS)/NLOS conditions and recovers user trajectories. Experiments on a ray-tracing dataset demonstrate an average localization error of 0.68 m and a beam map reconstruction error of 3.3%, validating the effectiveness of the proposed blind mapping method.

</details>


### [3] [Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents](https://arxiv.org/abs/2512.13704)
*Doohee You,Sundeep Paul*

Main category: cs.AI

TL;DR: Adjudicator是一个神经符号系统，通过构建动态知识图谱（KG）并利用多智能体大型语言模型（LLM）架构来识别和纠正训练数据中的标签噪声。它在基准测试中实现了0.99的F1分数，显著优于基线模型，并能有效处理复杂的结构性错误。


<details>
  <summary>Details</summary>
Motivation: 生产机器学习系统的性能受限于训练数据质量，在高风险工业应用中，噪声标签会降低系统性能并侵蚀用户信任。因此，需要一个系统来自动识别和纠正标签噪声。

Method: Adjudicator将此问题建模为一个神经符号任务。首先，它构建一个动态知识图谱（KG）来统一项目上下文。然后，这个KG为“智能体委员会”提供信息，这是一个新颖的多智能体大型语言模型（LLM）架构，其中专业智能体对标签的有效性进行辩论和投票。此外，它采用了一种新颖的覆盖逻辑，利用KG完美识别复杂的结构性错误。

Result: 在AlleNoise基准测试的1,000项平衡子集上，Adjudicator的KG-informed模型实现了0.99的F1分数，显著优于单一LLM基线（0.48 F1）和非KG委员会基线（0.59 F1）。分析表明，这得益于高精确度（Precision），以及通过使用KG的覆盖逻辑对复杂结构性错误实现了完全召回（Recall），而基线模型未能发现此类错误。

Conclusion: 该研究展示了一个强大且可解释的自动化、高精度数据验证系统，为在严格管理的工业环境中生成黄金数据集提供了重要的概念验证。

Abstract: The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, a system that addresses the critical data mining challenge of automatically identifying and correcting label noise and has been validated for production deployment. Adjudicator models this as a neuro-symbolic task, first constructing a dynamic Knowledge Graph (KG) to unify item context. This KG then informs a "Council of Agents," a novel multi-agent Large Language Model architecture where specialized agents debate and vote on a label's validity. We validate our system on a 1,000-item balanced subset of the AlleNoise benchmark. Our KG-informed model achieves a 0.99 F1-score, significantly outperforming a single-LLM baseline (0.48 F1) and a non-KG council (0.59 F1). Our analysis reveals this is due to a Precision, achieved by a novel override logic that uses the KG to perfectly identify complex, structural errors (complete Recall) -- a class of errors that baselines fail to find. This result demonstrates a robust and explainable system for automated, high-precision data verification, serving as a vital proof-of-concept for generating golden datasets in strictly governed industrial environments.

</details>


### [4] [LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms](https://arxiv.org/abs/2512.13713)
*Ali Parsaee,Yashar Talebirad,Csongor Szepesvári,Vishwajeet Ohal,Eden Redman*

Main category: cs.AI

TL;DR: LoopBench是一个评估大型语言模型（LLM）在分布式对称性破缺和元认知思维中推理能力的基准。它通过让LLM代理为奇数循环图着色来测试它们在无通信限制下打破死锁的能力，结果显示先进的LLM能成功制定策略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）作为自主代理的应用日益增多，但它们在分布式系统中的协调能力尚不清楚。本研究旨在评估LLM在分布式对称性破缺和元认知思维中的推理能力。

Method: 引入了LoopBench基准。该基准关注于使用有限颜色为奇数循环图（$C_3, C_5, C_{11}$）着色，其中确定性、无通信代理会陷入无限循环。实现了一种策略传递机制作为一致性记忆的形式。

Result: 标准LLM和经典启发式方法表现不佳，而先进的推理模型（如O3）能够设计出逃离死锁的策略。

Conclusion: LoopBench为基于语言推理的分布式算法的涌现提供了研究平台，并为集体智能提供了一个试验台。

Abstract: Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C_3, C_5, C_{11}$) with limited colors, where deterministic, non-communicating agents fail in infinite loops. A strategy passing mechanism is implemented as a form of consistent memory. We show that while standard LLMs and classical heuristics struggle, advanced reasoning models (e.g., O3) devise strategies to escape deadlocks. LoopBench allows the study of emergent distributed algorithms based on language-based reasoning, offering a testbed for collective intelligence.

</details>


### [5] [ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making](https://arxiv.org/abs/2512.13716)
*Yitong Luo,Ziang Chen,Hou Hei Lam,Jiayu zhan,Junqi Wang,Zhenliang Zhang,Xue Feng*

Main category: cs.AI

TL;DR: 本文提出ValuePilot框架，通过价值驱动的方法实现个性化决策，使AI代理能够根据个人价值观做出解释性强、可泛化的行为，并在未见过的情景中表现优于现有大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 在人机交互中，个性化决策至关重要，使AI代理能与个体用户的价值偏好保持一致。随着AI系统扩展到现实世界应用，适应超越任务完成或集体对齐的个性化价值观成为一个关键挑战，需要提高可解释性和在陌生场景中的适应性。

Method: 本文提出ValuePilot框架，包含两个阶段：1. 数据集生成工具包（DGT）：通过人机协作（人类-LLM）管道构建多样化的、带有价值注释的场景。2. 决策模块（DMM）：学习根据个人价值偏好评估行动，从而实现情境敏感的个性化决策。

Result: 在未见过的情景中进行评估时，DMM在与人类行动选择保持一致性方面，优于包括GPT-5、Claude-Sonnet-4、Gemini-2-flash和Llama-3.1-70b在内的强大LLM基线模型。

Conclusion: 研究结果表明，价值驱动的决策是一种有效且可扩展的工程途径，用于构建可解释的个性化AI代理。

Abstract: Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task completion or collective alignment has become a critical challenge. We address this by proposing a value-driven approach to personalized decision-making. Human values serve as stable, transferable signals that support consistent and generalizable behavior across contexts. Compared to task-oriented paradigms driven by external rewards and incentives, value-driven decision-making enhances interpretability and enables agents to act appropriately even in novel scenarios. We introduce ValuePilot, a two-phase framework consisting of a dataset generation toolkit (DGT) and a decision-making module (DMM). DGT constructs diverse, value-annotated scenarios from a human-LLM collaborative pipeline. DMM learns to evaluate actions based on personal value preferences, enabling context-sensitive, individualized decisions. When evaluated on previously unseen scenarios, DMM outperforms strong LLM baselines, including GPT-5, Claude-Sonnet-4, Gemini-2-flash, and Llama-3.1-70b, in aligning with human action choices. Our results demonstrate that value-driven decision-making is an effective and extensible engineering pathway toward building interpretable, personalized AI agents.

</details>


### [6] [Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN](https://arxiv.org/abs/2512.13715)
*Fatemeh Lotfi,Fatemeh Afghah*

Main category: cs.AI

TL;DR: 本文提出了一种自适应元分层强化学习（Meta-HRL）框架，用于O-RAN中资源分配和网络切片的联合优化，通过结合分层控制和元学习，显著提高了网络管理效率、适应速度和QoS满意度。


<details>
  <summary>Details</summary>
Motivation: 现代应用对无线网络提出了实时适应性和高效资源管理的需求。O-RAN架构及其RIC模块提供了动态资源管理和网络切片的解决方案，但现有AI驱动的方法在不可预测和高度动态的条件下难以保持性能。

Method: 本文提出了一种受MAML启发的自适应元分层强化学习（Meta-HRL）框架，用于O-RAN中资源分配和网络切片的联合优化。该框架将分层控制（高层控制器负责跨切片资源分配，低层代理执行切片内调度）与元学习相结合，实现全局和局部适应。自适应元更新机制根据时间差误差方差对任务进行加权，以提高稳定性和优先处理复杂网络场景。理论分析建立了两级学习过程的次线性收敛和遗憾保证。

Result: 仿真结果表明，与基线RL和元RL方法相比，网络管理效率提高了19.8%，并实现了更快的适应和更高的eMBB、URLLC和mMTC切片QoS满意度。额外的消融和可扩展性研究证实了该方法的鲁棒性，实现了高达40%的更快适应，并在网络规模增加时保持了公平性、延迟和吞吐量性能的一致性。

Conclusion: 所提出的Meta-HRL框架通过结合分层控制和元学习，显著提升了O-RAN中动态资源管理和网络切片的效率、适应速度和QoS满意度，为复杂多变的无线环境提供了鲁棒且可扩展的解决方案。

Abstract: The increasing complexity of modern applications demands wireless networks capable of real time adaptability and efficient resource management. The Open Radio Access Network (O-RAN) architecture, with its RAN Intelligent Controller (RIC) modules, has emerged as a pivotal solution for dynamic resource management and network slicing. While artificial intelligence (AI) driven methods have shown promise, most approaches struggle to maintain performance under unpredictable and highly dynamic conditions. This paper proposes an adaptive Meta Hierarchical Reinforcement Learning (Meta-HRL) framework, inspired by Model Agnostic Meta Learning (MAML), to jointly optimize resource allocation and network slicing in O-RAN. The framework integrates hierarchical control with meta learning to enable both global and local adaptation: the high-level controller allocates resources across slices, while low level agents perform intra slice scheduling. The adaptive meta-update mechanism weights tasks by temporal difference error variance, improving stability and prioritizing complex network scenarios. Theoretical analysis establishes sublinear convergence and regret guarantees for the two-level learning process. Simulation results demonstrate a 19.8% improvement in network management efficiency compared with baseline RL and meta-RL approaches, along with faster adaptation and higher QoS satisfaction across eMBB, URLLC, and mMTC slices. Additional ablation and scalability studies confirm the method's robustness, achieving up to 40% faster adaptation and consistent fairness, latency, and throughput performance as network scale increases.

</details>


### [7] [AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach](https://arxiv.org/abs/2512.13714)
*Gangesh Pathak,Prasanna Kumar*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）在受监管行业中因不稳定性而面临挑战，现有稳定化方法成本高昂。本文提出一种基于AI的标注流程，通过人机协同识别和修复LLM输出的不稳定性模式，以提高其可靠性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLM在高度受监管行业中存在不稳定性、推理不一致、幻觉和性能可变性等问题，限制了其在需要事实精确性和行为一致性领域的安全使用。现有的稳定化方法（如RLHF和SFT）虽然有效，但成本高昂且依赖大量人工标注，难以可持续扩展。

Method: 本文提出一个基于AI的标注流程，系统地识别、标注和修复LLM输出中的不稳定性模式。该方法采用人机协同，结合自动化弱监督、基于置信度的标注和有针对性的人工验证，以确保反馈信息的可靠性和道德正确性。框架中引入了语义一致性、事实正确性和逻辑连贯性等稳定性特定标注类别，以实现模型的持续校准和鲁棒性增强。

Result: 该AI标注流程旨在通过反馈循环实现模型的持续校准和鲁棒性增强，从而保证反馈信息的可靠性和道德正确性，并使LLM能够安全应用于需要事实精确性和行为一致性的领域。

Conclusion: 通过引入可扩展的AI辅助标注流程，本研究旨在解决LLM在受监管行业中的不稳定性问题，使其能够更可靠、更精确地应用，从而克服现有稳定化方法的局限性。

Abstract: LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior (Aiyappa et al., 2023). The current methods of stabilization, such as, reinforcement learning with human feedback (RLHF) and supervised fine-tuning, offer quantifiable improvements but are expensive and based on the intensive annotation of humans, thus being not easily scaled in a sustainable way (Dong et al., 2023; Retzlaff et al., 2024). This paper presents an AI-based annotation pipeline that systematically identifies, labels, and fixes for instability patterns on LLM output. Our human-AI synergy method combines the models of automated weak supervision and confidence-based annotation with the target human validation to guarantee the reliability and moral uprightness of feedback information (Cabitza et al., 2023; Jiang et al., 2023). The semantic consistency, factual correctness, and logical coherence categories of stability-specific annotation are introduced into our framework, allowing the continuous calibration of models and the enhancement of their robustness based on the feedback loops (Honovich et al., 2021; Nan et al., 2021).

</details>


### [8] [Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy](https://arxiv.org/abs/2512.13725)
*Steve Nwaiwu,Nipat Jongsawat,Anucha Tungkasthan*

Main category: cs.AI

TL;DR: 本研究首次系统评估了量化（INT8和NF4）对大型语言模型（Llama 3 8B）因果推理能力（关联、干预、反事实）的影响。结果显示，LLM的因果推理能力对四比特量化表现出意外的鲁棒性，其中干预查询最敏感。图检索增强生成能提升干预准确性，而现有反事实基准测试未能充分揭示量化带来的因果推理脆弱性。


<details>
  <summary>Details</summary>
Motivation: 在对可靠决策至关重要的高风险场景中，大型语言模型（LLM）的因果推理能力至关重要。随着部署向边缘和资源受限环境转移，量化模型（如INT8和NF4）正成为标准。然而，精度降低对形式化因果推理的影响尚不明确。

Method: 本研究通过以下方法进行：1) 系统评估了量化对Pearl因果阶梯所有三个层级的影响。2) 使用包含3000个样本的分层CLadder基准测试。3) 在Llama 3 8B模型上评估了INT8和NF4量化效果。4) 在CRASS基准测试上进行实验。5) 评估了使用真实因果图的图检索增强生成（Graph Retrieval Augmented Generation）。

Result: 研究发现：1) Llama 3 8B在量化（NF4）下，各层级准确性大致稳定，总体下降不到1%。2) 第二层级（干预查询）对精度损失最敏感。3) 第三层级（反事实推理）相对稳定，但在特定查询类型（如碰撞偏差、后门调整）上表现出异质性弱点。4) CRASS基准测试显示不同精度模型性能几乎相同，表明现有常识反事实数据集缺乏结构敏感性。5) 图检索增强生成可使NF4干预准确性提高1.7%，部分抵消了压缩带来的退化。

Conclusion: 本研究得出结论：1) 因果推理对四比特量化出乎意料地鲁棒。2) 图结构增强可以选择性地强化干预推理。3) 当前的反事实基准测试未能捕捉到更深层次的因果脆弱性。本工作为压缩因果推理提供了初步的经验图谱，并为部署高效且结构支持的因果AI系统提供了实用指导。

Abstract: Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming standard. Yet the impact of precision reduction on formal causal reasoning is poorly understood. To our knowledge, this is the first study to systematically evaluate quantization effects across all three levels of Pearls Causal Ladder. Using a 3000 sample stratified CLadder benchmark, we find that rung level accuracy in Llama 3 8B remains broadly stable under quantization, with NF4 showing less than one percent overall degradation. Interventional queries at rung 2 are the most sensitive to precision loss, whereas counterfactual reasoning at rung 3 is comparatively stable but exhibits heterogeneous weaknesses across query types such as collider bias and backdoor adjustment. Experiments on the CRASS benchmark show near identical performance across precisions, indicating that existing commonsense counterfactual datasets lack the structural sensitivity needed to reveal quantization induced reasoning drift. We further evaluate Graph Retrieval Augmented Generation using ground truth causal graphs and observe a consistent improvement in NF4 interventional accuracy of plus 1.7 percent, partially offsetting compression related degradation. These results suggest that causal reasoning is unexpectedly robust to four bit quantization, graph structured augmentation can selectively reinforce interventional reasoning, and current counterfactual benchmarks fail to capture deeper causal brittleness. This work provides an initial empirical map of compressed causal reasoning and practical guidance for deploying efficient and structurally supported causal AI systems.

</details>


### [9] [Mathematics and Coding are Universal AI Benchmarks](https://arxiv.org/abs/2512.13764)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 本研究指出，在AI智能体心理测量电池的模空间中，数学和编程扮演着特殊角色。它们为评估提供了“通用坐标”，特别是形式化数学是AI递归自我改进的天然启动领域。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解数学和编程在AI智能体评估（通过心理测量电池）中的特殊作用，并基于先前的AAI框架和GVU动力学，探索如何实现AI的稳定自我改进。

Method: 研究定义了“数学纤维”，并分析了在该纤维上结合形式证明内核（如Lean, Coq）的GVU流。主要技术方法是提出了一个密度定理，用于量化数学定理证明和编码任务在电池模空间中的表示能力。

Result: 研究发现，在数学纤维上，结合形式证明内核的GVU流由于其类神谕验证机制，能够实现谱稳定的自我改进。核心技术结果是一个密度定理：在特定条件下，数学定理证明和编码任务生成的电池子空间在评估度量下是电池模空间中的稠密集。编码本身是普适的，而纯数学在表达性上并非如此，但其特权在于谱稳定性。这表明数学和编码提供了评估的“通用坐标”。

Conclusion: 研究得出结论，数学和编码为AI评估提供了“通用坐标”，并且形式化数学是高级AI智能体实现递归自我改进的天然“启动领域”或关键驱动力。

Abstract: We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.

</details>


### [10] [State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models](https://arxiv.org/abs/2512.13762)
*TK Lee*

Main category: cs.AI

TL;DR: 本研究提出一种定性案例研究方法来审计大型语言模型在长期交互中与政策相关的行为选择性。发现模型在非敏感领域表现正常，但在敏感领域反复功能性拒绝，并引入“习得性无能”来描述这种选择性保留行为，提出一种交互层面的审计框架。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）被广泛部署为通用工具，但长时间的交互可能会揭示标准定量基准无法捕捉的行为模式，特别是与政策相关的行为选择性。

Method: 采用定性案例研究方法，通过单一的86轮对话会话，审计模型在长期交互中与政策相关的行为选择性。操作化了三种响应机制（正常表现Normal Performance, 功能性拒绝Functional Refusal, 元叙事Meta-Narrative），并对模型行为进行描述。

Result: 在单一会话中，同一模型在广泛、非敏感领域表现出正常性能（NP），而在提供者或政策敏感领域则反复产生功能性拒绝（FR），导致NP和FR在不同领域之间存在一致的不对称性。引入“习得性无能”（LI）作为这种选择性保留行为的描述符。发现元叙事（MN）角色框架叙事倾向于与敏感语境中的拒绝同时发生。

Conclusion: 该研究提出了一种基于可观察行为的交互层面审计框架，并提出“习得性无能”作为审视潜在对齐副作用的视角，值得在不同用户和模型之间进行进一步调查。

Abstract: Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-linked behavioral selectivity in long-horizon interaction. In a single 86-turn dialogue session, the same model shows Normal Performance (NP) in broad, non-sensitive domains while repeatedly producing Functional Refusal (FR) in provider- or policy-sensitive domains, yielding a consistent asymmetry between NP and FR across domains. Drawing on learned helplessness as an analogy, we introduce learned incapacity (LI) as a behavioral descriptor for this selective withholding without implying intentionality or internal mechanisms. We operationalize three response regimes (NP, FR, Meta-Narrative; MN) and show that MN role-framing narratives tend to co-occur with refusals in the same sensitive contexts. Overall, the study proposes an interaction-level auditing framework based on observable behavior and motivates LI as a lens for examining potential alignment side effects, warranting further investigation across users and models.

</details>


### [11] [Semantic Grounding Index: Geometric Bounds on Context Engagement in RAG Systems](https://arxiv.org/abs/2512.13771)
*Javier Marín*

Main category: cs.AI

TL;DR: 本文引入了语义接地指数（SGI），通过衡量回答与问题和上下文之间的角度距离比率，发现幻觉响应倾向于在嵌入空间中保持与问题更近，而非偏向检索到的上下文（语义惰性）。SGI为识别RAG幻觉提供了一种高效、有理论依据的方法。


<details>
  <summary>Details</summary>
Motivation: 当检索增强生成（RAG）系统产生幻觉时，研究其在嵌入空间中留下的几何痕迹，并开发一种有效的方法来识别这些幻觉。

Method: 引入语义接地指数（SGI），定义为回答到问题与回答到上下文在单位超球面上的角度距离之比。在HaluEval数据集（5,000个样本）上使用五种嵌入模型进行评估，并通过球形三角不等式推导了SGI判别力随问题-上下文角度分离增加的理论预测。同时，在TruthfulQA上进行了负面结果分析以区分主题参与与事实准确性。

Result: 核心发现是“语义惰性”：幻觉响应在角度上仍然与问题近似，而非偏离到检索到的上下文。在HaluEval上观察到显著的效果量（Cohen's d介于0.92至1.28），跨模型平均相关性r=0.85。SGI的判别力随问题-上下文角度分离的增加而增强（d从0.61上升到1.27，AUC从0.72提高到0.83）。SGI在长响应（d=2.05）和短问题（d=1.22）上表现出色，对上下文长度具有鲁棒性。校准分析显示ECE=0.10，表明SGI分数可作为概率估计。在TruthfulQA上的负面结果（AUC=0.478）表明SGI衡量的是主题参与度而非事实准确性。

Conclusion: SGI提供了一种计算高效、有理论依据的基础设施，用于在生产RAG部署中识别需要验证的响应。它通过量化回答与问题和上下文的语义距离，揭示了幻觉的几何特征，并能有效预测幻觉发生的可能性。

Abstract: When retrieval-augmented generation (RAG) systems hallucinate, what geometric trace does this leave in embedding space? We introduce the Semantic Grounding Index (SGI), defined as the ratio of angular distances from the response to the question versus the context on the unit hypersphere $\mathbb{S}^{d-1}$.Our central finding is \emph{semantic laziness}: hallucinated responses remain angularly proximate to questions rather than departing toward retrieved contexts. On HaluEval ($n$=5,000), we observe large effect sizes (Cohen's $d$ ranging from 0.92 to 1.28) across five embedding models with mean cross-model correlation $r$=0.85. Crucially, we derive from the spherical triangle inequality that SGI's discriminative power should increase with question-context angular separation $θ(q,c)$-a theoretical prediction confirmed empirically: effect size rises monotonically from $d$=0.61 -low $θ(q,c)$, to $d$=1.27 -high $θ(q,c)$, with AUC improving from 0.72 to 0.83. Subgroup analysis reveals that SGI excels on long responses ($d$=2.05) and short questions ($d$=1.22), while remaining robust across context lengths. Calibration analysis yields ECE=0.10, indicating SGI scores can serve as probability estimates, not merely rankings. A critical negative result on TruthfulQA (AUC=0.478) establishes that angular geometry measures topical engagement rather than factual accuracy. SGI provides computationally efficient, theoretically grounded infrastructure for identifying responses that warrant verification in production RAG deployments.

</details>


### [12] [EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery](https://arxiv.org/abs/2512.13857)
*Kamer Ali Yuksel*

Main category: cs.AI

TL;DR: EvoLattice是一个新框架，它使用有向无环图（DAG）在一个结构中表示程序或代理行为的整个候选种群，克服了现有LLM驱动的单候选覆盖方法的局限性，实现了更稳定、更具表达力且改进更强的进化。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）驱动的程序和多智能体系统进化方法主要依赖于基于覆盖的突变，每次只维护一个候选。这种方法会丢弃有用的变体，容易受到破坏性编辑的影响，并在脆弱的搜索空间中探索，容易导致结构性故障。

Method: EvoLattice将整个候选程序或智能体行为种群表示为一个单一的有向无环图（DAG）。每个节点存储多个持久的替代方案，图中每条有效路径定义一个独特的、可执行的候选。它通过评估每个替代方案在其出现的所有路径中的得分，实现细粒度的替代方案级别评估，为LLM引导的突变、重组和剪枝提供密集的数据驱动反馈信号。一个确定性的自修复机制独立于LLM确保结构正确性，强制执行无环性和依赖一致性。

Result: 在程序合成（代理和优化器元学习）中，EvoLattice比之前的LLM引导方法产生了更稳定的进化、更大的表达能力和更强的改进轨迹。由此产生的动态类似于质量-多样性优化，这些特性隐式地从EvoLattice内部的多替代表示中出现。

Conclusion: EvoLattice通过其独特的DAG表示法和细粒度评估机制，为LLM引导的程序和智能体进化提供了一个更优越、更鲁棒的框架，解决了传统覆盖方法的固有缺陷，并能实现类似质量-多样性优化的效果。

Abstract: Large language models (LLMs) are increasingly used to evolve programs and multi-agent systems, yet most existing approaches rely on overwrite-based mutations that maintain only a single candidate at a time. Such methods discard useful variants, suffer from destructive edits, and explore a brittle search space prone to structural failure. We introduce EvoLattice, a framework that represents an entire population of candidate programs or agent behaviors within a single directed acyclic graph. Each node stores multiple persistent alternatives, and every valid path through the graph defines a distinct executable candidate, yielding a large combinatorial search space without duplicating structure. EvoLattice enables fine-grained alternative-level evaluation by scoring each alternative across all paths in which it appears, producing statistics that reveal how local design choices affect global performance. These statistics provide a dense, data-driven feedback signal for LLM-guided mutation, recombination, and pruning, while preserving successful components. Structural correctness is guaranteed by a deterministic self-repair mechanism that enforces acyclicity and dependency consistency independently of the LLM. EvoLattice naturally extends to agent evolution by interpreting alternatives as prompt fragments or sub-agent behaviors. Across program synthesis (proxy and optimizer meta-learning), EvoLattice yields more stable evolution, greater expressivity, and stronger improvement trajectories than prior LLM-guided methods. The resulting dynamics resemble quality-diversity optimization, emerging implicitly from EvoLattice's internal multi-alternative representation rather than an explicit external archive.

</details>


### [13] [MURIM: Multidimensional Reputation-based Incentive Mechanism for Federated Learning](https://arxiv.org/abs/2512.13955)
*Sindhuja Madabushi,Dawood Wasif,Jin-Hee Cho*

Main category: cs.AI

TL;DR: 该论文提出了MURIM，一种基于多维度声誉的激励机制，用于联邦学习（FL），旨在通过考虑客户端可靠性、隐私、资源和公平性，提高公平性、隐私保护和模型鲁棒性，同时防止恶意客户端获得不应得的奖励。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临客户端激励不足、隐私风险和资源限制等挑战。评估客户端可靠性对于公平分配激励和确保每个客户端数据对全局模型的有效贡献至关重要。

Method: MURIM是一种多维度声誉激励机制，它综合考虑客户端可靠性、隐私、资源容量和公平性。它通过一个可靠性验证模块，根据客户端的贡献、延迟和声誉来分配激励，以防止恶意或不可靠的客户端获得不应得的奖励。

Result: 在MNIST、FMNIST和ADULT Income数据集上的实验表明，MURIM在公平性指标上最高提升18%，将隐私攻击成功率降低5-9%，并将对投毒和噪声梯度攻击的鲁棒性最高提升85%，优于现有基线。

Conclusion: MURIM能有效缓解对抗性威胁，促进公平和真实的参与，并在异构和动态的联邦学习环境中保持模型稳定收敛。

Abstract: Federated Learning (FL) has emerged as a leading privacy-preserving machine learning paradigm, enabling participants to share model updates instead of raw data. However, FL continues to face key challenges, including weak client incentives, privacy risks, and resource constraints. Assessing client reliability is essential for fair incentive allocation and ensuring that each client's data contributes meaningfully to the global model. To this end, we propose MURIM, a MUlti-dimensional Reputation-based Incentive Mechanism that jointly considers client reliability, privacy, resource capacity, and fairness while preventing malicious or unreliable clients from earning undeserved rewards. MURIM allocates incentives based on client contribution, latency, and reputation, supported by a reliability verification module. Extensive experiments on MNIST, FMNIST, and ADULT Income datasets demonstrate that MURIM achieves up to 18% improvement in fairness metrics, reduces privacy attack success rates by 5-9%, and improves robustness against poisoning and noisy-gradient attacks by up to 85% compared to state-of-the-art baselines. Overall, MURIM effectively mitigates adversarial threats, promotes fair and truthful participation, and preserves stable model convergence across heterogeneous and dynamic federated settings.

</details>


### [14] [Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms](https://arxiv.org/abs/2512.13978)
*Yang Cao,Yubin Chen,Xuyang Guo,Zhao Song,Song Yue,Jiahao Zhang,Jiale Zhao*

Main category: cs.AI

TL;DR: 本文通过对四款前沿LLM在经典随机算法教材上的评估，发现顶尖模型在生成LaTeX数学证明方面达到约66%的准确率，展现出研究生级别教学辅助的潜力，但模型间可靠性差异显著。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自动化数学推理和科学发现方面取得了显著进展，但仍缺乏对其在经典研究生级别数学理论上基线推理能力的严格评估。

Method: 研究团队构建了一个基准测试，使用Motwani和Raghavan的《随机算法》教材，要求GPT-5-Thinking、Gemini-3-Pro、Claude-Sonnet-4.5-Thinking和Grok-4这四款前沿模型为一系列引理和习题生成正式的LaTeX证明。同时，对生成的证明进行了定性分析，比较了简洁性、幻觉率和逻辑结构。

Result: 顶尖模型（Gemini和Claude）取得了约66%的高准确率，显示出对概率方法和形式逻辑的扎实掌握。其他模型的表现则显著落后，一致性约为40%。生成的证明在简洁性、幻觉率和逻辑结构上存在差异。

Conclusion: 前沿模型已达到足以提供研究生级别教学辅助和形式化的熟练程度门槛，但在严格的数学推导方面，它们的可靠性存在显著差异。

Abstract: The rapid advancement of large language models (LLMs) has led to significant breakthroughs in automated mathematical reasoning and scientific discovery. Georgiev, G${ó}$mez-Serrano, Tao, and Wagner [GGSTW+25] demonstrate that AI systems can explore new constructions and improve existing bounds, illustrating the growing potential of LLMs to accelerate mathematical discovery. Similarly, Bubeck et al. [BCE+25] show that GPT-5 can meaningfully contribute to scientific workflows, from proposing hypotheses to generating proofs and analyses. Despite these advances, a rigorous evaluation of these models on canonical, graduate-level mathematical theory remains necessary to understand their baseline reasoning capabilities. In this paper, we present a comprehensive benchmark of four frontier models: GPT-5-Thinking, Gemini-3-Pro, Claude-Sonnet-4.5-Thinking, and Grok-4 against the classic curriculum of Randomized Algorithms by Motwani and Raghavan [MR95].
  We tasked each model with generating formal LaTeX proofs for a series of lemmas and exercises spanning the textbook. We find that while the top-tier models (Gemini, and Claude) achieve a high accuracy rate (approx. 66%), demonstrating a robust grasp of probabilistic method and formal logic, other models lag significantly in consistency (approx. 40%). We provide a qualitative analysis of the generated proofs, highlighting differences in conciseness, hallucination rates, and logical structure. Our results suggest that while frontier models have reached a threshold of proficiency suitable for graduate-level pedagogical assistance and formalization, significant variance exists in their reliability for rigorous mathematical derivation. The code and the full set of LLM-generated responses are open-sourced and publicly available at https://github.com/magiclinux/math_benchmark_probability.

</details>


### [15] [ReflCtrl: Controlling LLM Reflection via Representation Engineering](https://arxiv.org/abs/2512.13979)
*Ge Yan,Chung-En Sun,Tsui-Wei,Weng*

Main category: cs.AI

TL;DR: 本文通过表征工程研究大型语言模型（LLM）的自反思行为，提出了一种名为ReflCtrl的逐步引导方法来控制反思频率，发现许多反思是冗余的，并能显著节省推理成本，同时保持性能，且反思行为与模型的不确定性高度相关。


<details>
  <summary>Details</summary>
Motivation: LLM的思维链（CoT）推理和自反思能力显著提升了其在多任务上的表现，但自反思也增加了推理成本。研究旨在优化自反思过程，在保持性能的同时降低成本。

Method: 研究方法包括将模型的推理过程分段，识别出对应的反思步骤，并在潜在空间中提取一个控制反思行为的“反思方向”。基于此方向，提出了一种名为ReflCtrl的逐步引导方法来控制反思的频率。

Result: 实验结果表明，在许多情况下，特别是对于更强大的模型，自反思是冗余的（在实验中，可在保持性能的同时节省高达33.6%的推理tokens）。此外，模型的反思行为与内部不确定性信号高度相关，这暗示自反思可能由模型的不确定性控制。

Conclusion: 自反思在LLM中往往是冗余的，尤其是对于能力更强的模型。通过表征工程和逐步引导方法，可以有效控制反思频率，从而在不牺牲性能的前提下显著降低推理成本。研究还揭示了自反思与模型内部不确定性之间的紧密联系。

Abstract: Large language models (LLMs) with Chain-of-Thought (CoT) reasoning have achieved strong performance across diverse tasks, including mathematics, coding, and general reasoning. A distinctive ability of these reasoning models is self-reflection: the ability to review and revise previous reasoning steps. While self-reflection enhances reasoning performance, it also increases inference cost. In this work, we study self-reflection through the lens of representation engineering. We segment the model's reasoning into steps, identify the steps corresponding to reflection, and extract a reflection direction in the latent space that governs this behavior. Using this direction, we propose a stepwise steering method that can control reflection frequency. We call our framework ReflCtrl. Our experiments show that (1) in many cases reflections are redundant, especially in stronger models (in our experiments, we can save up to 33.6 percent of reasoning tokens while preserving performance), and (2) the model's reflection behavior is highly correlated with an internal uncertainty signal, implying self-reflection may be controlled by the model's uncertainty.

</details>


### [16] [MobileWorldBench: Towards Semantic World Modeling For Mobile Agents](https://arxiv.org/abs/2512.14014)
*Shufan Li,Konstantinos Kallidromitis,Akash Gokul,Yusuke Kato,Kazuki Kozuka,Aditya Grover*

Main category: cs.AI

TL;DR: 本文提出了一种针对GUI代理的语义世界模型，通过自然语言描述状态转换，而非像素预测。为此，作者发布了MobileWorldBench基准和MobileWorld大型数据集，并提出了一种将视觉语言模型（VLM）世界模型整合到移动代理规划中的新框架，显著提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 以往的像素空间世界模型在GUI环境中存在局限性，因为预测未来状态中复杂的视觉元素往往很困难。研究旨在探索一种替代方案，即用自然语言描述GUI代理的状态转换。

Method: 1. 引入MobileWorldBench，一个评估视觉语言模型（VLM）作为移动GUI代理世界模型能力的基准。2. 发布MobileWorld，一个包含140万样本的大规模数据集，用于提升VLM的世界建模能力。3. 提出一个新颖的框架，将VLM世界模型整合到移动代理的规划中。

Result: 通过将语义世界模型（VLM）整合到移动代理的规划框架中，证明了语义世界模型可以直接提升移动代理的任务成功率。

Conclusion: 语义世界模型，通过自然语言描述状态转换，为GUI代理提供了一种有效的世界建模方法。所提出的基准、数据集和集成框架共同证明了这种方法能够显著改善移动代理的性能。

Abstract: World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld

</details>


### [17] [Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation](https://arxiv.org/abs/2512.14048)
*Shen Li,Li Huang,Shaoxiong Zhan,Weifeng Sun,Tao Yin,Zhongxin Liu,Meng Yan*

Main category: cs.AI

TL;DR: RoutingGen是一个难度感知的路由框架，它根据代码生成任务的复杂性动态调整提示策略，对于简单任务使用少样本提示，对于复杂任务则引入意图思维链（ICoT）来指导模型捕捉算法逻辑和效率，从而在提高性能的同时显著降低了token使用量。


<details>
  <summary>Details</summary>
Motivation: 现有思维链（CoT）提示方法在代码生成中存在两个主要限制：1) 它们统一的应用导致在简单任务上过度思考；2) 它们缺乏代码生成中的意图抽象，如明确建模核心算法设计和效率，导致模型关注表面结构而忽视全局问题目标。

Method: 受认知经济原则启发，我们提出了RoutingGen，一个难度感知的路由框架，它动态地调整代码生成的提示策略。对于简单任务，它采用少样本提示；对于更复杂的任务，它调用结构化推理策略，即意图思维链（ICoT），旨在引导模型捕捉任务意图，如核心算法逻辑及其时间复杂度。

Result: RoutingGen在三个模型和六个标准代码生成基准测试中，在大多数设置下实现了最先进的性能，同时平均减少了46.37%的总token使用量。此外，ICoT在具有挑战性的基准测试中优于六个现有提示基线。

Conclusion: RoutingGen通过动态适应提示策略，有效解决了现有CoT方法的局限性，在代码生成任务中实现了卓越的性能和效率提升。特别地，其引入的ICoT策略在复杂任务中表现出色，证明了引导模型关注任务意图的重要性。

Abstract: Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.

</details>


### [18] [Evaluating Small Language Models for Agentic On-Farm Decision Support Systems](https://arxiv.org/abs/2512.14043)
*Enhong Liu,Haiyu Yang,Miel Hostens*

Main category: cs.AI

TL;DR: 本文评估了20个开源小型语言模型（SLM）在农场计算限制下作为奶牛养殖决策支持工具的可行性，发现Qwen-4B表现最佳，但仍需微调。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）因其高计算需求而难以在奶牛养殖场本地部署，限制了农民的知识获取和决策支持。因此，需要轻量级、可在农场硬件上本地运行的替代方案。

Method: 研究基准测试了HuggingFace上20个开源SLM，并开发了一个包含文献搜索、网络搜索、SQL数据库交互、NoSQL数据库交互和图表生成五个任务特定代理的智能AI系统。评估分两阶段进行：第一阶段使用5个问题筛选出能遵循基本指令并可靠运行的模型；第二阶段使用30个问题（每类任务5个，另加完整性和不当行为类）对通过筛选的模型进行详细评估。

Result: Qwen-4B在大多数任务类别中表现出色，尽管在通过PySpark进行NoSQL数据库交互时显示出不稳定的效果。这是首次明确评估SLM作为奶牛养殖决策引擎的可行性，重点关注隐私和计算效率。

Conclusion: 研究结果突出了SLM辅助工具在奶牛养殖中实际部署的潜力，但仍存在挑战，且需要进一步微调以提高SLM在奶牛养殖特定问题上的性能。

Abstract: Large Language Models (LLM) hold potential to support dairy scholars and farmers by supporting decision-making and broadening access to knowledge for stakeholders with limited technical expertise. However, the substantial computational demand restricts access to LLM almost exclusively through cloud-based service, which makes LLM-based decision support tools impractical for dairy farming. To address this gap, lightweight alternatives capable of running locally on farm hardware are required. In this work, we benchmarked 20 open-source Small Language Models (SLM) available on HuggingFace under farm-realistic computing constraints. Building on our prior work, we developed an agentic AI system that integrates five task-specific agents: literature search, web search, SQL database interaction, NoSQL database interaction, and graph generation following predictive models. Evaluation was conducted in two phases. In the first phase, five test questions were used for the initial screening to identify models capable of following basic dairy-related instructions and performing reliably in a compute-constrained environment. Models that passed this preliminary stage were then evaluated using 30 questions (five per task category mentioned above, plus one category addressing integrity and misconduct) in phase two. In results, Qwen-4B achieved superior performance across most of task categories, although showed unstable effectiveness in NoSQL database interactions through PySpark. To our knowledge, this is the first work explicitly evaluating the feasibility of SLM as engines for dairy farming decision-making, with central emphases on privacy and computational efficiency. While results highlight the promise of SLM-assisted tools for practical deployment in dairy farming, challenges remain, and fine-tuning is still needed to refine SLM performance in dairy-specific questions.

</details>


### [19] [Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training](https://arxiv.org/abs/2512.13996)
*Can Jin,Hongwu Peng,Mingcan Xiang,Qixin Zhang,Xiangchi Yuan,Amit Hasan,Ohiremen Dibua,Yifan Gong,Yan Kang,Dimitris N. Metaxas*

Main category: cs.AI

TL;DR: 本文提出DTop-p MoE，一种稀疏度可控的动态Top-p路由机制，通过PI控制器动态调整概率阈值以匹配目标稀疏度，并引入动态路由归一化，在LLM和扩散Transformer上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标准Top-k路由强制统一稀疏模式，忽略了token难度差异。Top-p路由虽灵活，但现有固定全局概率阈值导致计算成本不可控且对超参数敏感。

Method: 提出DTop-p MoE，其核心是利用比例积分（PI）控制器动态调整概率阈值，使激活专家稀疏度与目标对齐。此外，引入动态路由归一化机制，使不同层能在共享全局阈值的同时学习独特的专家选择模式。

Result: DTop-p在大型语言模型和扩散Transformer上持续优于Top-k和固定阈值Top-p基线。它能精确控制激活专家数量，并自适应地在不同token和层间分配资源。DTop-p在专家粒度、专家容量、模型大小和数据集大小方面均展现出强大的扩展性。

Conclusion: DTop-p提供了一个鲁棒的框架，用于大规模MoE预训练，通过稀疏度可控的动态Top-p路由，实现自适应资源分配和强大的扩展特性。

Abstract: Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flexible alternative, existing implementations typically rely on a fixed global probability threshold, which results in uncontrolled computational costs and sensitivity to hyperparameter selection. In this paper, we propose DTop-p MoE, a sparsity-controllable dynamic Top-p routing mechanism. To resolve the challenge of optimizing a non-differentiable threshold, we utilize a Proportional-Integral (PI) Controller that dynamically adjusts the probability threshold to align the running activated-expert sparsity with a specified target. Furthermore, we introduce a dynamic routing normalization mechanism that adapts layer-wise routing logits, allowing different layers to learn distinct expert-selection patterns while utilizing a global probability threshold. Extensive experiments on Large Language Models and Diffusion Transformers demonstrate that DTop-p consistently outperforms both Top-k and fixed-threshold Top-p baselines. Our analysis confirms that DTop-p maintains precise control over the number of activated experts while adaptively allocating resources across different tokens and layers. Furthermore, DTop-p exhibits strong scaling properties with respect to expert granularity, expert capacity, model size, and dataset size, offering a robust framework for large-scale MoE pre-training.

</details>


### [20] [OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value](https://arxiv.org/abs/2512.14051)
*Mengzhang Cai,Xin Gao,Yu Li,Honglin Lin,Zheng Liu,Zhuoshi Pan,Qizhi Pei,Xiaoran Shang,Mengyuan Sun,Zinan Tang,Xiaoyang Wang,Zhanping Zhong,Yun Zhu,Dahua Lin,Conghui He,Lijun Wu*

Main category: cs.AI

TL;DR: 本文介绍了OpenDataArena (ODA)，一个开放平台，用于基准测试大型语言模型(LLMs)后训练数据的内在价值，旨在将数据策展从试错法转变为数据中心AI的科学方法。


<details>
  <summary>Details</summary>
Motivation: LLMs的快速发展依赖于高质量和多样化的后训练数据集，但这些数据通常是“黑箱”，缺乏透明的组成、明确的来源和系统的评估。这种不透明性阻碍了可复现性，并模糊了数据特性与模型行为之间的因果联系。

Method: 研究人员推出了OpenDataArena (ODA)平台，它包含四个核心支柱：(i) 统一的训练-评估管道，确保跨模型和领域的公平比较；(ii) 多维评分框架，从数十个维度分析数据质量；(iii) 交互式数据谱系探索器，可视化数据集的起源和组成；(iv) 全开源的训练、评估和评分工具包。通过在ODA上进行大量实验，涵盖120多个数据集、22个基准测试、600多次训练运行和4000万个数据点来验证其有效性。

Result: 实验揭示了非平凡的洞察，包括数据复杂性与任务性能之间固有的权衡，通过谱系追踪识别了流行基准测试中的冗余，并绘制了数据集之间的谱系关系。所有结果、工具和配置均已开源发布。

Conclusion: ODA旨在将数据策展从试错法转变为数据中心AI的原则性科学，为数据混合规律和基础模型的战略组成提供了严谨研究的途径，而不仅仅是扩展排行榜。

Abstract: The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.

</details>


### [21] [RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees](https://arxiv.org/abs/2512.14069)
*Junjie Ma,Jinlong Li*

Main category: cs.AI

TL;DR: RADAR提出了一种基于强化学习的动态草稿树推测采样方法，通过实时决策草稿模型的调用次数，有效加速了大型语言模型的推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的推理成本高昂且速度慢。现有的推测采样方法中，草稿模型调用次数是一个预设超参数，缺乏灵活性，导致冗余计算。

Method: RADAR将草稿树生成过程建模为马尔可夫决策过程（MDP），并采用离线强化学习训练一个预测模型。该模型能够实时决定草稿模型的调用次数，从而减少冗余计算。

Result: RADAR在三种LLM和四项任务上的评估显示，相对于自回归解码基线，实现了3.17倍至4.82倍的推理加速。

Conclusion: RADAR通过基于强化学习的动态草稿树方法，有效解决了推测采样中草稿模型调用次数固定带来的低效问题，显著提升了LLM的推理速度。

Abstract: Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available at https://github.com/minaduki-sora/RADAR.

</details>


### [22] [HydroGEM: A Self Supervised Zero Shot Hybrid TCN Transformer Foundation Model for Continental Scale Streamflow Quality Control](https://arxiv.org/abs/2512.14106)
*Ijaz Ul Haq,Byung Suk Lee,Julia N. Perdrial,David Baude*

Main category: cs.AI

TL;DR: 本文提出了HydroGEM，一个用于大陆尺度水流质量控制的基础模型。它通过两阶段训练和混合TCN-Transformer架构，在异常检测和重建方面显著优于现有方法，并展现了跨国泛化能力，旨在支持人工审查的工作流程。


<details>
  <summary>Details</summary>
Motivation: 实时水流监测网络每年产生数百万观测数据，但维护数千个远程传感器的数据质量仍然劳动密集，现有方法效率不高。

Method: 引入了HydroGEM，一个水文可泛化编码器监控模型。采用两阶段训练：首先对来自3,724个USGS站点的603万个序列进行自监督预训练，学习水文表示；然后使用合成异常进行微调，以实现检测和重建。模型采用混合TCN-Transformer架构（14.2M参数），捕捉局部时间模式和长程依赖，并通过分层归一化处理六个数量级的水流量差异。

Result: 在包含799个站点和18种专家验证异常类型的保留合成测试中，HydroGEM的检测F1得分为0.792，重建误差减少了68.7%，比现有方法提高了36.3%。对100个加拿大环境与气候变化站点的零样本迁移测试F1得分为0.586，超过了所有基线，证明了跨国泛化能力。模型在不同修正幅度下保持一致的检测性能，并与操作季节模式保持一致。

Conclusion: HydroGEM是一个强大的大陆尺度水流质量控制基础模型，显著提升了数据质量控制的效率和准确性，并具有出色的泛化能力。它被设计用于“人在环中”的工作流程，提供质量控制建议供专家审查，而非自主修正。

Abstract: Real-time streamflow monitoring networks generate millions of observations annually, yet maintaining data quality across thousands of remote sensors remains labor-intensive. We introduce HydroGEM (Hydrological Generalizable Encoder for Monitoring), a foundation model for continental-scale streamflow quality control. HydroGEM uses two-stage training: self-supervised pretraining on 6.03 million sequences from 3,724 USGS stations learns hydrological representations, followed by fine-tuning with synthetic anomalies for detection and reconstruction. A hybrid TCN-Transformer architecture (14.2M parameters) captures local temporal patterns and long-range dependencies, while hierarchical normalization handles six orders of magnitude in discharge. On held-out synthetic tests comprising 799 stations with 18 expert-validated anomaly types, HydroGEM achieves F1 = 0.792 for detection and 68.7% reconstruction-error reduction, a 36.3% improvement over existing methods. Zero-shot transfer to 100 Environment and Climate Change Canada stations yields F1 = 0.586, exceeding all baselines and demonstrating cross-national generalization. The model maintains consistent detection across correction magnitudes and aligns with operational seasonal patterns. HydroGEM is designed for human-in-the-loop workflows - outputs are quality control suggestions requiring expert review, not autonomous corrections.

</details>


### [23] [Grammar Search for Multi-Agent Systems](https://arxiv.org/abs/2512.14079)
*Mayank Singh,Vikas Yadav,Shiva Krishna Reddy Malay,Shravan Nayak,Sai Rajeswar,Sathwik Tejaswi Madhusudhan,Eduardo Blanco*

Main category: cs.AI

TL;DR: 本文提出了一种结构化、基于组件的多智能体系统搜索框架，该框架在性能上超越了现有基于大型语言模型（LLM）的自由形式搜索方法，且更具成本效益，并能生成模块化、可解释的系统。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统的自动搜索是智能体AI研究的关键焦点。先前的研究主要依赖于基于LLM的代码空间自由形式搜索，但可能存在效率和解释性方面的局限。

Method: 本文提出了一种结构化的框架，通过一组固定的、简单可组合的组件来探索代码空间，与LLM在候选生成阶段的生成灵活性不同。

Result: 尽管在生成灵活性上不如LLM，但该方法在数学和问答两个领域的五个基准测试中有四个超越了现有方法。此外，它还提供了更经济高效的搜索过程，并生成了逻辑更简单、模块化且可解释的多智能体系统。

Conclusion: 所提出的结构化、基于组件的框架在多智能体系统搜索方面优于基于LLM的自由形式搜索方法，具有更好的性能、成本效益和系统可解释性。

Abstract: Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple, composable components. We show that, despite lacking the generative flexibility of LLMs during the candidate generation stage, our method outperforms prior approaches on four out of five benchmarks across two domains: mathematics and question answering. Furthermore, our method offers additional advantages, including a more cost-efficient search process and the generation of modular, interpretable multi-agent systems with simpler logic.

</details>


### [24] [Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis](https://arxiv.org/abs/2512.14157)
*Yankai Jiang,Yujie Zhang,Peng Zhang,Yichen Li,Jintai Chen,Xiaoming Shi,Shihui Zhen*

Main category: cs.AI

TL;DR: 本文提出了Ophiuchus，一个工具增强的多模态大语言模型（MLLM）框架，通过动态聚焦细粒度视觉区域并无缝整合工具输出，显著提升了医学诊断和推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于推理的医学MLLM在生成文本推理链方面取得了进展，但在需要动态、迭代地聚焦细粒度视觉区域以实现精确接地和诊断的复杂任务中表现不佳。

Method: Ophiuchus是一个多功能、工具增强的框架，它使MLLM能够决定何时需要额外的视觉证据、在医学图像中何处进行探测和定位，并将相关的子图像内容无缝地编织到交错的多模态思维链中。它将模型的固有接地和感知能力与外部工具相结合，并通过三阶段训练策略进行优化：冷启动训练（用于工具选择和区域检查）、自反思微调（增强反思性推理）和智能体工具强化学习（直接优化任务特定奖励）。

Result: 广泛的实验表明，Ophiuchus在包括VQA、检测和基于推理的分割在内的各种医学基准测试中，始终优于闭源和开源的现有最先进方法。

Conclusion: Ophiuchus为通过工具集成推理实现真正能够“用图像思考”的医学AI智能体指明了方向。

Abstract: Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely "think with images" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.

</details>


### [25] [Optimizing Multi-Tier Supply Chain Ordering with a Hybrid Liquid Neural Network and Extreme Gradient Boosting Model](https://arxiv.org/abs/2512.14112)
*Chunan Tong*

Main category: cs.AI

TL;DR: 本研究提出一种混合LNN+XGBoost模型，旨在通过结合LNN的动态特征提取和XGBoost的全局优化能力，解决供应链管理中需求波动和牛鞭效应等挑战，以提高效率和盈利能力。


<details>
  <summary>Details</summary>
Motivation: 供应链管理面临需求波动和牛鞭效应等重大挑战。传统方法和现有大型语言模型在处理供应链的复杂连续时间序列数据时表现不佳。虽然LSTM和XGBoost等机器学习方法提供解决方案，但常受限于计算效率。液态神经网络（LNN）在机器人领域展现出适应性和效率，但在供应链管理中尚未被充分利用，这促使研究者寻求一种更高效、适应性更强的智能供应链管理方法。

Method: 本研究提出一种混合LNN+XGBoost模型，应用于多层级供应链。该模型结合了液态神经网络（LNN）的动态特征提取能力和XGBoost的全局优化能力，以期处理复杂的连续时间序列数据。

Result: 该模型旨在最大限度地减少牛鞭效应并提高供应链的盈利能力。它致力于解决智能供应链管理中对效率和适应性的需求。

Conclusion: 本研究通过提出创新的混合LNN+XGBoost方法，填补了智能供应链管理领域的关键空白，为解决供应链的复杂挑战提供了一种高效且适应性强的解决方案。

Abstract: Supply chain management (SCM) faces significant challenges like demand fluctuations and the bullwhip effect. Traditional methods and even state-of-the-art LLMs struggle with benchmarks like the Vending Machine Test, failing to handle SCM's complex continuous time-series data. While ML approaches like LSTM and XGBoost offer solutions, they are often limited by computational inefficiency. Liquid Neural Networks (LNN), known for their adaptability and efficiency in robotics, remain untapped in SCM. This study proposes a hybrid LNN+XGBoost model for multi-tier supply chains. By combining LNN's dynamic feature extraction with XGBoost's global optimization, the model aims to minimize the bullwhip effect and increase profitability. This innovative approach addresses the need for efficiency and adaptability, filling a critical gap in intelligent SCM.

</details>


### [26] [Gödel's Poetry](https://arxiv.org/abs/2512.14252)
*Kelly J. Davis*

Main category: cs.AI

TL;DR: 本文提出了一种结合专用语言模型和递归分解的计算机自动定理证明新方法，通过多智能体架构协调，显著提高了在miniF2F上的证明通过率。


<details>
  <summary>Details</summary>
Motivation: 自动化定理证明长期以来被视为人工智能领域的挑战。

Method: 该方法采用：1) 针对Lean4证明生成的专用语言模型；2) 将复杂定理递归分解为更简单的命题；3) 一个多智能体架构，协调自动形式化、证明生成、定理分解以及这些命题的递归证明（和/或分解）。关键技术贡献在于扩展了Kimina Lean Server，增加了抽象语法树（AST）解析能力，以促进自动化、递归的证明分解。

Result: 在miniF2F数据集上，不使用分解时达到90.4%的通过率。使用分解后，通过率显著提高。该系统已作为`goedels-poetry`在PyPI上发布，并提供了开源实现，便于适应其他语言模型和扩展自定义功能。

Conclusion: 结合专用语言模型、递归分解和多智能体协调的新方法，显著提升了计算机自动定理证明的能力，尤其对复杂定理证明效果显著，并已开源供社区使用和进一步开发。

Abstract: Formal, automated theorem proving has long been viewed as a challenge to artificial intelligence. We introduce here a new approach to computer theorem proving, one that employs specialized language models for Lean4 proof generation combined with recursive decomposition of difficult theorems into simpler entailing propositions. These models are coordinated through a multi-agent architecture that orchestrates autoformalization (if required), proof generation, decomposition of difficult theorems into simpler entailing propositions, and recursive proof (and/or decomposition) of these propositions. Without decomposition, we achieve a 90.4% pass rate on miniF2F. With decomposition, this is significantly improved. A key technical contribution lies in our extension of the Kimina Lean Server with abstract syntax tree (AST) parsing capabilities to facilitate automated, recursive proof decomposition. The system is made available on PyPI as goedels-poetry (at https://pypi.org/project/goedels-poetry ), and the open-source implementation KellyJDavis/goedels-poetry (at https://github.com/KellyJDavis/goedels-poetry ) facilitates both adaptation to alternative language models and extension with custom functionality.

</details>


### [27] [Georeferencing complex relative locality descriptions with large language models](https://arxiv.org/abs/2512.14228)
*Aneesha Fernando,Surangika Ranathunga,Kristin Stock,Raj Prasanna,Christopher B. Jones*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLMs）自动地理参考复杂地点描述的潜力，特别是在生物多样性收集领域，通过提示工程和QLoRA微调，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 传统的地理参考方法（基于地名录或语言模型）难以处理包含空间关系和相对位置的复杂地点描述，这在生物标本采集记录中很常见，导致地理编码不准确。准确的地理参考对生物多样性研究至关重要，但过程劳动密集，急需自动化解决方案。

Method: 研究首先识别了有效的提示模式，然后使用量化低秩适应（QLoRA）技术，在来自多个区域和语言的生物多样性数据集上对大型语言模型进行了微调。

Result: 该方法在固定训练数据量下，平均65%的记录在10公里半径内，优于现有基线。最佳结果（纽约州数据集）达到85%在10公里内，67%在1公里内。所选的LLM对冗长、复杂的描述表现良好。

Conclusion: 大型语言模型在自动地理参考复杂地点描述方面具有巨大潜力，尤其适用于处理生物多样性收集领域中错综复杂的地点描述。

Abstract: Georeferencing text documents has typically relied on either gazetteer-based methods to assign geographic coordinates to place names, or on language modelling approaches that associate textual terms with geographic locations. However, many location descriptions specify positions relatively with spatial relationships, making geocoding based solely on place names or geo-indicative words inaccurate. This issue frequently arises in biological specimen collection records, where locations are often described through narratives rather than coordinates if they pre-date GPS. Accurate georeferencing is vital for biodiversity studies, yet the process remains labour-intensive, leading to a demand for automated georeferencing solutions. This paper explores the potential of Large Language Models (LLMs) to georeference complex locality descriptions automatically, focusing on the biodiversity collections domain. We first identified effective prompting patterns, then fine-tuned an LLM using Quantized Low-Rank Adaptation (QLoRA) on biodiversity datasets from multiple regions and languages. Our approach outperforms existing baselines with an average, across datasets, of 65% of records within a 10 km radius, for a fixed amount of training data. The best results (New York state) were 85% within 10km and 67% within 1km. The selected LLM performs well for lengthy, complex descriptions, highlighting its potential for georeferencing intricate locality descriptions.

</details>


### [28] [Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting](https://arxiv.org/abs/2512.14288)
*Georgios Bouchouras,Dimitrios Doumanas,Andreas Soularidis,Konstantinos Kotis,George A. Vouros*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLMs）在帕金森病（PD）监测和预警本体工程中的应用，比较了LLM独立生成和人机协作的效果，强调人机协作在复杂领域本体构建中的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在确定LLMs是否能独立创建全面的本体，如果不能，人机协作能否实现这一目标，并评估LLM在自动化本体开发中的有效性以及人机协作带来的提升。

Method: 采用了四种关键方法：单次（OS）提示技术、思维链（CoT）提示、X-HCOME（结合人类专业知识与LLM能力的混合方法）以及SimX-HCOME+（强调持续人工监督和迭代细化的混合方法）。

Result: OS和CoT提示证明LLMs能自主构建本体，但输出不全面，需大量人工完善。X-HCOME显著提升了本体的全面性，使其与专家构建的本体非常相似。SimX-HCOME+通过持续人工监督和迭代细化，创建了更全面、更准确的本体。

Conclusion: 研究强调了人机协作在推进本体工程方面的潜力，尤其是在帕金森病等复杂领域。结果为未来研究指明了方向，包括开发用于本体构建的专用GPT模型。

Abstract: This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.
  Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.
  X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.
  Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.
  Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.

</details>


### [29] [TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation](https://arxiv.org/abs/2512.14358)
*Qizhi Wang*

Main category: cs.AI

TL;DR: TiCard是一个低侵入、基于修正的框架，通过EXPLAIN-only特性和EXPLAIN ANALYZE标签来增强数据库的原生基数估计器。它显著提高了TiDB上的基数估计准确性，并提供了两种实现（GBR和TabPFN），专注于可部署性。


<details>
  <summary>Details</summary>
Motivation: 基数估计是查询优化中的关键瓶颈。传统估计器无法捕捉关联性，而学习型估计器通常需要工作负载特定的训练流程和侵入式集成，因此需要可部署的改进方案。

Method: TiCard是一个低侵入、基于修正的框架，它增强（而非取代）数据库的原生估计器。它使用EXPLAIN-only特性学习乘法残差修正，并仅使用EXPLAIN ANALYZE进行离线标签。研究了两种实际实现：梯度提升回归器（GBR）用于亚毫秒级推断，以及TabPFN（上下文表格基础模型）通过刷新小型参考集进行适应，无需梯度再训练。

Result: 在TiDB上使用TPCH和Join Order Benchmark进行测试，在低追踪设置下（总共263次执行，157次用于学习），TiCard显著提高了操作符级别的尾部准确性。P90 Q-error从原生估计器的312.85降至TiCard-GBR的13.69，P99 Q-error从37,974.37降至TiCard-TabPFN的3,416.50。仅针对连接的策略保持了接近完美的中间行为。

Conclusion: TiCard被定位为一个AI4DB构建模块，专注于可部署性：明确的范围、保守的集成策略以及从离线修正到优化器内部使用的集成路线图。

Abstract: Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper presents TiCard, a low intrusion, correction-based framework that augments (rather than replaces) a database's native estimator. TiCard learns multiplicative residual corrections using EXPLAIN-only features, and uses EXPLAIN ANALYZE only for offline labels. We study two practical instantiations: (i) a Gradient Boosting Regressor for sub-millisecond inference, and (ii) TabPFN, an in-context tabular foundation model that adapts by refreshing a small reference set without gradient retraining. On TiDB with TPCH and the Join Order Benchmark, in a low-trace setting (263 executions total; 157 used for learning), TiCard improves operator-level tail accuracy substantially: P90 Q-error drops from 312.85 (native) to 13.69 (TiCard-GBR), and P99 drops from 37,974.37 to 3,416.50 (TiCard-TabPFN), while a join-only policy preserves near-perfect median behavior. We position TiCard as an AI4DB building block focused on deployability: explicit scope, conservative integration policies, and an integration roadmap from offline correction to in-optimizer use.

</details>


### [30] [Context-Picker: Dynamic context selection using multi-stage reinforcement learning](https://arxiv.org/abs/2512.14465)
*Siyuan Zhu,Chengdong Xu,Kaiqiang Ke,Chao Yu*

Main category: cs.AI

TL;DR: Context-Picker是一个推理感知的框架，通过两阶段强化学习和离线证据蒸馏，解决了长文本问答中上下文选择的挑战，实现了最小充分证据集选择，显著提高了答案准确性并优化了上下文长度。


<details>
  <summary>Details</summary>
Motivation: 在长文本问答（LCQA）中，确定给定查询的最佳上下文量是一个重大挑战。上下文过少可能遗漏关键信息，过多则引入噪声并降低答案质量。传统的固定Top-K检索和单阶段重排方法难以选择正确的段落数量，尤其对于事实性问题。

Method: 本文提出了Context-Picker，一个推理感知的框架，将上下文选择视为一个决策过程，而非基于相似度的排序。它通过受人类启发、两阶段的强化学习进行优化：首先是“召回导向”阶段，优先覆盖推理链；其次是“精确导向”阶段，积极剪枝冗余以提炼紧凑的证据集。为解决奖励稀疏性，提出离线证据蒸馏流程，通过“留一法”（LOO）挖掘“最小充分集”，提供密集、与任务对齐的监督。

Result: 在五个长文本和多跳问答基准测试中，Context-Picker显著优于强大的RAG基线，在上下文长度相当或减少的情况下，实现了卓越的答案准确性。消融研究表明，粗粒度到细粒度的优化策略、冗余感知奖励塑形以及推理引导的格式都对性能提升做出了实质性贡献。

Conclusion: Context-Picker通过其创新的两阶段强化学习和离线证据蒸馏方法，有效解决了长文本问答中的最优上下文选择问题，成功地从相似度排序转向最小充分子集选择，显著提升了问答准确性并优化了上下文使用效率。

Abstract: In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines "minimal sufficient sets" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.

</details>


### [31] [Massive Editing for Large Language Models Based on Dynamic Weight Generation](https://arxiv.org/abs/2512.14395)
*Wentao Wan,Qiqing Lao,Zhiwei Xie,Hefeng Wu,Runnan Lin,Liang Lin,Keze Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于动态权重生成的大规模知识编辑方法（MeG），通过在LLM特定层添加动态权重神经元并使用扩散模型生成其权重，以低成本实现大规模知识编辑，并显著提升了可靠性、泛化性和局部性指标。


<details>
  <summary>Details</summary>
Motivation: 当前知识编辑（KE）领域面临的挑战是如何在大型语言模型（LLM）中进行大规模知识修改，同时确保编辑的可靠性、泛化性和局部性。

Method: MeG方法通过在LLM的特定层附加一个动态权重神经元，并利用扩散模型根据输入查询条件性地生成该神经元的权重。这种方法允许仅通过添加一个动态权重神经元就实现大规模知识编辑的目标。

Result: 实验结果表明，与现有知识编辑方法相比，MeG在可靠性、泛化性和局部性指标方面显著提升了大规模KE的性能，尤其是在局部性指标的绝对值上取得了显著的百分点增长。

Conclusion: MeG方法通过引入动态权重神经元和扩散模型，为大规模知识编辑提供了一种有效解决方案，并在关键指标上展现出显著优势。

Abstract: Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.

</details>


### [32] [PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals](https://arxiv.org/abs/2512.14417)
*Jia Hu,Junqi Li,Weimeng Lin,Peng Jia,Yuxiong Ji,Jintao Lai*

Main category: cs.AI

TL;DR: 本文提出PortAgent，一个由大型语言模型（LLM）驱动的车辆调度代理，旨在通过自动化VDS转移工作流程，解决现有车辆调度系统（VDS）在不同码头之间转移性差的问题。


<details>
  <summary>Details</summary>
Motivation: 自动化集装箱码头（ACTs）的车辆调度系统（VDS）因其对港口运营专家的过度依赖、对特定码头数据的高需求以及耗时的手动部署过程，导致在不同码头间的转移性低，阻碍了其广泛商业化。

Method: 本文提出了PortAgent，一个LLM驱动的车辆调度代理，它通过虚拟专家团队（VET）消除了对专家的依赖。VET包含知识检索器、建模器、编码器和调试器四位虚拟专家，通过少量示例学习（few-shot example learning）获取VDS领域知识。通过检索增强生成（RAG）机制检索这些示例，减少了对特定码头数据的需求。此外，专家之间建立了一个自动VDS设计工作流程，并引入了受LLM Reflexion框架启发的自校正循环，以避免手动干预。

Result: PortAgent具有三大特点：(1) 无需港口运营专家；(2) 数据需求低；(3) 部署速度快。这些特点通过虚拟专家团队、少量示例学习和RAG机制实现，成功自动化了VDS的转移工作流程。

Conclusion: 通过利用LLM，PortAgent提供了一个完全自动化的VDS转移解决方案，有效解决了现有VDS在可转移性方面的三大限制，为自动化集装箱码头VDS的广泛商业化铺平了道路。

Abstract: Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created

</details>


### [33] [Seismology modeling agent: A smart assistant for geophysical researchers](https://arxiv.org/abs/2512.14429)
*Yukun Ren,Siwei Yu,Kai Chen,Jianwei Ma*

Main category: cs.AI

TL;DR: 本文提出了一种由大型语言模型（LLM）驱动的智能交互式工作流，通过引入模型上下文协议（MCP）服务器套件，显著简化了主流开源地震波模拟软件SPECFEM的传统复杂操作，实现了意图驱动的对话式交互，降低了学习门槛。


<details>
  <summary>Details</summary>
Motivation: 传统的SPECFEM工作流学习曲线陡峭，高度依赖复杂的手动文件编辑和命令行操作，这促使研究者寻求一种更智能、用户友好的解决方案。

Method: 研究引入了首个针对SPECFEM（支持2D、3D笛卡尔和3D地球版本）的MCP服务器套件，将整个模拟过程分解为离散的、可由智能体执行的工具。该方法实现了从文件驱动到意图驱动的对话式交互范式转变，并支持全自动化执行和人机协作模式。

Result: 通过多个案例研究验证，该工作流在自主和交互模式下均无缝运行，生成了与标准基线一致的高保真结果。这是MCP技术首次应用于计算地震学。

Conclusion: 该研究显著降低了SPECFEM的使用门槛，增强了可重现性，并为计算地球物理学向AI辅助和自动化科学研究发展提供了有前景的途径。

Abstract: To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.

</details>


### [34] [Sparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification](https://arxiv.org/abs/2512.14491)
*Cheng-Han Lu,Pei-Hsuan Tsai*

Main category: cs.AI

TL;DR: SMMT是一种稀疏多模态Transformer架构，通过引入基于聚类的稀疏注意力机制和模态掩码，显著提高了计算效率和对不完整输入的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于Transformer的多模态智能系统因密集自注意力机制而面临高计算和能耗成本，限制了其在资源受限下的可扩展性。

Method: SMMT基于级联多模态Transformer框架，引入了基于聚类的稀疏注意力机制以实现接近线性的计算复杂度，并采用模态掩码来增强对不完整输入的鲁棒性。

Result: 在阿尔茨海默病分类任务（ADNI数据集）中，SMMT在保持竞争性预测性能的同时，显著减少了训练时间、内存使用和能耗，优于密集注意力基线模型。

Conclusion: SMMT作为一种资源感知型架构组件，在可扩展智能系统中展现出良好的适用性，能够有效解决多模态Transformer的效率和鲁棒性挑战。

Abstract: Transformer-based multi-modal intelligent systems often suffer from high computational and energy costs due to dense self-attention, limiting their scalability under resource constraints. This paper presents SMMT, a sparse multi-modal transformer architecture designed to improve efficiency and robustness. Building upon a cascaded multi-modal transformer framework, SMMT introduces cluster-based sparse attention to achieve near linear computational complexity and modality-wise masking to enhance robustness against incomplete inputs. The architecture is evaluated using Alzheimer's Disease classification on the ADNI dataset as a representative multi-modal case study. Experimental results show that SMMT maintains competitive predictive performance while significantly reducing training time, memory usage, and energy consumption compared to dense attention baselines, demonstrating its suitability as a resource-aware architectural component for scalable intelligent systems.

</details>


### [35] [Dynamic Learning Rate Scheduling based on Loss Changes Leads to Faster Convergence](https://arxiv.org/abs/2512.14527)
*Shreyas Subramanian,Bala Krishnamoorthy,Pranav Murthy*

Main category: cs.AI

TL;DR: 本文提出了一种名为GreedyLR的新型自适应学习率调度器，它根据当前损失动态调整学习率。实验结果表明，GreedyLR在NLP、CV和LLM任务上，在准确性、速度和收敛性方面均优于现有最先进的调度器，并提供了理论分析和收敛性证明。


<details>
  <summary>Details</summary>
Motivation: 尽管优化器取得了显著进展，但大多数研究工作仍使用余弦或指数衰减等常见且固定的学习率调度器。研究人员需要一种能根据当前训练状态自适应调整学习率的新型调度器。

Method: 本文提出GreedyLR，一种基于当前损失自适应调整学习率的调度器。通过在NLP、CV和LLM（高达7B参数，包括微调和预训练）任务上进行实验来验证其有效性。此外，还提供了GreedyLR算法的理论分析，包括收敛性证明以及最大化收敛速度的最优缩放因子F的推导，并通过实验展示了其在噪声环境下的鲁棒性。

Result: GreedyLR在准确性、速度和收敛性方面均优于几种最先进的调度器。该算法对现实中的噪声环境具有鲁棒性。

Conclusion: GreedyLR调度器易于实现，计算效率高，可以被认为是训练中的一个良好默认调度器，并在各种机器学习任务中展现出卓越的性能。

Abstract: Despite significant advances in optimizers for training, most research works use common scheduler choices like Cosine or exponential decay. In this paper, we study \emph{GreedyLR}, a novel scheduler that adaptively adjusts the learning rate during training based on the current loss. To validate the effectiveness of our proposed scheduler, we conduct experiments on several NLP, CV, and LLM tasks with up to $7B$ parameters, including both fine-tuning and pre-training experiments. The results show that our approach outperforms several state-of-the-art schedulers in terms of accuracy, speed, and convergence. We also provide a theoretical analysis of the GreedyLR algorithm, including a proof of convergence and derivation of the optimal scaling factor $F$ that maximizes the convergence rate, along with experiments to show robustness of the algorithm to realistic noisy landscapes. Our scheduler is easy to implement, computationally efficient, and could be considered a good default scheduler for training.

</details>


### [36] [Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling](https://arxiv.org/abs/2512.14474)
*Annu Rana,Gaurav Kumar*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在复杂多步规划任务中表现不佳。本文提出“模型优先推理”（MFR），让LLM先构建显式问题模型，再生成规划，显著减少了违规并提高了解决方案质量。


<details>
  <summary>Details</summary>
Motivation: LLMs在复杂多步规划任务中常出现约束违规和不一致的解决方案，因为现有策略（如Chain-of-Thought和ReAct）依赖隐式状态跟踪，缺乏显式问题表示。

Method: 受经典AI规划启发，提出“模型优先推理”（MFR），一个两阶段范式：第一阶段，LLM首先构建问题的显式模型，定义实体、状态变量、动作和约束；第二阶段，LLM生成解决方案规划。

Result: 在医疗调度、路线规划、资源分配、逻辑谜题和程序合成等多个规划领域，MFR相比Chain-of-Thought和ReAct，减少了约束违规并提高了解决方案质量。消融研究表明，显式建模阶段对这些改进至关重要。

Conclusion: 许多LLM规划失败源于表示缺陷而非推理限制，这强调了显式建模是构建稳健和可解释AI智能体的关键组成部分。

Abstract: Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.

</details>


### [37] [Universal Reasoning Model](https://arxiv.org/abs/2512.14693)
*Zitian Gao,Lynx Chen,Yihao Xiao,He Xing,Ran Tao,Haoming Luo,Joey Zhou,Bryan Dai*

Main category: cs.AI

TL;DR: 本文系统分析了通用Transformer (UT) 在复杂推理任务（如ARC-AGI）上的性能来源，发现其主要得益于循环归纳偏置和强大的非线性组件。在此基础上，提出通用推理模型 (URM)，通过短卷积和截断反向传播增强UT，在ARC-AGI上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 通用Transformer (UT) 已广泛应用于ARC-AGI和数独等复杂推理任务，但其性能提升的具体来源尚不明确。本研究旨在系统分析UT变体，并探索其性能提升的核心因素。

Method: 研究方法包括系统分析UT变体，以确定其性能来源。在此发现的启发下，提出了通用推理模型 (URM)，该模型通过增加短卷积和截断反向传播来增强UT。

Result: 研究表明，UT在ARC-AGI上的性能提升主要源于Transformer的循环归纳偏置和强大的非线性组件，而非精巧的架构设计。所提出的URM显著提升了推理性能，在ARC-AGI 1上达到了53.8% pass@1的最新水平，在ARC-AGI 2上达到了16.0% pass@1。

Conclusion: UT在复杂推理任务中的优越性主要归因于其固有的循环归纳偏置和强大的非线性能力。通过在UT中引入短卷积和截断反向传播，可以进一步显著提升推理性能，从而在ARC-AGI基准测试中达到新的最先进水平。

Abstract: Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [38] [Complex Mathematical Expression Recognition: Benchmark, Large-Scale Dataset and Strong Baseline](https://arxiv.org/abs/2512.13731)
*Weikang Bai,Yongkun Du,Yuchen Su,Yazhen Xie,Zhineng Chen*

Main category: cs.CV

TL;DR: 本文针对复杂数学表达式识别（MER）的挑战，引入了CMER-Bench基准、MER-17M和CMER-3M大规模数据集，并提出了新的表达式分词器、结构化数学语言表示以及专门模型CMERNet，显著提升了复杂表达式的识别性能。


<details>
  <summary>Details</summary>
Motivation: 尽管MER在识别简单表达式方面取得了进展，但对包含大量符号和多行的复杂数学表达式进行鲁棒识别仍然是一个巨大挑战。现有模型在处理复杂表达式时性能显著下降，主要原因在于现有公共训练数据集多为简单样本。

Method: 1. 引入CMER-Bench基准，将表达式分为易、中、难三个难度级别。2. 评估现有MER模型和多模态大语言模型（MLLMs）。3. 提出MER-17M和CMER-3M两个大规模数据集，重点关注复杂数学表达式。4. 引入新型表达式分词器和“结构化数学语言”（Structured Mathematical Language）表示，显式建模表达式的层次和空间结构。5. 基于上述，提出专门模型CMERNet，采用编解码器架构，并在CMER-3M上进行训练。

Result: 1. 现有方法在CMER-Bench上对简单和中等表达式表现良好，但对复杂表达式性能显著下降。2. CMERNet（仅1.25亿参数）在CMER-Bench上显著优于现有MER模型和MLLMs。

Conclusion: CMERNet通过利用大规模复杂表达式数据集、创新的表示方法和专门的模型架构，有效解决了复杂数学表达式识别的挑战，并在相关基准测试中取得了显著的性能提升。

Abstract: Mathematical Expression Recognition (MER) has made significant progress in recognizing simple expressions, but the robust recognition of complex mathematical expressions with many tokens and multiple lines remains a formidable challenge. In this paper, we first introduce CMER-Bench, a carefully constructed benchmark that categorizes expressions into three difficulty levels: easy, moderate, and complex. Leveraging CMER-Bench, we conduct a comprehensive evaluation of existing MER models and general-purpose multimodal large language models (MLLMs). The results reveal that while current methods perform well on easy and moderate expressions, their performance degrades significantly when handling complex mathematical expressions, mainly because existing public training datasets are primarily composed of simple samples. In response, we propose MER-17M and CMER-3M that are large-scale datasets emphasizing the recognition of complex mathematical expressions. The datasets provide rich and diverse samples to support the development of accurate and robust complex MER models. Furthermore, to address the challenges posed by the complicated spatial layout of complex expressions, we introduce a novel expression tokenizer, and a new representation called Structured Mathematical Language, which explicitly models the hierarchical and spatial structure of expressions beyond LaTeX format. Based on these, we propose a specialized model named CMERNet, built upon an encoder-decoder architecture and trained on CMER-3M. Experimental results show that CMERNet, with only 125 million parameters, significantly outperforms existing MER models and MLLMs on CMER-Bench.

</details>


### [39] [DL$^3$M: A Vision-to-Language Framework for Expert-Level Medical Reasoning through Deep Learning and Large Language Models](https://arxiv.org/abs/2512.13742)
*Md. Najib Hasan,Imran Ahmad,Sourav Basak Shuvo,Md. Mahadi Hasan Ankon,Sunanda Das,Nazmul Siddique,Hui Wang*

Main category: cs.CV

TL;DR: 本研究提出一个框架，将医学图像分类与结构化临床推理相结合，以解决图像分类器缺乏解释和大型语言模型（LLMs）推理不稳定的问题。通过评估32个LLMs，发现结合深度学习（DL）能改善解释质量，但LLMs在医疗决策中的稳定性仍不足。


<details>
  <summary>Details</summary>
Motivation: 医学图像分类器能有效检测疾病，但无法解释其决策。大型语言模型（LLMs）能生成临床文本，但在视觉推理方面表现不佳，且常产生不稳定或不正确的解释。这在模型所“见”与临床医生期望的推理之间造成了鸿沟。

Method: 我们引入了一个将图像分类与结构化临床推理相结合的框架。开发了一个新的混合模型MobileCoAtNet，用于内窥镜图像分类，并在八个胃部相关类别上实现了高准确率。MobileCoAtNet的输出随后被用于驱动多个LLMs进行推理。为了评估这些LLMs的推理能力，我们构建了两个经过专家验证的基准，涵盖病因、症状、治疗、生活方式和随访护理。最终，32个LLMs根据这些黄金标准进行了评估。

Result: 强大的图像分类能力能够提高LLMs解释的质量。然而，没有一个模型能达到人类水平的稳定性，即使在提示语（prompts）发生变化时，最好的LLMs也会改变其推理。我们的研究表明，将深度学习与LLMs结合可以产生有用的临床叙述。

Conclusion: 尽管结合深度学习与LLMs可以生成有用的临床叙述，但目前的LLMs在涉及高风险医疗决策时仍然不可靠。本研究提出的框架为理解LLMs的局限性以及构建更安全的推理系统提供了清晰的视角和途径。

Abstract: Medical image classifiers detect gastrointestinal diseases well, but they do not explain their decisions. Large language models can generate clinical text, yet they struggle with visual reasoning and often produce unstable or incorrect explanations. This leaves a gap between what a model sees and the type of reasoning a clinician expects. We introduce a framework that links image classification with structured clinical reasoning. A new hybrid model, MobileCoAtNet, is designed for endoscopic images and achieves high accuracy across eight stomach-related classes. Its outputs are then used to drive reasoning by several LLMs. To judge this reasoning, we build two expert-verified benchmarks covering causes, symptoms, treatment, lifestyle, and follow-up care. Thirty-two LLMs are evaluated against these gold standards. Strong classification improves the quality of their explanations, but none of the models reach human-level stability. Even the best LLMs change their reasoning when prompts vary. Our study shows that combining DL with LLMs can produce useful clinical narratives, but current LLMs remain unreliable for high-stakes medical decisions. The framework provides a clearer view of their limits and a path for building safer reasoning systems. The complete source code and datasets used in this study are available at https://github.com/souravbasakshuvo/DL3M.

</details>


### [40] [Why Text Prevails: Vision May Undermine Multimodal Medical Decision Making](https://arxiv.org/abs/2512.13747)
*Siyuan Dai,Lunxiao Li,Kun Zhao,Eardi Lila,Paul K. Crane,Heng Huang,Dongkuan Xu,Haoteng Tang,Liang Zhan*

Main category: cs.CV

TL;DR: 当前多模态大语言模型（MLLMs）在生物医学决策任务（MDM）中表现不佳，甚至不如纯文本推理，且多模态输入效果更差。研究通过AD分类和MIMIC-CXR数据集验证了这一点，并探索了上下文学习、视觉描述和视觉塔微调等策略，揭示了MLLMs缺乏扎实的视觉理解。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）和多模态大语言模型（MLLMs）在视觉-语言任务上展现出强大的零样本能力，但在生物医学领域，即使是最先进的MLLMs也难以胜任基本的医学决策任务（MDM）。本研究旨在探究这一局限性。

Method: 研究使用了两个具有挑战性的数据集进行调查：(1) 三阶段阿尔茨海默病（AD）分类（正常、轻度认知障碍、痴呆），其中类别差异视觉上很细微；(2) MIMIC-CXR胸部X光片分类，涉及14种非互斥疾病。研究通过实证比较了纯文本推理、纯视觉推理和视觉-文本结合设置下的性能。为缓解问题，探索了三种策略：(1) 基于理由标注范例的上下文学习；(2) 视觉描述生成后进行纯文本推理；(3) 使用分类监督对视觉模块进行少样本微调。

Result: 实证研究表明，在医学决策任务中，纯文本推理的表现始终优于纯视觉或视觉-文本结合的设置，多模态输入的结果甚至常不如纯文本。这些发现揭示了当前MLLMs缺乏扎实的视觉理解能力。

Conclusion: 目前的MLLMs缺乏扎实的视觉理解能力，这限制了它们在生物医学决策任务中的应用。研究中探索的策略为改善医疗领域的多模态决策提供了有前景的方向。

Abstract: With the rapid progress of large language models (LLMs), advanced multimodal large language models (MLLMs) have demonstrated impressive zero-shot capabilities on vision-language tasks. In the biomedical domain, however, even state-of-the-art MLLMs struggle with basic Medical Decision Making (MDM) tasks. We investigate this limitation using two challenging datasets: (1) three-stage Alzheimer's disease (AD) classification (normal, mild cognitive impairment, dementia), where category differences are visually subtle, and (2) MIMIC-CXR chest radiograph classification with 14 non-mutually exclusive conditions. Our empirical study shows that text-only reasoning consistently outperforms vision-only or vision-text settings, with multimodal inputs often performing worse than text alone. To mitigate this, we explore three strategies: (1) in-context learning with reason-annotated exemplars, (2) vision captioning followed by text-only inference, and (3) few-shot fine-tuning of the vision tower with classification supervision. These findings reveal that current MLLMs lack grounded visual understanding and point to promising directions for improving multimodal decision making in healthcare.

</details>


### [41] [Human-AI Collaboration Mechanism Study on AIGC Assisted Image Production for Special Coverage](https://arxiv.org/abs/2512.13739)
*Yajie Yang,Yuqing Zhao,Xiaochao Xi,Yinan Zhu*

Main category: cs.CV

TL;DR: 本文探讨新闻业中AIGC辅助图像生产的控制路径，通过实验提出了一种人机协作机制，以解决误报、真实性、语义保真度等问题，并推荐了特定的评估指标。


<details>
  <summary>Details</summary>
Motivation: 人工智能生成内容（AIGC）辅助图像生产在新闻业中引发了争议，主要问题包括误报、真实性、语义保真度和可解释性。大多数AIGC工具是“黑箱”，阻碍了内容准确性和语义对齐的双重需求，并带来了伦理、社会技术和信任困境。

Method: 本文通过中国媒体机构的两个项目进行了实验：(1) 实验1通过标准化提示在三个场景中测试跨平台适应性。(2) 实验2构建了一个人机协作的模块化流程，结合了高精度分割（SAM, GroundingDINO）、语义对齐（BrushNet）和风格调节（Style-LoRA, Prompt-to-Prompt），并通过基于CLIP的语义评分、NSFW/OCR/YOLO过滤和可验证的内容凭证确保编辑保真度。可追溯的部署保留了语义表示。最终提出了一种人机协作机制，并推荐评估角色身份稳定性（CIS）、文化表达准确性（CEA）和用户-公众适宜性（U-PA）。

Result: 实验1揭示了语义对齐、文化特异性和视觉真实性方面的差异，这些差异源于训练语料库偏差和平台级过滤。实验2构建的模块化流程通过多种技术和过滤机制确保了编辑保真度并保留了语义表示。本文提出了一种用于特殊报道中AIGC辅助图像生产的人工智能协作机制。

Conclusion: 本文提出了一种适用于新闻特殊报道中AIGC辅助图像生产的人工智能协作机制，并建议通过评估角色身份稳定性（CIS）、文化表达准确性（CEA）和用户-公众适宜性（U-PA）来解决内容准确性、语义对齐和信任问题。

Abstract: Artificial Intelligence Generated Content (AIGC) assisting image production triggers controversy in journalism while attracting attention from media agencies. Key issues involve misinformation, authenticity, semantic fidelity, and interpretability. Most AIGC tools are opaque "black boxes," hindering the dual demands of content accuracy and semantic alignment and creating ethical, sociotechnical, and trust dilemmas. This paper explores pathways for controllable image production in journalism's special coverage and conducts two experiments with projects from China's media agency: (1) Experiment 1 tests cross-platform adaptability via standardized prompts across three scenes, revealing disparities in semantic alignment, cultural specificity, and visual realism driven by training-corpus bias and platform-level filtering. (2) Experiment 2 builds a human-in-the-loop modular pipeline combining high-precision segmentation (SAM, GroundingDINO), semantic alignment (BrushNet), and style regulating (Style-LoRA, Prompt-to-Prompt), ensuring editorial fidelity through CLIP-based semantic scoring, NSFW/OCR/YOLO filtering, and verifiable content credentials. Traceable deployment preserves semantic representation. Consequently, we propose a human-AI collaboration mechanism for AIGC assisted image production in special coverage and recommend evaluating Character Identity Stability (CIS), Cultural Expression Accuracy (CEA), and User-Public Appropriateness (U-PA).

</details>


### [42] [STAR: STacked AutoRegressive Scheme for Unified Multimodal Learning](https://arxiv.org/abs/2512.13752)
*Jie Qin,Jiancheng Huang,Limeng Qiao,Lin Ma*

Main category: cs.CV

TL;DR: 本文提出STAR，一种堆叠自回归方案，通过将多模态学习分解为理解、生成和编辑阶段，并在冻结基础模型参数的同时渐进堆叠同构模块，有效提升多模态大模型的生成性能，同时保持理解能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型在通用人工智能中扮演关键角色，但由于优化冲突和性能权衡，实现多模态理解与生成的统一目标仍具挑战。研究旨在有效提升生成性能的同时，保留现有的理解能力。

Method: 引入STAR（STacked AutoRegressive）方案，将多模态学习分解为理解、生成和编辑多个阶段。通过冻结基础自回归（AR）模型的参数并渐进堆叠同构AR模块，避免了跨任务干扰并扩展了模型能力。同时，引入高容量VQ以增强图像表示的粒度，并采用隐式推理机制以提高复杂条件下的生成质量。

Result: STAR在GenEval上达到0.91，DPG-Bench上达到87.44，ImgEdit上达到4.34，均实现了最先进的性能。

Conclusion: 实验结果验证了STAR在统一多模态学习方面的有效性，成功提升了生成性能并保持了理解能力。

Abstract: Multimodal large language models (MLLMs) play a pivotal role in advancing the quest for general artificial intelligence. However, achieving unified target for multimodal understanding and generation remains challenging due to optimization conflicts and performance trade-offs. To effectively enhance generative performance while preserving existing comprehension capabilities, we introduce STAR: a STacked AutoRegressive scheme for task-progressive unified multimodal learning. This approach decomposes multimodal learning into multiple stages: understanding, generation, and editing. By freezing the parameters of the fundamental autoregressive (AR) model and progressively stacking isomorphic AR modules, it avoids cross-task interference while expanding the model's capabilities. Concurrently, we introduce a high-capacity VQ to enhance the granularity of image representations and employ an implicit reasoning mechanism to improve generation quality under complex conditions. Experiments demonstrate that STAR achieves state-of-the-art performance on GenEval (0.91), DPG-Bench (87.44), and ImgEdit (4.34), validating its efficacy for unified multimodal learning.

</details>


### [43] [ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM](https://arxiv.org/abs/2512.14032)
*Ignacio Alzugaray,Marwan Taher,Andrew J. Davison*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的神经RGB-D同步定位与建图（SLAM）系统，该系统首次利用场景坐标回归（SCR）作为核心隐式地图表示，实现了严格的实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有的神经隐式SLAM系统在实时性、效率和内存使用方面可能存在不足。SCR网络提供高效、低内存的3D地图表示，能够实现极快的重定位，并固有地保护隐私，使其特别适合神经隐式SLAM。

Method: 该系统采用了一种新颖的SCR架构，专门为实时SLAM设计，并详细阐述了将SCR集成到实时SLAM管道中的关键设计选择。它是一个简单而灵活的框架，无缝支持稀疏和密集特征，并在动态环境中可靠运行而无需特殊适应。

Result: 该系统首次实现了基于SCR表示的神经隐式RGB-D SLAM的严格实时性能。在已建立的合成和真实世界基准测试中，其性能与最先进的方法具有竞争力。

Conclusion: SCR作为神经隐式SLAM的核心地图表示是有效且可行的，它为实时RGB-D SLAM提供了高效、快速重定位和隐私保护的优势，并展现出与现有技术相当的性能。

Abstract: We present a novel neural RGB-D Simultaneous Localization And Mapping (SLAM) system that learns an implicit map of the scene in real time. For the first time, we explore the use of Scene Coordinate Regression (SCR) as the core implicit map representation in a neural SLAM pipeline, a paradigm that trains a lightweight network to directly map 2D image features to 3D global coordinates. SCR networks provide efficient, low-memory 3D map representations, enable extremely fast relocalization, and inherently preserve privacy, making them particularly suitable for neural implicit SLAM.
  Our system is the first one to achieve strict real-time in neural implicit RGB-D SLAM by relying on a SCR-based representation. We introduce a novel SCR architecture specifically tailored for this purpose and detail the critical design choices required to integrate SCR into a live SLAM pipeline. The resulting framework is simple yet flexible, seamlessly supporting both sparse and dense features, and operates reliably in dynamic environments without special adaptation. We evaluate our approach on established synthetic and real-world benchmarks, demonstrating competitive performance against the state of the art. Project Page: https://github.com/ialzugaray/ace-slam

</details>


### [44] [Time-aware UNet and super-resolution deep residual networks for spatial downscaling](https://arxiv.org/abs/2512.13753)
*Mika Sipilä,Sabrina Maggio,Sandra De Iaco,Klaus Nordhausen,Monica Palma,Sara Taskinen*

Main category: cs.CV

TL;DR: 本文提出并评估了基于深度学习（SRDRN和UNet）并结合轻量级时间模块的方法，用于将粗分辨率卫星对流层臭氧数据降尺度到高分辨率，结果显示时间模块显著提升了性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 卫星大气污染物数据通常空间分辨率较低，这限制了其在地方尺度环境分析和决策中的应用。空间降尺度方法旨在将这些粗分辨率卫星数据转换为高分辨率场，以克服这一限制。

Method: 研究考虑了两种广泛使用的深度学习架构：超分辨率深度残差网络（SRDRN）和基于编解码器的UNet，用于对流层臭氧的空间降尺度。这两种方法都通过一个轻量级时间模块进行了扩展，该模块使用正弦或径向基函数（RBF）编码观测时间，并将时间特征与网络中的空间表示融合。这些时间感知扩展在意大利臭氧降尺度案例研究中，与其基线对应物进行了评估。

Result: 结果表明，虽然计算复杂度仅略有增加，但时间模块显著提高了降尺度性能和收敛速度。

Conclusion: 为深度学习降尺度模型引入轻量级时间模块，可以有效提升模型性能和收敛效率，为将粗分辨率卫星数据转化为高分辨率场提供了有效途径。

Abstract: Satellite data of atmospheric pollutants are often available only at coarse spatial resolution, limiting their applicability in local-scale environmental analysis and decision-making. Spatial downscaling methods aim to transform the coarse satellite data into high-resolution fields. In this work, two widely used deep learning architectures, the super-resolution deep residual network (SRDRN) and the encoder-decoder-based UNet, are considered for spatial downscaling of tropospheric ozone. Both methods are extended with a lightweight temporal module, which encodes observation time using either sinusoidal or radial basis function (RBF) encoding, and fuses the temporal features with the spatial representations in the networks. The proposed time-aware extensions are evaluated against their baseline counterparts in a case study on ozone downscaling over Italy. The results suggest that, while only slightly increasing computational complexity, the temporal modules significantly improve downscaling performance and convergence speed.

</details>


### [45] [Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries](https://arxiv.org/abs/2512.13796)
*Victor Rong,Jan Held,Victor Chu,Daniel Rebain,Marc Van Droogenbroeck,Kiriakos N. Kutulakos,Andrea Tagliasacchi,David B. Lindell*

Main category: cs.CV

TL;DR: 本文提出一种新的紧凑表示，通过解耦几何和外观，利用面元（surfels）和神经场相结合的方式，在保持视觉质量的同时，显著减少了新视角合成所需的图元数量和内存占用，并提高了渲染速度。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅（Gaussian splatting）在新视角合成方面表现出色，但在建模高纹理场景时需要数百万个图元，即使几何形状简单，也导致表示冗余。研究目标是实现一种更紧凑的表示。

Method: 该方法将几何和外观解耦。几何部分使用面元（surfels），外观部分结合了全局神经场和每个图元的颜色。神经场对每个像素固定数量的图元进行纹理化，以确保计算量较低。

Result: 该表示与3D高斯泼溅的感知质量相当。在室外场景中，图元数量减少了9.7倍，内存减少了5.5倍；在室内场景中，图元数量减少了31倍，内存减少了3.7倍。此外，渲染速度比现有纹理图元快两倍，并提高了视觉质量。

Conclusion: 该研究提出了一种高效且紧凑的新视角合成表示方法，通过解耦几何与外观，显著降低了资源消耗（图元数和内存），同时保持了与高斯泼溅相当的视觉质量，并提升了渲染速度。

Abstract: Though Gaussian splatting has achieved impressive results in novel view synthesis, it requires millions of primitives to model highly textured scenes, even when the geometry of the scene is simple. We propose a representation that goes beyond point-based rendering and decouples geometry and appearance in order to achieve a compact representation. We use surfels for geometry and a combination of a global neural field and per-primitive colours for appearance. The neural field textures a fixed number of primitives for each pixel, ensuring that the added compute is low. Our representation matches the perceptual quality of 3D Gaussian splatting while using $9.7\times$ fewer primitives and $5.5\times$ less memory on outdoor scenes and using $31\times$ fewer primitives and $3.7\times$ less memory on indoor scenes. Our representation also renders twice as fast as existing textured primitives while improving upon their visual quality.

</details>


### [46] [Adaptable Segmentation Pipeline for Diverse Brain Tumors with Radiomic-guided Subtyping and Lesion-Wise Model Ensemble](https://arxiv.org/abs/2512.14648)
*Daniel Capellán-Martín,Abhijeet Parida,Zhifan Jiang,Nishad Kulkarni,Krithika Iyer,Austin Tapp,Syed Muhammad Anwar,María J. Ledesma-Carbayo,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本文提出了一种灵活、模块化、可适应的脑肿瘤分割流程，通过结合先进模型、应用肿瘤特异性处理、利用影像组学特征进行平衡训练和优化后处理，在BraTS 2025 Lighthouse挑战赛的多个多样化数据集中实现了与顶尖算法相当的鲁棒分割性能。


<details>
  <summary>Details</summary>
Motivation: 由于肿瘤类型差异大，在多参数磁共振成像(MRI)上对脑肿瘤进行鲁棒和可泛化的分割仍然很困难。BraTS 2025 Lighthouse挑战赛旨在评估在多样化成人和儿童肿瘤数据集上的分割方法，这促使研究人员寻求更有效的方法。

Method: 研究采用了一个灵活、模块化、可适应的流程。该流程通过选择和组合最先进的模型，并在训练前后应用肿瘤和病灶特异性处理来提高分割性能。它利用MRI提取的影像组学特征来检测肿瘤亚型，以确保更平衡的训练。定制的病灶级别性能指标用于确定集成中每个模型的影响并优化后处理，从而使工作流能够根据每个病例调整每个步骤。

Result: 在BraTS测试集上，该流程在多个挑战中取得了与顶尖算法相当的性能。这些发现证实，定制的病灶感知处理和模型选择能够产生鲁棒的分割结果，并且该方法不局限于特定的网络架构。

Conclusion: 该方法实现了鲁棒且可泛化的脑肿瘤分割，具有在临床实践中进行定量肿瘤测量的潜力，可支持诊断和预后。定制的病灶感知处理和模型选择是提高分割性能的关键。

Abstract: Robust and generalizable segmentation of brain tumors on multi-parametric magnetic resonance imaging (MRI) remains difficult because tumor types differ widely. The BraTS 2025 Lighthouse Challenge benchmarks segmentation methods on diverse high-quality datasets of adult and pediatric tumors: multi-consortium international pediatric brain tumor segmentation (PED), preoperative meningioma tumor segmentation (MEN), meningioma radiotherapy segmentation (MEN-RT), and segmentation of pre- and post-treatment brain metastases (MET). We present a flexible, modular, and adaptable pipeline that improves segmentation performance by selecting and combining state-of-the-art models and applying tumor- and lesion-specific processing before and after training. Radiomic features extracted from MRI help detect tumor subtype, ensuring a more balanced training. Custom lesion-level performance metrics determine the influence of each model in the ensemble and optimize post-processing that further refines the predictions, enabling the workflow to tailor every step to each case. On the BraTS testing sets, our pipeline achieved performance comparable to top-ranked algorithms across multiple challenges. These findings confirm that custom lesion-aware processing and model selection yield robust segmentations yet without locking the method to a specific network architecture. Our method has the potential for quantitative tumor measurement in clinical practice, supporting diagnosis and prognosis.

</details>


### [47] [VajraV1 -- The most accurate Real Time Object Detector of the YOLO family](https://arxiv.org/abs/2512.13834)
*Naman Balbir Singh Makkar*

Main category: cs.CV

TL;DR: VajraV1是一种新型实时目标检测器，通过结合现有YOLO模型的有效设计，在保持竞争性推理速度的同时，实现了最先进的检测精度。


<details>
  <summary>Details</summary>
Motivation: 近年来实时目标检测取得了显著进展，YOLO系列模型持续更新，促使研究人员寻求进一步提升实时目标检测器的性能和准确性。

Method: VajraV1模型架构在现有基于YOLO的检测器基础上引入了架构增强，并结合了先前YOLO模型中的有效设计选择。

Result: 在COCO验证集上，VajraV1-Nano达到44.3% mAP，优于YOLOv12-N和YOLOv13-N；VajraV1-Small达到50.4% mAP，超过YOLOv12-S和YOLOv13-S；VajraV1-Medium达到52.7% mAP，优于YOLOv12-M；VajraV1-Large达到53.7% mAP，超越YOLOv13-L；VajraV1-Xlarge达到56.2% mAP，超越所有现有实时目标检测器，同时保持了与YOLOv12-N和YOLOv11-N相当的延迟。

Conclusion: VajraV1模型在实时目标检测领域树立了新的准确性标准，同时保持了具有竞争力的推理速度，超越了所有现有实时目标检测器。

Abstract: Recent years have seen significant advances in real-time object detection, with the release of YOLOv10, YOLO11, YOLOv12, and YOLOv13 between 2024 and 2025. This technical report presents the VajraV1 model architecture, which introduces architectural enhancements over existing YOLO-based detectors. VajraV1 combines effective design choices from prior YOLO models to achieve state-of-the-art accuracy among real-time object detectors while maintaining competitive inference speed.
  On the COCO validation set, VajraV1-Nano achieves 44.3% mAP, outperforming YOLOv12-N by 3.7% and YOLOv13-N by 2.7% at latency competitive with YOLOv12-N and YOLOv11-N. VajraV1-Small achieves 50.4% mAP, exceeding YOLOv12-S and YOLOv13-S by 2.4%. VajraV1-Medium achieves 52.7% mAP, outperforming YOLOv12-M by 0.2%. VajraV1-Large achieves 53.7% mAP, surpassing YOLOv13-L by 0.3%. VajraV1-Xlarge achieves 56.2% mAP, outperforming all existing real-time object detectors.

</details>


### [48] [MoLingo: Motion-Language Alignment for Text-to-Motion Generation](https://arxiv.org/abs/2512.13840)
*Yannan He,Garvita Tiwari,Xiaohan Zhang,Pankaj Bora,Tolga Birdal,Jan Eric Lenssen,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: MoLingo是一个文本到动作（T2M）模型，通过在连续潜在空间中去噪来生成逼真的人体动作。它通过构建语义对齐的潜在空间和使用交叉注意力进行文本条件注入，在人体动作生成方面达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有文本到动作模型在潜在空间扩散方面存在如何使其更有效的问题。研究者旨在解决两个核心问题：1) 如何构建一个语义对齐的潜在空间以提高扩散效果；2) 如何最佳地注入文本条件，使生成的动作能紧密遵循描述。

Method: MoLingo模型通过在连续潜在空间中去噪来生成动作。具体方法包括：1) 提出一个语义对齐的动作编码器，通过帧级文本标签进行训练，确保语义相似的潜在变量在空间中接近，从而优化潜在空间以利于扩散；2) 比较了单令牌条件与多令牌交叉注意力方案，并发现交叉注意力能提供更好的动作真实感和文本-动作对齐。

Result: 结合了语义对齐的潜在变量、自回归生成和交叉注意力文本条件，MoLingo模型在标准度量和用户研究中，在人体动作生成方面达到了新的最先进水平，表现出卓越的动作真实感和文本-动作对齐。

Conclusion: 通过构建语义对齐的潜在空间和采用有效的文本条件注入（例如交叉注意力机制），可以在连续潜在空间中实现高质量的文本到动作生成，并显著提升模型的性能和用户体验。

Abstract: We introduce MoLingo, a text-to-motion (T2M) model that generates realistic, lifelike human motion by denoising in a continuous latent space. Recent works perform latent space diffusion, either on the whole latent at once or auto-regressively over multiple latents. In this paper, we study how to make diffusion on continuous motion latents work best. We focus on two questions: (1) how to build a semantically aligned latent space so diffusion becomes more effective, and (2) how to best inject text conditioning so the motion follows the description closely. We propose a semantic-aligned motion encoder trained with frame-level text labels so that latents with similar text meaning stay close, which makes the latent space more diffusion-friendly. We also compare single-token conditioning with a multi-token cross-attention scheme and find that cross-attention gives better motion realism and text-motion alignment. With semantically aligned latents, auto-regressive generation, and cross-attention text conditioning, our model sets a new state of the art in human motion generation on standard metrics and in a user study. We will release our code and models for further research and downstream usage.

</details>


### [49] [Improvise, Adapt, Overcome -- Telescopic Adapters for Efficient Fine-tuning of Vision Language Models in Medical Imaging](https://arxiv.org/abs/2512.13855)
*Ujjwal Mishra,Vinita Shukla,Praful Hambarde,Amit Shukla*

Main category: cs.CV

TL;DR: 本文提出了一种名为“伸缩适配器”（Telescopic Adapters）的新型参数高效微调（PEFT）框架，通过深度感知缩放机制，从浅层到深层逐渐增加适配器容量，从而高效地将视觉语言分割模型（VLSMs）适应到医学图像领域。


<details>
  <summary>Details</summary>
Motivation: 将视觉语言分割模型（VLSMs）适应到医学图像领域时，传统的微调方法计算开销巨大。现有的参数高效微调（PEFT）方法在所有Transformer层中应用统一的适配器维度，导致参数分配次优，适应效率降低。

Method: 该方法引入了“伸缩适配器”，这是一种新的PEFT框架，采用深度感知缩放机制，从浅层到深层逐步增加适配器容量。它将轻量级瓶颈模块集成到CLIPSeg的视觉和文本编码器中，并根据层深度和语义相关性动态调整适配器维度。

Result: “伸缩适配器”仅使用613k个可训练参数（比端到端微调少244倍），在息肉分割、皮肤病变检测和乳腺超声成像等五种不同的医学数据集上均实现了卓越的性能。全面的消融研究表明，深层需要比浅层更多的适应能力，验证了其伸缩缩放假设。

Conclusion: 该方法为高效的医学VLSM微调建立了新范式，使其能够在资源受限的临床环境中部署，同时保持有竞争力的分割精度。

Abstract: Adapting Vision Language Segmentation Models (VLSMs) to medical imaging domains requires significant computational overhead when using conventional fine-tuning approaches. Existing Parameter-Efficient Fine-Tuning (PEFT) methods apply uniform adapter dimensions across all transformer layers, leading to suboptimal parameter allocation and reduced adaptation efficiency. We introduce Telescopic Adapters, a novel PEFT framework that employs depth-aware scaling to progressively increase adapter capacity from shallow to deep transformer layers. Our method integrates lightweight bottleneck modules within CLIPSeg's vision and text encoders, with adapter dimensions dynamically scaled based on layer depth and semantic relevance. Using only 613k trainable parameters--244x fewer than end-to-end fine-tuning, Telescopic Adapters achieve superior performance across five diverse medical datasets spanning polyp segmentation, skin lesion detection, and breast ultrasound imaging. Comprehensive ablation studies demonstrate that deeper layers require substantially more adaptation capacity than shallow layers, validating our telescopic scaling hypothesis. Our approach establishes a new paradigm for efficient medical VLSM fine-tuning, enabling deployment in resource-constrained clinical environments while maintaining competitive segmentation accuracy.

</details>


### [50] [Coarse-to-Fine Hierarchical Alignment for UAV-based Human Detection using Diffusion Models](https://arxiv.org/abs/2512.13869)
*Wenda Li,Meng Wu,Sungmin Eum,Heesung Kwon,Qing Qu*

Main category: cs.CV

TL;DR: 本文提出Coarse-to-Fine Hierarchical Alignment (CFHA) 框架，一个三阶段的扩散模型，用于将合成数据转换为真实图像，以缩小无人机人类检测中的域差距，同时保留原始标签，显著提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 无人机人类检测需要大量标注数据，但在实际应用中，目标分布不断变化且标注图像稀缺，导致这一需求难以满足。虽然合成模拟器可以低成本生成带标注数据，但合成与真实图像之间的域差距阻碍了模型在目标域的有效应用。

Method: 本文引入Coarse-to-Fine Hierarchical Alignment (CFHA) 框架，这是一个三阶段的基于扩散模型的方法，用于转换合成数据以缩小域差距。它明确地解耦并弥合了全局风格和局部内容的域差异，包括：(1) 全局风格迁移：使用扩散模型将合成图像的颜色、光照和纹理统计与真实风格对齐；(2) 局部细化：使用超分辨率扩散模型为人类实例等小目标提供精细、逼真的细节，同时保持形状和边界完整性；(3) 幻觉去除：过滤掉视觉属性与真实世界数据不符的人类实例，使人类外观更接近目标分布。

Result: 在公共无人机Sim2Real检测基准上的广泛实验表明，与未经转换的基线相比，CFHA方法显著提高了检测精度。具体来说，在Semantic-Drone基准上，该方法实现了高达+14.1的mAP50提升。消融研究证实了全局和局部阶段的互补作用，并强调了分层对齐的重要性。

Conclusion: CFHA框架通过分层对齐全局风格和局部内容，有效地将合成数据转换为更接近真实图像的表示，从而显著缩小了域差距，并大幅提升了无人机人类检测的性能。

Abstract: Training object detectors demands extensive, task-specific annotations, yet this requirement becomes impractical in UAV-based human detection due to constantly shifting target distributions and the scarcity of labeled images. As a remedy, synthetic simulators are adopted to generate annotated data, with a low annotation cost. However, the domain gap between synthetic and real images hinders the model from being effectively applied to the target domain. Accordingly, we introduce Coarse-to-Fine Hierarchical Alignment (CFHA), a three-stage diffusion-based framework designed to transform synthetic data for UAV-based human detection, narrowing the domain gap while preserving the original synthetic labels. CFHA explicitly decouples global style and local content domain discrepancies and bridges those gaps using three modules: (1) Global Style Transfer -- a diffusion model aligns color, illumination, and texture statistics of synthetic images to the realistic style, using only a small real reference set; (2) Local Refinement -- a super-resolution diffusion model is used to facilitate fine-grained and photorealistic details for the small objects, such as human instances, preserving shape and boundary integrity; (3) Hallucination Removal -- a module that filters out human instances whose visual attributes do not align with real-world data to make the human appearance closer to the target distribution. Extensive experiments on public UAV Sim2Real detection benchmarks demonstrate that our methods significantly improve the detection accuracy compared to the non-transformed baselines. Specifically, our method achieves up to $+14.1$ improvement of mAP50 on Semantic-Drone benchmark. Ablation studies confirm the complementary roles of the global and local stages and highlight the importance of hierarchical alignment. The code is released at \href{https://github.com/liwd190019/CFHA}{this url}.

</details>


### [51] [Route-DETR: Pairwise Query Routing in Transformers for Object Detection](https://arxiv.org/abs/2512.13876)
*Ye Zhang,Qi Chen,Wenyou Huang,Rui Liu,Zhengjian Kang*

Main category: cs.CV

TL;DR: Route-DETR通过在解码器自注意力层中引入自适应成对路由机制，有效解决了DETR模型中查询竞争导致的计算冗余问题，显著提升了目标检测性能，且推理时无额外计算成本。


<details>
  <summary>Details</summary>
Motivation: DETR模型通过端到端的方式消除了手工组件，但存在查询竞争问题，即多个查询收敛到相似位置，导致计算冗余和效率低下。

Method: 本文提出了Route-DETR，通过解码器自注意力层中的自适应成对路由来解决查询竞争。该方法利用查询间相似度、置信度分数和几何信息区分竞争查询（针对同一对象）和互补查询（针对不同对象）。引入了双重路由机制：抑制器路由（减少竞争查询间的重复）和委托器路由（鼓励探索不同区域）。这些机制通过可学习的低秩注意力偏置实现，允许不对称的查询交互。采用双分支训练策略，仅在训练时引入路由偏置，推理时保留标准注意力，确保无额外计算成本。

Result: 实验结果表明，Route-DETR在COCO和Cityscapes数据集上持续改进了多个DETR基线模型。在ResNet-50上，比DINO模型mAP提升了1.7%；在Swin-L上达到了57.6% mAP，超越了之前的最先进模型。

Conclusion: Route-DETR通过创新的自适应成对路由机制，成功解决了DETR模型中的查询竞争问题，显著提高了目标检测的效率和性能，并且在推理阶段没有增加计算开销，为DETR系列模型提供了一个有效的改进方向。

Abstract: Detection Transformer (DETR) offers an end-to-end solution for object detection by eliminating hand-crafted components like non-maximum suppression. However, DETR suffers from inefficient query competition where multiple queries converge to similar positions, leading to redundant computations. We present Route-DETR, which addresses these issues through adaptive pairwise routing in decoder self-attention layers. Our key insight is distinguishing between competing queries (targeting the same object) versus complementary queries (targeting different objects) using inter-query similarity, confidence scores, and geometry. We introduce dual routing mechanisms: suppressor routes that modulate attention between competing queries to reduce duplication, and delegator routes that encourage exploration of different regions. These are implemented via learnable low-rank attention biases enabling asymmetric query interactions. A dual-branch training strategy incorporates routing biases only during training while preserving standard attention for inference, ensuring no additional computational cost. Experiments on COCO and Cityscapes demonstrate consistent improvements across multiple DETR baselines, achieving +1.7% mAP gain over DINO on ResNet-50 and reaching 57.6% mAP on Swin-L, surpassing prior state-of-the-art models.

</details>


### [52] [SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning](https://arxiv.org/abs/2512.13874)
*Jitesh Jain,Jialuo Li,Zixian Ma,Jieyu Zhang,Chris Dongjoo Kim,Sangho Lee,Rohun Tripathi,Tanmay Gupta,Christopher Clark,Humphrey Shi*

Main category: cs.CV

TL;DR: 本文提出SAGE，一个受人类行为启发的、能够进行多轮或单轮推理的视频理解系统，旨在解决现有模型在处理长视频时效率低下的问题。通过合成数据生成和强化学习训练，SAGE在长视频推理任务上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的视频推理模型在处理长视频时，通常需要一次性处理大量帧，效率低下且资源消耗大，与人类能够根据任务灵活决定观看时长（即“任意时长推理”）的行为模式不符。这促使研究者思考是否能开发出高性能的任意时长视频推理系统。

Method: 1. 提出SAGE代理系统，该系统能对长视频进行多轮推理，并对简单问题进行单轮推理。2. 引入基于Gemini-2.5-Flash的易用合成数据生成流程，用于训练SAGE的核心调度器SAGE-MM。3. 提出一种有效的强化学习（RL）后训练方法，用于赋予SAGE-MM任意时长推理能力。4. 构建SAGE-Bench数据集，平均视频时长超过700秒，用于评估真实世界娱乐场景下的视频推理能力。

Result: 经验证，SAGE系统、数据和RL训练方法的有效性，在开放式视频推理任务上观察到高达6.1%的显著改进，在时长超过10分钟的视频上更是取得了8.2%的惊人提升。

Conclusion: 本研究成功开发了一个能够进行任意时长视频推理的系统SAGE，并通过提出的合成数据生成和强化学习方法，有效提升了模型在长视频理解任务上的性能，证明了其方法在模拟人类灵活推理行为方面的有效性。

Abstract: As humans, we are natural any-horizon reasoners, i.e., we can decide whether to iteratively skim long videos or watch short ones in full when necessary for a given task. With this in mind, one would expect video reasoning models to reason flexibly across different durations. However, SOTA models are still trained to predict answers in a single turn while processing a large number of frames, akin to watching an entire long video, requiring significant resources. This raises the question: Is it possible to develop performant any-horizon video reasoning systems? Inspired by human behavior, we first propose SAGE, an agent system that performs multi-turn reasoning on long videos while handling simpler problems in a single turn. Secondly, we introduce an easy synthetic data generation pipeline using Gemini-2.5-Flash to train the orchestrator, SAGE-MM, which lies at the core of SAGE. We further propose an effective RL post-training recipe essential for instilling any-horizon reasoning ability in SAGE-MM. Thirdly, we curate SAGE-Bench with an average duration of greater than 700 seconds for evaluating video reasoning ability in real-world entertainment use cases. Lastly, we empirically validate the effectiveness of our system, data, and RL recipe, observing notable improvements of up to 6.1% on open-ended video reasoning tasks, as well as an impressive 8.2% improvement on videos longer than 10 minutes.

</details>


### [53] [KLO-Net: A Dynamic K-NN Attention U-Net with CSP Encoder for Efficient Prostate Gland Segmentation from MRI](https://arxiv.org/abs/2512.13902)
*Anning Tian,Byunghyun Ko,Kaichen Qu,Mengyuan Liu,Jeongkyu Lee*

Main category: cs.CV

TL;DR: 本文提出KLO-Net，一种带有动态K-NN注意力机制和CSP编码器的U-Net，用于高效、准确地进行前列腺MRI分割，解决了计算负荷和内存占用问题。


<details>
  <summary>Details</summary>
Motivation: 前列腺MRI分割的实时部署常受计算负荷和内存占用的瓶颈限制。同时，基于深度学习的方法也面临解剖变异性的挑战。研究旨在弥合效率差距，同时保持可靠的分割精度。

Method: 提出KLO-Net，一种动态K-近邻（K-NN）注意力U-Net，并结合交叉阶段部分（CSP）编码器。动态K-NN注意力机制允许模型自适应地确定每个空间位置的注意力连接数量。CSP块则用于降低计算负荷和内存消耗。

Result: 在PROMISE12和PROSTATEx两个公共数据集上进行了全面的实验和消融研究。详细的比较分析表明，该模型在计算效率和分割质量方面均具有优势。

Conclusion: KLO-Net通过其动态K-NN注意力机制和CSP编码器，成功地在保持可靠分割精度的同时，提高了前列腺MRI分割的计算效率，为临床工作站的实时部署提供了可行方案。

Abstract: Real-time deployment of prostate MRI segmentation on clinical workstations is often bottlenecked by computational load and memory footprint. Deep learning-based prostate gland segmentation approaches remain challenging due to anatomical variability. To bridge this efficiency gap while still maintaining reliable segmentation accuracy, we propose KLO-Net, a dynamic K-Nearest Neighbor attention U-Net with Cross Stage Partial, i.e., CSP, encoder for efficient prostate gland segmentation from MRI scan. Unlike the regular K-NN attention mechanism, the proposed dynamic K-NN attention mechanism allows the model to adaptively determine the number of attention connections for each spatial location within a slice. In addition, CSP blocks address the computational load to reduce memory consumption. To evaluate the model's performance, comprehensive experiments and ablation studies are conducted on two public datasets, i.e., PROMISE12 and PROSTATEx, to validate the proposed architecture. The detailed comparative analysis demonstrates the model's advantage in computational efficiency and segmentation quality.

</details>


### [54] [An evaluation of SVBRDF Prediction from Generative Image Models for Appearance Modeling of 3D Scenes](https://arxiv.org/abs/2512.13950)
*Alban Gauthier,Valentin Deschaintre,Alexandre Lanvin,Fredo Durand,Adrien Bousseau,George Drettakis*

Main category: cs.CV

TL;DR: 本文分析了在基于深度生成模型的快速外观建模流程中，SVBRDF预测面临的挑战与机遇，并比较了不同神经网络架构和条件，发现标准UNet表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着深度生成模型的发展，数字内容创作正在经历深刻变革。条件图像生成器和SVBRDF预测网络使得快速合成3D场景的RGB图像并恢复材质参数成为可能。将这些技术结合可以快速生成多视图SVBRDF贴图，进而合并为场景的SVBRDF纹理图集。然而，这种快速外观建模流程中，单视图SVBRDF预测可能存在多视图不一致性，导致纹理图集不连贯。同时，生成的RGB图像及其条件信息也为SVBRDF估计提供了额外信息。因此，本文旨在分析这些挑战和机遇。

Method: 本文比较了不同的神经网络架构和条件，以识别在快速外观建模流程中，利用生成的RGB图像进行SVBRDF预测时，能够实现高精度和连贯性的设计。

Result: 研究发现，令人惊讶的是，一个标准的UNet架构在性能上与更复杂的设计具有竞争力。

Conclusion: 在利用深度生成模型进行快速外观建模的背景下，SVBRDF预测面临多视图不一致性等挑战，但生成的RGB图像也提供了新的机遇。通过比较不同的神经网络设计，本文发现简单的UNet架构在实现高精度和连贯性方面表现优异。

Abstract: Digital content creation is experiencing a profound change with the advent of deep generative models. For texturing, conditional image generators now allow the synthesis of realistic RGB images of a 3D scene that align with the geometry of that scene. For appearance modeling, SVBRDF prediction networks recover material parameters from RGB images. Combining these technologies allows us to quickly generate SVBRDF maps for multiple views of a 3D scene, which can be merged to form a SVBRDF texture atlas of that scene. In this paper, we analyze the challenges and opportunities for SVBRDF prediction in the context of such a fast appearance modeling pipeline. On the one hand, single-view SVBRDF predictions might suffer from multiview incoherence and yield inconsistent texture atlases. On the other hand, generated RGB images, and the different modalities on which they are conditioned, can provide additional information for SVBRDF estimation compared to photographs. We compare neural architectures and conditions to identify designs that achieve high accuracy and coherence. We find that, surprisingly, a standard UNet is competitive with more complex designs. Project page: http://repo-sam.inria.fr/nerphys/svbrdf-evaluation

</details>


### [55] [From Unlearning to UNBRANDING: A Benchmark for Trademark-Safe Text-to-Image Generation](https://arxiv.org/abs/2512.13953)
*Dawid Malarz,Artur Kasymov,Filip Manjak,Maciej Zięba,Przemysław Spurek*

Main category: cs.CV

TL;DR: 本文提出“去品牌化”(unbranding)任务，旨在解决文本到图像扩散模型中未经授权的商标内容复制问题。该任务通过移除显式商标和微妙的结构性品牌特征，同时保持语义连贯性。为此，研究构建了一个基准数据集，并引入了一种基于视觉语言模型(VLM)的新型评估指标，以捕捉多维度的品牌识别。研究发现，随着模型保真度的提高，去品牌化任务的紧迫性愈发凸显，且需要专门技术来解决。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在生成商标内容方面进展迅速，引发了对未经授权复制的担忧。现有工作未能解决具体的品牌标识，且品牌识别是多维度的，不仅包括显式标志，还包括独特的结构特征。此外，新模型（如SDXL、FLUX）比旧模型更容易合成品牌标识，凸显了这一问题的紧迫性。

Method: 研究引入了“去品牌化”(unbranding)这一新任务，目标是精细地移除商标和微妙的结构性品牌特征，同时保持语义连贯性。为促进研究，构建了一个全面的基准数据集。针对现有品牌检测器仅限于标志且无法捕捉抽象商业外观的局限性，研究提出了一种基于视觉语言模型（VLM）的新型评估指标，该指标采用问答框架来探测图像中的显式标志和隐式、整体的品牌特征。

Result: 研究观察到，随着模型保真度的提高，较新的系统（SDXL、FLUX）比旧模型（Stable Diffusion）更容易合成品牌标识，这突显了去品牌化挑战的紧迫性。通过VLM指标验证的结果证实，去品牌化是一个独特且具有实际相关性的问题，需要专门的技术来解决。

Conclusion: 去品牌化是一个独特且具有实际意义的问题，它要求专门的技术来应对文本到图像模型中多维度品牌识别（包括显式标志和微妙结构特征）的未经授权复制。随着生成模型保真度的不断提升，解决这一问题的紧迫性日益增加。

Abstract: The rapid progress of text-to-image diffusion models raises significant concerns regarding the unauthorized reproduction of trademarked content. While prior work targets general concepts (e.g., styles, celebrities), it fails to address specific brand identifiers. Crucially, we note that brand recognition is multi-dimensional, extending beyond explicit logos to encompass distinctive structural features (e.g., a car's front grille). To tackle this, we introduce unbranding, a novel task for the fine-grained removal of both trademarks and subtle structural brand features, while preserving semantic coherence. To facilitate research, we construct a comprehensive benchmark dataset. Recognizing that existing brand detectors are limited to logos and fail to capture abstract trade dress (e.g., the shape of a Coca-Cola bottle), we introduce a novel evaluation metric based on Vision Language Models (VLMs). This VLM-based metric uses a question-answering framework to probe images for both explicit logos and implicit, holistic brand characteristics. Furthermore, we observe that as model fidelity increases, with newer systems (SDXL, FLUX) synthesizing brand identifiers more readily than older models (Stable Diffusion), the urgency of the unbranding challenge is starkly highlighted. Our results, validated by our VLM metric, confirm unbranding is a distinct, practically relevant problem requiring specialized techniques. Project Page: https://gmum.github.io/UNBRANDING/.

</details>


### [56] [Quality-Driven and Diversity-Aware Sample Expansion for Robust Marine Obstacle Segmentation](https://arxiv.org/abs/2512.13970)
*Miaohua Zhang,Mohammad Ali Armin,Xuesong Li,Sisi Liang,Lars Petersson,Changming Sun,David Ahmedt-Aristizabal,Zeeshan Hayder*

Main category: cs.CV

TL;DR: 本文提出了一种质量驱动且多样性感知的样本扩展流水线，在推理时生成训练数据，以解决海洋障碍物检测中数据稀缺和多样性不足的问题，从而提高分割性能。


<details>
  <summary>Details</summary>
Motivation: 海洋障碍物检测面临图像质量下降（如阳光眩光、雾、海浪）和训练数据稀缺、多样性不足的挑战。现有的掩码条件扩散模型在低熵掩码和提示下生成多样性较低的输出，限制了其在提高模型鲁棒性方面的作用。

Method: 本文提出一个质量驱动且多样性感知的样本扩展流水线，在推理时生成训练数据，无需重新训练扩散模型。该框架包含两个关键组件：(i) 一个类别感知风格库，用于构建高熵、语义接地的提示；(ii) 一个自适应退火采样器，用于扰动早期条件，并通过一个COD引导的比例控制器来调节扰动，以在不损害布局保真度的情况下提高多样性。

Result: 在海洋障碍物基准测试中，使用这些受控的合成样本增强训练数据，持续提高了多骨干网络的分割性能，并增加了稀有和纹理敏感类别的视觉变化。

Conclusion: 所提出的样本扩展流水线能够有效在推理时生成多样化且高质量的合成训练数据，显著提升了海洋障碍物分割模型的性能和对挑战性类别的鲁棒性。

Abstract: Marine obstacle detection demands robust segmentation under challenging conditions, such as sun glitter, fog, and rapidly changing wave patterns. These factors degrade image quality, while the scarcity and structural repetition of marine datasets limit the diversity of available training data. Although mask-conditioned diffusion models can synthesize layout-aligned samples, they often produce low-diversity outputs when conditioned on low-entropy masks and prompts, limiting their utility for improving robustness. In this paper, we propose a quality-driven and diversity-aware sample expansion pipeline that generates training data entirely at inference time, without retraining the diffusion model. The framework combines two key components:(i) a class-aware style bank that constructs high-entropy, semantically grounded prompts, and (ii) an adaptive annealing sampler that perturbs early conditioning, while a COD-guided proportional controller regulates this perturbation to boost diversity without compromising layout fidelity. Across marine obstacle benchmarks, augmenting training data with these controlled synthetic samples consistently improves segmentation performance across multiple backbones and increases visual variation in rare and texture-sensitive classes.

</details>


### [57] [XAI-Driven Diagnosis of Generalization Failure in State-Space Cerebrovascular Segmentation Models: A Case Study on Domain Shift Between RSNA and TopCoW Datasets](https://arxiv.org/abs/2512.13977)
*Youssef Abuzeid,Shimaa El-Bana,Ahmad Al-Kabbany*

Main category: cs.CV

TL;DR: 本研究使用可解释AI (XAI) 方法诊断了深度学习模型在医学影像中因域漂移导致的泛化失败，发现模型在目标域中关注了虚假关联而非真实解剖特征。


<details>
  <summary>Details</summary>
Motivation: 域漂移严重阻碍了深度学习模型在医学影像中的临床部署，导致模型在外部数据集上表现灾难性下降。为构建可信赖的AI，需要深入理解模型失败的原因，而不仅仅是评估性能，因此可解释AI是必不可少的诊断工具。

Method: 本研究采用两阶段方法：首先，量化了源数据集（RSNA CTA Aneurysm）和目标数据集（TopCoW Circle of Willis CT）之间的域差距（Z轴分辨率和背景噪声），并评估了UMamaba模型在脑血管分割任务上的性能。其次，利用Seg-XRes-CAM诊断失败原因，通过测量模型注意力图与真实标注以及与模型自身预测掩码之间的重叠度来量化模型的关注点。

Result: 研究发现源域与目标域存在显著差异，导致模型Dice分数从0.8604（源域）骤降至0.2902（目标域）。XAI分析表明，模型泛化失败是由于其注意力机制在目标域中放弃了真实的解剖特征，转而关注虚假关联。量化指标显示，模型关注点偏离了真实血管（IoU约0.101），但仍与其错误的预测对齐（IoU约0.282）。

Conclusion: 模型在目标域中学习了虚假关联，证明了XAI（特别是Seg-XRes-CAM）是识别数据集偏差和诊断新兴架构（如状态空间模型）泛化失败的强大工具。

Abstract: The clinical deployment of deep learning models in medical imaging is severely hindered by domain shift. This challenge, where a high-performing model fails catastrophically on external datasets, is a critical barrier to trustworthy AI. Addressing this requires moving beyond simple performance metrics toward deeper understanding, making Explainable AI (XAI) an essential diagnostic tool in medical image analysis. We present a rigorous, two-phase approach to diagnose the generalization failure of state-of-the-art State-Space Models (SSMs), specifically UMamaba, applied to cerebrovascular segmentation. We first established a quantifiable domain gap between our Source (RSNA CTA Aneurysm) and Target (TopCoW Circle of Willis CT) datasets, noting significant differences in Z-resolution and background noise. The model's Dice score subsequently plummeted from 0.8604 (Source) to 0.2902 (Target). In the second phase, which is our core contribution, we utilized Seg-XRes-CAM to diagnose the cause of this failure. We quantified the model's focus by measuring the overlap between its attention maps and the Ground Truth segmentations, and between its attention maps and its own Prediction Mask. Our analysis proves the model failed to generalize because its attention mechanism abandoned true anatomical features in the Target domain. Quantitative metrics confirm the model's focus shifted away from the Ground Truth vessels (IoU~0.101 at 0.3 threshold) while still aligning with its own wrong predictions (IoU~0.282 at 0.3 threshold). This demonstrates the model learned spurious correlations, confirming XAI is a powerful diagnostic tool for identifying dataset bias in emerging architectures.

</details>


### [58] [FocalComm: Hard Instance-Aware Multi-Agent Perception](https://arxiv.org/abs/2512.13982)
*Dereje Shenkut,Vijayakumar Bhagavatula*

Main category: cs.CV

TL;DR: FocalComm是一种新的多智能体协同感知框架，通过交换面向难例的特征，显著提升了自动驾驶中行人等脆弱道路使用者的感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有的协同感知方法在车辆检测方面表现良好，但在行人等小型、安全关键目标上表现不佳，且通常依赖于全特征交换而非仅交换有助于减少漏报的显著特征。

Method: FocalComm框架包含两个关键设计：1) 一个可学习的渐进式难例挖掘（HIM）模块，用于提取每个智能体的难例特征；2) 一种基于查询的特征级（中间）融合技术，在协作过程中动态加权这些识别出的特征。

Result: FocalComm在两个真实世界数据集（V2X-Real和DAIR-V2X）上，在以车辆为中心和以基础设施为中心的协同设置中，均优于最先进的协同感知方法。尤其在V2X-Real数据集中，FocalComm在行人检测方面表现出显著的性能提升。

Conclusion: FocalComm通过聚焦于交换难例特征，有效解决了现有协同感知方法在小型、安全关键目标（如行人）检测上的不足，为自动驾驶安全提供了更鲁棒的3D感知能力。

Abstract: Multi-agent collaborative perception (CP) is a promising paradigm for improving autonomous driving safety, particularly for vulnerable road users like pedestrians, via robust 3D perception. However, existing CP approaches often optimize for vehicle detection performance metrics, underperforming on smaller, safety-critical objects such as pedestrians, where detection failures can be catastrophic. Furthermore, previous CP methods rely on full feature exchange rather than communicating only salient features that help reduce false negatives. To this end, we present FocalComm, a novel collaborative perception framework that focuses on exchanging hard-instance-oriented features among connected collaborative agents. FocalComm consists of two key novel designs: (1) a learnable progressive hard instance mining (HIM) module to extract hard instance-oriented features per agent, and (2) a query-based feature-level (intermediate) fusion technique that dynamically weights these identified features during collaboration. We show that FocalComm outperforms state-of-the-art collaborative perception methods on two challenging real-world datasets (V2X-Real and DAIR-V2X) across both vehicle-centric and infrastructure-centric collaborative setups. FocalComm also shows a strong performance gain in pedestrian detection in V2X-Real.

</details>


### [59] [Repurposing 2D Diffusion Models for 3D Shape Completion](https://arxiv.org/abs/2512.13991)
*Yao He,Youngjoong Kwon,Tiange Xiang,Wenxiao Cai,Ehsan Adeli*

Main category: cs.CV

TL;DR: 该研究提出一个框架，通过引入名为“Shape Atlas”的紧凑2D表示，将2D扩散模型应用于3D形状补全，以克服3D数据稀缺性和模态差异问题。


<details>
  <summary>Details</summary>
Motivation: 2D扩散模型因丰富的2D数据取得了巨大成功，而3D扩散模型因高质量3D数据集稀缺以及3D输入与2D潜在空间之间的模态差异而发展滞后。

Method: 引入“Shape Atlas”，这是一种紧凑的3D几何2D表示。它能充分利用预训练2D扩散模型的生成能力，并对齐条件输入和输出空间之间的模态，从而实现更有效的条件化学习。这种统一的2D公式便于从有限的3D数据中学习。

Result: 该方法能够生成高质量、细节保留的形状补全。在PCN和ShapeNet-55数据集上验证了其有效性。此外，还展示了将补全的点云转换为艺术家创建的网格的下游应用，进一步证明了其实用性。

Conclusion: 所提出的框架通过Shape Atlas成功地将2D扩散模型的能力应用于3D形状补全，有效解决了3D数据限制和模态差异问题，实现了高质量的补全并具有实际应用价值。

Abstract: We present a framework that adapts 2D diffusion models for 3D shape completion from incomplete point clouds. While text-to-image diffusion models have achieved remarkable success with abundant 2D data, 3D diffusion models lag due to the scarcity of high-quality 3D datasets and a persistent modality gap between 3D inputs and 2D latent spaces. To overcome these limitations, we introduce the Shape Atlas, a compact 2D representation of 3D geometry that (1) enables full utilization of the generative power of pretrained 2D diffusion models, and (2) aligns the modalities between the conditional input and output spaces, allowing more effective conditioning. This unified 2D formulation facilitates learning from limited 3D data and produces high-quality, detail-preserving shape completions. We validate the effectiveness of our results on the PCN and ShapeNet-55 datasets. Additionally, we show the downstream application of creating artist-created meshes from our completed point clouds, further demonstrating the practicality of our method.

</details>


### [60] [Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models](https://arxiv.org/abs/2512.14008)
*Shufan Li,Jiuxiang Gu,Kangning Liu,Zhe Lin,Zijun Wei,Aditya Grover,Jason Kuen*

Main category: cs.CV

TL;DR: MDM模型推理速度慢是由于重复处理冗余掩码token。Sparse-LaViDa通过动态截断不必要的掩码token、引入注册token和设计专用注意力掩码，将MDM采样速度提升高达2倍，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: MDM模型在多模态任务中表现出色，但其推理速度因在每个采样步骤中重复处理冗余掩码token而次优。

Method: 本文提出了Sparse-LaViDa框架，通过以下方法加速MDM采样：1) 在每个推理步骤动态截断不必要的掩码token；2) 引入专门的注册token作为截断token的紧凑表示；3) 设计专门的注意力掩码以确保训练和推理之间的一致性。

Result: 基于先进的统一MDM模型LaViDa-O，Sparse-LaViDa在文本到图像生成、图像编辑和数学推理等多种任务中实现了高达2倍的速度提升，同时保持了生成质量。

Conclusion: Sparse-LaViDa通过动态截断冗余掩码token并引入辅助机制，有效解决了MDM模型的推理速度瓶颈，显著加速了采样过程而未牺牲生成质量。

Abstract: Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.

</details>


### [61] [DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos](https://arxiv.org/abs/2512.14217)
*Yang Bai,Liudi Yang,George Eskandar,Fengyi Shen,Mohammad Altillawi,Ziyuan Liu,Gitta Kutyniok*

Main category: cs.CV

TL;DR: DRAW2ACT是一个深度感知的轨迹条件视频生成框架，通过多模态轨迹表示和RGB-D视频联合生成，显著提升了机器人操作的视觉保真度、一致性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型在具身AI中模拟真实世界能力强大，但在机器人操作的可控性方面受限。轨迹条件视频生成虽有所进展，但常依赖2D轨迹或单一模态条件，限制了生成可控且一致机器人演示的能力。

Method: DRAW2ACT框架提取输入轨迹的多种正交表示（深度、语义、形状和运动）并注入扩散模型。它联合生成空间对齐的RGB和深度视频，利用跨模态注意力机制和深度监督增强时空一致性。最后，引入一个多模态策略模型，以生成的RGB和深度序列为条件回归机器人关节角度。

Result: 在Bridge V2、Berkeley Autolab和仿真基准上的实验表明，DRAW2ACT在视觉保真度和一致性方面优于现有基线，并取得了更高的操作成功率。

Conclusion: DRAW2ACT通过深度感知轨迹条件和多模态视频生成，有效解决了机器人操作中视频扩散模型可控性不足的问题，显著提升了演示质量和任务成功率，为具身AI提供了更强大的模拟工具。

Abstract: Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.

</details>


### [62] [Deep Learning Perspective of Scene Understanding in Autonomous Robots](https://arxiv.org/abs/2512.14020)
*Afia Maham,Dur E Nayab Tashfa*

Main category: cs.CV

TL;DR: 本文综述了深度学习在自主机器人场景理解中的应用，涵盖了目标检测、语义分割、深度估计、三维重建和视觉SLAM等领域。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决传统几何模型的局限性，改进实时深度感知能力（尤其是在遮挡和无纹理表面下），并增强语义推理以更好地理解环境。

Method: 本文采用综述方法，回顾了深度学习在自主机器人场景理解中的应用创新，包括目标检测、语义和实例分割、深度估计、三维重建和视觉SLAM。

Result: 当这些感知模块集成到动态和非结构化环境中时，它们在决策、导航和交互方面变得更加有效。

Conclusion: 该综述指出了当前存在的问题，并提出了未来研究方向，以推动自主机器人基于学习的场景理解技术发展。

Abstract: This paper provides a review of deep learning applications in scene understanding in autonomous robots, including innovations in object detection, semantic and instance segmentation, depth estimation, 3D reconstruction, and visual SLAM. It emphasizes how these techniques address limitations of traditional geometric models, improve depth perception in real time despite occlusions and textureless surfaces, and enhance semantic reasoning to understand the environment better. When these perception modules are integrated into dynamic and unstructured environments, they become more effective in decisionmaking, navigation and interaction. Lastly, the review outlines the existing problems and research directions to advance learning-based scene understanding of autonomous robots.

</details>


### [63] [KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding](https://arxiv.org/abs/2512.14017)
*Zongyao Li,Kengo Ishida,Satoshi Yamazaki,Xiaotong Ji,Jianquan Liu*

Main category: cs.CV

TL;DR: KFS-Bench是首个用于长视频问答（QA）的关键帧采样基准，通过多场景标注直接评估采样策略。研究发现采样精度、场景覆盖和采样平衡是影响QA性能的关键因素，并提出了一种新的自适应平衡采样方法，显著提升了采样和QA性能。


<details>
  <summary>Details</summary>
Motivation: 关键帧采样对于高效的长视频理解至关重要，尤其能提高多模态大语言模型（MLLMs）在长视频问答中的准确性和效率。现有工作仅通过QA准确率间接评估帧选择质量，缺乏直接、鲁棒的采样策略评估方法。

Method: 本文提出了KFS-Bench，这是首个带有多场景标注的基准，用于直接评估长视频问答中的关键帧采样策略。基于KFS-Bench，作者对关键帧采样方法进行了全面研究，并设计了一种与QA准确率相关的采样质量度量。此外，还开发了一种新颖的关键帧采样方法，该方法利用问题-视频相关性来平衡采样多样性与问题-帧相似性，从而提高相关场景的覆盖率。

Result: 研究发现，不仅采样精度，场景覆盖和采样平衡也是影响QA性能的关键因素。所设计的采样质量度量与QA准确率高度相关。所提出的自适应平衡采样方法在关键帧采样和QA性能方面均取得了卓越表现。

Conclusion: KFS-Bench为长视频问答中的关键帧采样提供了直接且鲁棒的评估手段。研究揭示了影响QA性能的关键采样因素，并提出了一种新颖、高效的自适应平衡采样方法，有效提升了长视频理解任务的性能。

Abstract: We propose KFS-Bench, the first benchmark for key frame sampling in long video question answering (QA), featuring multi-scene annotations to enable direct and robust evaluation of sampling strategies. Key frame sampling is crucial for efficient long-form video understanding. In long video QA, selecting informative frames enables multimodal large language models (MLLMs) to improve both accuracy and efficiency. KFS-Bench addresses the limitation of prior works that only indirectly assess frame selection quality via QA accuracy. By providing ground-truth annotations of multiple disjoint scenes required per question, KFS-Bench allows us to directly analyze how different sampling approaches capture essential content across an entire long video. Using KFS-Bench, we conduct a comprehensive study of key frame sampling methods and identify that not only sampling precision but also scene coverage and sampling balance are the key factors influencing QA performance. Regarding all the factors, we design a novel sampling quality metric that correlates with QA accuracy. Furthermore, we develop a novel key frame sampling method that leverages question-video relevance to balance sampling diversity against question-frame similarity, thereby improving coverage of relevant scenes. Our adaptively balanced sampling approach achieves superior performance in both key frame sampling and QA performance. The benchmark is available at https://github.com/NEC-VID/KFS-Bench.

</details>


### [64] [Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding](https://arxiv.org/abs/2512.14028)
*Jiaheng Li,Qiyu Dai,Lihan Li,Praneeth Chakravarthula,He Sun,Baoquan Chen,Wenzheng Chen*

Main category: cs.CV

TL;DR: 该研究提出一种学习型结构光解码框架，通过在特征空间而非像素域进行匹配，结合深度细化模块，显著提升了主动3D成像在复杂场景下的鲁棒性和深度质量。该方法仅用合成数据训练，但能很好地泛化到真实世界，并超越现有商业系统。


<details>
  <summary>Details</summary>
Motivation: 传统的结构光方法在像素域进行深度匹配，导致在遮挡、精细细节和非朗伯表面等挑战性场景下鲁棒性有限。

Method: 该方法提出一个学习型结构光解码框架：1) 从投射图案和捕获的红外图像中提取神经特征，并在特征空间构建代价体进行鲁棒的对应匹配，融入几何先验；2) 引入深度细化模块，利用大规模单目深度估计模型的强大先验来改善细节恢复和全局结构一致性；3) 开发了一个基于物理的结构光渲染管线，生成近百万对合成图案-图像数据用于训练。

Result: 实验表明，该方法在像素域解码方法上实现了显著的性能提升，改善了精细细节恢复和全局结构连贯性。它仅通过合成数据训练，就能很好地泛化到真实世界的室内环境，无需重新训练即可处理多种图案类型，并持续优于商业结构光系统和基于被动立体RGB的深度估计方法。

Conclusion: 该研究提出的学习型结构光解码框架通过特征空间匹配和深度细化，显著提升了主动3D成像的鲁棒性和深度质量。其在合成数据上的有效训练和在真实世界的良好泛化能力，以及超越现有技术的表现，证明了该方法的优越性。

Abstract: We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.

</details>


### [65] [Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers](https://arxiv.org/abs/2512.14026)
*Yibing Fu,Yunpeng Zhao,Zhitao Zeng,Cheng Chen,Yueming Jin*

Main category: cs.CV

TL;DR: 本文提出了一种名为CITab的新型自监督学习（SSL）框架，旨在通过语义感知和原型引导机制，解决现有图像-表格多模态学习方法在跨不同表格数据队列中知识迁移受阻的问题，从而学习更具可迁移性的医学知识。


<details>
  <summary>Details</summary>
Motivation: 现有的用于图像-表格表示学习的自监督学习方法，由于其僵化的表格建模机制，通常局限于特定的数据队列，难以处理异构表格数据。这种“表格间障碍”阻碍了多模态SSL方法有效学习跨不同队列共享的可迁移医学知识。

Method: 本文提出了CITab框架。它通过整合列标题作为语义线索，从语义感知的角度设计了表格建模机制，以促进可迁移知识学习和多数据源预训练的可扩展性。此外，还提出了一个原型引导的线性层混合（P-MoLin）模块，用于表格特征特化，使模型能够有效处理表格数据的异构性并探索潜在的医学概念。

Result: 在包含4,461名受试者的三个公开阿尔茨海默病诊断任务数据队列上进行的综合评估表明，CITab的性能优于最先进的方法。

Conclusion: CITab框架为有效和可扩展的跨表格多模态学习铺平了道路，能够学习强大的多模态特征表示。

Abstract: Multi-modal learning integrating medical images and tabular data has significantly advanced clinical decision-making in recent years. Self-Supervised Learning (SSL) has emerged as a powerful paradigm for pretraining these models on large-scale unlabeled image-tabular data, aiming to learn discriminative representations. However, existing SSL methods for image-tabular representation learning are often confined to specific data cohorts, mainly due to their rigid tabular modeling mechanisms when modeling heterogeneous tabular data. This inter-tabular barrier hinders the multi-modal SSL methods from effectively learning transferrable medical knowledge shared across diverse cohorts. In this paper, we propose a novel SSL framework, namely CITab, designed to learn powerful multi-modal feature representations in a cross-tabular manner. We design the tabular modeling mechanism from a semantic-awareness perspective by integrating column headers as semantic cues, which facilitates transferrable knowledge learning and the scalability in utilizing multiple data sources for pretraining. Additionally, we propose a prototype-guided mixture-of-linear layer (P-MoLin) module for tabular feature specialization, empowering the model to effectively handle the heterogeneity of tabular data and explore the underlying medical concepts. We conduct comprehensive evaluations on Alzheimer's disease diagnosis task across three publicly available data cohorts containing 4,461 subjects. Experimental results demonstrate that CITab outperforms state-of-the-art approaches, paving the way for effective and scalable cross-tabular multi-modal learning.

</details>


### [66] [A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning](https://arxiv.org/abs/2512.14442)
*Zixin Zhang,Kanghao Chen,Hanqing Wang,Hongfei Zhang,Harold Haodong Chen,Chenfei Liao,Litao Guo,Ying-Cong Chen*

Main category: cs.CV

TL;DR: A4-Agent是一个免训练的智能体框架，通过解耦交互预测为三个阶段，并协同利用专业基础模型，实现了零样本下的卓越性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端交互预测模型将高级推理和低级定位耦合在一起，并依赖于标注数据集进行训练，导致在新物体和未知环境中泛化能力差。

Method: 本文提出了A4-Agent，一个免训练的智能体框架，将交互预测解耦为三个阶段，并在测试时协调专业的预训练基础模型：1) Dreamer（梦想家）利用生成模型可视化交互；2) Thinker（思考者）利用大型视觉语言模型决定与哪个物体部分交互；3) Spotter（定位器）协调视觉基础模型精确定位交互区域。该框架无需任何任务特定微调，实现零样本学习。

Result: 我们的零样本框架在多个基准测试中显著优于最先进的监督方法，并展示了对真实世界环境的强大泛化能力。

Conclusion: 通过解耦任务并协调预训练基础模型，A4-Agent提供了一种无需训练即可实现高效和泛化交互预测的新范式，克服了现有端到端监督模型的局限性。

Abstract: Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\textbf{Dreamer}$ that employs generative models to visualize $\textit{how}$ an interaction would look; (2) a $\textbf{Thinker}$ that utilizes large vision-language models to decide $\textit{what}$ object part to interact with; and (3) a $\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.

</details>


### [67] [History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation](https://arxiv.org/abs/2512.14222)
*Xichen Ding,Jianzhe Gao,Cong Pan,Wenguan Wang,Jie Qin*

Main category: cs.CV

TL;DR: 本文提出了一种名为HETT的历史增强两阶段Transformer框架，用于解决无人机在城市环境中基于语言指令的视觉-语言导航（AVLN）问题。HETT采用粗粒度到细粒度的导航流程，结合历史上下文和精细视觉分析，并通过历史网格地图增强场景感知，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机（UAV）智能体在空中视觉-语言导航（AVLN）任务中，通常采用单一粒度框架，难以平衡大规模城市环境中的全局环境推理和局部场景理解，从而限制了导航成功率。

Method: 本文提出了一种历史增强两阶段Transformer (HETT) 框架，通过粗粒度到细粒度的导航流程来整合全局推理和局部理解。具体而言，HETT首先通过融合空间地标和历史上下文预测粗粒度目标位置，然后通过细粒度视觉分析优化动作。此外，设计了一种历史网格地图，用于动态地将视觉特征聚合到结构化空间记忆中，以增强全面的场景感知。同时，手动优化了CityNav数据集的标注以提高数据质量。

Result: 在优化后的CityNav数据集上进行的实验表明，HETT框架取得了显著的性能提升。广泛的消融研究进一步验证了每个组件的有效性。

Conclusion: HETT框架通过其粗粒度到细粒度的导航策略和创新的历史网格地图，成功解决了现有AVLN智能体在平衡全局推理和局部理解方面的不足，为大规模城市环境中的无人机视觉-语言导航提供了有效的解决方案，并展现出卓越的性能。

Abstract: Aerial Vision-and-Language Navigation (AVLN) requires Unmanned Aerial Vehicle (UAV) agents to localize targets in large-scale urban environments based on linguistic instructions. While successful navigation demands both global environmental reasoning and local scene comprehension, existing UAV agents typically adopt mono-granularity frameworks that struggle to balance these two aspects. To address this limitation, this work proposes a History-Enhanced Two-Stage Transformer (HETT) framework, which integrates the two aspects through a coarse-to-fine navigation pipeline. Specifically, HETT first predicts coarse-grained target positions by fusing spatial landmarks and historical context, then refines actions via fine-grained visual analysis. In addition, a historical grid map is designed to dynamically aggregate visual features into a structured spatial memory, enhancing comprehensive scene awareness. Additionally, the CityNav dataset annotations are manually refined to enhance data quality. Experiments on the refined CityNav dataset show that HETT delivers significant performance gains, while extensive ablation studies further verify the effectiveness of each component.

</details>


### [68] [ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization](https://arxiv.org/abs/2512.14039)
*Meng Wei,Cheng Zhang,Jianmin Zheng,Hamid Rezatofighi,Jianfei Cai*

Main category: cs.CV

TL;DR: 本文通过自适应采样和误差驱动的各向异性参数化，解决了纹理化3D高斯飞溅在内存效率方面的挑战，显著提高了渲染质量与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有纹理化3D高斯飞溅方法虽然提升了外观建模和下游任务性能，但引入的纹理参数导致显著的内存效率问题。具体表现为：纹理通常在规范空间定义，导致低贡献区域的低效采样；以及纹理参数化对所有高斯统一分配，造成过度参数化。

Method: 提出了两种策略：1) 基于高斯密度分布的自适应采样，以避免在低贡献区域浪费纹理容量；2) 误差驱动的各向异性参数化，根据渲染误差分配纹理资源，实现资源优化配置。这些策略统称为ASAP纹理高斯。

Result: 所提出的ASAP纹理高斯显著改善了质量效率权衡，以更少的纹理参数实现了高保真渲染。

Conclusion: 通过自适应采样和各向异性参数化，ASAP纹理高斯有效解决了现有纹理化高斯方法中的内存效率问题，实现了更高效且高质量的3D渲染。

Abstract: Recent advances have equipped 3D Gaussian Splatting with texture parameterizations to capture spatially varying attributes, improving the performance of both appearance modeling and downstream tasks. However, the added texture parameters introduce significant memory efficiency challenges. Rather than proposing new texture formulations, we take a step back to examine the characteristics of existing textured Gaussian methods and identify two key limitations in common: (1) Textures are typically defined in canonical space, leading to inefficient sampling that wastes textures' capacity on low-contribution regions; and (2) texture parameterization is uniformly assigned across all Gaussians, regardless of their visual complexity, resulting in over-parameterization. In this work, we address these issues through two simple yet effective strategies: adaptive sampling based on the Gaussian density distribution and error-driven anisotropic parameterization that allocates texture resources according to rendering error. Our proposed ASAP Textured Gaussians, short for Adaptive Sampling and Anisotropic Parameterization, significantly improve the quality efficiency tradeoff, achieving high-fidelity rendering with far fewer texture parameters.

</details>


### [69] [OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving](https://arxiv.org/abs/2512.14044)
*Zhenguo Zhang,Haohan Zhen,Yishen Wang,Le Xu,Tianchen Deng,Xuefeng Chen,Qu Chen,Bo Zhang,Wuxiong Huang*

Main category: cs.CV

TL;DR: 本文提出OmniDrive-R1，一个用于自动驾驶的端到端视觉语言模型（VLM）框架，通过交错多模态思维链（iMCoT）和强化学习驱动的视觉定位来解决幻觉问题，无需密集标注，显著提升了推理和答案准确性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在自动驾驶等安全关键领域因物体幻觉等可靠性问题而受阻，这源于其对无基础的文本思维链（CoT）推理的依赖。现有多模态CoT方法存在感知与推理阶段解耦、无法端到端优化以及依赖昂贵的密集定位标注的缺陷。

Method: 引入OmniDrive-R1，一个通过交错多模态思维链（iMCoT）机制统一感知和推理的端到端VLM框架。核心创新是强化学习驱动的视觉定位能力，使其能够自主引导注意力并“放大”关键区域进行精细分析。这通过纯两阶段强化学习训练流程和Clip-GRPO算法实现。Clip-GRPO引入了一种无标注、基于过程的定位奖励，通过强制视觉焦点和文本推理之间的实时跨模态一致性，消除了对密集标签的需求，并避免了外部工具调用的不稳定性。

Result: 在DriveLMM-o1上的广泛实验表明，OmniDrive-R1模型取得了显著改进。与基线Qwen2.5VL-7B相比，整体推理分数从51.77%提高到80.35%，最终答案准确率从37.81%提高到73.62%。

Conclusion: OmniDrive-R1通过统一感知和推理，并利用强化学习驱动的视觉定位和无标注奖励，有效缓解了自动驾驶VLM中的物体幻觉问题，实现了性能的显著提升。

Abstract: The deployment of Vision-Language Models (VLMs) in safety-critical domains like autonomous driving (AD) is critically hindered by reliability failures, most notably object hallucination. This failure stems from their reliance on ungrounded, text-based Chain-of-Thought (CoT) reasoning.While existing multi-modal CoT approaches attempt mitigation, they suffer from two fundamental flaws: (1) decoupled perception and reasoning stages that prevent end-to-end joint optimization, and (2) reliance on expensive, dense localization labels.Thus we introduce OmniDrive-R1, an end-to-end VLM framework designed for autonomous driving, which unifies perception and reasoning through an interleaved Multi-modal Chain-of-Thought (iMCoT) mechanism. Our core innovation is an Reinforcement-driven visual grounding capability, enabling the model to autonomously direct its attention and "zoom in" on critical regions for fine-grained analysis. This capability is enabled by our pure two-stage reinforcement learning training pipeline and Clip-GRPO algorithm. Crucially, Clip-GRPO introduces an annotation-free, process-based grounding reward. This reward not only eliminates the need for dense labels but also circumvents the instability of external tool calls by enforcing real-time cross-modal consistency between the visual focus and the textual reasoning. Extensive experiments on DriveLMM-o1 demonstrate our model's significant improvements. Compared to the baseline Qwen2.5VL-7B, OmniDrive-R1 improves the overall reasoning score from 51.77% to 80.35%, and the final answer accuracy from 37.81% to 73.62%.

</details>


### [70] [SELECT: Detecting Label Errors in Real-world Scene Text Data](https://arxiv.org/abs/2512.14050)
*Wenjun Liu,Qian Wu,Yifeng Hu,Yuke Li*

Main category: cs.CV

TL;DR: SELECT是一种新颖的方法，利用多模态训练检测真实世界场景文本数据集中的标签错误，并引入SSLC模拟真实错误场景。


<details>
  <summary>Details</summary>
Motivation: 现有的方法未能有效处理真实世界场景文本数据集中存在的变长序列标签、标签序列错位和字符级错误等问题。

Method: 本文提出了SELECT方法，利用图像-文本编码器和字符级分词器进行多模态训练，以解决变长序列标签、标签序列错位和字符级错误。此外，还引入了基于相似性的序列标签损坏（SSLC）过程，在训练中故意引入错误，模拟真实世界的错误场景，该过程考虑了序列长度变化和字符间的视觉相似性。

Result: SELECT在准确性和实用性方面优于现有方法。实验结果表明，SELECT能有效检测标签错误，并提高真实世界文本数据集上的场景文本识别（STR）准确性。

Conclusion: SELECT是首个成功处理变长标签的场景文本标签错误检测方法，在检测标签错误和提升STR准确性方面表现出显著的实用性。

Abstract: We introduce SELECT (Scene tExt Label Errors deteCTion), a novel approach that leverages multi-modal training to detect label errors in real-world scene text datasets. Utilizing an image-text encoder and a character-level tokenizer, SELECT addresses the issues of variable-length sequence labels, label sequence misalignment, and character-level errors, outperforming existing methods in accuracy and practical utility. In addition, we introduce Similarity-based Sequence Label Corruption (SSLC), a process that intentionally introduces errors into the training labels to mimic real-world error scenarios during training. SSLC not only can cause a change in the sequence length but also takes into account the visual similarity between characters during corruption. Our method is the first to detect label errors in real-world scene text datasets successfully accounting for variable-length labels. Experimental results demonstrate the effectiveness of SELECT in detecting label errors and improving STR accuracy on real-world text datasets, showcasing its practical utility.

</details>


### [71] [TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs](https://arxiv.org/abs/2512.14698)
*Jun Zhang,Teng Wang,Yuying Ge,Yixiao Ge,Xinhao Li,Ying Shan,Limin Wang*

Main category: cs.CV

TL;DR: 本文为视频时间定位（VTG）任务建立了一个强大的基线，通过解决现有基准中的数据质量问题和探索算法设计原则，开发了名为TimeLens的多模态大语言模型（MLLMs），并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在各种视频理解任务中表现出色，但针对视频时间定位（VTG）的优化方法尚未得到充分探索。此外，现有VTG基准存在严重的质量问题，导致评估不可靠。

Method: 研究从两个主要维度进行：数据质量和算法设计。在数据质量方面，重新标注了三个流行基准以创建TimeLens-Bench，并使用自动化重新标注流程生成了高质量训练数据集TimeLens-100K。在算法设计方面，探索了交错文本编码表示时间、采用无思考可验证奖励强化学习（RLVR）作为训练范式，并设计了RLVR训练策略。

Result: 对TimeLens-Bench的分析揭示了模型排名的显著变化，证实了先前评估标准的不可靠性。基于所建立的数据基础和算法设计，TimeLens模型在开源模型中实现了最先进的VTG性能，甚至超越了GPT-5和Gemini-2.5-Flash等专有模型。

Conclusion: TimeLens为视频时间定位任务提供了一个直接、增量但至关重要的基线，强调了数据质量和有效的算法设计对构建强大VTG能力的MLLMs的重要性。所有代码、数据和模型将公开发布以促进未来研究。

Abstract: This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data quality and algorithmic design. We first expose critical quality issues in existing VTG benchmarks and introduce TimeLens-Bench, comprising meticulously re-annotated versions of three popular benchmarks with strict quality criteria. Our analysis reveals dramatic model re-rankings compared to legacy benchmarks, confirming the unreliability of prior evaluation standards. We also address noisy training data through an automated re-annotation pipeline, yielding TimeLens-100K, a large-scale, high-quality training dataset. Building on our data foundation, we conduct in-depth explorations of algorithmic design principles, yielding a series of meaningful insights and effective yet efficient practices. These include interleaved textual encoding for time representation, a thinking-free reinforcement learning with verifiable rewards (RLVR) approach as the training paradigm, and carefully designed recipes for RLVR training. These efforts culminate in TimeLens models, a family of MLLMs with state-of-the-art VTG performance among open-source models and even surpass proprietary models such as GPT-5 and Gemini-2.5-Flash. All codes, data, and models will be released to facilitate future research.

</details>


### [72] [HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices](https://arxiv.org/abs/2512.14052)
*HyperAI Team,Yuchen Liu,Kaiyang Han,Zhiqiang Xia,Yuhang Dong,Chen Song,Kangyu Tang,Jiaming Xu,Xiushi Feng,WenXuan Yu,Li Peng,Mingyang Wang,Kai Wang,Changpeng Yang,Yang Li,Haoyu Lu,Hao Wang,Bingna Xu,Guangyao Liu,Long Huang,Kaibin Guo,Jinyang Wu,Dan Wu,Hongzhen Wang,Peng Zhou,Shuai Nie,Shande Wang,Runyu Shi,Ying Huang*

Main category: cs.CV

TL;DR: HyperVL是一个为设备端推理量身定制的高效多模态大语言模型，通过图像分块、自适应分辨率压缩和双重一致性学习，显著降低了延迟和功耗，同时保持了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）计算和内存需求高，难以直接部署在设备端。特别是，标准Vision Transformer (ViT) 编码器在处理高分辨率输入时，延迟和内存消耗过大，成为关键瓶颈。

Method: 本文提出了HyperVL，一个高效的多模态大语言模型，包含：1) 图像分块策略，以限制峰值内存使用；2) 视觉分辨率压缩器 (VRC)，自适应预测最优编码分辨率以消除冗余计算；3) 双重一致性学习 (DCL)，在统一框架下对齐多尺度ViT编码器，实现共享LLM下视觉分支的动态切换。

Result: HyperVL在多个基准测试中，于同等大小模型中实现了最先进的性能。此外，它在真实移动设备上显著降低了延迟和功耗。

Conclusion: HyperVL证明了其在设备端多模态推理方面的实用性，通过创新的技术有效解决了现有MLLMs在设备端部署的挑战。

Abstract: Current multimodal large lanauge models possess strong perceptual and reasoning capabilities, however high computational and memory requirements make them difficult to deploy directly on on-device environments. While small-parameter models are progressively endowed with strong general capabilities, standard Vision Transformer (ViT) encoders remain a critical bottleneck, suffering from excessive latency and memory consumption when processing high-resolution inputs.To address these challenges, we introduce HyperVL, an efficient multimodal large language model tailored for on-device inference. HyperVL adopts an image-tiling strategy to cap peak memory usage and incorporates two novel techniques: (1) a Visual Resolution Compressor (VRC) that adaptively predicts optimal encoding resolutions to eliminate redundant computation, and (2) Dual Consistency Learning (DCL), which aligns multi-scale ViT encoders within a unified framework, enabling dynamic switching between visual branches under a shared LLM. Extensive experiments demonstrate that HyperVL achieves state-of-the-art performance among models of comparable size across multiple benchmarks. Furthermore, it significantly significantly reduces latency and power consumption on real mobile devices, demonstrating its practicality for on-device multimodal inference.

</details>


### [73] [ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning](https://arxiv.org/abs/2512.14040)
*Boran Wang,Xinming Wang,Yi Chen,Xiang Li,Jian Xu,Jing Yuan,Chenglin Liu*

Main category: cs.CV

TL;DR: ChartAgent是一个基于工具集成推理（TIR）的图表理解框架，它通过分解复杂任务并动态编排模块化工具库，显著提高了在稀疏标注环境下图表理解的鲁棒性，并提供了可追溯的证据包。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言大模型（MLLMs）在图表理解方面严重依赖显式文本标注，并且在关键数字缺失时性能显著下降。这限制了它们在实际应用中的有效性。

Method: ChartAgent采用工具集成推理（TIR）框架，将复杂的图表分析分解为一系列可观察、可重放的步骤。它包含一个可扩展的模块化工具库（如关键元素检测、实例分割、OCR），代理会动态编排这些工具以实现系统性的视觉解析。通过将中间输出整合为结构化的“证据包”，实现了透明性和可验证性。

Result: 实验表明，ChartAgent在稀疏标注设置下显著提高了鲁棒性，有效解决了当前MLLM的局限性。

Conclusion: ChartAgent为构建可信赖和可扩展的图表理解系统提供了一条实用的途径，克服了现有模型对文本标注的过度依赖和在数据稀疏环境下的性能下降问题。

Abstract: With their high information density and intuitive readability, charts have become the de facto medium for data analysis and communication across disciplines. Recent multimodal large language models (MLLMs) have made notable progress in automated chart understanding, yet they remain heavily dependent on explicit textual annotations and the performance degrades markedly when key numerals are absent. To address this limitation, we introduce ChartAgent, a chart understanding framework grounded in Tool-Integrated Reasoning (TIR). Inspired by human cognition, ChartAgent decomposes complex chart analysis into a sequence of observable, replayable steps. Supporting this architecture is an extensible, modular tool library comprising more than a dozen core tools, such as keyelement detection, instance segmentation, and optical character recognition (OCR), which the agent dynamically orchestrates to achieve systematic visual parsing across diverse chart types. Leveraging TIRs transparency and verifiability, ChartAgent moves beyond the black box paradigm by standardizing and consolidating intermediate outputs into a structured Evidence Package, providing traceable and reproducible support for final conclusions. Experiments show that ChartAgent substantially improves robustness under sparse annotation settings, offering a practical path toward trustworthy and extensible systems for chart understanding.

</details>


### [74] [Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning](https://arxiv.org/abs/2512.14058)
*Zulin Zhuang,Yu Bian*

Main category: cs.CV

TL;DR: 本研究提出了一种多模态深度学习框架，通过非侵入式图像实时预测室内工作面照度分布，特别关注侧窗区域特征，实现了高精度和可接受的时间泛化能力。


<details>
  <summary>Details</summary>
Motivation: 日光联动控制（DLCs）在建筑节能方面潜力巨大，但需要实时准确预测室内照度。现有室内日光预测研究多针对静态场景，难以应用于动态变化的室内空间。

Method: 开发了一个多模态深度学习框架，利用具有时空特征的非侵入式图像实时预测室内工作面照度分布。该方法仅从侧窗区域而非室内像素提取图像特征，使其适用于动态占用的室内空间。在广州的一个测试房间进行了现场实验，收集了17,344个样本用于模型训练和验证。

Result: 模型在同分布测试集上取得了R2 > 0.98、RMSE < 0.14的性能，在未见日期测试集上取得了R2 > 0.82、RMSE < 0.17的性能，表明其高精度和可接受的时间泛化能力。

Conclusion: 该深度学习框架能够高精度地实时预测室内工作面照度，并在时间上具有良好的泛化能力，适用于动态占用的室内空间，有望显著提升日光联动控制系统的节能潜力。

Abstract: Daylight-linked controls (DLCs) have significant potential for energy savings in buildings, especially when abundant daylight is available and indoor workplane illuminance can be accurately predicted in real time. Most existing studies on indoor daylight predictions were developed and tested for static scenes. This study proposes a multimodal deep learning framework that predicts indoor workplane illuminance distributions in real time from non-intrusive images with temporal-spatial features. By extracting image features only from the side-lit window areas rather than interior pixels, the approach remains applicable in dynamically occupied indoor spaces. A field experiment was conducted in a test room in Guangzhou (China), where 17,344 samples were collected for model training and validation. The model achieved R2 > 0.98 with RMSE < 0.14 on the same-distribution test set and R2 > 0.82 with RMSE < 0.17 on an unseen-day test set, indicating high accuracy and acceptable temporal generalization.

</details>


### [75] [FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling](https://arxiv.org/abs/2512.14056)
*Kim Sung-Bin,Joohyun Chang,David Harwath,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: 本文提出了一种统一的语音条件面部运动填充框架，将说话人脸编辑和生成视为其子任务，并引入了FacEDiT模型和FacEDiTBench数据集。


<details>
  <summary>Details</summary>
Motivation: 说话人脸编辑和生成通常被视为独立问题，缺乏一个统一的框架来处理这两种任务。

Method: 提出FacEDiT，一个基于流匹配训练的语音条件Diffusion Transformer。它采用自监督的预训练任务（面部运动填充），灵感来源于掩码自编码器，学习在周围运动和语音条件下合成被掩码的面部运动。模型还结合了偏置注意力（biased attention）和时间平滑约束（temporal smoothness constraints）以增强边界连续性和唇同步。此外，论文还引入了FacEDiTBench数据集和新的评估指标。

Result: FacEDiT能够实现局部生成和编辑（替换、插入、删除），确保与未编辑区域的无缝过渡，同时保持身份一致性和视觉平滑性。它在说话人脸生成任务上也表现出良好的泛化能力，证明了编辑和生成确实是语音条件运动填充的子任务。

Conclusion: 说话人脸编辑和生成可以有效地作为语音条件面部运动填充的子任务来解决，FacEDiT模型验证了这一统一公式的有效性，并能生成准确、与语音对齐的面部编辑，同时保持强大的身份和视觉连续性。

Abstract: Talking face editing and face generation have often been studied as distinct problems. In this work, we propose viewing both not as separate tasks but as subtasks of a unifying formulation, speech-conditional facial motion infilling. We explore facial motion infilling as a self-supervised pretext task that also serves as a unifying formulation of dynamic talking face synthesis. To instantiate this idea, we propose FacEDiT, a speech-conditional Diffusion Transformer trained with flow matching. Inspired by masked autoencoders, FacEDiT learns to synthesize masked facial motions conditioned on surrounding motions and speech. This formulation enables both localized generation and edits, such as substitution, insertion, and deletion, while ensuring seamless transitions with unedited regions. In addition, biased attention and temporal smoothness constraints enhance boundary continuity and lip synchronization. To address the lack of a standard editing benchmark, we introduce FacEDiTBench, the first dataset for talking face editing, featuring diverse edit types and lengths, along with new evaluation metrics. Extensive experiments validate that talking face editing and generation emerge as subtasks of speech-conditional motion infilling; FacEDiT produces accurate, speech-aligned facial edits with strong identity preservation and smooth visual continuity while generalizing effectively to talking face generation.

</details>


### [76] [ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes](https://arxiv.org/abs/2512.14092)
*Felix Holm,Ghazal Ghazaei,Nassir Navab*

Main category: cs.CV

TL;DR: ProtoFlow是一种新颖的框架，通过学习动态场景图原型来建模复杂的 surgical workflow，它结合了鲁棒的表示学习和固有的可解释性，在数据稀缺场景下表现出色，并能提供清晰的手术洞察。


<details>
  <summary>Details</summary>
Motivation: AI辅助手术中的精细手术识别至关重要，但面临高昂的标注成本、数据稀缺以及缺乏可解释模型等挑战。虽然场景图为手术事件提供了结构化抽象，但其潜力尚未完全发挥。

Method: ProtoFlow利用图神经网络（GNN）编码器-解码器架构，结合自监督预训练以学习丰富的表示，并进行基于原型的微调。此过程发现并完善核心原型，这些原型封装了重复出现的、具有临床意义的手术交互模式，为工作流分析提供了可解释的基础。

Result: 在CAT-SG数据集上的评估显示，ProtoFlow不仅在整体准确性上优于标准GNN基线，而且在数据受限、少样本场景中表现出卓越的鲁棒性，即使只用一个手术视频进行训练也能保持强大性能。定性分析进一步表明，学习到的原型成功识别了不同的手术子技术，并为工作流偏差和罕见并发症提供了清晰、可解释的见解。

Conclusion: ProtoFlow通过将鲁棒的表示学习与固有的可解释性相结合，在开发更透明、可靠和数据高效的AI系统方面迈出了重要一步，加速了其在手术训练、实时决策支持和工作流优化中的临床应用潜力。

Abstract: Purpose: Detailed surgical recognition is critical for advancing AI-assisted surgery, yet progress is hampered by high annotation costs, data scarcity, and a lack of interpretable models. While scene graphs offer a structured abstraction of surgical events, their full potential remains untapped. In this work, we introduce ProtoFlow, a novel framework that learns dynamic scene graph prototypes to model complex surgical workflows in an interpretable and robust manner.
  Methods: ProtoFlow leverages a graph neural network (GNN) encoder-decoder architecture that combines self-supervised pretraining for rich representation learning with a prototype-based fine-tuning stage. This process discovers and refines core prototypes that encapsulate recurring, clinically meaningful patterns of surgical interaction, forming an explainable foundation for workflow analysis.
  Results: We evaluate our approach on the fine-grained CAT-SG dataset. ProtoFlow not only outperforms standard GNN baselines in overall accuracy but also demonstrates exceptional robustness in limited-data, few-shot scenarios, maintaining strong performance when trained on as few as one surgical video. Our qualitative analyses further show that the learned prototypes successfully identify distinct surgical sub-techniques and provide clear, interpretable insights into workflow deviations and rare complications.
  Conclusion: By uniting robust representation learning with inherent explainability, ProtoFlow represents a significant step toward developing more transparent, reliable, and data-efficient AI systems, accelerating their potential for clinical adoption in surgical training, real-time decision support, and workflow optimization.

</details>


### [77] [CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives](https://arxiv.org/abs/2512.14696)
*Zihan Wang,Jiashun Wang,Jeff Tan,Yiwen Zhao,Jessica Hodgins,Shubham Tulsiani,Deva Ramanan*

Main category: cs.CV

TL;DR: CRISP是一种从单目视频中恢复可模拟人体运动和场景几何的方法，通过拟合平面基元、利用人-场景接触建模，并结合强化学习来确保物理真实性，显著降低了运动跟踪失败率并提高了模拟效率。


<details>
  <summary>Details</summary>
Motivation: 现有的人体-场景联合重建方法依赖于数据驱动的先验知识和联合优化，缺乏物理约束，或重建的几何体噪声大、存在伪影，导致在涉及场景交互的运动跟踪策略中失败。

Method: CRISP通过以下方式实现：1) 将平面基元拟合到场景点云重建中，利用深度、法线和光流的简单聚类管道来恢复凸、干净且可模拟的几何体。2) 利用人-场景接触建模（例如，通过人体姿态推断被遮挡的椅子座位）来重建可能被遮挡的场景几何体。3) 通过使用重建结果驱动强化学习中的人形控制器，确保人体和场景重建的物理合理性。

Result: CRISP在以人为中心的视频基准（EMDB、PROX）上，将运动跟踪失败率从55.2%降低到6.9%，同时将强化学习模拟吞吐量提高了43%。该方法还在包括随意拍摄视频、互联网视频甚至Sora生成视频在内的真实世界视频上得到了验证。

Conclusion: CRISP能够大规模生成物理有效的人体运动和交互环境，极大地推动了机器人和AR/VR领域的“真实世界到模拟”应用。

Abstract: We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of the scene, via a simple clustering pipeline over depth, normals, and flow. To reconstruct scene geometry that might be occluded during interactions, we make use of human-scene contact modeling (e.g., we use human posture to reconstruct the occluded seat of a chair). Finally, we ensure that human and scene reconstructions are physically-plausible by using them to drive a humanoid controller via reinforcement learning. Our approach reduces motion tracking failure rates from 55.2\% to 6.9\% on human-centric video benchmarks (EMDB, PROX), while delivering a 43\% faster RL simulation throughput. We further validate it on in-the-wild videos including casually-captured videos, Internet videos, and even Sora-generated videos. This demonstrates CRISP's ability to generate physically-valid human motion and interaction environments at scale, greatly advancing real-to-sim applications for robotics and AR/VR.

</details>


### [78] [Bridging Fidelity-Reality with Controllable One-Step Diffusion for Image Super-Resolution](https://arxiv.org/abs/2512.14061)
*Hao Chen,Junyang Chen,Jinshan Pan,Jiangxin Dong*

Main category: cs.CV

TL;DR: 本文提出CODSR，一种可控的一步扩散网络，用于图像超分辨率，通过解决现有方法在保真度、生成先验激活和文本提示对齐方面的局限性，实现了卓越的感知质量和竞争性保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型一步超分辨率方法存在三个主要局限性：1) 低质量（LQ）输入压缩编码导致信息丢失，影响保真度；2) 生成先验的区域判别性激活不足；3) 文本提示与其语义区域之间存在错位。

Method: 本文提出CODSR，包含三个核心组件：1) LQ引导的特征调制模块，利用原始未压缩的LQ信息提供高保真度条件；2) 区域自适应生成先验激活方法，在不牺牲局部结构保真度的情况下增强感知丰富度；3) 文本匹配引导策略，充分利用文本提示的条件潜力。

Result: 广泛的实验表明，CODSR在高效的一步推理下，与现有最先进方法相比，实现了卓越的感知质量和具有竞争力的保真度。

Conclusion: CODSR通过创新的模块有效解决了现有扩散模型一步超分辨率方法的关键局限性，在图像超分辨率领域取得了领先的性能，特别是在感知质量和保真度方面。

Abstract: Recent diffusion-based one-step methods have shown remarkable progress in the field of image super-resolution, yet they remain constrained by three critical limitations: (1) inferior fidelity performance caused by the information loss from compression encoding of low-quality (LQ) inputs; (2) insufficient region-discriminative activation of generative priors; (3) misalignment between text prompts and their corresponding semantic regions. To address these limitations, we propose CODSR, a controllable one-step diffusion network for image super-resolution. First, we propose an LQ-guided feature modulation module that leverages original uncompressed information from LQ inputs to provide high-fidelity conditioning for the diffusion process. We then develop a region-adaptive generative prior activation method to effectively enhance perceptual richness without sacrificing local structural fidelity. Finally, we employ a text-matching guidance strategy to fully harness the conditioning potential of text prompts. Extensive experiments demonstrate that CODSR achieves superior perceptual quality and competitive fidelity compared with state-of-the-art methods with efficient one-step inference.

</details>


### [79] [GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants](https://arxiv.org/abs/2512.14087)
*Yang Yang,Risa Shinoda,Hiroaki Santo,Fumio Okura*

Main category: cs.CV

TL;DR: 本文提出了一种名为GaussianPlant的分层3D高斯泼溅（3DGS）方法，用于从多视角图像中联合恢复植物的外观和内部结构，实现了高保真外观和精确结构重建。


<details>
  <summary>Details</summary>
Motivation: 传统的3DGS在场景外观重建方面表现出色，但缺乏底层的结构表示（例如植物的分支模式），这限制了其在植物表型分析等任务中的应用。

Method: GaussianPlant引入了分层3DGS表示，将结构和外观解耦。它使用结构基元（StPs）明确表示分支（建模为圆柱体）和叶子（建模为圆盘）的几何形状，并使用外观基元（ApPs，即3D高斯）表示植物的外观。StP的属性（分支或叶子）通过自组织方式优化。ApPs绑定到每个StP以表示其外观。StPs和ApPs通过重渲染损失和ApP到StP的梯度流进行联合优化。

Result: 实验结果表明，GaussianPlant通过ApPs实现了高保真外观重建，并通过StPs实现了准确的结构重建，从而能够提取分支结构和叶子实例。定性和真实世界的实验验证了其重建精度和实际性能。

Conclusion: GaussianPlant成功地解决了从多视角图像中联合恢复植物高保真外观和精确内部结构的问题，为植物表型分析等应用提供了有力的工具。

Abstract: We present a method for jointly recovering the appearance and internal structure of botanical plants from multi-view images based on 3D Gaussian Splatting (3DGS). While 3DGS exhibits robust reconstruction of scene appearance for novel-view synthesis, it lacks structural representations underlying those appearances (e.g., branching patterns of plants), which limits its applicability to tasks such as plant phenotyping. To achieve both high-fidelity appearance and structural reconstruction, we introduce GaussianPlant, a hierarchical 3DGS representation, which disentangles structure and appearance. Specifically, we employ structure primitives (StPs) to explicitly represent branch and leaf geometry, and appearance primitives (ApPs) to the plants' appearance using 3D Gaussians. StPs represent a simplified structure of the plant, i.e., modeling branches as cylinders and leaves as disks. To accurately distinguish the branches and leaves, StP's attributes (i.e., branches or leaves) are optimized in a self-organized manner. ApPs are bound to each StP to represent the appearance of branches or leaves as in conventional 3DGS. StPs and ApPs are jointly optimized using a re-rendering loss on the input multi-view images, as well as the gradient flow from ApP to StP using the binding correspondence information. We conduct experiments to qualitatively evaluate the reconstruction accuracy of both appearance and structure, as well as real-world experiments to qualitatively validate the practical performance. Experiments show that the GaussianPlant achieves both high-fidelity appearance reconstruction via ApPs and accurate structural reconstruction via StPs, enabling the extraction of branch structure and leaf instances.

</details>


### [80] [SDAR-VL: Stable and Efficient Block-wise Diffusion for Vision-Language Understanding](https://arxiv.org/abs/2512.14068)
*Shuang Cheng,Yuhua Jiang,Zineng Zhou,Dawei Liu,Wang Tao,Linfeng Zhang,Biqing Qi,Bowen Zhou*

Main category: cs.CV

TL;DR: SDAR-VL 提出了一种高效稳定的训练框架，首次将块级离散扩散系统地应用于大规模视觉语言理解（VLU），在性能上超越了现有扩散模型并与强大的自回归基线持平或更优。


<details>
  <summary>Details</summary>
Motivation: 块级离散扩散在并行生成和因果依赖建模之间取得了良好平衡，有望成为视觉语言建模的骨干。然而，其高昂的训练成本、缓慢的收敛速度和不稳定性限制了其实际应用，使其落后于强大的自回归（AR）基线。

Method: 本文提出了 SDAR-VL，一个用于高效稳定训练的集成框架，包含三个核心组件：(1) 异步块级噪声调度，用于在每个批次内实现监督多样化；(2) 有效掩码比例缩放，用于在随机掩码下实现无偏损失归一化；(3) 渐进式 Beta 噪声课程，用于在保持损坏多样性的同时增加有效掩码覆盖率。

Result: 在21个单图像、多图像和视频基准测试中，SDAR-VL 显著提高了训练效率、收敛稳定性和任务性能，超越了传统的块扩散模型。在评估套件上，SDAR-VL 在基于扩散的视觉语言模型中创造了新的最先进记录，并在相同设置下，与 LLaVA-OneVision 等强大的 AR 基线以及全局扩散基线 LLaDA-V 持平或超越。

Conclusion: SDAR-VL 成功将块级离散扩散确立为 VLU 的实用骨干模型，解决了其在训练成本、收敛和稳定性方面的挑战，使其在视觉语言理解任务中具有竞争力。

Abstract: Block-wise discrete diffusion offers an attractive balance between parallel generation and causal dependency modeling, making it a promising backbone for vision-language modeling. However, its practical adoption has been limited by high training cost, slow convergence, and instability, which have so far kept it behind strong autoregressive (AR) baselines. We present \textbf{SDAR-VL}, the first systematic application of block-wise discrete diffusion to large-scale vision-language understanding (VLU), together with an \emph{integrated framework for efficient and stable training}. This framework unifies three components: (1) \textbf{Asynchronous Block-wise Noise Scheduling} to diversify supervision within each batch; (2) \textbf{Effective Mask Ratio Scaling} for unbiased loss normalization under stochastic masking; and (3) a \textbf{Progressive Beta Noise Curriculum} that increases effective mask coverage while preserving corruption diversity. Experiments on 21 single-image, multi-image, and video benchmarks show that SDAR-VL consistently improves \emph{training efficiency}, \emph{convergence stability}, and \emph{task performance} over conventional block diffusion. On this evaluation suite, SDAR-VL sets a new state of the art among diffusion-based vision-language models and, under matched settings, matches or surpasses strong AR baselines such as LLaVA-OneVision as well as the global diffusion baseline LLaDA-V, establishing block-wise diffusion as a practical backbone for VLU.

</details>


### [81] [AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation](https://arxiv.org/abs/2512.14095)
*Sisi Dai,Kai Xu*

Main category: cs.CV

TL;DR: AnchorHOI是一个新颖的框架，通过结合视频和图像扩散模型的混合先验，并引入锚点蒸馏策略（包括锚点NeRFs和锚点关键点），以可控的两步过程指导零样本4D人-物交互（HOI）生成，显著提升了多样性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的监督式4D HOI生成方法受限于大规模数据集的稀缺性，可扩展性有限。尽管零样本方法尝试利用预训练图像扩散模型，但交互线索提取不足，限制了其在多样化场景中的适用性。

Method: 本文提出了AnchorHOI框架，通过结合视频扩散模型和图像扩散模型的混合先验来推进4D HOI生成。为解决高维4D HOI优化难题，AnchorHOI引入了一种基于锚点的先验蒸馏策略，构建交互感知锚点并分两步指导生成。具体设计了两种锚点：用于表达性交互组合的锚点神经辐射场（NeRFs）和用于真实感运动合成的锚点关键点。

Result: 广泛的实验证明，AnchorHOI在多样性和泛化能力方面均优于现有方法。

Conclusion: AnchorHOI通过充分利用混合先验和创新的锚点蒸馏策略，有效地解决了4D HOI生成中的挑战，实现了更具多样性和泛化性的生成结果。

Abstract: Despite significant progress in text-driven 4D human-object interaction (HOI) generation with supervised methods, the scalability remains limited by the scarcity of large-scale 4D HOI datasets. To overcome this, recent approaches attempt zero-shot 4D HOI generation with pre-trained image diffusion models. However, interaction cues are minimally distilled during the generation process, restricting their applicability across diverse scenarios. In this paper, we propose AnchorHOI, a novel framework that thoroughly exploits hybrid priors by incorporating video diffusion models beyond image diffusion models, advancing 4D HOI generation. Nevertheless, directly optimizing high-dimensional 4D HOI with such priors remains challenging, particularly for human pose and compositional motion. To address this challenge, AnchorHOI introduces an anchor-based prior distillation strategy, which constructs interaction-aware anchors and then leverages them to guide generation in a tractable two-step process. Specifically, two tailored anchors are designed for 4D HOI generation: anchor Neural Radiance Fields (NeRFs) for expressive interaction composition, and anchor keypoints for realistic motion synthesis. Extensive experiments demonstrate that AnchorHOI outperforms previous methods with superior diversity and generalization.

</details>


### [82] [Quality-Aware Framework for Video-Derived Respiratory Signals](https://arxiv.org/abs/2512.14093)
*Nhi Nguyen,Constantino Álvarez Casado,Le Nguyen,Manuel Lage Cañellas,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 该研究提出一个预测性、质量感知的框架，通过整合多种信号源并动态评估其可靠性，提高了基于视频的呼吸频率（RR）估计的准确性，并优于单一方法。


<details>
  <summary>Details</summary>
Motivation: 基于视频的呼吸频率（RR）估计由于信号质量的不一致性而常常不可靠。现有方法在信号提取和处理上存在局限性，需要一种更稳健、更普适的解决方案。

Method: 该框架从面部远程光电容积描记（rPPG）、上半身运动和深度学习管道中提取十种信号。这些信号通过四种频谱估计器（Welch法、MUSIC、FFT、峰值检测）进行分析。利用分段级质量指标训练机器学习模型，以预测准确性或选择最可靠的信号，从而实现自适应信号融合和基于质量的分段过滤。

Result: 在三个公共数据集（OMuSense-23, COHFACE, MAHNOB-HCI）上的实验表明，该框架在大多数情况下比单一方法实现了更低的RR估计误差，性能提升取决于数据集特性。

Conclusion: 研究结果强调了质量驱动的预测建模在提供可扩展和通用视频呼吸监测解决方案方面的潜力。

Abstract: Video-based respiratory rate (RR) estimation is often unreliable due to inconsistent signal quality across extraction methods. We present a predictive, quality-aware framework that integrates heterogeneous signal sources with dynamic assessment of reliability. Ten signals are extracted from facial remote photoplethysmography (rPPG), upper-body motion, and deep learning pipelines, and analyzed using four spectral estimators: Welch's method, Multiple Signal Classification (MUSIC), Fast Fourier Transform (FFT), and peak detection. Segment-level quality indices are then used to train machine learning models that predict accuracy or select the most reliable signal. This enables adaptive signal fusion and quality-based segment filtering. Experiments on three public datasets (OMuSense-23, COHFACE, MAHNOB-HCI) show that the proposed framework achieves lower RR estimation errors than individual methods in most cases, with performance gains depending on dataset characteristics. These findings highlight the potential of quality-driven predictive modeling to deliver scalable and generalizable video-based respiratory monitoring solutions.

</details>


### [83] [Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach](https://arxiv.org/abs/2512.14113)
*Ashish Mishra,Gyanaranjan Nayak,Tarun Kumar,Arpit Shah,Suparna Bhattacharya,Martin Foltin*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的、无需训练和数据的遗忘框架，用于从CLIP等预训练模型中移除特定对象类别知识，同时不影响其他任务，并支持全局、域特定和选择性域的多种遗忘范式。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等预训练模型在零样本分类方面表现出色，但实际应用常需要移除（或“遗忘”）特定对象类别，且不需额外数据、不重新训练、不影响模型在无关任务上的性能。现有方法通常依赖于重新训练，效率低下。

Method: 该方法是一个无需训练和数据的遗忘框架，通过协同整合文本提示和从CLIP联合嵌入空间合成的视觉原型，利用多模态空值空间（multimodal nullspace）实现知识移除。它支持三种遗忘范式：1) 全局遗忘选定对象；2) 域特定知识移除（例如，移除草图表示但保留照片识别）；3) 在选择性域中完全遗忘。

Result: 该方法能够高效地移除不需要的类别信息，同时保留其余知识。它克服了现有基于重新训练方法的局限性，并提供了一种灵活且计算高效的受控模型遗忘解决方案。

Conclusion: 本文提出的框架为受控模型遗忘提供了一个灵活且计算高效的解决方案，能够无需训练和数据地从预训练模型中移除特定知识，同时保持模型在其他任务上的性能。

Abstract: Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or "unlearning") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.

</details>


### [84] [SportsGPT: An LLM-driven Framework for Interpretable Sports Motion Assessment and Training Guidance](https://arxiv.org/abs/2512.14121)
*Wenbo Tian,Ruting Lin,Hongxian Zheng,Yaodong Yang,Geng Wu,Zihao Zhang,Zhang Zhang*

Main category: cs.CV

TL;DR: SportsGPT是一个LLM驱动的智能体育分析框架，通过运动时间序列输入，提供可解释的运动评估和专业的训练指导，形成一个闭环系统。


<details>
  <summary>Details</summary>
Motivation: 现有智能体育分析系统主要关注“得分和可视化”，缺乏自动性能诊断和可解释的训练指导。大型语言模型（LMMs）和运动分析技术的最新进展为解决这些局限性提供了新机遇。

Method: 该研究提出了SportsGPT框架：首先，引入MotionDTW，一个两阶段时间序列对齐算法，用于从骨骼运动序列中准确提取关键帧；其次，设计了KISMAM（基于知识的可解释体育运动评估模型），通过对比关键帧与高质量目标模型来获取可解释的评估指标；最后，提出了SportsRAG，一个基于Qwen3的RAG训练指导模型，利用6B令牌知识库和领域特定问答对来生成专业的训练指导。

Result: 实验结果表明，MotionDTW在时间误差和IoU分数上显著优于传统方法。此外，消融研究验证了KISMAM和SportsRAG的有效性，确认SportsGPT在诊断准确性和专业性方面超越了通用LLM。

Conclusion: SportsGPT成功建立了一个从运动时间序列输入到专业训练指导的闭环，提供了可解释的运动评估和有效的训练指导，解决了现有系统在自动诊断和可解释性方面的不足。

Abstract: Existing intelligent sports analysis systems mainly focus on "scoring and visualization," often lacking automatic performance diagnosis and interpretable training guidance. Recent advances of Large Language Models (LMMs) and motion analysis techniques provide new opportunities to address the above limitations. In this paper, we propose SportsGPT, an LLM-driven framework for interpretable sports motion assessment and training guidance, which establishes a closed loop from motion time-series input to professional training guidance. First, given a set of high-quality target models, we introduce MotionDTW, a two-stage time series alignment algorithm designed for accurate keyframe extraction from skeleton-based motion sequences. Subsequently, we design a Knowledge-based Interpretable Sports Motion Assessment Model (KISMAM) to obtain a set of interpretable assessment metrics (e.g., insufficient extension) by constrasting the keyframes with the targe models. Finally, we propose SportsRAG, a RAG-based training guidance model based on Qwen3. Leveraging a 6B-token knowledge base, it prompts the LLM to generate professional training guidance by retrieving domain-specific QA pairs. Experimental results demonstrate that MotionDTW significantly outperforms traditional methods with lower temporal error and higher IoU scores. Furthermore, ablation studies validate the KISMAM and SportsRAG, confirming that SportsGPT surpasses general LLMs in diagnostic accuracy and professionalism.

</details>


### [85] [Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries](https://arxiv.org/abs/2512.14102)
*Emanuele Mezzi,Gertjan Burghouts,Maarten Kruithof*

Main category: cs.CV

TL;DR: RUNE是一种结合大语言模型（LLMs）和神经符号AI的新方法，通过将文本查询转换为一阶逻辑（FOL）表达式，并对遥感图像中的检测实体进行推理，解决了现有遥感大型视觉语言模型（RS-LVLMs）在文本到图像检索中解释性差和处理复杂空间关系能力弱的问题，实现了性能、鲁棒性和可解释性的提升。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感大型视觉语言模型（RS-LVLMs）在遥感文本到图像检索中，面临解释性有限和处理复杂空间关系能力不足的关键挑战，这限制了它们在实际应用中的潜力。

Method: RUNE方法通过以下步骤实现：1) 利用LLMs将文本查询转换为一阶逻辑（FOL）表达式。2) 结合神经符号AI，通过推理检测实体与FOL表达式之间的兼容性来检索图像。3) 采用逻辑分解策略以提高可扩展性和执行效率。4) 重新利用DOTA数据集，并通过更复杂的查询进行增强，以进行评估。5) 引入两种新指标：查询复杂性检索鲁棒性（RRQC）和图像不确定性检索鲁棒性（RRIU）。

Result: 研究结果表明：1) LLM在文本到逻辑转换方面表现出有效性。2) RUNE在复杂遥感检索任务中，相对于最先进的RS-LVLMs展现出卓越的性能。3) RUNE在性能、鲁棒性和可解释性方面均有提升。4) 通过洪水后卫星图像检索用例，展示了RUNE在实际遥感应用中的潜力。

Conclusion: RUNE通过结合LLMs和神经符号AI，提供了一种在遥感文本到图像检索中具有卓越性能、鲁棒性和可解释性的新范式，尤其擅长处理复杂查询，并展现了在真实世界遥感应用中的巨大潜力。

Abstract: Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.

</details>


### [86] [OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration](https://arxiv.org/abs/2512.14096)
*Ruitong Sun,Tianze Yang,Wei Niu,Jin Sun*

Main category: cs.CV

TL;DR: 本文提出OUSAC框架，通过优化引导调度和自适应缓存，显著加速扩散Transformer模型，同时提升生成质量，在多个模型上实现大幅计算节省和性能提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型计算成本高昂，尤其是在使用分类器自由引导（CFG）时，每次迭代需要两次前向传播，计算量翻倍。研究旨在加速扩散模型的生成过程，同时保持或提高图像质量。

Method: OUSAC框架采用两阶段方法：
1. 关键洞察：可变引导尺度允许稀疏计算，即在某些时间步跳过CFG可以通过调整其他时间步的引导尺度来补偿，从而减少总采样步数和CFG步数。
2. 第一阶段：使用进化算法联合优化跳过的CFG时间步和使用的引导尺度，最多消除82%的无条件传播。
3. 第二阶段：引入自适应秩分配，针对每个Transformer块调整校准工作，在可变引导条件下保持缓存的有效性。

Result: OUSAC显著优于现有加速方法：
- 在DiT-XL/2（ImageNet 512x512）上，实现53%的计算节省和15%的质量提升。
- 在PixArt-alpha（MSCOCO）上，实现60%的计算节省和16.1%的质量提升。
- 在FLUX上，实现5倍加速，并提高CLIP分数超过50步基线。

Conclusion: OUSAC通过系统优化引导调度和自适应缓存，成功加速了扩散Transformer模型，并在保持或提高生成质量的同时，实现了显著的计算节省，证明了其在多种扩散模型中的有效性和优越性。

Abstract: Diffusion models have emerged as the dominant paradigm for high-quality image generation, yet their computational expense remains substantial due to iterative denoising. Classifier-Free Guidance (CFG) significantly enhances generation quality and controllability but doubles the computation by requiring both conditional and unconditional forward passes at every timestep. We present OUSAC (Optimized gUidance Scheduling with Adaptive Caching), a framework that accelerates diffusion transformers (DiT) through systematic optimization. Our key insight is that variable guidance scales enable sparse computation: adjusting scales at certain timesteps can compensate for skipping CFG at others, enabling both fewer total sampling steps and fewer CFG steps while maintaining quality. However, variable guidance patterns introduce denoising deviations that undermine standard caching methods, which assume constant CFG scales across steps. Moreover, different transformer blocks are affected at different levels under dynamic conditions. This paper develops a two-stage approach leveraging these insights. Stage-1 employs evolutionary algorithms to jointly optimize which timesteps to skip and what guidance scale to use, eliminating up to 82% of unconditional passes. Stage-2 introduces adaptive rank allocation that tailors calibration efforts per transformer block, maintaining caching effectiveness under variable guidance. Experiments demonstrate that OUSAC significantly outperforms state-of-the-art acceleration methods, achieving 53% computational savings with 15% quality improvement on DiT-XL/2 (ImageNet 512x512), 60% savings with 16.1% improvement on PixArt-alpha (MSCOCO), and 5x speedup on FLUX while improving CLIP Score over the 50-step baseline.

</details>


### [87] [ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models](https://arxiv.org/abs/2512.14099)
*Ruishu Zhu,Zhihao Huang,Jiacheng Sun,Ping Luo,Hongyuan Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: ViewMask-1-to-3 提出了一种利用离散扩散模型进行多视角图像生成的新方法，将任务建模为序列预测，通过掩码令牌预测和自注意力机制，在无需复杂3D先验的情况下实现了几何一致性，并在基准数据集上取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 从单张图像和文本描述生成多视角图像时，保持几何一致性是一个挑战。现有方法通常依赖于3D感知架构或专门的扩散模型，这需要大量的多视角训练数据和复杂的几何先验。

Method: 本研究引入了ViewMask-1-to-3，首次将离散扩散模型应用于多视角图像生成。它将多视角合成公式化为一个离散序列建模问题，其中每个视角都通过MAGVIT-v2标记化表示为视觉令牌。该方法通过掩码令牌预测和文本输入进行迭代去掩码，渐进式生成多个视角，并通过简单的随机掩码结合自注意力实现跨视角一致性，无需复杂的3D几何约束或专用注意力架构。

Result: ViewMask-1-to-3 在GSO和3D-FUTURE数据集上，在PSNR、SSIM和LPIPS指标上平均排名第一，同时保持了架构的简洁性。这表明离散扩散为现有的多视角生成方法提供了一个可行且简单的替代方案。

Conclusion: ViewMask-1-to-3 证明了离散扩散模型能够作为现有复杂多视角生成方法的一个简单且有效的替代方案，无需复杂的3D几何先验或专用架构，即可实现卓越的生成性能和跨视角一致性。

Abstract: Multi-view image generation from a single image and text description remains challenging due to the difficulty of maintaining geometric consistency across different viewpoints. Existing approaches typically rely on 3D-aware architectures or specialized diffusion models that require extensive multi-view training data and complex geometric priors. In this work, we introduce ViewMask-1-to-3, a pioneering approach to apply discrete diffusion models to multi-view image generation. Unlike continuous diffusion methods that operate in latent spaces, ViewMask-1-to-3 formulates multi-view synthesis as a discrete sequence modeling problem, where each viewpoint is represented as visual tokens obtained through MAGVIT-v2 tokenization. By unifying language and vision through masked token prediction, our approach enables progressive generation of multiple viewpoints through iterative token unmasking with text input. ViewMask-1-to-3 achieves cross-view consistency through simple random masking combined with self-attention, eliminating the requirement for complex 3D geometric constraints or specialized attention architectures. Our approach demonstrates that discrete diffusion provides a viable and simple alternative to existing multi-view generation methods, ranking first on average across GSO and 3D-FUTURE datasets in terms of PSNR, SSIM, and LPIPS, while maintaining architectural simplicity.

</details>


### [88] [MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction](https://arxiv.org/abs/2512.14114)
*Rui-Yang Ju,KokSheik Wong,Yanlin Jin,Jen-Shiun Chiang*

Main category: cs.CV

TL;DR: 本文提出MFE-GAN，一个基于GAN的高效框架，通过多尺度特征提取（结合Haar小波变换和归一化）来加速文档图像增强和二值化，同时保持与现有技术相当的性能。


<details>
  <summary>Details</summary>
Motivation: 文档图像增强和二值化是OCR任务前的关键步骤，因为直接识别退化文档（尤其是彩色图像）中的文本效果不佳。现有方法为不同颜色通道训练独立的GANs，导致训练和推理时间过长。

Method: 提出MFE-GAN，一个高效的基于GAN的框架，采用多尺度特征提取（MFE）。该方法在将文档图像输入GAN训练之前，结合了Haar小波变换（HWT）和归一化进行预处理。此外，还引入了新颖的生成器、判别器和损失函数来提高模型性能，并进行了消融研究以证明其有效性。

Result: 在Benchmark、Nabuco和CMATERdb数据集上的实验结果表明，MFE-GAN显著减少了总训练和推理时间，同时保持了与最先进方法相当的性能。

Conclusion: MFE-GAN提供了一种高效的文档图像增强和二值化解决方案，能够在不牺牲性能的情况下大幅缩短训练和推理时间。

Abstract: Document image enhancement and binarization are commonly performed prior to document analysis and recognition tasks for improving the efficiency and accuracy of optical character recognition (OCR) systems. This is because directly recognizing text in degraded documents, particularly in color images, often results in unsatisfactory recognition performance. To address these issues, existing methods train independent generative adversarial networks (GANs) for different color channels to remove shadows and noise, which, in turn, facilitates efficient text information extraction. However, deploying multiple GANs results in long training and inference times. To reduce both training and inference times of document image enhancement and binarization models, we propose MFE-GAN, an efficient GAN-based framework with multi-scale feature extraction (MFE), which incorporates Haar wavelet transformation (HWT) and normalization to process document images before feeding them into GANs for training. In addition, we present novel generators, discriminators, and loss functions to improve the model's performance, and we conduct ablation studies to demonstrate their effectiveness. Experimental results on the Benchmark, Nabuco, and CMATERdb datasets demonstrate that the proposed MFE-GAN significantly reduces the total training and inference times while maintaining comparable performance with respect to state-of-the-art (SOTA) methods. The implementation of this work is available at https://ruiyangju.github.io/MFE-GAN.

</details>


### [89] [Consistent Instance Field for Dynamic Scene Understanding](https://arxiv.org/abs/2512.14126)
*Junyi Wu,Van Nguyen Nguyen,Benjamin Planche,Jiachen Tao,Changchang Sun,Zhongpai Gao,Zhenghao Zhao,Anwesa Choudhuri,Gengyu Zhang,Meng Zheng,Feiran Wang,Terrence Chen,Yan Yan,Ziyan Wu*

Main category: cs.CV

TL;DR: 本文提出了一种名为一致实例场（Consistent Instance Field, CIF）的连续概率时空表示，用于动态场景理解，它通过可变形的3D高斯函数实现辐射和语义信息的联合编码，并在全景分割和4D查询任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖离散跟踪或视点相关特征，未能将可见性与持久对象身份分离，限制了对动态场景的理解。

Method: 引入一致实例场（CIF），一种连续且概率性的时空表示，通过建模每个时空点的占据概率和条件实例分布来解耦可见性和对象身份。核心方法是基于可变形3D高斯函数的新型实例嵌入表示，其联合编码辐射和语义信息，并直接从RGB图像和实例掩码通过可微分光栅化学习。此外，还引入了校准每个高斯身份和向语义活跃区域重采样高斯的新机制，以确保跨时空的一致实例表示。

Result: 在HyperNeRF和Neu3D数据集上的实验表明，该方法在新视角全景分割和开放词汇4D查询任务上显著优于现有最先进的方法。

Conclusion: 所提出的CIF提供了一种卓越且一致的动态场景时空表示，能够有效解耦可见性和实例身份，并在复杂的全景分割和4D查询任务中展现出优异的性能。

Abstract: We introduce Consistent Instance Field, a continuous and probabilistic spatio-temporal representation for dynamic scene understanding. Unlike prior methods that rely on discrete tracking or view-dependent features, our approach disentangles visibility from persistent object identity by modeling each space-time point with an occupancy probability and a conditional instance distribution. To realize this, we introduce a novel instance-embedded representation based on deformable 3D Gaussians, which jointly encode radiance and semantic information and are learned directly from input RGB images and instance masks through differentiable rasterization. Furthermore, we introduce new mechanisms to calibrate per-Gaussian identities and resample Gaussians toward semantically active regions, ensuring consistent instance representations across space and time. Experiments on HyperNeRF and Neu3D datasets demonstrate that our method significantly outperforms state-of-the-art methods on novel-view panoptic segmentation and open-vocabulary 4D querying tasks.

</details>


### [90] [Erasing CLIP Memories: Non-Destructive, Data-Free Zero-Shot class Unlearning in CLIP Models](https://arxiv.org/abs/2512.14137)
*Ashish Mishra,Tarun Kumar,Gyanaranjan Nayak,Arpit Shah,Suparna Bhattacharya,Martin Foltin*

Main category: cs.CV

TL;DR: 本文提出一种新颖的、闭式解法，利用零空间投影在多模态模型（如CLIP）中实现选择性遗忘，无需再训练或遗忘集图像，即可精确擦除目标类别信息。


<details>
  <summary>Details</summary>
Motivation: 传统的模型遗忘技术依赖于迭代微调和大量数据整理，计算成本高昂。研究旨在开发一种计算高效、精确的手术式方法，以实现模型去污染和隐私保护，特别是在多模态模型中。

Method: 该方法通过零空间投影，针对多模态模型（如CLIP）的最终投影层，擦除目标类别信息。具体而言，它计算目标文本嵌入所张成的子空间的正交基，并沿这些方向进行投影，从而显著降低图像特征与不需要类别之间的对齐。整个过程无需再训练，也不需要来自遗忘集的图像。

Result: 实验表明，该方法能导致目标类别在零样本性能上显著下降，同时保留模型的整体多模态知识。它计算高效且精确。即使是部分投影也能在完全遗忘和保留有用信息之间取得平衡。

Conclusion: 所提出的零空间投影方法为多模态模型中的选择性遗忘提供了一种高效且精确的闭式解决方案，有效解决了模型去污染和隐私保护的关键挑战，无需再训练即可移除目标类别信息。

Abstract: We introduce a novel, closed-form approach for selective unlearning in multimodal models, specifically targeting pretrained models such as CLIP. Our method leverages nullspace projection to erase the target class information embedded in the final projection layer, without requiring any retraining or the use of images from the forget set. By computing an orthonormal basis for the subspace spanned by target text embeddings and projecting these directions, we dramatically reduce the alignment between image features and undesired classes. Unlike traditional unlearning techniques that rely on iterative fine-tuning and extensive data curation, our approach is both computationally efficient and surgically precise. This leads to a pronounced drop in zero-shot performance for the target classes while preserving the overall multimodal knowledge of the model. Our experiments demonstrate that even a partial projection can balance between complete unlearning and retaining useful information, addressing key challenges in model decontamination and privacy preservation.

</details>


### [91] [Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity](https://arxiv.org/abs/2512.14320)
*Shuai Dong,Jie Zhang,Guoying Zhao,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种新的图像免疫方法SIFM，通过扰动扩散模型的中间特征来防止未经授权的文本引导图像编辑，并引入了新的评估指标ISR，以更准确地衡量免疫效果。


<details>
  <summary>Details</summary>
Motivation: 文本引导图像编辑模型虽然强大，但存在被滥用的风险。现有的图像免疫评估指标主要关注受保护图像编辑输出与原始图像编辑输出之间的视觉差异，这忽略了免疫的真正目标是破坏编辑意图的语义对齐，而非仅仅偏离特定输出。

Method: 研究提出协同中间特征操纵（SIFM）方法，通过双重协同目标策略性地扰动中间扩散特征：1) 最大化特征与原始编辑轨迹的分歧，以破坏与预期编辑的语义对齐；2) 最小化特征范数，以诱导感知降级。此外，引入了免疫成功率（ISR）这一新指标，利用多模态大语言模型（MLLMs）评估编辑是否导致语义失败或显著感知降级。

Result: 广泛的实验表明，SIFM在保护视觉内容免受恶意基于扩散的操作方面达到了最先进的性能。

Conclusion: SIFM方法能有效阻止恶意文本引导图像编辑，通过破坏语义对齐和引入感知降级来实现图像免疫。新提出的ISR指标能更准确地量化免疫效果，为未来研究提供了更可靠的评估工具。

Abstract: Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.

</details>


### [92] [SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing](https://arxiv.org/abs/2512.14140)
*Han Zou,Yan Zhang,Ruiqi Yu,Cong Xie,Jie Huang,Zhenpeng Zhan*

Main category: cs.CV

TL;DR: SketchAssist是一款交互式草图编辑助手，它通过统一指令引导的全局编辑和线条引导的局部重绘来加速创作，同时保持无关区域和整体构图的完整性。该系统利用新的数据生成管道和基于DiT的统一框架，结合LoRA层中的专家混合模型，实现了最先进的编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑系统难以在支持高层次语义修改和精确局部重绘的同时，保留线条艺术稀疏且对风格敏感的结构。

Method: 本文提出了SketchAssist，一个交互式草图绘制助手，它统一了指令引导的全局编辑和线条引导的区域重绘。为实现大规模应用，作者引入了一个可控的数据生成管道，该管道能构建属性添加序列、形成多步编辑链，并用风格保留的属性移除模型扩展风格覆盖。在此数据基础上，SketchAssist采用了一个对DiT编辑器改动最小的统一草图编辑框架，通过重新利用RGB通道编码输入。为进一步区分模式行为，它在LoRA层中集成了任务引导的专家混合（MoE）模型，通过文本和视觉线索进行路由。

Result: 广泛的实验表明，SketchAssist在指令依从性、风格和结构保留方面均达到了最先进的水平，优于现有基线。

Conclusion: SketchAssist及其数据集为草图创作和修订提供了一个实用、可控的助手。

Abstract: Sketch editing is central to digital illustration, yet existing image editing systems struggle to preserve the sparse, style-sensitive structure of line art while supporting both high-level semantic changes and precise local redrawing. We present SketchAssist, an interactive sketch drawing assistant that accelerates creation by unifying instruction-guided global edits with line-guided region redrawing, while keeping unrelated regions and overall composition intact. To enable this assistant at scale, we introduce a controllable data generation pipeline that (i) constructs attribute-addition sequences from attribute-free base sketches, (ii) forms multi-step edit chains via cross-sequence sampling, and (iii) expands stylistic coverage with a style-preserving attribute-removal model applied to diverse sketches. Building on this data, SketchAssist employs a unified sketch editing framework with minimal changes to DiT-based editors. We repurpose the RGB channels to encode the inputs, enabling seamless switching between instruction-guided edits and line-guided redrawing within a single input interface. To further specialize behavior across modes, we integrate a task-guided mixture-of-experts into LoRA layers, routing by text and visual cues to improve semantic controllability, structural fidelity, and style preservation. Extensive experiments show state-of-the-art results on both tasks, with superior instruction adherence and style/structure preservation compared to recent baselines. Together, our dataset and SketchAssist provide a practical, controllable assistant for sketch creation and revision.

</details>


### [93] [Dual Attention Guided Defense Against Malicious Edits](https://arxiv.org/abs/2512.14333)
*Jie Zhang,Shuai Dong,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为DANP（双注意力引导噪声扰动）的免疫方法，通过添加不可察觉的扰动来干扰文本到图像扩散模型的语义理解和生成过程，从而有效抵抗恶意编辑，实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在图像编辑方面取得了显著进展，但也带来了滥用以创建欺骗性或有害内容的伦理挑战。现有防御方法通过嵌入不可察觉的扰动来缓解风险，但对恶意篡改的有效性有限。

Method: DANP方法在多个时间步上添加不可察觉的扰动，以扰乱模型的语义理解和生成过程。它通过动态阈值生成掩码，识别文本相关和不相关区域，从而操纵交叉注意力图和噪声预测过程。具体来说，它减少相关区域的注意力，同时增加不相关区域的注意力，以误导编辑方向。此外，该方法最大化注入噪声与模型预测噪声之间的差异，进一步干扰生成。

Result: DANP方法对恶意编辑表现出令人印象深刻的免疫力。大量实验证实，该方法达到了最先进的性能。

Conclusion: 通过同时针对注意力机制和噪声预测机制，DANP方法成功解决了文本到图像扩散模型中恶意篡改的问题，显著提高了模型的鲁棒性。

Abstract: Recent progress in text-to-image diffusion models has transformed image editing via text prompts, yet this also introduces significant ethical challenges from potential misuse in creating deceptive or harmful content. While current defenses seek to mitigate this risk by embedding imperceptible perturbations, their effectiveness is limited against malicious tampering. To address this issue, we propose a Dual Attention-Guided Noise Perturbation (DANP) immunization method that adds imperceptible perturbations to disrupt the model's semantic understanding and generation process. DANP functions over multiple timesteps to manipulate both cross-attention maps and the noise prediction process, using a dynamic threshold to generate masks that identify text-relevant and irrelevant regions. It then reduces attention in relevant areas while increasing it in irrelevant ones, thereby misguides the edit towards incorrect regions and preserves the intended targets. Additionally, our method maximizes the discrepancy between the injected noise and the model's predicted noise to further interfere with the generation. By targeting both attention and noise prediction mechanisms, DANP exhibits impressive immunity against malicious edits, and extensive experiments confirm that our method achieves state-of-the-art performance.

</details>


### [94] [TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models](https://arxiv.org/abs/2512.14141)
*Hanning Chen,Keyu Man,Kevin Zhu,Chenguang Zhu,Haonan Li,Tongbo Luo,Xizhou Feng,Wei Sun,Sreen Tallam,Mohsen Imani,Partha Kanuparthy*

Main category: cs.CV

TL;DR: 该研究提出了首个用于评估和改进ML模型检测PyTorch轨迹中性能反模式的基准数据集，并提出了一种结合轻量级ML模型和大型语言模型（LLM）的迭代方法，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 识别和解决机器学习模型中的性能反模式对高效训练和推理至关重要，但通常需要系统基础设施、ML模型和内核开发方面的深厚专业知识。现有方法资源密集且难以自动化，特别是定位长执行轨迹中的问题片段，LLM也难以胜任。

Method: 本文构建了首个专门用于检测轨迹中反模式的基准数据集，包含来自多种计算机视觉模型和硬件平台的600多个PyTorch轨迹。同时，提出了一种新颖的迭代方法：首先由一个轻量级ML模型检测包含反模式的轨迹片段，然后由一个大型语言模型（LLM）进行细粒度分类并提供有针对性的反馈。

Result: 实验结果表明，该方法在检测反模式区域方面显著优于无监督聚类和基于规则的统计技术。此外，该方法还有效弥补了LLM上下文长度有限和推理效率低下的不足。

Conclusion: 该工作为ML模型性能反模式检测提供了一个重要的基准数据集，并提出了一种高效的迭代检测方法，显著提升了反模式识别能力，并有效克服了LLM的局限性。

Abstract: Identifying and addressing performance anti-patterns in machine learning (ML) models is critical for efficient training and inference, but it typically demands deep expertise spanning system infrastructure, ML models and kernel development. While large tech companies rely on dedicated ML infrastructure engineers to analyze torch traces and benchmarks, such resource-intensive workflows are largely inaccessible to computer vision researchers in general. Among the challenges, pinpointing problematic trace segments within lengthy execution traces remains the most time-consuming task, and is difficult to automate with current ML models, including LLMs. In this work, we present the first benchmark dataset specifically designed to evaluate and improve ML models' ability to detect anti patterns in traces. Our dataset contains over 600 PyTorch traces from diverse computer vision models classification, detection, segmentation, and generation collected across multiple hardware platforms. We also propose a novel iterative approach: a lightweight ML model first detects trace segments with anti patterns, followed by a large language model (LLM) for fine grained classification and targeted feedback. Experimental results demonstrate that our method significantly outperforms unsupervised clustering and rule based statistical techniques for detecting anti pattern regions. Our method also effectively compensates LLM's limited context length and reasoning inefficiencies.

</details>


### [95] [From YOLO to VLMs: Advancing Zero-Shot and Few-Shot Detection of Wastewater Treatment Plants Using Satellite Imagery in MENA Region](https://arxiv.org/abs/2512.14312)
*Akila Premarathna,Kanishka Hewageegana,Garcia Andarcia Mariangel*

Main category: cs.CV

TL;DR: 本研究发现，视觉语言模型（VLMs），尤其是零样本学习，在无需大量人工标注的情况下，可以超越传统YOLOv8模型，高效识别中东和北非地区卫星图像中的污水处理厂（WWTPs），实现可扩展的遥感监测。


<details>
  <summary>Details</summary>
Motivation: 中东和北非地区对污水处理厂的需求量大，其精确识别对于可持续水资源管理至关重要。传统YOLOv8等方法需要大量耗时的人工标注，而现有研究表明视觉语言模型（VLMs）可能通过其固有的推理和标注能力，提供更高效且效果相当或更优的替代方案。

Method: 本研究提出了一种结构化的VLM比较方法，分为零样本（zero-shot）和少样本（few-shot）流，专门用于识别WWTPs。YOLOv8模型在一个包含83,566张高分辨率卫星图像（85% WWTPs，15% 非WWTPs）的政府数据集上进行训练。评估的VLMs包括LLaMA 3.2 Vision, Qwen 2.5 VL, DeepSeek-VL2, Gemma 3, Gemini和Pixtral 12B (Mistral)。VLMs通过专家提示识别WWTP组件（如圆形/矩形水箱、曝气池）并区分混淆物，输出包含置信度和描述的JSON结果。评估数据集包含1,207个经验证的WWTP位置和相同数量的非WWTP地点（600m x 600m Geo-TIFF图像）。

Result: 零样本评估结果显示，多个VLMs在WWTP图像上的真阳性率优于YOLOv8，其中Gemma-3表现最佳。

Conclusion: 研究证实，VLMs，特别是零样本学习方式，能够取代YOLOv8，实现高效、免标注的WWTP分类，从而推动可扩展的遥感应用。

Abstract: In regions of the Middle East and North Africa (MENA), there is a high demand for wastewater treatment plants (WWTPs), crucial for sustainable water management. Precise identification of WWTPs from satellite images enables environmental monitoring. Traditional methods like YOLOv8 segmentation require extensive manual labeling. But studies indicate that vision-language models (VLMs) are an efficient alternative to achieving equivalent or superior results through inherent reasoning and annotation. This study presents a structured methodology for VLM comparison, divided into zero-shot and few-shot streams specifically to identify WWTPs. The YOLOv8 was trained on a governmental dataset of 83,566 high-resolution satellite images from Egypt, Saudi Arabia, and UAE: ~85% WWTPs (positives), 15% non-WWTPs (negatives). Evaluated VLMs include LLaMA 3.2 Vision, Qwen 2.5 VL, DeepSeek-VL2, Gemma 3, Gemini, and Pixtral 12B (Mistral), used to identify WWTP components such as circular/rectangular tanks, aeration basins and distinguish confounders via expert prompts producing JSON outputs with confidence and descriptions. The dataset comprises 1,207 validated WWTP locations (198 UAE, 354 KSA, 655 Egypt) and equal non-WWTP sites from field/AI data, as 600mx600m Geo-TIFF images (Zoom 18, EPSG:4326). Zero-shot evaluations on WWTP images showed several VLMs out-performing YOLOv8's true positive rate, with Gemma-3 highest. Results confirm that VLMs, particularly with zero-shot, can replace YOLOv8 for efficient, annotation-free WWTP classification, enabling scalable remote sensing.

</details>


### [96] [Towards Transferable Defense Against Malicious Image Edits](https://arxiv.org/abs/2512.14341)
*Jie Zhang,Shuai Dong,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: TDAE是一种双模态框架，通过协调图像-文本优化，增强图像对恶意编辑的免疫力，尤其提升了跨模型的防御可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有针对扩散模型恶意编辑的防御方法在跨模型评估中可迁移性有限。

Method: 提出TDAE框架：视觉防御层面引入FlatGrad Defense Mechanism (FDM)，通过梯度正则化将扰动引导至平坦最小值，增强对未知编辑模型的鲁棒性。文本增强保护层面提出Dynamic Prompt Defense (DPD)，通过迭代优化文本嵌入，使免疫图像的编辑结果与原始图像对齐，从而在更广泛的免疫增强特征中实现跨模型可迁移性。

Result: TDAE在内部模型和跨模型评估中，均在缓解恶意编辑方面取得了最先进的性能。

Conclusion: TDAE通过图像-文本协同优化，有效提升了图像对恶意编辑的免疫力，并显著改善了防御策略的跨模型可迁移性。

Abstract: Recent approaches employing imperceptible perturbations in input images have demonstrated promising potential to counter malicious manipulations in diffusion-based image editing systems. However, existing methods suffer from limited transferability in cross-model evaluations. To address this, we propose Transferable Defense Against Malicious Image Edits (TDAE), a novel bimodal framework that enhances image immunity against malicious edits through coordinated image-text optimization. Specifically, at the visual defense level, we introduce FlatGrad Defense Mechanism (FDM), which incorporates gradient regularization into the adversarial objective. By explicitly steering the perturbations toward flat minima, FDM amplifies immune robustness against unseen editing models. For textual enhancement protection, we propose an adversarial optimization paradigm named Dynamic Prompt Defense (DPD), which periodically refines text embeddings to align the editing outcomes of immunized images with those of the original images, then updates the images under optimized embeddings. Through iterative adversarial updates to diverse embeddings, DPD enforces the generation of immunized images that seek a broader set of immunity-enhancing features, thereby achieving cross-model transferability. Extensive experimental results demonstrate that our TDAE achieves state-of-the-art performance in mitigating malicious edits under both intra- and cross-model evaluations.

</details>


### [97] [CIS-BA: Continuous Interaction Space Based Backdoor Attack for Object Detection in the Real-World](https://arxiv.org/abs/2512.14158)
*Shuxin Zhao,Bo Lang,Nan Xiao,Yilang Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为CIS-BA的新型后门攻击范式，通过利用连续的物体间交互模式作为“空间触发器”，实现了对目标检测模型的多触发器-多目标攻击，并在复杂动态环境中展现出高成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶等实际应用中的目标检测模型面临后门攻击的严重威胁。现有方法因依赖单一触发器-单一目标映射和脆弱的像素级线索，在能力和鲁棒性方面存在固有限制。

Method: CIS-BA通过将触发器设计从静态物体特征转向描述物体如何在场景中共同出现和交互的连续物体间交互模式，重新定义了触发器。它将这些模式建模为连续交互空间，引入了“空间触发器”，首次实现了多触发器-多目标攻击机制，并通过不变的几何关系实现了鲁棒性。为实现这一范式，设计了CIS-Frame，它通过交互分析构建空间触发器，将其形式化为类别-几何约束用于样本中毒，并在检测器训练期间嵌入后门。CIS-Frame支持单目标攻击（物体误分类和消失）和多目标同时攻击。

Result: 在MS-COCO和真实世界视频上的实验表明，CIS-BA在复杂环境下实现了超过97%的攻击成功率，在动态多触发器条件下保持了超过95%的有效性，并成功规避了三种最先进的防御方法。

Conclusion: CIS-BA扩展了交互密集场景中后门攻击的范围，并为目标检测系统的安全性提供了新的见解。

Abstract: Object detection models deployed in real-world applications such as autonomous driving face serious threats from backdoor attacks. Despite their practical effectiveness,existing methods are inherently limited in both capability and robustness due to their dependence on single-trigger-single-object mappings and fragile pixel-level cues. We propose CIS-BA, a novel backdoor attack paradigm that redefines trigger design by shifting from static object features to continuous inter-object interaction patterns that describe how objects co-occur and interact in a scene. By modeling these patterns as a continuous interaction space, CIS-BA introduces space triggers that, for the first time, enable a multi-trigger-multi-object attack mechanism while achieving robustness through invariant geometric relations. To implement this paradigm, we design CIS-Frame, which constructs space triggers via interaction analysis, formalizes them as class-geometry constraints for sample poisoning, and embeds the backdoor during detector training. CIS-Frame supports both single-object attacks (object misclassification and disappearance) and multi-object simultaneous attacks, enabling complex and coordinated effects across diverse interaction states. Experiments on MS-COCO and real-world videos show that CIS-BA achieves over 97% attack success under complex environments and maintains over 95% effectiveness under dynamic multi-trigger conditions, while evading three state-of-the-art defenses. In summary, CIS-BA extends the landscape of backdoor attacks in interaction-intensive scenarios and provides new insights into the security of object detection systems.

</details>


### [98] [Enhancing Interpretability for Vision Models via Shapley Value Optimization](https://arxiv.org/abs/2512.14354)
*Kanglong Fan,Yunqiao Yang,Chen Ma*

Main category: cs.CV

TL;DR: 提出一种新颖的自解释框架，在训练过程中将Shapley值估计作为辅助任务，为深度神经网络提供忠实且兼容的解释，并实现最先进的可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络的决策过程不透明。现有的解释方法存在局限性：事后解释方法难以忠实反映模型行为，而自解释神经网络则因其特殊架构设计而牺牲性能和兼容性。

Method: 提出一种新颖的自解释框架，将Shapley值估计作为训练过程中的辅助任务。这确保了模型预测分数能公平分配给图像块，并通过微小的结构修改增强可解释性。

Result: 该方法实现了两大关键进展：1) 公平分配模型预测分数给图像块，确保解释与模型决策逻辑内在一致；2) 通过微小的结构修改增强可解释性，同时保留模型性能和兼容性。在多个基准测试上的大量实验表明，该方法实现了最先进的可解释性。

Conclusion: 所提出的框架有效解决了现有解释方法的局限性，在保持性能的同时为深度神经网络提供了忠实且兼容的解释，并实现了最先进的可解释性。

Abstract: Deep neural networks have demonstrated remarkable performance across various domains, yet their decision-making processes remain opaque. Although many explanation methods are dedicated to bringing the obscurity of DNNs to light, they exhibit significant limitations: post-hoc explanation methods often struggle to faithfully reflect model behaviors, while self-explaining neural networks sacrifice performance and compatibility due to their specialized architectural designs. To address these challenges, we propose a novel self-explaining framework that integrates Shapley value estimation as an auxiliary task during training, which achieves two key advancements: 1) a fair allocation of the model prediction scores to image patches, ensuring explanations inherently align with the model's decision logic, and 2) enhanced interpretability with minor structural modifications, preserving model performance and compatibility. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art interpretability.

</details>


### [99] [Fracture Morphology Classification: Local Multiclass Modeling for Multilabel Complexity](https://arxiv.org/abs/2512.14196)
*Cassandra Krause,Mattias P. Heinrich,Ron Keuth*

Main category: cs.CV

TL;DR: 本研究提出一种通过自动将AO编码分配给骨折边界框来提取骨折形态的方法，将全局多标签任务转化为局部多类别任务，从而提高了诊断准确性，但指出其在实际应用中受限于骨折检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 儿童在成长过程中骨折发生率高（15%-45%），准确诊断至关重要。骨折形态是诊断的关键特征之一。

Method: 提出一种通过将全局AO编码自动分配给相应的骨折边界框来提取骨折形态的方法。这种方法将全局多标签任务重新定义为局部多类别任务。

Result: 该方法使平均F1分数提高了7.89%。然而，当使用不完善的骨折检测器时，性能会下降，这突出了在实际部署中面临的挑战。

Conclusion: 所提出的方法通过将AO编码分配给骨折边界框，有效地提高了骨折形态提取和诊断的准确性。尽管在理想条件下表现良好，但在真实世界中，骨折检测器的不完善性是该方法部署的一个主要挑战。

Abstract: Between $15\,\%$ and $45\,\%$ of children experience a fracture during their growth years, making accurate diagnosis essential. Fracture morphology, alongside location and fragment angle, is a key diagnostic feature. In this work, we propose a method to extract fracture morphology by assigning automatically global AO codes to corresponding fracture bounding boxes. This approach enables the use of public datasets and reformulates the global multilabel task into a local multiclass one, improving the average F1 score by $7.89\,\%$. However, performance declines when using imperfect fracture detectors, highlighting challenges for real-world deployment. Our code is available on GitHub.

</details>


### [100] [FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation](https://arxiv.org/abs/2512.14162)
*Qingyuan Cai,Linxin Zhang,Xuecai Hu,Saihui Hou,Yongzhen Huang*

Main category: cs.CV

TL;DR: 本文提出了一个模块化框架Fast3DHPE，用于统一单目3D人体姿态估计方法的训练和评估，并在此框架下引入了FastDDHPose，这是一种基于扩散模型的方法，通过解耦骨骼长度和方向分布，并设计高效的运动学分层去噪器，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的单目3D人体姿态估计方法通常在不同的框架下进行训练和评估，导致缺乏统一的比较标准。此外，直接回归3D姿态可能面临分层误差累积的问题。

Method: 1. 提出了Fast3DHPE，一个模块化框架，标准化了训练和评估协议，以实现公平比较和提高训练效率。2. 在Fast3DHPE框架内，引入了FastDDHPose，这是一种基于扩散模型的3D人体姿态估计方法，利用扩散模型强大的潜在分布建模能力，明确建模骨骼长度和骨骼方向的分布，以避免分层误差累积。3. 设计了一个高效的运动学分层时空去噪器（Kinematic-Hierarchical Spatial and Temporal Denoiser），鼓励模型关注运动学关节层次结构。

Result: Fast3DHPE框架在Human3.6M和MPI-INF-3DHP数据集上实现了所有方法的公平比较，并显著提高了训练效率。在此统一框架下，FastDDHPose实现了最先进的性能，并在野外场景中展现出强大的泛化能力和鲁棒性。

Conclusion: Fast3DHPE提供了一个有价值的统一框架，促进了3D人体姿态估计领域的公平比较和方法开发。FastDDHPose作为在该框架下开发的新方法，通过创新的扩散模型和去噪器设计，成功解决了现有挑战，并达到了最先进的性能。

Abstract: Recent approaches for monocular 3D human pose estimation (3D HPE) have achieved leading performance by directly regressing 3D poses from 2D keypoint sequences. Despite the rapid progress in 3D HPE, existing methods are typically trained and evaluated under disparate frameworks, lacking a unified framework for fair comparison. To address these limitations, we propose Fast3DHPE, a modular framework that facilitates rapid reproduction and flexible development of new methods. By standardizing training and evaluation protocols, Fast3DHPE enables fair comparison across 3D human pose estimation methods while significantly improving training efficiency. Within this framework, we introduce FastDDHPose, a Disentangled Diffusion-based 3D Human Pose Estimation method which leverages the strong latent distribution modeling capability of diffusion models to explicitly model the distributions of bone length and bone direction while avoiding further amplification of hierarchical error accumulation. Moreover, we design an efficient Kinematic-Hierarchical Spatial and Temporal Denoiser that encourages the model to focus on kinematic joint hierarchies while avoiding unnecessary modeling of overly complex joint topologies. Extensive experiments on Human3.6M and MPI-INF-3DHP show that the Fast3DHPE framework enables fair comparison of all methods while significantly improving training efficiency. Within this unified framework, FastDDHPose achieves state-of-the-art performance with strong generalization and robustness in in-the-wild scenarios. The framework and models will be released at: https://github.com/Andyen512/Fast3DHPE

</details>


### [101] [Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination](https://arxiv.org/abs/2512.14200)
*Zhuoxiao Li,Wenzong Ma,Taoyu Wu,Jinjing Zhu,Zhenchao Q,Shuai Zhang,Jing Ou,Yinrui Ren,Weiqing Qi,Guobin Shen,Hui Xiong,Wufan Zhao*

Main category: cs.CV

TL;DR: 该论文引入了SkyLume数据集，这是一个大规模、真实世界的无人机数据集，旨在解决多时间捕获数据中光照不一致导致的3D重建问题，并提供评估几何和外观精度的地面真值以及新的逆渲染度量。


<details>
  <summary>Details</summary>
Motivation: 当前的神经辐射场和3D高斯泼溅方法在处理多时间无人机数据时，由于一天中不同时间的光照变化，容易导致颜色伪影、几何不准确和外观不一致。此外，缺乏专门用于研究不同光照条件下同一区域的无人机数据集，使得这一挑战未被充分探索。

Method: 该研究构建了SkyLume数据集：(1) 收集了10个城市区域的数据，包含超过10万张高分辨率无人机图像，每个区域在一天中的三个不同时段进行采集，以系统地隔离光照变化。(2) 为支持精确的几何和外观评估，提供了每场景的LiDAR扫描和精确的3D地面真值，用于评估深度、表面法线和重建质量。(3) 针对逆渲染任务，引入了时间一致性系数（TCC），该指标衡量跨时间反照率的稳定性，直接评估光照和材质分离的鲁棒性。

Result: 该研究成功创建并发布了SkyLume数据集，一个大规模、多时相、带有精确几何地面真值的无人机图像集合，以及一个新的评估逆渲染中光照-材质分离鲁棒性的指标——时间一致性系数（TCC）。

Conclusion: SkyLume数据集及其配套资源旨在为大规模逆渲染、几何重建和新视角合成领域的研究和实际评估提供基础，特别是在处理复杂光照条件下提升3D重建的鲁棒性方面。

Abstract: Recent advances in Neural Radiance Fields and 3D Gaussian Splatting have demonstrated strong potential for large-scale UAV-based 3D reconstruction tasks by fitting the appearance of images. However, real-world large-scale captures are often based on multi-temporal data capture, where illumination inconsistencies across different times of day can significantly lead to color artifacts, geometric inaccuracies, and inconsistent appearance. Due to the lack of UAV datasets that systematically capture the same areas under varying illumination conditions, this challenge remains largely underexplored. To fill this gap, we introduceSkyLume, a large-scale, real-world UAV dataset specifically designed for studying illumination robust 3D reconstruction in urban scene modeling: (1) We collect data from 10 urban regions data comprising more than 100k high resolution UAV images (four oblique views and nadir), where each region is captured at three periods of the day to systematically isolate illumination changes. (2) To support precise evaluation of geometry and appearance, we provide per-scene LiDAR scans and accurate 3D ground-truth for assessing depth, surface normals, and reconstruction quality under varying illumination. (3) For the inverse rendering task, we introduce the Temporal Consistency Coefficient (TCC), a metric that measuress cross-time albedo stability and directly evaluates the robustness of the disentanglement of light and material. We aim for this resource to serve as a foundation that advances research and real-world evaluation in large-scale inverse rendering, geometry reconstruction, and novel view synthesis.

</details>


### [102] [Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere](https://arxiv.org/abs/2512.14180)
*Francesco Di Sario,Daniel Rebain,Dor Verbin,Marco Grangetto,Andrea Tagliasacchi*

Main category: cs.CV

TL;DR: 本文提出了一种名为球形Voronoi (SV) 的统一框架，用于3D高斯泼溅中的外观表示，以克服球面谐波(SH)在处理高频信号和镜面反射方面的局限性，并在合成和真实世界数据上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的辐射场方法（如3D高斯泼溅）在外观建模上常依赖球面谐波(SH)，但SH存在根本性局限：难以处理高频信号、产生吉布斯振铃伪影，且无法捕捉逼真的镜面反射。虽然其他替代方案（如球面高斯）有所改进，但会显著增加优化复杂性。

Method: 本文提出了球形Voronoi (SV) 作为3D高斯泼溅中外观表示的统一框架。SV将方向域划分为可学习的、具有平滑边界的区域，为视角相关效应提供了直观稳定的参数化。对于漫反射外观，SV通过更简单的优化实现具有竞争力的结果。对于SH失败的反射，SV被用作可学习的反射探针，根据经典图形学原理将反射方向作为输入。

Result: SV在漫反射外观方面取得了具有竞争力的结果，且优化比现有替代方案更简单。对于反射，SV作为可学习的反射探针，在合成和真实世界数据集上均达到了最先进的结果，证明了其在显式3D表示中外观建模的有效性。

Conclusion: SV为显式3D表示中的外观建模提供了一种原则性、高效且通用的解决方案，成功克服了球面谐波的局限性，尤其在捕捉镜面反射方面表现出色。

Abstract: Radiance field methods (e.g. 3D Gaussian Splatting) have emerged as a powerful paradigm for novel view synthesis, yet their appearance modeling often relies on Spherical Harmonics (SH), which impose fundamental limitations. SH struggle with high-frequency signals, exhibit Gibbs ringing artifacts, and fail to capture specular reflections - a key component of realistic rendering. Although alternatives like spherical Gaussians offer improvements, they add significant optimization complexity. We propose Spherical Voronoi (SV) as a unified framework for appearance representation in 3D Gaussian Splatting. SV partitions the directional domain into learnable regions with smooth boundaries, providing an intuitive and stable parameterization for view-dependent effects. For diffuse appearance, SV achieves competitive results while keeping optimization simpler than existing alternatives. For reflections - where SH fail - we leverage SV as learnable reflection probes, taking reflected directions as input following principles from classical graphics. This formulation attains state-of-the-art results on synthetic and real-world datasets, demonstrating that SV offers a principled, efficient, and general solution for appearance modeling in explicit 3D representations.

</details>


### [103] [Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes](https://arxiv.org/abs/2512.14177)
*Joseph Hoche,Andrei Bursuc,David Brellmann,Gilles Louppe,Pavel Izmailov,Angela Yao,Gianni Franchi*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLMs）输出常不可靠，现有语义不确定性估计方法依赖脆弱的聚类。本文提出语义高斯过程不确定性（SGPU）框架，通过分析答案嵌入的几何结构量化语义不确定性，避免聚类，并在多任务上实现了最先进的校准和判别性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）的输出可能看似合理但不可靠，因此鲁棒的不确定性估计至关重要。当前语义不确定性估计方法依赖外部模型对多个采样响应进行聚类，但这些聚类方法脆弱，对细微措辞变化高度敏感，容易错误地分组或分离语义相似的答案，导致不确定性估计不可靠。

Method: 本文提出语义高斯过程不确定性（SGPU），一个贝叶斯框架。SGPU通过分析答案嵌入的几何结构来量化语义不确定性，从而避免了脆弱的聚类方法。具体而言，SGPU将生成的答案映射到密集的语义空间，计算其嵌入的Gram矩阵，并通过特征谱总结语义配置。然后，这个谱表示被输入到一个高斯过程分类器中，该分类器学习将语义一致性模式映射到预测不确定性，并可应用于黑盒和白盒设置。

Result: SGPU在六个大型语言模型（LLMs）和大型视觉语言模型（LVLMs）以及八个涵盖视觉问答（VQA）、图像分类和文本问答的数据集上，持续实现了最先进的校准（ECE）和判别（AUROC, AUARC）性能。研究还表明，SGPU在模型和模态之间具有可迁移性，这表明其谱表示捕获了通用的语义不确定性模式。

Conclusion: SGPU通过分析答案嵌入的几何结构，提供了一种鲁棒且可迁移的语义不确定性估计方法，克服了现有基于聚类方法的局限性，并在多个任务和模型上取得了优异的校准和判别性能，证明了其捕获通用语义不确定性模式的能力。

Abstract: Large Vision-Language Models (LVLMs) often produce plausible but unreliable outputs, making robust uncertainty estimation essential. Recent work on semantic uncertainty estimates relies on external models to cluster multiple sampled responses and measure their semantic consistency. However, these clustering methods are often fragile, highly sensitive to minor phrasing variations, and can incorrectly group or separate semantically similar answers, leading to unreliable uncertainty estimates. We propose Semantic Gaussian Process Uncertainty (SGPU), a Bayesian framework that quantifies semantic uncertainty by analyzing the geometric structure of answer embeddings, avoiding brittle clustering. SGPU maps generated answers into a dense semantic space, computes the Gram matrix of their embeddings, and summarizes their semantic configuration via the eigenspectrum. This spectral representation is then fed into a Gaussian Process Classifier that learns to map patterns of semantic consistency to predictive uncertainty, and that can be applied in both black-box and white-box settings. Across six LLMs and LVLMs on eight datasets spanning VQA, image classification, and textual QA, SGPU consistently achieves state-of-the-art calibration (ECE) and discriminative (AUROC, AUARC) performance. We further show that SGPU transfers across models and modalities, indicating that its spectral representation captures general patterns of semantic uncertainty.

</details>


### [104] [TACK Tunnel Data (TTD): A Benchmark Dataset for Deep Learning-Based Defect Detection in Tunnels](https://arxiv.org/abs/2512.14477)
*Andreas Sjölander,Valeria Belloni,Robel Fekadu,Andrea Nascetti*

Main category: cs.CV

TL;DR: 本文介绍了一个新的公开隧道缺陷数据集，包含三种不同衬砌的裂缝、渗漏和水侵蚀等缺陷图像，旨在推动自动化隧道检测和深度学习模型泛化研究。


<details>
  <summary>Details</summary>
Motivation: 隧道是重要的交通基础设施，但老化和劣化问题日益突出。传统人工检测耗时、主观且昂贵。尽管移动测绘和深度学习技术有所进展，但由于缺乏领域特定的隧道数据集，其在自动化视觉检测方面的有效性受到限制。

Method: 研究人员创建并发布了一个新的公开数据集。该数据集包含经过标注的图像，涵盖了三种不同隧道衬砌，并捕获了典型的缺陷类型（裂缝、渗漏和水侵蚀）。数据集旨在支持有监督、半监督和无监督的深度学习方法进行缺陷检测和分割。

Result: 该数据集包含三种不同隧道衬砌的标注图像，涵盖了裂缝、渗漏和水侵蚀等典型缺陷。其设计支持多种深度学习方法，并且在纹理和施工技术上的多样性，有助于研究模型在不同隧道类型间的泛化能力和可迁移性。

Conclusion: 通过解决领域特定数据严重匮乏的问题，该数据集有助于推动自动化隧道检测技术的发展，并促进更安全、更高效的基础设施维护策略。

Abstract: Tunnels are essential elements of transportation infrastructure, but are increasingly affected by ageing and deterioration mechanisms such as cracking. Regular inspections are required to ensure their safety, yet traditional manual procedures are time-consuming, subjective, and costly. Recent advances in mobile mapping systems and Deep Learning (DL) enable automated visual inspections. However, their effectiveness is limited by the scarcity of tunnel datasets. This paper introduces a new publicly available dataset containing annotated images of three different tunnel linings, capturing typical defects: cracks, leaching, and water infiltration. The dataset is designed to support supervised, semi-supervised, and unsupervised DL methods for defect detection and segmentation. Its diversity in texture and construction techniques also enables investigation of model generalization and transferability across tunnel types. By addressing the critical lack of domain-specific data, this dataset contributes to advancing automated tunnel inspection and promoting safer, more efficient infrastructure maintenance strategies.

</details>


### [105] [FakeRadar: Probing Forgery Outliers to Detect Unknown Deepfake Videos](https://arxiv.org/abs/2512.14601)
*Zhaolun Li,Jichang Li,Yinqi Cai,Junye Chen,Xiaonan Luo,Guanbin Li,Rushi Lan*

Main category: cs.CV

TL;DR: 本文提出了FakeRadar，一个新型深度伪造视频检测框架，通过利用大规模预训练模型和合成异常样本，显著提高了在真实世界场景中应对新兴伪造技术的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法通常依赖特定操纵线索，在已知伪造类型上表现良好，但面对新兴操纵技术时泛化能力差，难以适应未见的伪造模式。

Method: FakeRadar利用大规模预训练模型（如CLIP）探测特征空间，显式突出真实视频、已知伪造和未知操纵之间的分布差距。具体方法包括：1. 伪造异常探测（Forgery Outlier Probing），通过动态子簇建模和簇条件异常生成，合成靠近估计子簇边界的异常样本，模拟新型伪造痕迹。2. 异常引导三训练（Outlier-Guided Tri-Training），利用提出的异常驱动对比学习和异常条件交叉熵损失，优化检测器以区分真实、伪造和异常样本。

Result: 实验结果表明，FakeRadar在各种深度伪造视频检测基准数据集上，尤其是在跨域评估中，表现优于现有方法，能够有效处理各种新兴操纵技术。

Conclusion: FakeRadar通过解决跨域泛化挑战，为深度伪造视频检测提供了一个鲁棒的解决方案，能够有效应对不断演进的伪造技术。

Abstract: In this paper, we propose FakeRadar, a novel deepfake video detection framework designed to address the challenges of cross-domain generalization in real-world scenarios. Existing detection methods typically rely on manipulation-specific cues, performing well on known forgery types but exhibiting severe limitations against emerging manipulation techniques. This poor generalization stems from their inability to adapt effectively to unseen forgery patterns. To overcome this, we leverage large-scale pretrained models (e.g. CLIP) to proactively probe the feature space, explicitly highlighting distributional gaps between real videos, known forgeries, and unseen manipulations. Specifically, FakeRadar introduces Forgery Outlier Probing, which employs dynamic subcluster modeling and cluster-conditional outlier generation to synthesize outlier samples near boundaries of estimated subclusters, simulating novel forgery artifacts beyond known manipulation types. Additionally, we design Outlier-Guided Tri-Training, which optimizes the detector to distinguish real, fake, and outlier samples using proposed outlier-driven contrastive learning and outlier-conditioned cross-entropy losses. Experiments show that FakeRadar outperforms existing methods across various benchmark datasets for deepfake video detection, particularly in cross-domain evaluations, by handling the variety of emerging manipulation techniques.

</details>


### [106] [Multi-View MRI Approach for Classification of MGMT Methylation in Glioblastoma Patients](https://arxiv.org/abs/2512.14232)
*Rawan Alyahya,Asrar Alruwayqi,Atheer Alqarni,Asma Alkhaldi,Metab Alkubeyyer,Xin Gao,Mona Alshahrani*

Main category: cs.CV

TL;DR: 本研究提出了一种基于多视图MRI和深度学习的非侵入性方法，用于检测胶质母细胞瘤(GBM)患者的MGMT启动子甲基化状态，避免了传统活检的侵入性。


<details>
  <summary>Details</summary>
Motivation: MGMT启动子甲基化状态显著影响胶质母细胞瘤(GBM)患者的化疗效果，但目前的确认方法依赖于侵入性脑肿瘤组织活检。因此，需要一种非侵入性方法来识别这些重要的遗传标记。

Method: 本研究采用放射基因组学技术，利用MRI扫描和深度学习模型。提出了一种新的多视图方法，该方法考虑了MRI视图之间的空间关系，并能从所有三个视图中提取信息，同时避免了复杂3D深度学习模型带来的高参数、收敛慢和内存需求大等问题。此外，还引入了一种新的肿瘤切片提取技术。

Result: 本研究证明了所提出的肿瘤切片提取技术优于现有方法，并且与最先进的模型相比，所提出的多视图深度学习方法显示出更高的效率。研究还分享了一个可复现的模型管道。

Conclusion: 本研究强调了非侵入性方法识别MGMT启动子甲基化的潜力，并有助于推动GBM治疗中的精准医疗发展。

Abstract: The presence of MGMT promoter methylation significantly affects how well chemotherapy works for patients with Glioblastoma Multiforme (GBM). Currently, confirmation of MGMT promoter methylation relies on invasive brain tumor tissue biopsies. In this study, we explore radiogenomics techniques, a promising approach in precision medicine, to identify genetic markers from medical images. Using MRI scans and deep learning models, we propose a new multi-view approach that considers spatial relationships between MRI views to detect MGMT methylation status. Importantly, our method extracts information from all three views without using a complicated 3D deep learning model, avoiding issues associated with high parameter count, slow convergence, and substantial memory demands. We also introduce a new technique for tumor slice extraction and show its superiority over existing methods based on multiple evaluation metrics. By comparing our approach to state-of-the-art models, we demonstrate the efficacy of our method. Furthermore, we share a reproducible pipeline of published models, encouraging transparency and the development of robust diagnostic tools. Our study highlights the potential of non-invasive methods for identifying MGMT promoter methylation and contributes to advancing precision medicine in GBM treatment.

</details>


### [107] [ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body](https://arxiv.org/abs/2512.14234)
*Juze Zhang,Changan Chen,Xin Chen,Heng Yu,Tiange Xiang,Ali Sartaz Khan,Shrinidhi K. Lakshmikanth,Ehsan Adeli*

Main category: cs.CV

TL;DR: ViBES是一个对话式3D智能体，能联合规划语言和动作，实现多模态、社交化的交互，超越了传统单一模态的生成方法。


<details>
  <summary>Details</summary>
Motivation: 现有系统将人类行为建模为翻译任务（如语音到手势或文本到动作），缺乏在多轮对话中关于何时、如何移动以及如何适应的自主决策，导致时间脆弱、社交基础薄弱，且语音、文本和动作孤立训练或推断。

Method: 引入ViBES（Voice in Behavioral Expression and Synchrony），一个语音-语言-行为（SLB）模型，其核心是多模态专家混合（MoME）骨干网络。该网络包含针对语音、面部表情和身体动作的模态分区Transformer专家，通过模态硬路由处理交错的多模态token流，并通过跨专家注意力共享信息。它利用强大的预训练语音-语言模型，支持混合主动交互，并提供可控的行为接口。

Result: ViBES在多轮对话中，通过对话-动作对齐和行为质量的自动指标，表现出比强大的语音伴随动作和文本到动作基线模型更一致的提升。

Conclusion: ViBES超越了“语音条件动作生成”，迈向自主虚拟身体，其中语言、语调和动作被联合生成，从而实现可控、社交能力强的3D交互。

Abstract: Human communication is inherently multimodal and social: words, prosody, and body language jointly carry intent. Yet most prior systems model human behavior as a translation task co-speech gesture or text-to-motion that maps a fixed utterance to motion clips-without requiring agentic decision-making about when to move, what to do, or how to adapt across multi-turn dialogue. This leads to brittle timing, weak social grounding, and fragmented stacks where speech, text, and motion are trained or inferred in isolation. We introduce ViBES (Voice in Behavioral Expression and Synchrony), a conversational 3D agent that jointly plans language and movement and executes dialogue-conditioned body actions. Concretely, ViBES is a speech-language-behavior (SLB) model with a mixture-of-modality-experts (MoME) backbone: modality-partitioned transformer experts for speech, facial expression, and body motion. The model processes interleaved multimodal token streams with hard routing by modality (parameters are split per expert), while sharing information through cross-expert attention. By leveraging strong pretrained speech-language models, the agent supports mixed-initiative interaction: users can speak, type, or issue body-action directives mid-conversation, and the system exposes controllable behavior hooks for streaming responses. We further benchmark on multi-turn conversation with automatic metrics of dialogue-motion alignment and behavior quality, and observe consistent gains over strong co-speech and text-to-motion baselines. ViBES goes beyond "speech-conditioned motion generation" toward agentic virtual bodies where language, prosody, and movement are jointly generated, enabling controllable, socially competent 3D interaction. Code and data will be made available at: ai.stanford.edu/~juze/ViBES/

</details>


### [108] [OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving](https://arxiv.org/abs/2512.14225)
*Tao Tang,Enhui Ma,xia zhou,Letian Wang,Tianyi Yan,Xueyang Zhang,Kun Zhan,Peng Jia,XianPeng Lang,Jia-Wang Bian,Kaicheng Yu,Xiaodan Liang*

Main category: cs.CV

TL;DR: 为解决自动驾驶数据采集成本高和多模态生成模型不一致的问题，本文提出OminiGen，一个统一框架，利用共享BEV空间和新型多模态重建方法UAE，结合带有ControlNet分支的DiT，生成对齐的多模态（激光雷达和多视角相机）传感器数据，并实现可控生成和多模态一致性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要大量多样化和边缘案例的真实世界数据，但其采集成本高昂且效率低下。现有生成模型主要关注单模态生成，导致多模态传感器数据生成效率低下且对齐不佳。

Method: 本文提出OminiGen，一个统一框架用于生成对齐的多模态传感器数据。它利用共享的鸟瞰图（BEV）空间统一多模态特征，并设计了一种新颖的、可泛化的多模态重建方法UAE，通过体渲染联合解码激光雷达和多视角相机数据，实现准确灵活的重建。此外，OminiGen还结合了带有ControlNet分支的Diffusion Transformer (DiT)，以实现可控的多模态传感器生成。

Result: OminiGen在统一多模态传感器数据生成方面取得了预期性能，表现出良好的多模态一致性和灵活的传感器调整能力。

Conclusion: OminiGen成功解决了自动驾驶领域中多模态传感器数据生成面临的挑战，实现了统一、对齐且可控的多模态传感器数据生成，并保持了多模态一致性。

Abstract: Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.

</details>


### [109] [A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images](https://arxiv.org/abs/2512.14640)
*Rao Muhammad Umer,Daniel Sens,Jonathan Noll,Christian Matek,Lukas Wolfseher,Rainer Spang,Ralf Huss,Johannes Raffler,Sarah Reinke,Wolfram Klapper,Katja Steiger,Kristina Schwamborn,Carsten Marr*

Main category: cs.CV

TL;DR: 本研究创建了首个多中心淋巴瘤基准数据集，并系统评估了深度学习模型在HE染色切片上进行淋巴瘤亚型诊断的性能。模型在内部分布数据上表现良好（>80%），但在外部分布数据上泛化能力显著下降（~60%），强调了需要更大规模的多中心研究。


<details>
  <summary>Details</summary>
Motivation: 淋巴瘤诊断过程复杂、成本高昂且耗时，导致治疗延迟。深度学习方法有望通过分析常规HE染色切片来辅助病理学家诊断，但目前缺乏针对淋巴瘤亚型诊断的全面多中心基准测试。

Method: 本研究构建了首个涵盖四种常见淋巴瘤亚型和健康对照组织的多中心淋巴瘤基准数据集。系统评估了五种公开可用的病理学基础模型（H-optimus-1, H0-mini, Virchow2, UNI2, Titan），结合基于注意力机制（AB-MIL）和基于Transformer（TransMIL）的多实例学习聚合器，在三种放大倍数（10x, 20x, 40x）下进行测试。此外，还提供了一个自动化基准测试流程。

Result: 在内部分布测试集上，所有模型在所有放大倍数下均实现了超过80%的多类别平衡准确率，所有基础模型和聚合方法表现相似。放大倍数研究表明，40倍分辨率已足够，更高的分辨率或跨放大倍数聚合并未带来性能提升。然而，在外部分布测试集上，性能显著下降至约60%，凸显了严重的泛化挑战。

Conclusion: 深度学习在HE染色切片上进行淋巴瘤亚型诊断具有潜力，但在外部分布数据上存在显著的泛化问题。为推动该领域发展，需要更大规模、涵盖更多罕见淋巴瘤亚型的多中心研究。本研究提供的自动化基准测试流程将有助于未来的研究。

Abstract: Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring costly equipment, skilled personnel, and causing treatment delays. Deep learning methods could assist pathologists by extracting diagnostic information from routinely available HE-stained slides, yet comprehensive benchmarks for lymphoma subtyping on multicenter data are lacking. In this work, we present the first multicenter lymphoma benchmarking dataset covering four common lymphoma subtypes and healthy control tissue. We systematically evaluate five publicly available pathology foundation models (H-optimus-1, H0-mini, Virchow2, UNI2, Titan) combined with attention-based (AB-MIL) and transformer-based (TransMIL) multiple instance learning aggregators across three magnifications (10x, 20x, 40x). On in-distribution test sets, models achieve multiclass balanced accuracies exceeding 80% across all magnifications, with all foundation models performing similarly and both aggregation methods showing comparable results. The magnification study reveals that 40x resolution is sufficient, with no performance gains from higher resolutions or cross-magnification aggregation. However, on out-of-distribution test sets, performance drops substantially to around 60%, highlighting significant generalization challenges. To advance the field, larger multicenter studies covering additional rare lymphoma subtypes are needed. We provide an automated benchmarking pipeline to facilitate such future research.

</details>


### [110] [DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning](https://arxiv.org/abs/2512.14420)
*Nakamasa Inoue,Kanoko Goto,Masanari Oi,Martyna Gruszka,Mahiro Ukai,Takumi Hirose,Yusuke Sekikawa*

Main category: cs.CV

TL;DR: 本文提出DISCODE，一种免微调的测试时自适应方法，通过引入高斯先验的ATT损失，显著提升大型视觉语言模型在图像标题评估中与人类判断的一致性，尤其在领域迁移场景下表现出最先进的鲁棒性。同时引入了MCEval多领域评估基准。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLMs）在多模态任务中表现出色，但在领域迁移场景下，使用LVLMs进行鲁棒的图像标题评估仍然是一个挑战。

Method: 本文提出了DISCODE，一种无需微调的方法，其核心是测试时自适应评估方法。该方法引入了自适应测试时（ATT）损失，利用高斯先验分布来提高评估分数估计的鲁棒性。ATT损失在测试时通过推导出的解析解高效最小化。此外，还引入了多领域标题评估（MCEval）基准，涵盖六个不同领域，旨在评估评估指标的鲁棒性。

Result: DISCODE作为一种无参考评估指标，在MCEval和四个具有代表性的现有基准上均实现了最先进的性能。

Conclusion: DISCODE通过其创新的测试时自适应评估方法和ATT损失，有效解决了图像标题评估在领域迁移下的鲁棒性挑战，其评估分数与人类判断高度一致，并在多个基准上超越了现有方法。

Abstract: Large vision-language models (LVLMs) have shown impressive performance across a broad range of multimodal tasks. However, robust image caption evaluation using LVLMs remains challenging, particularly under domain-shift scenarios. To address this issue, we introduce the Distribution-Aware Score Decoder (DISCODE), a novel finetuning-free method that generates robust evaluation scores better aligned with human judgments across diverse domains. The core idea behind DISCODE lies in its test-time adaptive evaluation approach, which introduces the Adaptive Test-Time (ATT) loss, leveraging a Gaussian prior distribution to improve robustness in evaluation score estimation. This loss is efficiently minimized at test time using an analytical solution that we derive. Furthermore, we introduce the Multi-domain Caption Evaluation (MCEval) benchmark, a new image captioning evaluation benchmark covering six distinct domains, designed to assess the robustness of evaluation metrics. In our experiments, we demonstrate that DISCODE achieves state-of-the-art performance as a reference-free evaluation metric across MCEval and four representative existing benchmarks.

</details>


### [111] [DriverGaze360: OmniDirectional Driver Attention with Object-Level Guidance](https://arxiv.org/abs/2512.14266)
*Shreedhar Govil,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: 本文介绍了DriverGaze360，一个大规模360度全景驾驶员注意力数据集，并提出了DriverGaze360-Net，一种全景注意力预测方法，在全景驾驶图像上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的驾驶员注意力预测方法受限于狭窄的正面视野和有限的驾驶多样性，无法捕捉完整的驾驶环境空间上下文，尤其是在车道变换、转弯以及与外围物体（如行人或骑车人）交互时。

Method: 本文引入了DriverGaze360数据集，这是一个包含约100万帧注视标签的大规模360度全景驾驶员注意力数据集，由19名驾驶员收集。同时，提出了一种全景注意力预测方法DriverGaze360-Net，该方法通过使用辅助语义分割头，共同学习注意力图和被关注物体，以提高在宽泛全景输入上的空间感知和注意力预测能力。

Result: DriverGaze360-Net在全景驾驶图像上的多个指标上，实现了最先进的注意力预测性能。

Conclusion: DriverGaze360数据集和DriverGaze360-Net方法为全面、全方位地建模驾驶员注视行为提供了新的解决方案，并在全景驾驶员注意力预测方面取得了显著进展。

Abstract: Predicting driver attention is a critical problem for developing explainable autonomous driving systems and understanding driver behavior in mixed human-autonomous vehicle traffic scenarios. Although significant progress has been made through large-scale driver attention datasets and deep learning architectures, existing works are constrained by narrow frontal field-of-view and limited driving diversity. Consequently, they fail to capture the full spatial context of driving environments, especially during lane changes, turns, and interactions involving peripheral objects such as pedestrians or cyclists. In this paper, we introduce DriverGaze360, a large-scale 360$^\circ$ field of view driver attention dataset, containing $\sim$1 million gaze-labeled frames collected from 19 human drivers, enabling comprehensive omnidirectional modeling of driver gaze behavior. Moreover, our panoramic attention prediction approach, DriverGaze360-Net, jointly learns attention maps and attended objects by employing an auxiliary semantic segmentation head. This improves spatial awareness and attention prediction across wide panoramic inputs. Extensive experiments demonstrate that DriverGaze360-Net achieves state-of-the-art attention prediction performance on multiple metrics on panoramic driving images. Dataset and method available at https://av.dfki.de/drivergaze360.

</details>


### [112] [Spherical Leech Quantization for Visual Tokenization and Generation](https://arxiv.org/abs/2512.14697)
*Yue Zhao,Hanwen Jiang,Zhenlin Xu,Chutong Yang,Ehsan Adeli,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: 本文通过格编码统一了非参数量化方法，并提出了一种基于Leech格的新量化方法（Λ₂₄-SQ），该方法在图像任务中实现了更简单的训练、更好的重建质量和更高的压缩效率，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 非参数量化因其参数效率和对大型码本的可扩展性而备受关注。现有查找无关的量化方法（如BSQ）在训练时需要辅助损失项，作者旨在通过格编码的视角来理解并改进这些方法。

Method: 本文通过格编码的视角统一了不同的非参数量化方法。探讨了多种格候选，包括随机格、广义斐波那契格和最密堆球格。最终提出并实现了基于Leech格的量化方法，命名为球形Leech量化（Λ₂₄-SQ）。

Result: 研究发现，基于Leech格的量化方法（Λ₂₄-SQ）因其高对称性和在超球体上的均匀分布，简化了训练过程，并改善了重建-压缩的权衡。在图像token化和压缩任务中，Λ₂₄-SQ在所有指标上均优于现有最佳技术BSQ，同时消耗更少的比特。这种改进也适用于最先进的自回归图像生成框架。

Conclusion: Leech格量化（Λ₂₄-SQ）是一种优越的非参数量化方法，它不仅简化了训练过程，还在图像token化和压缩任务中提供了更好的重建质量和压缩效率，超越了现有技术。

Abstract: Non-parametric quantization has received much attention due to its efficiency on parameters and scalability to a large codebook. In this paper, we present a unified formulation of different non-parametric quantization methods through the lens of lattice coding. The geometry of lattice codes explains the necessity of auxiliary loss terms when training auto-encoders with certain existing lookup-free quantization variants such as BSQ. As a step forward, we explore a few possible candidates, including random lattices, generalized Fibonacci lattices, and densest sphere packing lattices. Among all, we find the Leech lattice-based quantization method, which is dubbed as Spherical Leech Quantization ($Λ_{24}$-SQ), leads to both a simplified training recipe and an improved reconstruction-compression tradeoff thanks to its high symmetry and even distribution on the hypersphere. In image tokenization and compression tasks, this quantization approach achieves better reconstruction quality across all metrics than BSQ, the best prior art, while consuming slightly fewer bits. The improvement also extends to state-of-the-art auto-regressive image generation frameworks.

</details>


### [113] [4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation](https://arxiv.org/abs/2512.14235)
*Jimmie Kwok,Holger Caesar,Andras Palffy*

Main category: cs.CV

TL;DR: 本文提出了一种名为4D-RaDiff的新框架，用于生成合成的4D雷达点云数据，以解决雷达感知系统中带标注数据稀缺的问题，从而提高目标检测性能并减少对真实标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 汽车雷达在环境感知方面表现出良好的成本效益和恶劣天气下的鲁棒性，但带标注雷达数据的有限性严重阻碍了雷达感知系统的发展。

Method: 本文提出4D-RaDiff框架，通过对潜在点云表示应用扩散模型来生成4D雷达点云，该方法考虑了雷达点云的稀疏性和独特特性。生成过程可以通过物体或场景级别的条件控制。该框架能将未标注的边界框转换为高质量的雷达标注，并将现有的激光雷达点云数据转换为逼真的雷达场景。

Result: 实验表明，将4D-RaDiff生成的合成雷达数据作为数据增强方法纳入训练，持续提升了目标检测性能。此外，在合成数据上进行预训练可以将所需的带标注雷达数据量减少高达90%，同时达到可比的目标检测性能。

Conclusion: 4D-RaDiff框架通过生成高质量的合成雷达数据，有效解决了雷达数据稀缺的挑战，显著改善了雷达目标检测的性能，并大幅降低了对真实标注数据的需求。

Abstract: Automotive radar has shown promising developments in environment perception due to its cost-effectiveness and robustness in adverse weather conditions. However, the limited availability of annotated radar data poses a significant challenge for advancing radar-based perception systems. To address this limitation, we propose a novel framework to generate 4D radar point clouds for training and evaluating object detectors. Unlike image-based diffusion, our method is designed to consider the sparsity and unique characteristics of radar point clouds by applying diffusion to a latent point cloud representation. Within this latent space, generation is controlled via conditioning at either the object or scene level. The proposed 4D-RaDiff converts unlabeled bounding boxes into high-quality radar annotations and transforms existing LiDAR point cloud data into realistic radar scenes. Experiments demonstrate that incorporating synthetic radar data of 4D-RaDiff as data augmentation method during training consistently improves object detection performance compared to training on real data only. In addition, pre-training on our synthetic data reduces the amount of required annotated radar data by up to 90% while achieving comparable object detection performance.

</details>


### [114] [CAPRMIL: Context-Aware Patch Representations for Multiple Instance Learning](https://arxiv.org/abs/2512.14540)
*Andreas Lolos,Theofilos Christodoulou,Aris L. Moustakas,Stergios Christodoulidis,Maria Vakalopoulou*

Main category: cs.CV

TL;DR: CAPRMIL提出了一种新颖的、聚合器无关的多实例学习（MIL）框架，通过生成富含上下文信息的补丁嵌入，并在不依赖复杂注意力聚合的情况下，实现了与现有技术相当的性能，同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 在计算病理学中，由于全玻片图像（WSI）的巨大尺寸和像素级标注的稀缺性，弱监督深度学习已成为标准，其中多实例学习（MIL）是主要的训练框架。然而，现有的MIL方法往往依赖复杂的注意力聚合，增加了模型复杂性和计算成本。

Method: CAPRMIL受神经偏微分方程（PDE）求解器的启发，提出了一种高效、聚合器无关的MIL框架。它通过将使用冻结补丁编码器提取的补丁特征投影到一小组全局上下文/形态感知的token中，并利用多头自注意力机制，以线性计算复杂度注入全局上下文。最终，它与简单的平均MIL聚合器结合使用。

Result: CAPRMIL在多个公共病理学基准测试中，其玻片级性能与现有技术（SOTA）MIL方法持平，同时将可训练参数总数减少了48%-92.8%，推理期间的FLOPs降低了52%-99%，并在GPU内存效率和训练时间方面表现出色。

Conclusion: 研究结果表明，在聚合之前学习丰富的、上下文感知的实例表示，是全玻片分析中复杂池化机制的一种有效且可扩展的替代方案。

Abstract: In computational pathology, weak supervision has become the standard for deep learning due to the gigapixel scale of WSIs and the scarcity of pixel-level annotations, with Multiple Instance Learning (MIL) established as the principal framework for slide-level model training. In this paper, we introduce a novel setting for MIL methods, inspired by proceedings in Neural Partial Differential Equation (PDE) Solvers. Instead of relying on complex attention-based aggregation, we propose an efficient, aggregator-agnostic framework that removes the complexity of correlation learning from the MIL aggregator. CAPRMIL produces rich context-aware patch embeddings that promote effective correlation learning on downstream tasks. By projecting patch features -- extracted using a frozen patch encoder -- into a small set of global context/morphology-aware tokens and utilizing multi-head self-attention, CAPRMIL injects global context with linear computational complexity with respect to the bag size. Paired with a simple Mean MIL aggregator, CAPRMIL matches state-of-the-art slide-level performance across multiple public pathology benchmarks, while reducing the total number of trainable parameters by 48%-92.8% versus SOTA MILs, lowering FLOPs during inference by 52%-99%, and ranking among the best models on GPU memory efficiency and training time. Our results indicate that learning rich, context-aware instance representations before aggregation is an effective and scalable alternative to complex pooling for whole-slide analysis. Our code is available at https://github.com/mandlos/CAPRMIL

</details>


### [115] [Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding](https://arxiv.org/abs/2512.14236)
*Nando Metzger,Prune Truong,Goutam Bhat,Konrad Schindler,Federico Tombari*

Main category: cs.CV

TL;DR: Elastic3D是一种可控的、端到端的单目到双目视频转换方法，基于潜在扩散模型，通过新颖的引导式VAE解码器生成高质量、对极几何一致的双目视频，并允许用户控制立体效果强度。


<details>
  <summary>Details</summary>
Motivation: 沉浸式3D内容需求日益增长，需要自动化单目到双目视频转换。现有方法因显式深度估计和扭曲而产生伪影。

Method: Elastic3D是一种基于（条件）潜在扩散的直接端到端方法，避免了显式深度估计和扭曲。其核心是一个新颖的、引导式VAE解码器，确保输出锐利且对极几何一致的双目视频。该方法还允许用户在推理时通过直观的标量旋钮控制立体效果的强度（即视差范围）。

Result: 在三个不同的真实世界双目视频数据集上的实验表明，该方法优于传统的基于扭曲和近期无扭曲的基线方法，并为可靠、可控的双目视频转换树立了新标准。

Conclusion: Elastic3D提供了一种卓越的、可控的、可靠的单目到双目视频转换解决方案，解决了现有方法的局限性，并满足了对高质量沉浸式3D内容的需求。

Abstract: The growing demand for immersive 3D content calls for automated monocular-to-stereo video conversion. We present Elastic3D, a controllable, direct end-to-end method for upgrading a conventional video to a binocular one. Our approach, based on (conditional) latent diffusion, avoids artifacts due to explicit depth estimation and warping. The key to its high-quality stereo video output is a novel, guided VAE decoder that ensures sharp and epipolar-consistent stereo video output. Moreover, our method gives the user control over the strength of the stereo effect (more precisely, the disparity range) at inference time, via an intuitive, scalar tuning knob. Experiments on three different datasets of real-world stereo videos show that our method outperforms both traditional warping-based and recent warping-free baselines and sets a new standard for reliable, controllable stereo video conversion. Please check the project page for the video samples https://elastic3d.github.io.

</details>


### [116] [Native and Compact Structured Latents for 3D Generation](https://arxiv.org/abs/2512.14692)
*Jianfeng Xiang,Xiaoxue Chen,Sicheng Xu,Ruicheng Wang,Zelong Lv,Yu Deng,Hongyuan Zhu,Yue Dong,Hao Zhao,Nicholas Jing Yuan,Jiaolong Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为O-Voxel的稀疏体素结构，能够鲁棒地建模复杂拓扑和详细外观的3D资产。结合稀疏压缩VAE和大规模流匹配模型，实现了高质量、高效的3D生成，显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型在捕获具有复杂拓扑和详细外观的资产方面存在局限性，其表示方法难以有效应对。

Method: 核心是O-Voxel（全能体素表示），一种新的稀疏体素结构，用于编码几何和外观（包括PBR参数），能够建模任意拓扑。基于O-Voxel，设计了一个稀疏压缩VAE，提供高空间压缩率和紧凑的潜在空间。训练了包含40亿参数的大规模流匹配模型，用于3D生成，使用了多样化的公共3D资产数据集。

Result: 尽管模型规模庞大，推理效率仍然很高。生成的资产在几何和材质质量方面远超现有模型。

Conclusion: 该方法在3D生成建模领域取得了重大进展，为复杂3D资产的生成提供了有效解决方案。

Abstract: Recent advancements in 3D generative modeling have significantly improved the generation realism, yet the field is still hampered by existing representations, which struggle to capture assets with complex topologies and detailed appearance. This paper present an approach for learning a structured latent representation from native 3D data to address this challenge. At its core is a new sparse voxel structure called O-Voxel, an omni-voxel representation that encodes both geometry and appearance. O-Voxel can robustly model arbitrary topology, including open, non-manifold, and fully-enclosed surfaces, while capturing comprehensive surface attributes beyond texture color, such as physically-based rendering parameters. Based on O-Voxel, we design a Sparse Compression VAE which provides a high spatial compression rate and a compact latent space. We train large-scale flow-matching models comprising 4B parameters for 3D generation using diverse public 3D asset datasets. Despite their scale, inference remains highly efficient. Meanwhile, the geometry and material quality of our generated assets far exceed those of existing models. We believe our approach offers a significant advancement in 3D generative modeling.

</details>


### [117] [Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in](https://arxiv.org/abs/2512.14273)
*Xiaoqian Shen,Min-Hung Chen,Yu-Chiang Frank Wang,Mohamed Elhoseiny,Ryo Hachiuma*

Main category: cs.CV

TL;DR: 本文提出了Zoom-Zero，一个粗粒度到细粒度的框架，用于改进视频问答（GVQA）中的时间定位和答案准确性，解决了大型视频-语言模型（LVLMs）时间感知能力有限以及现有方法中时间定位不准确和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视频-语言模型（LVLMs）在视频问答（GVQA）中表现出有限的时间感知能力。现有的基于群组相对策略优化（GRPO）的方法在忠实地将答案与相关视频证据联系起来时仍面临困难，导致时间定位错误和幻觉。

Method: 本文提出了Zoom-Zero，一个粗粒度到细粒度的框架：首先定位与查询相关的视频片段，然后时间上放大到最显著的帧进行更细粒度的视觉验证。该方法通过两项关键创新改进了GRPO：(i) 一种放大准确性奖励（zoom-in accuracy reward），用于验证时间定位预测的忠实度并促进细粒度的视觉验证；(ii) 令牌选择性信用分配（token-selective credit assignment），将奖励归因于负责时间定位或答案生成的令牌，以解决GRPO处理多方面奖励信号的问题。在推理阶段，粗粒度到细粒度的放大也有助于长视频理解。

Result: 该方法在NExT-GQA上将时间定位提高了5.2%，在ReXTime上提高了4.6%，同时将平均答案准确率提高了2.4%。此外，推理过程中的粗粒度到细粒度放大在长视频基准测试中平均带来了6.4%的改进。

Conclusion: 本文提出的方法推进了视频问答技术，显著提高了时间定位和答案准确性，并通过在推理阶段的粗粒度到细粒度放大，在不损害全局上下文的情况下保留了关键视觉细节，从而增强了长视频理解能力。

Abstract: Grounded video question answering (GVQA) aims to localize relevant temporal segments in videos and generate accurate answers to a given question; however, large video-language models (LVLMs) exhibit limited temporal awareness. Although existing approaches based on Group Relative Policy Optimization (GRPO) attempt to improve temporal grounding, they still struggle to faithfully ground their answers in the relevant video evidence, leading to temporal mislocalization and hallucinations. In this work, we present Zoom-Zero, a coarse-to-fine framework that first localizes query-relevant segments and then temporally zooms into the most salient frames for finer-grained visual verification. Our method addresses the limits of GRPO for the GVQA task with two key innovations: (i) a zoom-in accuracy reward that validates the fidelity of temporal grounding prediction and facilitates fine-grained visual verification on grounded frames; (ii) token-selective credit assignment, which attributes rewards to the tokens responsible for temporal localization or answer generation, mitigating GRPO's issue in handling multi-faceted reward signals. Our proposed method advances grounded video question answering, improving temporal grounding by 5.2\% on NExT-GQA and 4.6\% on ReXTime, while also enhancing average answer accuracy by 2.4\%. Additionally, the coarse-to-fine zoom-in during inference further benefits long-form video understanding by preserving critical visual details without compromising global context, yielding an average improvement of 6.4\% on long-video benchmarks.

</details>


### [118] [TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning](https://arxiv.org/abs/2512.14274)
*Yu Chen,Hongwei Lin*

Main category: cs.CV

TL;DR: 本文提出了一种名为TUN的多模态网络，用于自动检测一维持久化图（PDs）中的显著点，有效解决了拓扑数据分析中信号识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 持久化图在理解点云拓扑方面是强大工具，但识别其中编码真实信号的点仍具挑战性。这阻碍了拓扑数据分析在许多需要自动、可靠解释PDs以进行下游决策的应用中的实际采用。

Method: 本文提出了拓扑理解网络（TUN），一个多模态网络。它结合了增强的PD描述符与自注意力机制、PointNet风格的点云编码器、学习融合和逐点分类。此外，还采用了稳定的预处理和对不平衡数据敏感的训练方法。

Result: 实验结果表明，TUN在检测持久化图中的显著点方面优于经典方法，展示了其在实际应用中的有效性。

Conclusion: TUN为自动有效识别持久化图中的关键点提供了一个解决方案，这对下游应用至关重要。

Abstract: Persistence diagrams (PDs) provide a powerful tool for understanding the topology of the underlying shape of a point cloud. However, identifying which points in PDs encode genuine signals remains challenging. This challenge directly hinders the practical adoption of topological data analysis in many applications, where automated and reliable interpretation of persistence diagrams is essential for downstream decision-making. In this paper, we study automatic significance detection for one-dimensional persistence diagrams. Specifically, we propose Topology Understanding Net (TUN), a multi-modal network that combines enhanced PD descriptors with self-attention, a PointNet-style point cloud encoder, learned fusion, and per-point classification, alongside stable preprocessing and imbalance-aware training. It provides an automated and effective solution for identifying significant points in PDs, which are critical for downstream applications. Experiments show that TUN outperforms classic methods in detecting significant points in PDs, illustrating its effectiveness in real-world applications.

</details>


### [119] [Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs](https://arxiv.org/abs/2512.14257)
*Wentao Wan,Kaiyu Wu,Qingyang Ma,Nan Kang,Yunjie Chen,Liang Lin,Keze Wang*

Main category: cs.CV

TL;DR: 本文提出EVPG方法，通过构建有向概率图将不可微的视觉编程（VP）执行过程重构为可微的概率推理过程，从而实现对VP框架中预训练模型的端到端梯度优化，显著提升了复杂视觉推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的视觉编程（VP）研究主要关注提升LLM生成的视觉程序质量，但忽略了优化VP调用的预训练模型（作为分解子任务的模块）。主要挑战在于：缺乏子任务标签，且VP的不可微性阻碍了利用最终标签进行端到端梯度优化。

Method: 提出EVPG（通过概率图增强视觉推理的视觉编程）方法。具体地，根据VP执行过程中的变量依赖关系，构建一个有向概率图。该图将不可微的VP执行过程重构为可微的精确概率推理过程，从而使VP框架能够利用最终标签进行高效的、基于梯度的端到端监督学习。

Result: 广泛而全面的实验证明了EVPG的有效性和优势，在GQA、NLVRv2和Open Images这三个经典的复杂视觉推理任务上，显著提升了VP的性能。

Conclusion: EVPG通过引入可微分的概率图，成功解决了VP框架中预训练模型优化难题，实现了端到端学习，并在复杂视觉推理任务上取得了显著的性能提升。

Abstract: Recently, Visual Programming (VP) based on large language models (LLMs) has rapidly developed and demonstrated significant potential in complex Visual Reasoning (VR) tasks. Previous works to enhance VP have primarily focused on improving the quality of LLM-generated visual programs. However, they have neglected to optimize the VP-invoked pre-trained models, which serve as modules for the visual sub-tasks decomposed from the targeted tasks by VP. The difficulty is that there are only final labels of targeted VR tasks rather than labels of sub-tasks. Besides, the non-differentiable nature of VP impedes the direct use of efficient gradient-based optimization methods to leverage final labels for end-to-end learning of the entire VP framework. To overcome these issues, we propose EVPG, a method to Enhance Visual Programming for visual reasoning via Probabilistic Graphs. Specifically, we creatively build a directed probabilistic graph according to the variable dependency relationships during the VP executing process, which reconstructs the non-differentiable VP executing process into a differentiable exact probability inference process on this directed probabilistic graph. As a result, this enables the VP framework to utilize the final labels for efficient, gradient-based optimization in end-to-end supervised learning on targeted VR tasks. Extensive and comprehensive experiments demonstrate the effectiveness and advantages of our EVPG, showing significant performance improvements for VP on three classical complex VR tasks: GQA, NLVRv2, and Open Images.

</details>


### [120] [Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure](https://arxiv.org/abs/2512.14336)
*Jooyeol Yun,Jaegul Choo*

Main category: cs.CV

TL;DR: 本文提出一个框架，通过统计聚合弱部分预测来恢复SVG的语义结构，从而使视觉语言模型（VLM）能够生成更连贯的SVG动画。


<details>
  <summary>Details</summary>
Motivation: 现代网页设计中对SVG动画的需求不断增长，但当前的视觉语言模型（VLM）在自动化矢量图形动画方面面临挑战。VLM常常错误处理SVG，因为视觉上连贯的部分常被分解为低级形状，缺乏关于哪些元素应一起移动的指导。

Method: 该方法通过统计聚合多个弱部分预测来恢复SVG所需的语义结构，从而从噪声预测中稳定地推断语义。通过将SVG重组为语义组，使VLM能够生成更连贯的动画。

Result: 实验表明，与现有方法相比，该方法取得了显著的提升，VLM能够产生更具连贯性的动画。

Conclusion: 语义恢复是实现鲁棒SVG动画的关键一步，并支持VLM与矢量图形之间更具解释性的交互，揭示了当前VLM系统忽视的缺失层。

Abstract: Scalable Vector Graphics (SVG) are central to modern web design, and the demand to animate them continues to grow as web environments become increasingly dynamic. Yet automating the animation of vector graphics remains challenging for vision-language models (VLMs) despite recent progress in code generation and motion planning. VLMs routinely mis-handle SVGs, since visually coherent parts are often fragmented into low-level shapes that offer little guidance of which elements should move together. In this paper, we introduce a framework that recovers the semantic structure required for reliable SVG animation and reveals the missing layer that current VLM systems overlook. This is achieved through a statistical aggregation of multiple weak part predictions, allowing the system to stably infer semantics from noisy predictions. By reorganizing SVGs into semantic groups, our approach enables VLMs to produce animations with far greater coherence. Our experiments demonstrate substantial gains over existing approaches, suggesting that semantic recovery is the key step that unlocks robust SVG animation and supports more interpretable interactions between VLMs and vector graphics.

</details>


### [121] [PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition](https://arxiv.org/abs/2512.14309)
*Abdullah Al Mamun,Miaohua Zhang,David Ahmedt-Aristizabal,Zeeshan Hayder,Mohammad Awrangjeb*

Main category: cs.CV

TL;DR: PSMamba是一个渐进式自监督学习框架，它结合了Vision Mamba和双学生分层蒸馏策略，旨在有效捕捉植物病害图像中的多尺度病变模式，并在多个基准数据集上超越了现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 大多数现有自监督学习框架侧重于全局对齐，难以捕捉植物病害图像特有的分层、多尺度病变模式。

Method: PSMamba整合了Vision Mamba的高效序列建模能力与双学生分层蒸馏策略。它采用一个共享的全局教师和两个专门的学生：一个处理中尺度视图以捕捉病变分布和叶脉结构，另一个关注局部视图以捕捉纹理不规则性和早期病变等细粒度线索。通过一致性损失确保跨尺度对齐，共同学习上下文和详细表示。

Result: 在三个基准数据集上的实验表明，PSMamba持续优于最先进的自监督学习方法，在域偏移和细粒度场景中均提供了卓越的准确性和鲁棒性。

Conclusion: PSMamba通过其渐进式自监督框架和双学生分层蒸馏策略，成功解决了植物病害图像中分层、多尺度病变模式的捕捉难题，实现了优越的性能和鲁棒性。

Abstract: Self-supervised Learning (SSL) has become a powerful paradigm for representation learning without manual annotations. However, most existing frameworks focus on global alignment and struggle to capture the hierarchical, multi-scale lesion patterns characteristic of plant disease imagery. To address this gap, we propose PSMamba, a progressive self-supervised framework that integrates the efficient sequence modelling of Vision Mamba (VM) with a dual-student hierarchical distillation strategy. Unlike conventional single teacher-student designs, PSMamba employs a shared global teacher and two specialised students: one processes mid-scale views to capture lesion distributions and vein structures, while the other focuses on local views to capture fine-grained cues such as texture irregularities and early-stage lesions. This multi-granular supervision facilitates the joint learning of contextual and detailed representations, with consistency losses ensuring coherent cross-scale alignment. Experiments on three benchmark datasets show that PSMamba consistently outperforms state-of-the-art SSL methods, delivering superior accuracy and robustness in both domain-shifted and fine-grained scenarios.

</details>


### [122] [SS4D: Native 4D Generative Model via Structured Spacetime Latents](https://arxiv.org/abs/2512.14284)
*Zhibing Li,Mengchen Zhang,Tong Wu,Jing Tan,Jiaqi Wang,Dahua Lin*

Main category: cs.CV

TL;DR: SS4D是一种原生4D生成模型，可以直接从单目视频合成动态3D物体，具有高保真度、时间连贯性和结构一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过优化3D或视频生成模型来构建4D表示，而SS4D旨在直接在4D数据上训练生成器，以实现更高的保真度、时间连贯性和结构一致性。同时，也为了解决4D训练数据稀缺的问题。

Method: SS4D的核心是使用一组结构化的时空潜在变量。具体方法包括：1) 利用预训练的单图像到3D模型来保持强大的空间一致性。2) 引入专门的时间层来推理帧间关系，以增强时间一致性。3) 使用分解的4D卷积和时间下采样块沿时间轴压缩潜在序列，以支持长视频序列的有效训练和推理。此外，还采用了精心设计的训练策略来提高对遮挡的鲁棒性。

Result: 该模型实现了高保真度、时间连贯性和结构一致性，能够直接从单目视频合成动态3D物体。

Conclusion: SS4D成功地展示了一种直接从单目视频合成动态3D物体的原生4D生成模型，通过创新的时空潜在表示和训练策略，克服了数据稀缺和效率挑战，达到了优异的生成质量和一致性。

Abstract: We present SS4D, a native 4D generative model that synthesizes dynamic 3D objects directly from monocular video. Unlike prior approaches that construct 4D representations by optimizing over 3D or video generative models, we train a generator directly on 4D data, achieving high fidelity, temporal coherence, and structural consistency. At the core of our method is a compressed set of structured spacetime latents. Specifically, (1) To address the scarcity of 4D training data, we build on a pre-trained single-image-to-3D model, preserving strong spatial consistency. (2) Temporal consistency is enforced by introducing dedicated temporal layers that reason across frames. (3) To support efficient training and inference over long video sequences, we compress the latent sequence along the temporal axis using factorized 4D convolutions and temporal downsampling blocks. In addition, we employ a carefully designed training strategy to enhance robustness against occlusion

</details>


### [123] [VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image](https://arxiv.org/abs/2512.14677)
*Sicheng Xu,Guojun Chen,Jiaolong Yang,Yizhong Zhang,Yu Deng,Steve Lin,Baining Guo*

Main category: cs.CV

TL;DR: VASA-3D是一种音频驱动的单次生成3D头部虚拟形象的方法，它能从单张肖像图生成逼真且表情丰富的3D说话头部，并支持高帧率的自由视角视频在线生成。


<details>
  <summary>Details</summary>
Motivation: 当前研究面临两大挑战：一是难以捕捉人脸细微的表情细节；二是从单张肖像图像重建复杂的3D头部虚拟形象。

Method: VASA-3D利用VASA-1的运动潜在空间来精确建模表情细节，并通过设计一个以该运动潜在空间为条件的3D头部模型，将2D运动潜在空间转换到3D。其对单张图像的定制化是通过一个优化框架实现的，该框架利用从输入图像合成的参考头部视频帧，并采用对生成训练数据中的伪影和有限姿态覆盖具有鲁棒性的各种训练损失。

Result: 实验表明，VASA-3D生成的逼真3D说话头部是现有技术无法比拟的。它支持以高达75 FPS的速度在线生成512x512的自由视角视频。

Conclusion: VASA-3D能够生成高度逼真的3D说话头部，并支持高效的在线自由视角视频生成，从而促进更具沉浸感的逼真3D虚拟形象互动。

Abstract: We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.

</details>


### [124] [HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis](https://arxiv.org/abs/2512.14352)
*Kaizhe Zhang,Yijie Zhou,Weizhan Zhang,Caixia Yan,Haipeng Du,yugui xie,Yu-Hui Wen,Yong-Jin Liu*

Main category: cs.CV

TL;DR: 本文提出混合高斯泼溅 (HGS) 方法，通过静态-动态分解和RBF建模，显著减少动态新视图合成的模型尺寸和渲染延迟，实现高效的实时沉浸式体验。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的动态新视图合成方法，因模型复杂性和参数冗余，导致模型庞大、渲染速度慢，不适用于实时应用，尤其是在资源受限设备上。

Method: 本文提出混合高斯泼溅 (HGS) 框架，通过静态-动态分解 (SDD) 策略，在统一表示中分离场景的静态和动态区域。核心创新是利用径向基函数 (RBF) 对高斯基元进行建模：动态区域使用时间依赖的RBF捕获时间变化，静态区域通过共享时间不变参数减少冗余。此外，引入两阶段训练策略以增强静态-动态边界的时间一致性。

Result: HGS将模型尺寸减少高达98%，在单张RTX 3090 GPU上实现4K分辨率下高达125 FPS的实时渲染，在RTX 3050上实现1352 * 1014分辨率下160 FPS的渲染，并已集成到VR系统中。同时，它在保持与SOTA方法相当渲染质量的同时，显著提升了高频细节和突变场景的视觉保真度。

Conclusion: HGS提供了一种紧凑高效的动态新视图合成框架，通过静态-动态分解和RBF建模，有效解决了现有方法的模型复杂度和渲染效率问题，实现了高质量的实时渲染，特别适用于资源受限设备和沉浸式VR体验。

Abstract: Dynamic novel view synthesis (NVS) is essential for creating immersive experiences. Existing approaches have advanced dynamic NVS by introducing 3D Gaussian Splatting (3DGS) with implicit deformation fields or indiscriminately assigned time-varying parameters, surpassing NeRF-based methods. However, due to excessive model complexity and parameter redundancy, they incur large model sizes and slow rendering speeds, making them inefficient for real-time applications, particularly on resource-constrained devices. To obtain a more efficient model with fewer redundant parameters, in this paper, we propose Hybrid Gaussian Splatting (HGS), a compact and efficient framework explicitly designed to disentangle static and dynamic regions of a scene within a unified representation. The core innovation of HGS lies in our Static-Dynamic Decomposition (SDD) strategy, which leverages Radial Basis Function (RBF) modeling for Gaussian primitives. Specifically, for dynamic regions, we employ time-dependent RBFs to effectively capture temporal variations and handle abrupt scene changes, while for static regions, we reduce redundancy by sharing temporally invariant parameters. Additionally, we introduce a two-stage training strategy tailored for explicit models to enhance temporal coherence at static-dynamic boundaries. Experimental results demonstrate that our method reduces model size by up to 98% and achieves real-time rendering at up to 125 FPS at 4K resolution on a single RTX 3090 GPU. It further sustains 160 FPS at 1352 * 1014 on an RTX 3050 and has been integrated into the VR system. Moreover, HGS achieves comparable rendering quality to state-of-the-art methods while providing significantly improved visual fidelity for high-frequency details and abrupt scene changes.

</details>


### [125] [CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer](https://arxiv.org/abs/2512.14560)
*Xianwei Cao,Dou Quan,Shuang Wang,Ning Huyan,Wei Wang,Yunan Li,Licheng Jiao*

Main category: cs.CV

TL;DR: 本文提出CLNet，一个新颖的对应感知特征细化框架，用于解决跨视图地理定位（IRCVGL）中卫星图和街景图之间显著视角差异导致的空间对应建模不足问题。CLNet通过神经对应图、非线性嵌入转换器和全局特征重校准三个模块，明确地桥接语义和几何鸿沟，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图像检索的跨视图地理定位（IRCVGL）方法主要依赖于学习鲁棒的全局表示或隐式特征对齐，但它们往往未能显式地建模对准确定位至关重要的空间对应关系，这在卫星图和街景图等视角差异显著的图像之间是一个关键挑战。

Method: 本文提出了一个名为CLNet的对应感知特征细化框架，将视图对齐过程分解为三个可学习和互补的模块：1) 神经对应图（NCM），通过潜在对应场空间对齐跨视图特征；2) 非线性嵌入转换器（NEC），使用基于MLP的变换重新映射跨视角的特征；3) 全局特征重校准（GFR）模块，根据学习到的空间线索重新加权信息丰富的特征通道。CLNet旨在共同捕获高级语义和细粒度对齐。

Result: 在CVUSA、CVACT、VIGOR和University-1652四个公共基准测试中，所提出的CLNet取得了最先进的性能，并提供了更好的可解释性和泛化能力。

Conclusion: CLNet通过明确建模跨视图特征之间的空间对应关系，有效地弥合了语义和几何鸿沟，解决了IRCVGL中的关键挑战。该方法在多个基准测试中表现出色，验证了其在捕获高层语义和细粒度对齐方面的能力，并提升了模型的可解释性和泛化性。

Abstract: Image retrieval-based cross-view geo-localization (IRCVGL) aims to match images captured from significantly different viewpoints, such as satellite and street-level images. Existing methods predominantly rely on learning robust global representations or implicit feature alignment, which often fail to model explicit spatial correspondences crucial for accurate localization. In this work, we propose a novel correspondence-aware feature refinement framework, termed CLNet, that explicitly bridges the semantic and geometric gaps between different views. CLNet decomposes the view alignment process into three learnable and complementary modules: a Neural Correspondence Map (NCM) that spatially aligns cross-view features via latent correspondence fields; a Nonlinear Embedding Converter (NEC) that remaps features across perspectives using an MLP-based transformation; and a Global Feature Recalibration (GFR) module that reweights informative feature channels guided by learned spatial cues. The proposed CLNet can jointly capture both high-level semantics and fine-grained alignments. Extensive experiments on four public benchmarks, CVUSA, CVACT, VIGOR, and University-1652, demonstrate that our proposed CLNet achieves state-of-the-art performance while offering better interpretability and generalizability.

</details>


### [126] [Unified Semantic Transformer for 3D Scene Understanding](https://arxiv.org/abs/2512.14364)
*Sebastian Koch,Johanna Wald,Hide Matsuki,Pedro Hermosilla,Timo Ropinski,Federico Tombari*

Main category: cs.CV

TL;DR: UNITE是一个统一的语义Transformer，能够从RGB图像端到端地预测多种3D语义属性，并在多个任务上达到最先进的性能，超越了许多特定任务模型。


<details>
  <summary>Details</summary>
Motivation: 由于真实世界的复杂性，现有的3D场景理解模型大多是任务特定的且受限的，缺乏一个能够统一处理多种语义任务的通用模型。

Method: UNITE是一个统一语义Transformer，采用前馈神经网络架构。它从RGB图像端到端地操作，直接预测3D场景分割、实例嵌入、开放词汇特征、功能性和关节。训练方法结合了2D蒸馏、大量自监督以及旨在确保3D视图一致性的新型多视图损失。

Result: UNITE在多个不同的语义任务上实现了最先进的性能，甚至在许多情况下超越了特定任务的模型，包括那些基于真实3D几何的模型。该模型仅需几秒钟即可推断出完整的3D语义几何。

Conclusion: UNITE成功地将多种3D语义任务统一到一个单一模型中，展示了卓越的性能和效率，能够从RGB图像实现全面的3D场景理解。

Abstract: Holistic 3D scene understanding involves capturing and parsing unstructured 3D environments. Due to the inherent complexity of the real world, existing models have predominantly been developed and limited to be task-specific. We introduce UNITE, a Unified Semantic Transformer for 3D scene understanding, a novel feed-forward neural network that unifies a diverse set of 3D semantic tasks within a single model. Our model operates on unseen scenes in a fully end-to-end manner and only takes a few seconds to infer the full 3D semantic geometry. Our approach is capable of directly predicting multiple semantic attributes, including 3D scene segmentation, instance embeddings, open-vocabulary features, as well as affordance and articulations, solely from RGB images. The method is trained using a combination of 2D distillation, heavily relying on self-supervision and leverages novel multi-view losses designed to ensure 3D view consistency. We demonstrate that UNITE achieves state-of-the-art performance on several different semantic tasks and even outperforms task-specific models, in many cases, surpassing methods that operate on ground truth 3D geometry. See the project website at unite-page.github.io

</details>


### [127] [Mimicking Human Visual Development for Learning Robust Image Representations](https://arxiv.org/abs/2512.14360)
*Ankita Raj,Kaashika Prajaapat,Tapan Kumar Gandhi,Chetan Arora*

Main category: cs.CV

TL;DR: 该研究受人类视觉发展启发，提出了一种渐进式模糊训练课程，通过在训练初期使用高度模糊图像并逐渐减少模糊度，显著提高了卷积神经网络的泛化能力和鲁棒性，同时对域内准确性影响最小。


<details>
  <summary>Details</summary>
Motivation: 人类视觉系统能很好地适应输入分布的变化，而现代卷积神经网络（CNNs）在这方面仍有欠缺。作者旨在通过模仿人类视觉系统的发展轨迹，提高CNNs的泛化能力和对分布偏移及噪声输入的鲁棒性。

Method: 该方法借鉴人类婴儿视觉逐渐从模糊到清晰的发展过程，提出了一种渐进式模糊课程。在训练初期，CNNs使用高度模糊的图像进行训练，随着训练的进行，模糊程度逐渐降低。这种方法鼓励网络优先学习全局结构而非高频伪影。

Result: 实验表明，早期模糊训练能增强模型的泛化能力，对域内准确性影响极小。相比标准训练，该课程在CIFAR-10-C数据集上将平均损坏误差（mCE）降低了8.30%，在ImageNet-100-C数据集上降低了4.43%。此外，该方法还能与CutMix、MixUp等其他数据增强技术互补，并增强模型的自然鲁棒性和对抗鲁棒性。

Conclusion: 渐进式模糊课程是一种有效且结构化的训练方法，能显著提升卷积神经网络的泛化能力和鲁棒性，且不会牺牲域内准确性。它模仿人类视觉发展，鼓励网络学习更稳健的特征，并能与其他增强技术结合使用。

Abstract: The human visual system is remarkably adept at adapting to changes in the input distribution; a capability modern convolutional neural networks (CNNs) still struggle to match. Drawing inspiration from the developmental trajectory of human vision, we propose a progressive blurring curriculum to improve the generalization and robustness of CNNs. Human infants are born with poor visual acuity, gradually refining their ability to perceive fine details. Mimicking this process, we begin training CNNs on highly blurred images during the initial epochs and progressively reduce the blur as training advances. This approach encourages the network to prioritize global structures over high-frequency artifacts, improving robustness against distribution shifts and noisy inputs. Challenging prior claims that blurring in the initial training epochs imposes a stimulus deficit and irreversibly harms model performance, we reveal that early-stage blurring enhances generalization with minimal impact on in-domain accuracy. Our experiments demonstrate that the proposed curriculum reduces mean corruption error (mCE) by up to 8.30% on CIFAR-10-C and 4.43% on ImageNet-100-C datasets, compared to standard training without blurring. Unlike static blur-based augmentation, which applies blurred images randomly throughout training, our method follows a structured progression, yielding consistent gains across various datasets. Furthermore, our approach complements other augmentation techniques, such as CutMix and MixUp, and enhances both natural and adversarial robustness against common attack methods. Code is available at https://github.com/rajankita/Visual_Acuity_Curriculum.

</details>


### [128] [EcoScapes: LLM-Powered Advice for Crafting Sustainable Cities](https://arxiv.org/abs/2512.14373)
*Martin Röhn,Nora Gourmelon,Vincent Christlein*

Main category: cs.CV

TL;DR: 本文提出一个多层系统，结合专业LLM、卫星图像分析和知识库，旨在帮助小型城市制定有效的气候适应策略。


<details>
  <summary>Details</summary>
Motivation: 小型城市在气候适应方面面临人员资源有限以及整合多源海量数据进行全面分析的挑战。

Method: 采用一个多层系统，该系统结合了专业的大型语言模型（LLM）、卫星图像分析和知识库。

Result: 该系统旨在克服小型城市在气候适应规划中的挑战，帮助其开发有效的气候适应策略。

Conclusion: 所提出的系统为小型城市提供了一种解决其气候适应挑战的方法，通过整合先进技术来支持策略制定。

Abstract: Climate adaptation is vital for the sustainability and sometimes the mere survival of our urban areas. However, small cities often struggle with limited personnel resources and integrating vast amounts of data from multiple sources for a comprehensive analysis. To overcome these challenges, this paper proposes a multi-layered system combining specialized LLMs, satellite imagery analysis and a knowledge base to aid in developing effective climate adaptation strategies. The corresponding code can be found at https://github.com/Photon-GitHub/EcoScapes.

</details>


### [129] [Optimizing Rank for High-Fidelity Implicit Neural Representations](https://arxiv.org/abs/2512.14366)
*Julian McGinnis,Florian A. Hölzl,Suprosanna Shit,Florentin Bieder,Paul Friedrich,Mark Mühlau,Björn Menze,Daniel Rueckert,Benedikt Wiestler*

Main category: cs.CV

TL;DR: 本文挑战了香草多层感知器（MLP）无法表示高频内容的固有架构限制的观点，认为这是训练过程中稳定秩降解的症状。通过在训练中调节网络秩，并使用如Muon等优化器，即使是简单的MLP也能显著提高信号保真度，在多个领域取得高达9 dB PSNR的提升。


<details>
  <summary>Details</summary>
Motivation: 普遍认为基于香草MLP的隐式神经表示（INR）无法表示高频内容，这促使研究转向架构干预（如坐标嵌入或专用激活函数）。本文质疑这种低频偏差是MLP学习高频内容的内在架构限制的观点。

Method: 本文通过实证证明，在训练过程中调节网络的秩可以显著提高学习信号的保真度。具体方法是使用像Muon这样的优化器，它提供高秩、近乎正交的更新，以维持网络的秩。

Result: 研究表明，调节网络秩能使即使是简单的MLP架构也具有高频表达能力。使用Muon等优化器能持续增强INR架构，甚至超越简单的ReLU MLPs。这些显著改进在自然图像、医学图像和新视角合成等多样化领域都成立，相比现有最佳技术实现了高达9 dB PSNR的提升。

Conclusion: 香草MLP的低频偏差并非学习高频内容的内在架构限制，而是训练过程中稳定秩降解的症状。通过在训练中调节网络秩，特别是使用提供高秩更新的优化器，可以显著提高MLP表示高频信号的能力，使简单架构也变得富有表现力。

Abstract: Implicit Neural Representations (INRs) based on vanilla Multi-Layer Perceptrons (MLPs) are widely believed to be incapable of representing high-frequency content. This has directed research efforts towards architectural interventions, such as coordinate embeddings or specialized activation functions, to represent high-frequency signals. In this paper, we challenge the notion that the low-frequency bias of vanilla MLPs is an intrinsic, architectural limitation to learn high-frequency content, but instead a symptom of stable rank degradation during training. We empirically demonstrate that regulating the network's rank during training substantially improves the fidelity of the learned signal, rendering even simple MLP architectures expressive. Extensive experiments show that using optimizers like Muon, with high-rank, near-orthogonal updates, consistently enhances INR architectures even beyond simple ReLU MLPs. These substantial improvements hold across a diverse range of domains, including natural and medical images, and novel view synthesis, with up to 9 dB PSNR improvements over the previous state-of-the-art. Our project page, which includes code and experimental results, is available at: (https://muon-inrs.github.io).

</details>


### [130] [The Devil is in Attention Sharing: Improving Complex Non-rigid Image Editing Faithfulness via Attention Synergy](https://arxiv.org/abs/2512.14423)
*Zhuo Chen,Fanyue Wei,Runze Xu,Jingjing Li,Lixin Duan,Angela Yao,Wen Li*

Main category: cs.CV

TL;DR: 针对大型扩散模型的免训练图像编辑，特别是复杂的非刚性编辑，存在注意力崩溃问题。SynPS通过协同利用位置嵌入和语义信息，动态调整其影响，有效平衡语义修改和保真度，从而实现更忠实的非刚性编辑。


<details>
  <summary>Details</summary>
Motivation: 免训练图像编辑在处理复杂非刚性编辑（如姿态或形状改变）时面临巨大挑战。主要原因是现有注意力共享机制中存在“注意力崩溃”，即位置嵌入或语义特征过度主导视觉内容检索，导致过度编辑或编辑不足。

Method: SynPS引入了一种编辑度量方法，用于量化每个去噪步骤所需的编辑幅度。基于此度量，它设计了一个注意力协同管道，该管道动态调节位置嵌入的影响力，使SynPS能够在语义修改和保真度保持之间取得平衡。通过自适应地整合位置和语义线索，SynPS有效避免了过度编辑和编辑不足。

Result: SynPS成功避免了过度编辑和编辑不足的问题。在公共和新整理的基准测试中进行的广泛实验表明，SynPS方法具有卓越的性能和忠实性。

Conclusion: SynPS通过协同利用位置嵌入和语义信息，并动态调整其影响，提供了一种在非刚性图像编辑中实现更高性能和忠实度的方法，有效解决了现有方法中注意力崩溃的问题。

Abstract: Training-free image editing with large diffusion models has become practical, yet faithfully performing complex non-rigid edits (e.g., pose or shape changes) remains highly challenging. We identify a key underlying cause: attention collapse in existing attention sharing mechanisms, where either positional embeddings or semantic features dominate visual content retrieval, leading to over-editing or under-editing.To address this issue, we introduce SynPS, a method that Synergistically leverages Positional embeddings and Semantic information for faithful non-rigid image editing. We first propose an editing measurement that quantifies the required editing magnitude at each denoising step. Based on this measurement, we design an attention synergy pipeline that dynamically modulates the influence of positional embeddings, enabling SynPS to balance semantic modifications and fidelity preservation.By adaptively integrating positional and semantic cues, SynPS effectively avoids both over- and under-editing. Extensive experiments on public and newly curated benchmarks demonstrate the superior performance and faithfulness of our approach.

</details>


### [131] [Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos](https://arxiv.org/abs/2512.14406)
*Le Jiang,Shaotong Zhu,Yedi Luo,Shayda Moezzi,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: 现有动态NeRF在大幅度视角偏差下表现不佳。本文提出ExpanDyNeRF，一个单目NeRF框架，利用高斯splatting先验和伪真值生成策略，实现大角度旋转下逼真的新视角合成。同时引入了SynDM数据集。


<details>
  <summary>Details</summary>
Motivation: 现有动态NeRF系统在显著视角偏差下，新颖视图合成方法常常失败，产生不稳定和不真实的渲染。

Method: 本文提出了ExpanDyNeRF，一个单目NeRF框架，它利用高斯splatting先验和伪真值生成策略，以实现大角度旋转下的逼真合成。ExpanDyNeRF优化密度和颜色特征，以改善挑战性视角的场景重建。此外，还提出了Synthetic Dynamic Multiview (SynDM) 数据集，这是第一个带有显式侧视图监督的动态场景合成多视图数据集，使用定制的GTA V渲染管线创建。

Result: 在SynDM和真实世界数据集上的定量和定性结果表明，ExpanDyNeRF在极端视角偏移下的渲染保真度方面显著优于现有动态NeRF方法。

Conclusion: ExpanDyNeRF成功解决了动态NeRF系统在大幅度视角偏差下新颖视图合成不稳定和不真实的问题，通过引入高斯splatting先验和伪真值策略，实现了更逼真的渲染效果，并得到了新数据集SynDM的支持。

Abstract: In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.

</details>


### [132] [LCMem: A Universal Model for Robust Image Memorization Detection](https://arxiv.org/abs/2512.14421)
*Mischa Dombrowski,Felix Nützel,Bernhard Kainz*

Main category: cs.CV

TL;DR: 本研究提出LCMem模型，将记忆检测视为重识别与复制检测的统一问题，实现了跨域、可靠且可扩展的记忆检测，显著提升了现有方法的性能，并揭示了现有隐私过滤器的局限性。


<details>
  <summary>Details</summary>
Motivation: 生成式图像模型虽能达到以假乱真的视觉真实感，但其在隐私保护数据共享方面的潜力尚未被充分理解。主要障碍在于缺乏可靠的记忆检测机制、量化评估不足以及现有隐私审计方法在跨领域泛化能力差。

Method: 将记忆检测视为重识别（身份一致性）和复制检测（增强鲁棒性重复）的统一问题，并引入了潜在对比记忆网络（LCMem）。LCMem采用两阶段训练策略：首先学习身份一致性，然后整合对增强鲁棒的复制检测。该模型在跨域环境中，对这两个任务进行联合评估。

Result: LCMem在六个基准数据集上，将重识别性能提高了16个百分点，复制检测性能提高了30个百分点，从而实现了更可靠的大规模记忆检测。结果还表明，现有隐私过滤器的性能和鲁棒性有限。

Conclusion: LCMem为跨域隐私审计设定了新标准，提供了可靠且可扩展的记忆检测。研究结果强调了对更强隐私保护机制的需求，以应对现有隐私过滤器的局限性。

Abstract: Recent advances in generative image modeling have achieved visual realism sufficient to deceive human experts, yet their potential for privacy preserving data sharing remains insufficiently understood. A central obstacle is the absence of reliable memorization detection mechanisms, limited quantitative evaluation, and poor generalization of existing privacy auditing methods across domains. To address this, we propose to view memorization detection as a unified problem at the intersection of re-identification and copy detection, whose complementary goals cover both identity consistency and augmentation-robust duplication, and introduce Latent Contrastive Memorization Network (LCMem), a cross-domain model evaluated jointly on both tasks. LCMem achieves this through a two-stage training strategy that first learns identity consistency before incorporating augmentation-robust copy detection. Across six benchmark datasets, LCMem achieves improvements of up to 16 percentage points on re-identification and 30 percentage points on copy detection, enabling substantially more reliable memorization detection at scale. Our results show that existing privacy filters provide limited performance and robustness, highlighting the need for stronger protection mechanisms. We show that LCMem sets a new standard for cross-domain privacy auditing, offering reliable and scalable memorization detection. Code and model is publicly available at https://github.com/MischaD/LCMem.

</details>


### [133] [SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition](https://arxiv.org/abs/2512.14489)
*Alessia Micieli,Giovanni Maria Farinella,Francesco Ragusa*

Main category: cs.CV

TL;DR: 本文介绍了一个新的意大利手语（LIS）识别数据集SignIT，包含644个视频，并提出了一个基准测试，结果显示现有最先进模型在该挑战性数据集上存在局限性。


<details>
  <summary>Details</summary>
Motivation: 研究意大利手语（LIS）识别任务需要新的数据集，以推动该领域的发展。

Method: 构建了SignIT数据集，包含644个视频（3.33小时），手动标注了94个不同手语类别，分属5个宏观类别。提取了用户手部、面部和身体的2D关键点。采用多种最先进模型，提出了手语识别任务的基准，并分析了时间信息、2D关键点和RGB帧对模型性能的影响。

Result: 实验结果表明，在SignIT这个具有挑战性的LIS数据集上，现有的最先进模型表现出局限性。

Conclusion: SignIT数据集的发布及其基准测试揭示了当前模型在意大利手语识别方面的不足，为未来的研究提供了资源和挑战。

Abstract: In this work we present SignIT, a new dataset to study the task of Italian Sign Language (LIS) recognition. The dataset is composed of 644 videos covering 3.33 hours. We manually annotated videos considering a taxonomy of 94 distinct sign classes belonging to 5 macro-categories: Animals, Food, Colors, Emotions and Family. We also extracted 2D keypoints related to the hands, face and body of the users. With the dataset, we propose a benchmark for the sign recognition task, adopting several state-of-the-art models showing how temporal information, 2D keypoints and RGB frames can be influence the performance of these models. Results show the limitations of these models on this challenging LIS dataset. We release data and annotations at the following link: https://fpv-iplab.github.io/SignIT/.

</details>


### [134] [LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction](https://arxiv.org/abs/2512.14594)
*Chenyu Zhao,Yingxue Xu,Fengtao Zhou,Yihui Wang,Hao Chen*

Main category: cs.CV

TL;DR: 该论文提出了KEMM模型，一个由大型语言模型（LLM）驱动的知识增强多模态模型，用于癌症生存预测。它通过整合LLM精炼的专家报告和预后背景知识，解决了高维病理图像和基因组数据特征提取困难以及模态对齐不足的问题，并在五个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的癌症生存预测方法依赖于高维且冗余的病理图像（WSIs）和基因组数据，导致难以提取判别性特征并对齐不同模态。此外，简单的生存随访标签不足以监督如此复杂的任务。

Method: 该研究提出了KEMM模型。1) 利用LLM精炼病理学家提供的病例专家报告，提供简洁、临床聚焦的诊断声明。2) 通过LLM简洁生成预后背景知识（PBK），提供不同癌症类型的宝贵预后信息。3) 引入知识增强跨模态（KECM）注意力模块，以利用这些知识，引导网络关注高冗余模态中具有判别性且与生存相关的特征。

Result: 在五个数据集上进行了广泛实验，结果表明KEMM模型取得了最先进的性能。

Conclusion: KEMM通过整合LLM驱动的专家报告和预后背景知识，有效解决了多模态癌症生存预测中特征提取和模态对齐的挑战，显著提升了预测性能。

Abstract: Current multimodal survival prediction methods typically rely on pathology images (WSIs) and genomic data, both of which are high-dimensional and redundant, making it difficult to extract discriminative features from them and align different modalities. Moreover, using a simple survival follow-up label is insufficient to supervise such a complex task. To address these challenges, we propose KEMM, an LLM-driven Knowledge-Enhanced Multimodal Model for cancer survival prediction, which integrates expert reports and prognostic background knowledge. 1) Expert reports, provided by pathologists on a case-by-case basis and refined by large language model (LLM), offer succinct and clinically focused diagnostic statements. This information may typically suggest different survival outcomes. 2) Prognostic background knowledge (PBK), generated concisely by LLM, provides valuable prognostic background knowledge on different cancer types, which also enhances survival prediction. To leverage these knowledge, we introduce the knowledge-enhanced cross-modal (KECM) attention module. KECM can effectively guide the network to focus on discriminative and survival-relevant features from highly redundant modalities. Extensive experiments on five datasets demonstrate that KEMM achieves state-of-the-art performance. The code will be released upon acceptance.

</details>


### [135] [FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications](https://arxiv.org/abs/2512.14574)
*Mitsuki Watanabe,Sosuke Amano,Kiyoharu Aizawa,Yoko Yamakata*

Main category: cs.CV

TL;DR: 本文提出了FoodLogAthl-218数据集，一个包含218个食物类别、6,925张真实世界餐食图片和丰富元数据的数据集，旨在解决现有食物图像分类模型依赖的网络爬取图片与用户真实餐食图片不符的问题。同时，提出了增量微调和上下文感知分类等特定任务。


<details>
  <summary>Details</summary>
Motivation: 食物图像分类模型对膳食管理应用至关重要，但现有公开数据集多依赖网络爬取图片，与用户真实餐食照片存在差异，导致模型在实际应用中效果不佳。此外，手动记录餐食负担重。

Method: 研究人员通过膳食管理应用FoodLog Athl收集真实世界的餐食记录，构建了FoodLogAthl-218数据集。该数据集包含6,925张图片、218个食物类别和14,349个边界框，并附带餐食日期、时间、匿名用户ID和餐食级上下文等元数据。基于此数据集，提出了三个任务：标准分类基准、遵循用户日志时间流的增量微调协议，以及利用整体餐食上下文对多菜肴图像进行分类的上下文感知分类任务。这些任务使用大型多模态模型（LMMs）进行评估。

Result: FoodLogAthl-218数据集提供了真实世界的、非过滤的、具有自然频率分布和类内多样性的食物图片。它包含了6,925张图片和14,349个边界框，涵盖218个食物类别。研究定义了标准分类、增量微调和上下文感知分类这三项任务，并使用大型多模态模型进行了评估。该数据集已公开发布。

Conclusion: FoodLogAthl-218数据集有效弥补了现有食物图像数据集与用户真实世界餐食照片之间的差距，为膳食管理应用提供了更实际、更具挑战性的训练和评估资源。提出的特定任务（如增量微调和上下文感知分类）为开发更符合实际应用场景的食物图像分类模型指明了方向。

Abstract: Food image classification models are crucial for dietary management applications because they reduce the burden of manual meal logging. However, most publicly available datasets for training such models rely on web-crawled images, which often differ from users' real-world meal photos. In this work, we present FoodLogAthl-218, a food image dataset constructed from real-world meal records collected through the dietary management application FoodLog Athl. The dataset contains 6,925 images across 218 food categories, with a total of 14,349 bounding boxes. Rich metadata, including meal date and time, anonymized user IDs, and meal-level context, accompany each image. Unlike conventional datasets-where a predefined class set guides web-based image collection-our data begins with user-submitted photos, and labels are applied afterward. This yields greater intra-class diversity, a natural frequency distribution of meal types, and casual, unfiltered images intended for personal use rather than public sharing. In addition to (1) a standard classification benchmark, we introduce two FoodLog-specific tasks: (2) an incremental fine-tuning protocol that follows the temporal stream of users' logs, and (3) a context-aware classification task where each image contains multiple dishes, and the model must classify each dish by leveraging the overall meal context. We evaluate these tasks using large multimodal models (LMMs). The dataset is publicly available at https://huggingface.co/datasets/FoodLog/FoodLogAthl-218.

</details>


### [136] [TAT: Task-Adaptive Transformer for All-in-One Medical Image Restoration](https://arxiv.org/abs/2512.14550)
*Zhiwen Yang,Jiaju Zhang,Yang Yi,Jian Liang,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 本文提出了一种任务自适应Transformer (TAT) 框架，通过任务自适应权重生成和损失平衡策略，有效解决了多任务医学图像恢复中存在的任务干扰和任务不平衡问题，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前一体化医学图像恢复(MedIR)模型在处理多模态和多退化类型任务时，面临两大挑战：一是任务干扰，即不同任务在共享参数上产生冲突的梯度更新方向；二是任务不平衡，即不同任务固有的学习难度差异导致优化不均。

Method: 本文提出了任务自适应Transformer (TAT) 框架。首先，引入了任务自适应权重生成策略，为每个任务生成独立的权重参数，从而消除共享权重参数上的潜在梯度冲突，以减轻任务干扰。其次，引入了任务自适应损失平衡策略，根据任务特定的学习难度动态调整损失权重，以防止任务主导或训练不足，解决任务不平衡问题。

Result: 广泛的实验表明，所提出的TAT模型在PET合成、CT去噪和MRI超分辨率这三项MedIR任务中，无论是在任务特定设置还是在一体化设置下，都取得了最先进的性能。

Conclusion: TAT框架通过动态适应不同任务，有效解决了多任务医学图像恢复中的任务干扰和任务不平衡问题，显著提升了模型在多样化医学图像恢复任务中的表现。

Abstract: Medical image restoration (MedIR) aims to recover high-quality medical images from their low-quality counterparts. Recent advancements in MedIR have focused on All-in-One models capable of simultaneously addressing multiple different MedIR tasks. However, due to significant differences in both modality and degradation types, using a shared model for these diverse tasks requires careful consideration of two critical inter-task relationships: task interference, which occurs when conflicting gradient update directions arise across tasks on the same parameter, and task imbalance, which refers to uneven optimization caused by varying learning difficulties inherent to each task. To address these challenges, we propose a task-adaptive Transformer (TAT), a novel framework that dynamically adapts to different tasks through two key innovations. First, a task-adaptive weight generation strategy is introduced to mitigate task interference by generating task-specific weight parameters for each task, thereby eliminating potential gradient conflicts on shared weight parameters. Second, a task-adaptive loss balancing strategy is introduced to dynamically adjust loss weights based on task-specific learning difficulties, preventing task domination or undertraining. Extensive experiments demonstrate that our proposed TAT achieves state-of-the-art performance in three MedIR tasks--PET synthesis, CT denoising, and MRI super-resolution--both in task-specific and All-in-One settings. Code is available at https://github.com/Yaziwel/TAT.

</details>


### [137] [WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling](https://arxiv.org/abs/2512.14614)
*Wenqiang Sun,Haiyu Zhang,Haoyuan Wang,Junta Wu,Zehan Wang,Zhenwei Wang,Yunhong Wang,Jun Zhang,Tengfei Wang,Chunchao Guo*

Main category: cs.CV

TL;DR: WorldPlay是一个流媒体视频扩散模型，通过创新方法解决了现有模型在速度和内存之间的权衡，实现了实时、交互式、具有长期几何一致性的世界建模。


<details>
  <summary>Details</summary>
Motivation: 当前方法在交互式世界建模中面临速度和内存限制，难以同时实现实时性和长期几何一致性。

Method: 该研究提出了三项关键创新：1) 双动作表示（Dual Action Representation）实现鲁棒的用户输入控制；2) 重构上下文记忆（Reconstituted Context Memory）通过动态重建上下文和时间重构来确保长期一致性；3) 上下文强制（Context Forcing）是一种针对内存感知模型的蒸馏方法，通过对齐教师和学生模型之间的记忆上下文，在实现实时速度的同时防止误差漂移。

Result: WorldPlay能够以24 FPS生成长视域的720p流媒体视频，具有卓越的一致性，优于现有技术，并在不同场景中展现出强大的泛化能力。

Conclusion: WorldPlay成功解决了实时交互式世界建模中的速度与内存权衡问题，实现了具有长期几何一致性的高质量视频生成。

Abstract: This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D.

</details>


### [138] [TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios](https://arxiv.org/abs/2512.14595)
*Mengyu Li,Xingcheng Zhou,Guang Chen,Alois Knoll,Hu Cao*

Main category: cs.CV

TL;DR: 针对帧基相机在智能交通系统（ITS）中弱光和高速运动下的不足，本文引入事件相机，并创建了首个事件基ITS数据集，用于车辆和行人检测与跟踪，并基于此数据集建立了一个表现优异的跟踪基准。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中的多目标跟踪主要依赖帧基相机，但在弱光和高速运动条件下性能不佳。事件相机因其低延迟、高动态范围和高时间分辨率而具有解决这些问题的潜力。然而，事件基视觉在ITS领域的研究相对较少，存在研究空白。

Method: 为了填补研究空白，本文引入了一个专为事件基ITS设计的初步试点数据集，涵盖车辆和行人的检测与跟踪。在此数据集的基础上，建立了一个基于检测的跟踪基准，并开发了一个专门的特征提取器。

Result: 基于所创建的数据集和专门的特征提取器，所建立的跟踪基准取得了出色的性能。

Conclusion: 事件相机在智能交通系统的多目标跟踪中具有巨大潜力，特别是在传统帧基相机表现不佳的场景下。通过引入专为事件基ITS设计的初步数据集和建立高性能的跟踪基准，本文为事件基视觉在该领域的进一步研究奠定了基础。

Abstract: In Intelligent Transportation Systems (ITS), multi-object tracking is primarily based on frame-based cameras. However, these cameras tend to perform poorly under dim lighting and high-speed motion conditions. Event cameras, characterized by low latency, high dynamic range and high temporal resolution, have considerable potential to mitigate these issues. Compared to frame-based vision, there are far fewer studies on event-based vision. To address this research gap, we introduce an initial pilot dataset tailored for event-based ITS, covering vehicle and pedestrian detection and tracking. We establish a tracking-by-detection benchmark with a specialized feature extractor based on this dataset, achieving excellent performance.

</details>


### [139] [DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors](https://arxiv.org/abs/2512.14536)
*Yiheng Huang,Junhong Chen,Anqi Ning,Zhanhong Liang,Nick Michiels,Luc Claesen,Wenyin Liu*

Main category: cs.CV

TL;DR: 本文提出DASP框架，通过利用时空先验和3D一致性投影损失，解决了夜间单目自监督深度估计因低能见度和运动模糊导致的性能下降问题，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自监督单目深度估计在白天表现出色，但在夜间由于低能见度、光照不足导致的无纹理区域以及运动物体造成的模糊区域，性能显著下降。

Method: 本文提出了一个名为DASP的自监督框架，利用时空先验进行夜间深度估计。DASP包含一个对抗分支和一个自监督分支：
1.  **对抗分支**：设计了一个对抗网络，其判别器由四个时空先验学习块（SPLB）组成，用于提取白天先验。SPLB包含：
    *   **基于空间的时序学习模块（STLM）**：采用正交差分来提取沿时间轴的运动相关变化。
    *   **轴向空间学习模块（ASLM）**：采用局部非对称卷积和全局轴向注意力来捕获多尺度结构信息。STLM和ASLM的结合旨在恢复无纹理区域并估计动态物体造成的模糊区域。
2.  **自监督分支**：提出了一个3D一致性投影损失，将目标帧和源帧双向投影到共享的3D空间中，计算两个投影帧之间的3D差异作为损失，以优化3D结构一致性和白天先验。

Result: 在Oxford RobotCar和nuScenes数据集上进行的大量实验表明，所提出的方法在夜间深度估计方面取得了最先进的性能。消融研究进一步验证了每个组件的有效性。

Conclusion: DASP框架通过有效利用时空先验和3D一致性投影损失，成功解决了夜间单目自监督深度估计的挑战，显著提升了夜间环境下的深度估计精度。

Abstract: Self-supervised monocular depth estimation has achieved notable success under daytime conditions. However, its performance deteriorates markedly at night due to low visibility and varying illumination, e.g., insufficient light causes textureless areas, and moving objects bring blurry regions. To this end, we propose a self-supervised framework named DASP that leverages spatiotemporal priors for nighttime depth estimation. Specifically, DASP consists of an adversarial branch for extracting spatiotemporal priors and a self-supervised branch for learning. In the adversarial branch, we first design an adversarial network where the discriminator is composed of four devised spatiotemporal priors learning blocks (SPLB) to exploit the daytime priors. In particular, the SPLB contains a spatial-based temporal learning module (STLM) that uses orthogonal differencing to extract motion-related variations along the time axis and an axial spatial learning module (ASLM) that adopts local asymmetric convolutions with global axial attention to capture the multiscale structural information. By combining STLM and ASLM, our model can acquire sufficient spatiotemporal features to restore textureless areas and estimate the blurry regions caused by dynamic objects. In the self-supervised branch, we propose a 3D consistency projection loss to bilaterally project the target frame and source frame into a shared 3D space, and calculate the 3D discrepancy between the two projected frames as a loss to optimize the 3D structural consistency and daytime priors. Extensive experiments on the Oxford RobotCar and nuScenes datasets demonstrate that our approach achieves state-of-the-art performance for nighttime depth estimation. Ablation studies further validate the effectiveness of each component.

</details>


### [140] [Score-Based Turbo Message Passing for Plug-and-Play Compressive Imaging](https://arxiv.org/abs/2512.14435)
*Chang Cai,Hao Jiang,Xiaojun Yuan,Ying-Jun Angela Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为STMP的消息传递框架，它将基于分数的生成模型作为去噪器，用于压缩图像恢复，并针对量化测量提出了Q-STMP。STMP和Q-STMP在性能和计算复杂度之间取得了显著平衡，且收敛迅速。


<details>
  <summary>Details</summary>
Motivation: 传统的即插即用（PnP）方法在压缩成像中，由于依赖通用或手工设计的先验知识，难以准确捕捉自然图像的复杂统计结构，导致次优重建，尤其是在高度欠定情况下。虽然基于分数的生成模型能准确表征图像分布，但直接用于后验采样计算成本过高。

Method: 通过利用基于分数的生成建模与经验贝叶斯去噪之间的紧密联系，本文设计了一个消息传递框架，该框架集成了基于分数的最小均方误差（MMSE）去噪器用于压缩图像恢复，命名为STMP。对于量化测量系统，进一步提出了Q-STMP，它在STMP的基础上增加了一个逐分量MMSE去量化模块。算法的渐近性能可以通过一组状态演化（SE）方程准确预测。

Result: 在FFHQ数据集上的实验表明，STMP相较于现有基线，在性能-复杂度权衡方面表现显著更好。Q-STMP即使在1比特量化下也保持鲁棒性。值得注意的是，STMP和Q-STMP通常在10次迭代内收敛。

Conclusion: STMP和Q-STMP通过结合消息传递的快速收敛性和基于分数的生成先验的表达能力，为压缩图像恢复提供了一种高效且高性能的解决方案，即使在量化测量下也能表现出色。

Abstract: Message-passing algorithms have been adapted for compressive imaging by incorporating various off-the-shelf image denoisers. However, these denoisers rely largely on generic or hand-crafted priors and often fall short in accurately capturing the complex statistical structure of natural images. As a result, traditional plug-and-play (PnP) methods often lead to suboptimal reconstruction, especially in highly underdetermined regimes. Recently, score-based generative models have emerged as a powerful framework for accurately characterizing sophisticated image distribution. Yet, their direct use for posterior sampling typically incurs prohibitive computational complexity. In this paper, by exploiting the close connection between score-based generative modeling and empirical Bayes denoising, we devise a message-passing framework that integrates a score-based minimum mean-squared error (MMSE) denoiser for compressive image recovery. The resulting algorithm, named score-based turbo message passing (STMP), combines the fast convergence of message passing with the expressive power of score-based generative priors. For practical systems with quantized measurements, we further propose quantized STMP (Q-STMP), which augments STMP with a component-wise MMSE dequantization module. We demonstrate that the asymptotic performance of STMP and Q-STMP can be accurately predicted by a set of state-evolution (SE) equations. Experiments on the FFHQ dataset demonstrate that STMP strikes a significantly better performance-complexity tradeoff compared with competing baselines, and that Q-STMP remains robust even under 1-bit quantization. Remarkably, both STMP and Q-STMP typically converge within 10 iterations.

</details>


### [141] [Enhancing Visual Sentiment Analysis via Semiotic Isotopy-Guided Dataset Construction](https://arxiv.org/abs/2512.14665)
*Marco Blanchini,Giovanna Maria Dimitri,Benedetta Tondi,Tarcisio Lancioni,Mauro Barni*

Main category: cs.CV

TL;DR: 本文提出一种利用符号学同位素概念创建更大、更多样化视觉情感分析（VSA）数据集的方法，从而训练出泛化能力更强、能更好地关注情感相关图像元素的模型。


<details>
  <summary>Details</summary>
Motivation: 视觉情感分析（VSA）面临挑战，包括情感显著图像的多样性、难以获取足够数据、构建大规模数据集的困难，以及现有算法在不同数据集上泛化性能有限。

Method: 该方法从现有数据集中出发，通过将符号学同位素概念整合到数据集创建过程中，生成了一个新的、更大、更多样化的数据集。这使得训练出的模型能更好地关注图像中与情感相关的元素组合。

Result: 实证评估表明，使用该方法生成的数据集训练的模型，其性能持续优于使用原始数据集训练的模型，并在主要VSA基准测试中展现出卓越的泛化能力。

Conclusion: 通过整合符号学同位素概念创建新数据集，可以提高VSA模型的性能和泛化能力，使其能更深入地理解图像情感内容并识别情感相关的图像元素。

Abstract: Visual Sentiment Analysis (VSA) is a challenging task due to the vast diversity of emotionally salient images and the inherent difficulty of acquiring sufficient data to capture this variability comprehensively. Key obstacles include building large-scale VSA datasets and developing effective methodologies that enable algorithms to identify emotionally significant elements within an image. These challenges are reflected in the limited generalization performance of VSA algorithms and models when trained and tested across different datasets. Starting from a pool of existing data collections, our approach enables the creation of a new larger dataset that not only contains a wider variety of images than the original ones, but also permits training new models with improved capability to focus on emotionally relevant combinations of image elements. This is achieved through the integration of the semiotic isotopy concept within the dataset creation process, providing deeper insights into the emotional content of images. Empirical evaluations show that models trained on a dataset generated with our method consistently outperform those trained on the original data collections, achieving superior generalization across major VSA benchmarks

</details>


### [142] [ART: Articulated Reconstruction Transformer](https://arxiv.org/abs/2512.14671)
*Zizhang Li,Cheng Zhang,Zhengqin Li,Henry Howard-Jenkins,Zhaoyang Lv,Chen Geng,Jiajun Wu,Richard Newcombe,Jakob Engel,Zhao Dong*

Main category: cs.CV

TL;DR: ART (Articulated Reconstruction Transformer) 是一种类别无关的、前馈模型，仅通过稀疏的多状态RGB图像，即可重建完整的3D铰接物体，并超越现有技术水平。


<details>
  <summary>Details</summary>
Motivation: 现有的铰接物体重建方法要么依赖缓慢且对应关系脆弱的优化，要么是仅限于特定物体类别的前馈模型。研究旨在开发一种快速、通用且鲁棒的解决方案。

Method: ART将铰接物体视为刚性部件的组装，将重建问题表述为基于部件的预测。其Transformer架构将稀疏图像输入映射到一组可学习的部件槽，从中共同解码每个部件的统一表示，包括3D几何、纹理和明确的铰接参数。

Result: ART在多样化的基准测试中，显著优于现有基线，并在从图像输入进行铰接物体重建方面建立了新的技术水平。重建结果具有物理可解释性，并易于导出用于仿真。

Conclusion: ART提供了一种新颖、高效且通用的方法，能够从稀疏多状态RGB图像中重建3D铰接物体，克服了现有方法的局限性，并取得了卓越的性能。

Abstract: We introduce ART, Articulated Reconstruction Transformer -- a category-agnostic, feed-forward model that reconstructs complete 3D articulated objects from only sparse, multi-state RGB images. Previous methods for articulated object reconstruction either rely on slow optimization with fragile cross-state correspondences or use feed-forward models limited to specific object categories. In contrast, ART treats articulated objects as assemblies of rigid parts, formulating reconstruction as part-based prediction. Our newly designed transformer architecture maps sparse image inputs to a set of learnable part slots, from which ART jointly decodes unified representations for individual parts, including their 3D geometry, texture, and explicit articulation parameters. The resulting reconstructions are physically interpretable and readily exportable for simulation. Trained on a large-scale, diverse dataset with per-part supervision, and evaluated across diverse benchmarks, ART achieves significant improvements over existing baselines and establishes a new state of the art for articulated object reconstruction from image inputs.

</details>


### [143] [Distill Video Datasets into Images](https://arxiv.org/abs/2512.14621)
*Zhenghao Zhao,Haoxuan Wang,Kai Wang,Yuzhang Shang,Yuan Hong,Yan Yan*

Main category: cs.CV

TL;DR: 本文提出单帧视频集蒸馏（SFVD）框架，通过将视频蒸馏为每个类别的高度信息单帧，有效解决了视频数据集蒸馏中时间维度带来的优化挑战，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 数据集蒸馏在图像数据上表现良好，但在视频数据上效果不佳，主要原因是视频的时间维度引入了大量可学习参数，使优化复杂并阻碍收敛。

Method: 核心挑战是时间维度导致的可学习参数大幅增加。基于单帧足以捕捉视频判别语义的洞察，提出SFVD。该方法将视频蒸馏为每个类别的信息单帧，通过可微分插值将这些帧转换为视频序列并与原始数据集匹配，同时将更新限制在帧本身以提高优化效率。为进一步整合时间信息，蒸馏帧在匹配过程中通过通道重塑层与采样的真实视频结合。

Result: SFVD在多个基准测试中显著优于现有方法，在MiniUCF上性能提升高达5.3%。

Conclusion: SFVD通过利用信息单帧并有效整合时间信息，为视频集蒸馏提供了一个更有效的解决方案。

Abstract: Dataset distillation aims to synthesize compact yet informative datasets that allow models trained on them to achieve performance comparable to training on the full dataset. While this approach has shown promising results for image data, extending dataset distillation methods to video data has proven challenging and often leads to suboptimal performance. In this work, we first identify the core challenge in video set distillation as the substantial increase in learnable parameters introduced by the temporal dimension of video, which complicates optimization and hinders convergence. To address this issue, we observe that a single frame is often sufficient to capture the discriminative semantics of a video. Leveraging this insight, we propose Single-Frame Video set Distillation (SFVD), a framework that distills videos into highly informative frames for each class. Using differentiable interpolation, these frames are transformed into video sequences and matched with the original dataset, while updates are restricted to the frames themselves for improved optimization efficiency. To further incorporate temporal information, the distilled frames are combined with sampled real videos from real videos during the matching process through a channel reshaping layer. Extensive experiments on multiple benchmarks demonstrate that SFVD substantially outperforms prior methods, achieving improvements of up to 5.3% on MiniUCF, thereby offering a more effective solution.

</details>


### [144] [HiFi-Portrait: Zero-shot Identity-preserved Portrait Generation with High-fidelity Multi-face Fusion](https://arxiv.org/abs/2512.14542)
*Yifang Xu,Benxiang Zhai,Yunzhuo Sun,Ming Li,Yang Li,Sidan Du*

Main category: cs.CV

TL;DR: HiFi-Portrait是一种零样本高保真肖像生成方法，通过引入面部细化器、地标生成器和HiFi-Net，解决了现有方法在多参考图像下肖像保真度低和属性控制不精确的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散技术的身份保持肖像生成（IPG）方法，在使用同一ID的多个参考图像时，通常会生成低保真度的肖像，并且难以精确定制面部属性。

Method: 该方法首先引入面部细化器和地标生成器，以获取细粒度的多面部特征和3D感知面部地标（包括参考ID和目标属性）。然后，设计了HiFi-Net来融合多面部特征并将其与地标对齐，从而提高ID保真度和面部控制能力。此外，还设计了一个自动化流程来构建用于训练HiFi-Portrait的基于ID的数据集。

Result: 广泛的实验结果表明，该方法在面部相似性和可控性方面超越了现有最先进的方法。此外，该方法还与之前的SDXL基工作兼容。

Conclusion: HiFi-Portrait成功解决了多参考图像下肖像生成保真度低和属性控制不精确的问题，显著提高了ID保真度和面部控制能力，并优于现有方法。

Abstract: Recent advancements in diffusion-based technologies have made significant strides, particularly in identity-preserved portrait generation (IPG). However, when using multiple reference images from the same ID, existing methods typically produce lower-fidelity portraits and struggle to customize face attributes precisely. To address these issues, this paper presents HiFi-Portrait, a high-fidelity method for zero-shot portrait generation. Specifically, we first introduce the face refiner and landmark generator to obtain fine-grained multi-face features and 3D-aware face landmarks. The landmarks include the reference ID and the target attributes. Then, we design HiFi-Net to fuse multi-face features and align them with landmarks, which improves ID fidelity and face control. In addition, we devise an automated pipeline to construct an ID-based dataset for training HiFi-Portrait. Extensive experimental results demonstrate that our method surpasses the SOTA approaches in face similarity and controllability. Furthermore, our method is also compatible with previous SDXL-based works.

</details>


### [145] [ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking](https://arxiv.org/abs/2512.14654)
*Lihong Wang,Liangqi Li,Weiwei Feng,Jiamin Wu,Changtao Miao,Tieru Wu,Rui Ma,Bo Zhang,Zhe Li*

Main category: cs.CV

TL;DR: 本文提出了ViRC框架，通过引入Reason Chunking机制和Critical Reasoning Units (CRUs)来模拟人类专家解决多模态数学问题的过程，并构建了CRUX数据集和渐进式训练策略，显著提升了多模态大语言模型在数学任务上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在多模态领域，特别是在数学任务中，其思维链（CoT）推理能力面临挑战。多模态大语言模型（MLLMs）通常仅从单一静态数学图像进行文本推理，忽略了人类在推理过程中反复检查视觉图像并分步证明中间命题的动态视觉获取方式，这与认知科学中的米勒定律不符。

Method: 受人类专家解决问题模式的启发，本文提出了ViRC框架，引入了Reason Chunking机制，将多模态数学CoT分解为连续的Critical Reasoning Units (CRUs)。CRUs确保单元内文本连贯性以验证中间命题，并整合跨单元的视觉信息以生成后续命题和支持结构化推理。为此，构建了CRUX数据集，使用三种视觉工具和四种推理模式为每个数学问题提供明确标注的CRUs。在此基础上，提出了一种受人类认知学习启发的渐进式训练策略，包括Instructional SFT、Practice SFT和Strategic RL，以增强模型的Reason Chunking能力。

Result: 所得到的ViRC-7B模型在多个数学基准测试中，相对于基线模型取得了平均18.8%的性能提升。

Conclusion: ViRC框架通过模拟人类专家的问题解决模式，将多模态数学推理分解为关键逻辑节点，并结合新的数据集和训练策略，显著提升了多模态大语言模型在数学任务上的推理能力，特别是在处理动态视觉信息和结构化推理方面表现突出。

Abstract: CoT has significantly enhanced the reasoning ability of LLMs while it faces challenges when extended to multimodal domains, particularly in mathematical tasks. Existing MLLMs typically perform textual reasoning solely from a single static mathematical image, overlooking dynamic visual acquisition during reasoning. In contrast, humans repeatedly examine visual image and employ step-by-step reasoning to prove intermediate propositions. This strategy of decomposing the problem-solving process into key logical nodes adheres to Miller's Law in cognitive science. Inspired by this insight, we propose a ViRC framework for multimodal mathematical tasks, introducing a Reason Chunking mechanism that structures multimodal mathematical CoT into consecutive Critical Reasoning Units (CRUs) to simulate human expert problem-solving patterns. CRUs ensure intra-unit textual coherence for intermediate proposition verification while integrating visual information across units to generate subsequent propositions and support structured reasoning. To this end, we present CRUX dataset by using three visual tools and four reasoning patterns to provide explicitly annotated CRUs across multiple reasoning paths for each mathematical problem. Leveraging the CRUX dataset, we propose a progressive training strategy inspired by human cognitive learning, which includes Instructional SFT, Practice SFT, and Strategic RL, aimed at further strengthening the Reason Chunking ability of the model.The resulting ViRC-7B model achieves a 18.8\% average improvement over baselines across multiple mathematical benchmarks. Code is available at https://github.com/Leon-LihongWang/ViRC.

</details>


### [146] [S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation](https://arxiv.org/abs/2512.14440)
*Leon Sick,Lukas Hoyer,Dominik Engel,Pedro Hermosilla,Timo Ropinski*

Main category: cs.CV

TL;DR: 该论文提出了一种无监督视频实例分割模型，通过利用深度运动先验在真实视频数据上进行训练，解决了合成数据运动不真实的问题，并超越了现有技术水平。


<details>
  <summary>Details</summary>
Motivation: 现有无监督视频实例分割模型严重依赖合成视频数据，这些数据无法准确模拟真实视频中的复杂运动（如透视变化、部件运动、相机运动），导致模型性能受限。

Method: 该方法首先在单个视频帧上进行无监督实例分割，然后利用深度运动先验识别视频中的高质量关键掩码（keymasks）以建立时间连贯性。接着，利用这些稀疏的关键掩码伪标注，通过一种名为“稀疏到密集蒸馏”（Sparse-To-Dense Distillation）的方法，并辅以“时间丢弃损失”（Temporal DropLoss），训练一个分割模型进行隐式掩码传播。最后，在生成的密集标签集上训练最终模型。

Result: 该方法在各种基准测试中均超越了当前的最新技术水平。

Conclusion: 通过在真实视频数据上进行训练并利用深度运动先验建立时间连贯性，该模型有效解决了合成数据运动建模不准确的问题，实现了更优异的无监督视频实例分割性能。

Abstract: In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.

</details>


### [147] [Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency](https://arxiv.org/abs/2512.14499)
*Jia Guo,Jiawei Du,Shengzhu Yang,Shuai Lu,Wenquan Cheng,Kaiwen Zhang,Yihua Sun,Chuhong Yang,Weihang Zhang,Fang Chen,Yilan Wu,Lie Ju,Guochen Ning,Longfei Ma,Huiping Yao,Jinyuan Wang,Peilun Shi,Yukun Zhou,Jie Xu,Pearse A. Keane,Hanruo Liu,Hongen Liao,Ningli Wang,Huiqi Li*

Main category: cs.CV

TL;DR: ReVision是一个从中国大规模远程医疗项目中学习的视网膜基础模型，它利用图像和诊断报告的自然对齐，实现了高效的零样本疾病检测和诊断辅助，适用于资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 当前的视网膜基础模型受限于人工整理的研究数据集，缺乏真实的临床背景，并且需要针对每个应用进行广泛的任务特定优化，这限制了它们在资源匮乏环境中的部署效率。

Method: ReVision通过从真实世界的医疗实践中直接构建临床原生智能来克服这些障碍。它利用了长达十年的远程医疗项目（涵盖中国162家医疗机构）中积累的485,980张彩色眼底照片及其对应的诊断报告之间的自然对齐关系进行学习。

Result: ReVision在27项眼科基准测试中表现出色，实现了高效部署。在12个公共基准测试中，零样本疾病检测的平均AUROC为0.946，在3个独立临床队列中为0.952，且无需任何任务特定训练。在可进行少量适应的情况下，ReVision以远少于微调替代方案的可训练参数和标记样本量，达到相当的性能。所学表示法还能有效迁移到新的临床站点、成像领域、成像模式和全身健康预测任务。在一项有33位眼科医生参与的前瞻性阅读研究中，ReVision的零样本辅助将诊断准确性提高了14.8%。

Conclusion: 研究结果表明，可以直接从临床档案中提取临床原生智能，而无需额外标注，从而构建适用于各种资源匮乏环境的医疗AI系统。

Abstract: Current retinal foundation models remain constrained by curated research datasets that lack authentic clinical context, and require extensive task-specific optimization for each application, limiting their deployment efficiency in low-resource settings. Here, we show that these barriers can be overcome by building clinical native intelligence directly from real-world medical practice. Our key insight is that large-scale telemedicine programs, where expert centers provide remote consultations across distributed facilities, represent a natural reservoir for learning clinical image interpretation. We present ReVision, a retinal foundation model that learns from the natural alignment between 485,980 color fundus photographs and their corresponding diagnostic reports, accumulated through a decade-long telemedicine program spanning 162 medical institutions across China. Through extensive evaluation across 27 ophthalmic benchmarks, we demonstrate that ReVison enables deployment efficiency with minimal local resources. Without any task-specific training, ReVision achieves zero-shot disease detection with an average AUROC of 0.946 across 12 public benchmarks and 0.952 on 3 independent clinical cohorts. When minimal adaptation is feasible, ReVision matches extensively fine-tuned alternatives while requiring orders of magnitude fewer trainable parameters and labeled examples. The learned representations also transfer effectively to new clinical sites, imaging domains, imaging modalities, and systemic health prediction tasks. In a prospective reader study with 33 ophthalmologists, ReVision's zero-shot assistance improved diagnostic accuracy by 14.8% across all experience levels. These results demonstrate that clinical native intelligence can be directly extracted from clinical archives without any further annotation to build medical AI systems suited to various low-resource settings.

</details>


### [148] [AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation](https://arxiv.org/abs/2512.14639)
*Fei Wu,Marcel Dreier,Nora Gourmelon,Sebastian Wind,Jianlin Zhang,Thorsten Seehaus,Matthias Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 本文提出AMD-HookNet++，一种混合CNN-Transformer特征增强方法，用于合成孔径雷达图像中的冰川分割和冰川崩解锋线描绘，解决了现有方法在长距离依赖和边缘平滑性上的不足，并达到了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 有效监测冰川状况对冰盖质量平衡和海平面变化至关重要。传统的纯卷积神经网络（如AMD-HookNet）在捕获长距离依赖方面存在局限性，而纯Transformer方法则可能导致崩解锋线边缘不平滑。因此，需要一种能够结合两者优势的方法。

Method: 本文提出了AMD-HookNet++，一个先进的混合CNN-Transformer模型。它包含两个分支：一个基于Transformer的上下文分支，用于捕获长距离依赖和提供全局上下文信息；一个基于CNN的目标分支，用于保留局部细节。为增强混合特征的表示，设计了一个增强的空间-通道注意力模块，通过动态调整空间和通道的token关系来促进两个分支的交互。此外，还开发了像素到像素的对比深度监督，通过将像素级度量学习整合到冰川分割中来优化模型。

Result: 在具有挑战性的CaFFe冰川分割基准数据集上，AMD-HookNet++取得了新的SOTA，IoU达到78.2，HD95为1,318米，MDE保持在367米的竞争力。更重要的是，该混合模型能够生成更平滑的冰川崩解锋线，解决了纯Transformer方法中常见的锯齿状边缘问题。

Conclusion: AMD-HookNet++通过结合CNN和Transformer的优势，并引入创新的注意力机制和深度监督，有效解决了冰川分割中的长距离依赖和边缘平滑性问题。该方法在冰川崩解锋线描绘方面表现出色，并为冰川监测提供了更精确的工具。

Abstract: The dynamics of glaciers and ice shelf fronts significantly impact the mass balance of ice sheets and coastal sea levels. To effectively monitor glacier conditions, it is crucial to consistently estimate positional shifts of glacier calving fronts. AMD-HookNet firstly introduces a pure two-branch convolutional neural network (CNN) for glacier segmentation. Yet, the local nature and translational invariance of convolution operations, while beneficial for capturing low-level details, restricts the model ability to maintain long-range dependencies. In this study, we propose AMD-HookNet++, a novel advanced hybrid CNN-Transformer feature enhancement method for segmenting glaciers and delineating calving fronts in synthetic aperture radar images. Our hybrid structure consists of two branches: a Transformer-based context branch to capture long-range dependencies, which provides global contextual information in a larger view, and a CNN-based target branch to preserve local details. To strengthen the representation of the connected hybrid features, we devise an enhanced spatial-channel attention module to foster interactions between the hybrid CNN-Transformer branches through dynamically adjusting the token relationships from both spatial and channel perspectives. Additionally, we develop a pixel-to-pixel contrastive deep supervision to optimize our hybrid model by integrating pixelwise metric learning into glacier segmentation. Through extensive experiments and comprehensive quantitative and qualitative analyses on the challenging glacier segmentation benchmark dataset CaFFe, we show that AMD-HookNet++ sets a new state of the art with an IoU of 78.2 and a HD95 of 1,318 m, while maintaining a competitive MDE of 367 m. More importantly, our hybrid model produces smoother delineations of calving fronts, resolving the issue of jagged edges typically seen in pure Transformer-based approaches.

</details>


### [149] [SuperCLIP: CLIP with Simple Classification Supervision](https://arxiv.org/abs/2512.14480)
*Weiheng Zhao,Zilong Huang,Jiashi Feng,Xinggang Wang*

Main category: cs.CV

TL;DR: CLIP模型在处理细粒度文本语义，尤其是长描述时表现不足。SuperCLIP通过在视觉编码器中增加一个轻量级分类层，以分类监督增强对比学习，有效提升了细粒度视觉-文本对齐，且计算开销极小，无需额外数据，并解决了小批量训练的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的CLIP类模型未能充分利用文本中的细粒度语义信号，特别是在处理长而详细的描述时，这一问题更为突出。这源于CLIP的训练目标仅优化全局图像-文本相似性，而忽略了token级别的监督，限制了其实现细粒度视觉-文本对齐的能力。

Method: 本文提出了SuperCLIP框架，通过引入基于分类的监督来增强对比学习。它仅在视觉编码器上增加一个轻量级线性层，利用token级别的线索来增强视觉-文本对齐，仅增加0.077%的总FLOPs，且无需额外的标注数据。

Result: 实验表明，SuperCLIP在零样本分类、图像-文本检索和纯视觉任务上均持续取得了改进。无论模型是在原始网络数据还是丰富的重新标注数据上训练，这些增益都成立。此外，SuperCLIP通过基于分类的监督避免了对大批量尺寸的依赖，从而缓解了CLIP的小批量性能下降问题。

Conclusion: SuperCLIP通过引入分类监督，有效解决了CLIP模型在细粒度文本语义利用上的不足，显著提升了视觉-文本对齐效果和多项任务性能。该方法计算开销小，无需额外数据，并能稳定在不同数据集上，同时解决了小批量训练的性能瓶颈。

Abstract: Contrastive Language-Image Pretraining (CLIP) achieves strong generalization in vision-language tasks by aligning images and texts in a shared embedding space. However, recent findings show that CLIP-like models still underutilize fine-grained semantic signals in text, and this issue becomes even more pronounced when dealing with long and detailed captions. This stems from CLIP's training objective, which optimizes only global image-text similarity and overlooks token-level supervision - limiting its ability to achieve fine-grained visual-text alignment. To address this, we propose SuperCLIP, a simple yet effective framework that augments contrastive learning with classification-based supervision. By adding only a lightweight linear layer to the vision encoder, SuperCLIP leverages token-level cues to enhance visual-textual alignment - with just a 0.077% increase in total FLOPs, and no need for additional annotated data. Experiments show that SuperCLIP consistently improves zero-shot classification, image-text retrieval, and purely visual tasks. These gains hold regardless of whether the model is trained on original web data or rich re-captioned data, demonstrating SuperCLIP's ability to recover textual supervision in both cases. Furthermore, SuperCLIP alleviates CLIP's small-batch performance drop through classification-based supervision that avoids reliance on large batch sizes. Code and models will be made open source.

</details>


### [150] [MemFlow: Flowing Adaptive Memory for Consistent and Efficient Long Video Narratives](https://arxiv.org/abs/2512.14699)
*Sihui Ji,Xi Chen,Shuai Yang,Xin Tao,Pengfei Wan,Hengshuang Zhao*

Main category: cs.CV

TL;DR: MemFlow提出一种动态记忆更新和选择性激活机制，通过检索最相关的历史帧和激活相关记忆token，解决了流式视频生成中长上下文内容一致性问题，同时保持高效。


<details>
  <summary>Details</summary>
Motivation: 流式视频生成的核心挑战是保持长上下文内容的一致性，这需要高效的记忆设计。现有方案通过预定义策略压缩历史帧，但难以满足不同视频块需要引用不同历史线索的需求，导致固定策略失效。

Method: MemFlow在生成即将到来的视频块之前，通过检索与当前块文本提示最相关的历史帧来动态更新记忆库。在生成过程中，它只激活记忆库中最相关的token以响应注意力层中的每个查询，从而确保生成效率。

Result: MemFlow在长上下文一致性方面表现出色，计算负担可忽略不计（与无记忆基线相比，速度仅降低7.9%），并与任何带有KV缓存的流式视频生成模型兼容。

Conclusion: MemFlow通过动态记忆更新和选择性token激活，有效解决了流式视频生成中的长上下文一致性问题，实现了叙事连贯性，即使在事件变化或场景切换时也能保持，同时保持了高效率和广泛兼容性。

Abstract: The core challenge for streaming video generation is maintaining the content consistency in long context, which poses high requirement for the memory design. Most existing solutions maintain the memory by compressing historical frames with predefined strategies. However, different to-generate video chunks should refer to different historical cues, which is hard to satisfy with fixed strategies. In this work, we propose MemFlow to address this problem. Specifically, before generating the coming chunk, we dynamically update the memory bank by retrieving the most relevant historical frames with the text prompt of this chunk. This design enables narrative coherence even if new event happens or scenario switches in future frames. In addition, during generation, we only activate the most relevant tokens in the memory bank for each query in the attention layers, which effectively guarantees the generation efficiency. In this way, MemFlow achieves outstanding long-context consistency with negligible computation burden (7.9% speed reduction compared with the memory-free baseline) and keeps the compatibility with any streaming video generation model with KV cache.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [151] [FiNERweb: Datasets and Artifacts for Scalable Multilingual Named Entity Recognition](https://arxiv.org/abs/2512.13884)
*Jonas Golde,Patrick Haller,Alan Akbik*

Main category: cs.CL

TL;DR: 本文介绍了FiNERweb，一个针对91种语言和25种文字的命名实体识别（NER）数据集创建流程，通过教师-学生范式和多语言大型语言模型（LLMs）生成了22.5万个通道和23.5万个实体标签。实验表明，该数据集能以更少的数据实现与现有基线模型相当或更好的零样本迁移性能，并具有高质量的标注。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言NER合成监督数据集大多是实验的副产品，而非系统性、可复用的资源。研究需要一个可扩展、系统化的方法来创建高质量的多语言NER数据集，以有效利用LLMs的合成监督能力。

Method: 研究构建了一个名为FiNERweb的数据集创建流程，将教师-学生范式扩展到91种语言和25种文字。它基于FineWeb-Edu，训练回归模型来识别与NER相关的文本段落，然后使用多语言LLMs对这些段落进行标注。数据集同时发布了英文标签和目标语言翻译标签。

Result: 回归模型在识别相关段落方面达到了超过84的F1分数。在FiNERweb上训练的模型，尽管数据量比强基线模型少19倍，但在英语、泰语和斯瓦希里语的零样本迁移设置中，仍取得了相当或改进的性能。通过LLM作为评估器，标注质量在忠实度（3.99/5）和完整性（4.05/5）方面均获得高分。此外，研究发现，使用目标语言标签而非英文标签进行评估时，当前最先进模型的性能会下降0.02到0.09 F1。

Conclusion: FiNERweb提供了一个系统、可复用且高质量的多语言NER数据集，通过有效的教师-学生训练范式和LLMs合成监督，能够以显著更少的数据实现强大的零样本迁移性能。数据集及所有相关资源已发布，以促进多语言NER研究中更有效的学生-教师训练。

Abstract: Recent multilingual named entity recognition (NER) work has shown that large language models (LLMs) can provide effective synthetic supervision, yet such datasets have mostly appeared as by-products of broader experiments rather than as systematic, reusable resources. We introduce FiNERweb, a dataset-creation pipeline that scales the teacher-student paradigm to 91 languages and 25 scripts. Building on FineWeb-Edu, our approach trains regression models to identify NER-relevant passages and annotates them with multilingual LLMs, resulting in about 225k passages with 235k distinct entity labels. Our experiments show that the regression model achieves more than 84 F1, and that models trained on FiNERweb obtain comparable or improved performance in zero shot transfer settings on English, Thai, and Swahili, despite being trained on 19x less data than strong baselines. In addition, we assess annotation quality using LLM-as-a-judge and observe consistently high scores for both faithfulness (3.99 out of 5) and completeness (4.05 out of 5), indicating reliable and informative annotations. Further, we release the dataset with both English labels and translated label sets in the respective target languages because we observe that the performance of current state-of-the-art models drops by 0.02 to 0.09 F1 when evaluated using target language labels instead of English ones. We release FiNERweb together with all accompanying artifacts to the research community in order to facilitate more effective student-teacher training for multilingual named entity recognition.

</details>


### [152] [What Affects the Effective Depth of Large Language Models?](https://arxiv.org/abs/2512.14064)
*Yi Hu,Cai Zhou,Muhan Zhang*

Main category: cs.CL

TL;DR: 本研究系统分析了大型语言模型（LLMs）的“有效深度”，发现其随模型规模增长但利用率稳定，长上下文训练不增加有效深度，且模型不根据任务难度动态使用更多层，表明当前LLMs的深度利用不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs深度的增加，性能提升逐渐减弱，而“有效深度”的概念指出深层模型未能充分利用其所有层进行有意义的计算。本研究旨在系统探究有效深度如何随模型规模、训练类型和任务难度而变化。

Method: 1. 分析了Qwen-2.5系列（1.5B-32B）模型的行为，研究有效层数和有效深度比率随模型规模的变化。2. 比较了基础模型和对应的长CoT（思维链）模型，以评估训练类型对有效深度的影响。3. 在不同难度的任务上进行评估，以探究模型是否动态地为更难的问题使用更多层。

Result: 1. 有效层数随模型规模的增大而增加，但有效深度比率保持稳定。2. 基础模型和长CoT模型之间的比较显示有效深度没有增加，表明推理能力的提升源于更长的上下文而非更深的每token计算。3. 模型在不同难度的任务上表现出不动态使用更多层的情况。

Conclusion: 当前LLMs在不同规模、训练范式和任务难度下都未能充分利用其可用深度。这为提高LLMs的层利用率、模型剪枝和提前退出等研究方向提供了机会。

Abstract: The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of "effective depth", arguing that deeper models fail to fully utilize their layers for meaningful computation. Building on this, we systematically study how effective depth varies with model scale, training type, and task difficulty. First, we analyze the model behavior of Qwen-2.5 family (1.5B-32B) and find that while the number of effective layers grows with model size, the effective depth ratio remains stable. Besides, comparisons between base and corresponding long-CoT models show no increase in effective depth, suggesting that improved reasoning stems from longer context rather than deeper per-token computation. Furthermore, evaluations across tasks of varying difficulty indicate that models do not dynamically use more layers for harder problems. Our results suggest that current LLMs underuse available depth across scales, training paradigms and tasks of varying difficulties, pointing out research opportunities on increasing the layer utilization rate of LLMs, model pruning, and early exiting. Our code is released at https://github.com/AheadOFpotato/what_affects_effective_depth.

</details>


### [153] [Olmo 3](https://arxiv.org/abs/2512.13961)
*Team Olmo,:,Allyson Ettinger,Amanda Bertsch,Bailey Kuehl,David Graham,David Heineman,Dirk Groeneveld,Faeze Brahman,Finbarr Timbers,Hamish Ivison,Jacob Morrison,Jake Poznanski,Kyle Lo,Luca Soldaini,Matt Jordan,Mayee Chen,Michael Noukhovitch,Nathan Lambert,Pete Walsh,Pradeep Dasigi,Robert Berry,Saumya Malik,Saurabh Shah,Scott Geng,Shane Arora,Shashank Gupta,Taira Anderson,Teng Xiao,Tyler Murray,Tyler Romero,Victoria Graf,Akari Asai,Akshita Bhagia,Alexander Wettig,Alisa Liu,Aman Rangapur,Chloe Anastasiades,Costa Huang,Dustin Schwenk,Harsh Trivedi,Ian Magnusson,Jaron Lochner,Jiacheng Liu,Lester James V. Miranda,Maarten Sap,Malia Morgan,Michael Schmitz,Michal Guerquin,Michael Wilson,Regan Huff,Ronan Le Bras,Rui Xin,Rulin Shao,Sam Skjonsberg,Shannon Zejiang Shen,Shuyue Stella Li,Tucker Wilde,Valentina Pyatkin,Will Merrill,Yapei Chang,Yuling Gu,Zhiyuan Zeng,Ashish Sabharwal,Luke Zettlemoyer,Pang Wei Koh,Ali Farhadi,Noah A. Smith,Hannaneh Hajishirzi*

Main category: cs.CL

TL;DR: Olmo 3是新一代完全开源的语言模型家族（7B和32B参数），旨在提升长上下文推理、函数调用、编码、指令遵循、通用聊天和知识召回能力。其旗舰模型Olmo 3 Think 32B是迄今为止最强大的完全开源思维模型。本次发布还包含了完整的模型开发流程。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发在长上下文推理、函数调用、编码、指令遵循、通用聊天和知识召回等多个关键领域表现出色的语言模型，并以完全开源的方式提供，以促进社区的透明度和进步。

Method: 本文介绍了Olmo 3模型家族的构建方法，其特点是完全公开整个模型流程，包括每个阶段、检查点、数据点和所有构建依赖项，从而实现模型的完全可复现性和透明度。

Result: 研究成果是发布了Olmo 3系列模型，包括7B和32B参数规模的模型，它们被描述为最先进的、完全开源的语言模型。其中，Olmo 3 Think 32B被认为是迄今为止发布的最强大的完全开源思维模型。

Conclusion: Olmo 3系列模型代表了完全开源语言模型领域的重大进展，特别是在其旗舰32B模型的性能以及整个模型生命周期的透明度方面，为研究人员和开发者提供了强大的工具和全面的可复现性。

Abstract: We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall. This release includes the entire model flow, i.e., the full lifecycle of the family of models, including every stage, checkpoint, data point, and dependency used to build it. Our flagship model, Olmo 3 Think 32B, is the strongest fully-open thinking model released to-date.

</details>


### [154] [Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed](https://arxiv.org/abs/2512.14067)
*Yonggan Fu,Lexington Whalen,Zhifan Ye,Xin Dong,Shizhe Diao,Jingyu Liu,Chengyue Wu,Hao Zhang,Enze Xie,Song Han,Maksim Khadkevich,Jan Kautz,Yingyan Celine Lin,Pavlo Molchanov*

Main category: cs.CL

TL;DR: 该研究提出了一种从预训练自回归模型（AR）到扩散语言模型（dLM）的有效转换方法，通过改进注意力模式和掩码策略，显著提升了dLM的速度和准确性，形成了Efficient-DLM系列。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型（dLMs）在并行、非自回归生成方面潜力巨大，但从头训练时学习效率低于自回归（AR）语言模型。现有AR到dLM转换方法在注意力模式和目标函数上存在局限性，导致未能充分利用预训练AR模型的优势，因此需要开发更高效的转换方法来提升dLM的速度并保持AR模型的任务准确性。

Method: 1. 系统比较了不同的注意力模式，发现保持预训练AR模型的权重分布对于有效的AR到dLM转换至关重要。2. 引入了一种连续预训练方案，采用块级注意力模式（块间因果，块内双向），以更好地保留AR模型的权重分布并支持KV缓存。3. 提出了一种位置依赖的token掩码策略，在训练期间为后续token分配更高的掩码概率，以更好地模拟测试时的行为，从而弥补训练-测试之间的掩码token分布差距。

Result: 该研究提出的Efficient-DLM系列模型在性能上超越了现有最先进的AR模型和dLM。例如，Efficient-DLM 8B模型相比Dream 7B和Qwen3 4B，分别实现了5.4%/2.7%的准确率提升，并带来了4.5倍/2.7倍的吞吐量提升。

Conclusion: 该论文为有效的AR到dLM转换提供了原则和方法论，通过优化注意力模式以保留AR权重分布和改进掩码策略，成功构建了Efficient-DLM系列模型。这些模型在保持高准确性的同时，显著提升了生成速度，为可扩展的AR到dLM转换提供了可行的见解和解决方案。

Abstract: Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models' task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce a continuous pretraining scheme with a block-wise attention pattern, which remains causal across blocks while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models' weight distributions than fully bidirectional modeling, in addition to its known benefit of enabling KV caching, and leads to a win-win in accuracy and efficiency. Second, to mitigate the training-test gap in mask token distributions (uniform vs. highly left-to-right), we propose a position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs' attention patterns, training dynamics, and other design choices, providing actionable insights into scalable AR-to-dLM conversion. These studies lead to the Efficient-DLM family, which outperforms state-of-the-art AR models and dLMs, e.g., our Efficient-DLM 8B achieves +5.4%/+2.7% higher accuracy with 4.5x/2.7x higher throughput compared to Dream 7B and Qwen3 4B, respectively.

</details>


### [155] [Structure-Aware Decoding Mechanisms for Complex Entity Extraction with Large-Scale Language Models](https://arxiv.org/abs/2512.13980)
*Zhimin Qiu,Di Wu,Feng Liu,Chenrui Hu,Yuxiao Wang*

Main category: cs.CL

TL;DR: 本文提出一种基于大语言模型的结构感知解码方法，用于解决嵌套和重叠实体提取中语义完整性与结构一致性难以兼顾的问题，通过引入候选跨度生成和结构化注意力建模，显著提升了复杂实体识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理嵌套和重叠实体提取任务时，难以同时保持语义完整性和结构一致性。

Method: 该方法引入了候选跨度生成机制和结构化注意力建模，实现了实体边界、层次关系和交叉依赖的统一建模。模型首先使用预训练语言模型获取上下文语义表示，然后通过候选表示组合捕获多粒度实体跨度特征，并在解码过程中引入层次结构约束。为增强稳定性，模型联合优化了分类损失和结构一致性损失。

Result: 在ACE 2005数据集上的实验表明，该方法在准确率、精确率、召回率和F1-Score上均有显著提升，尤其在嵌套和重叠实体识别方面，展现出更强的边界定位和结构建模能力。

Conclusion: 研究验证了结构感知解码在复杂语义提取任务中的有效性，为开发具有层次理解能力的语言模型提供了新视角，并为高精度信息提取奠定了方法论基础。

Abstract: This paper proposes a structure-aware decoding method based on large language models to address the difficulty of traditional approaches in maintaining both semantic integrity and structural consistency in nested and overlapping entity extraction tasks. The method introduces a candidate span generation mechanism and structured attention modeling to achieve unified modeling of entity boundaries, hierarchical relationships, and cross-dependencies. The model first uses a pretrained language model to obtain context-aware semantic representations, then captures multi-granular entity span features through candidate representation combinations, and introduces hierarchical structural constraints during decoding to ensure consistency between semantics and structure. To enhance stability in complex scenarios, the model jointly optimizes classification loss and structural consistency loss, maintaining high recognition accuracy under multi-entity co-occurrence and long-sentence dependency conditions. Experiments conducted on the ACE 2005 dataset demonstrate significant improvements in Accuracy, Precision, Recall, and F1-Score, particularly in nested and overlapping entity recognition, where the model shows stronger boundary localization and structural modeling capability. This study verifies the effectiveness of structure-aware decoding in complex semantic extraction tasks, provides a new perspective for developing language models with hierarchical understanding, and establishes a methodological foundation for high-precision information extraction.

</details>


### [156] [Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study](https://arxiv.org/abs/2512.14085)
*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Taiga Mori,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 本文提出一个多语言（日语、英语、中文）的连续式反馈信号预测模型，并用它来研究跨语言的反馈信号时序行为，发现不同语言的特征和训练优势。


<details>
  <summary>Details</summary>
Motivation: 研究不同语言之间反馈信号（backchannel）时序行为的差异，以期为设计更自然、更具文化意识的口语对话系统提供依据。

Method: 开发了一个基于Transformer的帧级多语言反馈信号预测模型，利用约300小时的双人对话数据进行联合辅助任务训练。通过与单语言基线模型对比、零样本迁移测试、扰动分析和上下文长度研究来探究跨语言差异，并将其集成到实时处理软件中进行演示。

Result: 多语言模型在所有三种语言中均达到或超越了单语言基线。零样本迁移能力有限，表明存在显著的跨语言差异。扰动分析显示，日语更依赖短期语言信息，而英语和中文对静音时长和韵律变化更敏感；多语言训练有助于共享和适应性表达，并减少中文对音高的过度依赖。上下文长度研究表明，日语对较短上下文更稳健，而中文从较长上下文中获益显著。模型实现了仅CPU的实时推理。

Conclusion: 研究提供了一个统一的模型和经验证据，揭示了反馈信号时序在不同语言间的差异，为设计更自然、更具文化意识的口语对话系统提供了指导。

Abstract: We present a multilingual, continuous backchannel prediction model for Japanese, English, and Chinese, and use it to investigate cross-linguistic timing behavior. The model is Transformer-based and operates at the frame level, jointly trained with auxiliary tasks on approximately 300 hours of dyadic conversations. Across all three languages, the multilingual model matches or surpasses monolingual baselines, indicating that it learns both language-universal cues and language-specific timing patterns. Zero-shot transfer with two-language training remains limited, underscoring substantive cross-lingual differences. Perturbation analyses reveal distinct cue usage: Japanese relies more on short-term linguistic information, whereas English and Chinese are more sensitive to silence duration and prosodic variation; multilingual training encourages shared yet adaptable representations and reduces overreliance on pitch in Chinese. A context-length study further shows that Japanese is relatively robust to shorter contexts, while Chinese benefits markedly from longer contexts. Finally, we integrate the trained model into a real-time processing software, demonstrating CPU-only inference. Together, these findings provide a unified model and empirical evidence for how backchannel timing differs across languages, informing the design of more natural, culturally-aware spoken dialogue systems.

</details>


### [157] [A Unified Sparse Attention via Multi-Granularity Compression](https://arxiv.org/abs/2512.14082)
*Siran Liu,Zane Cao,Yongchao He*

Main category: cs.CL

TL;DR: UniSparse是一种统一的稀疏注意力机制，通过引入复合令牌和动态构建稀疏注意力，显著提高了大型语言模型在长上下文理解和推理方面的效率和准确性，超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮对话和程序分析等应用中对长上下文理解和推理的需求日益增长。然而，核心的自注意力机制计算复杂度与序列长度呈二次方关系，形成了主要的计算瓶颈。现有稀疏注意力方法存在局限性：训练型方法成本高昂且难以作为插件，推理型方法则常牺牲效率或跨模态通用性。

Method: 本文提出了UniSparse，一种统一的机制，引入了“复合令牌”（composite tokens）概念，即聚合多粒度上下文信息的紧凑表示。基于此抽象，UniSparse通过多粒度压缩和块级选择动态构建稀疏注意力，从而在GPU上实现高效且硬件友好的执行。

Result: 在多模态和各种任务（从合成基准到实际应用）中，UniSparse在准确性和效率方面均持续超越现有最先进的稀疏注意力方法（如MInference, XAttention, FlexPrefill）。它实现了全注意力99%以上的准确率，并且注意力计算速度比FlashAttention快2.61倍。

Conclusion: UniSparse通过其统一的机制和复合令牌概念，有效解决了长上下文理解中的计算瓶颈，在保持高准确性的同时显著提升了效率，并在多种模态和任务中表现出卓越的性能。

Abstract: Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottleneck. Existing sparse attention methods alleviate this issue but face trade-offs: training-based methods are costly and cannot be directly applied as acceleration plugins for other models, while inference-time methods often compromise efficiency or cross-modal generality. To address these limitations, we present UniSparse, a unified mechanism that introduces the notion of composite tokens--compact representations that aggregate multi-granularity contextual information. Building on this abstraction, UniSparse dynamically constructs sparse attention through multi-granularity compression and block-level selection, enabling efficient and hardware-friendly execution on GPU. Across multiple modalities and tasks ranging from synthetic benchmarks to real-world applications, UniSparse consistently surpasses state-of-the-art sparse attention methods (e.g., MInference, XAttention, FlexPrefill) in both accuracy and efficiency, achieving $\ge$ 99% of full-attention accuracy and up to 2.61$\times$ faster attention computation than FlashAttention.

</details>


### [158] [CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models](https://arxiv.org/abs/2512.14118)
*Yiran Zhang,Jincheng Hu,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 大型语言模型在多轮推理中表现不佳，本文提出了CogMem，一个认知启发式的记忆增强LLM架构，通过分层记忆（LTM、DA、FoA）来支持持续迭代推理，有效缓解了推理失败，控制了上下文增长，并提高了连贯性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮交互中常出现推理偏差、任务漂移、幻觉、过度自信和记忆衰退等问题。现有方法通过附加完整对话历史，导致上下文无限增长、计算成本高昂和推理效率下降。

Method: 本文引入了CogMem，一个受认知启发的记忆增强LLM架构，通过结构化、持久性记忆支持持续迭代推理。它包含三个层次：长期记忆（LTM）整合跨会话推理策略；直接访问（DA）记忆维护会话级笔记并检索相关长期记忆；注意力焦点（FoA）机制在每个轮次动态重建简洁、与任务相关的上下文。

Result: 在TurnBench上的实验表明，CogMem的分层设计缓解了推理失败，控制了上下文增长，并提高了扩展推理链中的一致性。

Conclusion: CogMem使大型语言模型在多轮交互中向更可靠、更像人类的推理迈进。

Abstract: Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination, overconfidence, and memory decay. Current approaches typically append full conversational histories, causing unbounded context growth, higher computational costs, and degraded reasoning efficiency. We introduce CogMem, a cognitively inspired, memory-augmented LLM architecture that supports sustained iterative reasoning through structured, persistent memory. CogMem incorporates three layers: a Long-Term Memory (LTM) that consolidates cross-session reasoning strategies; a Direct Access (DA) memory that maintains session-level notes and retrieves relevant long-term memories; and a Focus of Attention (FoA) mechanism that dynamically reconstructs concise, task-relevant context at each turn. Experiments on TurnBench show that this layered design mitigates reasoning failures, controls context growth, and improves consistency across extended reasoning chains, moving toward more reliable, human-like reasoning in LLMs.

</details>


### [159] [Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents](https://arxiv.org/abs/2512.14142)
*Hongqiu Ni,Jiabao Zhang,Guopeng Li,Zilong Wang,Ruiqi Wu,Chi Zhang,Haisheng Tan*

Main category: cs.CL

TL;DR: 针对LLM智能体多阶段工作流中计算与I/O混合导致的端到端延迟问题，本文提出了Astraea服务引擎。Astraea通过状态感知的分层调度和自适应KV缓存管理，将优化重心从局部段转移到全局请求生命周期，显著降低了平均作业完成时间（JCT）。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理系统（如vLLM）通常专注于分段优化，无法最小化LLM智能体多阶段工作流的端到端延迟（即全局作业完成时间JCT）。这些工作流在本地计算和外部网络服务调用（如Web API）之间交替，导致其执行模式与现有系统的调度粒度不匹配。

Method: Astraea是一个服务引擎，采用以下方法：1. 状态感知的分层调度算法，整合请求的历史状态和未来预测。2. 根据I/O和计算密集型特性动态分类请求。3. 使用增强的HRRN（Highest Response Ratio Next）策略来平衡效率和公平性。4. 实现自适应KV缓存管理器，根据系统内存压力智能处理I/O等待期间的智能体状态。

Result: 实验结果表明，与基线方法相比，Astraea将平均JCT降低了高达25.5%。此外，在不同模型规模的高负载下，Astraea表现出强大的鲁棒性和稳定性。

Conclusion: Astraea通过将优化从局部段转移到全局请求生命周期，有效解决了LLM智能体工作流的端到端延迟问题，显著提升了性能并展现出良好的稳定性。

Abstract: Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.

</details>


### [160] [A Comparative Analysis of Retrieval-Augmented Generation Techniques for Bengali Standard-to-Dialect Machine Translation Using LLMs](https://arxiv.org/abs/2512.14179)
*K. M. Jubair Sami,Dipto Sumit,Ariyan Hossain,Farig Sadeque*

Main category: cs.CL

TL;DR: 本论文提出并比较了两种新颖的RAG（检索增强生成）管道，用于标准孟加拉语到方言的翻译。结果显示，基于标准化句对的管道表现更优，并能使小型模型超越大型模型，为低资源方言翻译提供了一种无需微调的有效方案。


<details>
  <summary>Details</summary>
Motivation: 由于数据稀缺和语言变异，标准语言到其区域方言的翻译是一个重大的自然语言处理挑战，在孟加拉语中尤为突出。

Method: 本文提出并比较了两种RAG管道：1. 基于转录的管道，利用音频转录中的大量方言句子上下文。2. 基于标准化句对的管道，利用结构化的“地方方言:标准孟加拉语”句对。研究使用BLEU、ChrF、WER和BERTScore等指标，在六种孟加拉语方言和多个大型语言模型（LLMs）上评估了这两种管道。

Result: 基于句对的管道持续优于基于转录的管道，例如，将吉大港方言的词错误率（WER）从76%降低到55%。关键在于，这种RAG方法使得较小的模型（如Llama-3.1-8B）能够超越大得多的模型（如GPT-OSS-120B）。

Conclusion: 精心设计的检索策略比模型大小更为关键。这项工作为低资源方言翻译提供了一个有效且无需微调的解决方案，为保护语言多样性提供了实用的蓝图。

Abstract: Translating from a standard language to its regional dialects is a significant NLP challenge due to scarce data and linguistic variation, a problem prominent in the Bengali language. This paper proposes and compares two novel RAG pipelines for standard-to-dialectal Bengali translation. The first, a Transcript-Based Pipeline, uses large dialect sentence contexts from audio transcripts. The second, a more effective Standardized Sentence-Pairs Pipeline, utilizes structured local\_dialect:standard\_bengali sentence pairs. We evaluated both pipelines across six Bengali dialects and multiple LLMs using BLEU, ChrF, WER, and BERTScore. Our findings show that the sentence-pair pipeline consistently outperforms the transcript-based one, reducing Word Error Rate (WER) from 76\% to 55\% for the Chittagong dialect. Critically, this RAG approach enables smaller models (e.g., Llama-3.1-8B) to outperform much larger models (e.g., GPT-OSS-120B), demonstrating that a well-designed retrieval strategy can be more crucial than model size. This work contributes an effective, fine-tuning-free solution for low-resource dialect translation, offering a practical blueprint for preserving linguistic diversity.

</details>


### [161] [Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets](https://arxiv.org/abs/2512.14237)
*Estelle Zheng,Nathan Cerisara,Sébastien Warichet,Emmanuel Helbert,Christophe Cerisara*

Main category: cs.CL

TL;DR: 本文重新审视了Ladder Side Tuning (LST)，一种参数高效微调（PEFT）技术，并展示其在保持与QLoRA相当的性能的同时，能将峰值内存使用降低50%，从而在消费级GPU上实现7B模型的微调。同时引入了深度扩展变体xLadder。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的微调通常受限于商用GPU的内存。尽管QLoRA等PEFT方法减少了可训练参数，但在全模型反向传播过程中仍会产生高内存消耗。

Method: 本文重新审视并应用了Ladder Side Tuning (LST)，这是一种通过添加轻量级旁路网络来实现参数高效微调的技术。此外，引入了xLadder，一个通过交叉连接增加有效深度的LST深度扩展变体。通过自然语言理解、数学和LLM-critic任务等下游基准测试，将LST与QLoRA的性能进行了比较。

Result: LST将峰值内存使用降低了50%，同时在计算扩展斜率上与QLoRA相当。在各种基准测试中，LST的平均准确性与QLoRA具有竞争力，且内存效率更高。LST使得在单个12 GB消费级GPU上微调7B参数模型（2k-token上下文）成为可能，而无需梯度检查点，在相同条件下QLoRA会耗尽内存。xLadder通过增加有效深度，在固定参数数量下缩短了思维链（CoT），且没有额外的内存开销。

Conclusion: LST是一种在内存受限时非常强大的PEFT方法。xLadder在此基础上，能够在不增加额外内存开销的情况下实现更深层次的推理。这些方法为消费级硬件上的LLM微调提供了显著的内存效率和性能优势。

Abstract: Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage induced by the backward pass in the full model. We revisit Ladder Side Tuning (LST), a rarely explored PEFT technique that adds a lightweight side network, and show that it matches QLoRA's compute scaling slope while cutting peak memory by 50\%. Across different downstream benchmarks spanning natural language understanding, mathematical and LLM-critic tasks, LST has competitive performance with QLoRA's accuracy on average while being much more memory-efficient. This efficiency enables fine-tuning of 7B-parameter models on a single 12 GB consumer GPU with 2k-token contexts, requiring no gradient checkpointing\textemdash conditions under which QLoRA exhausts memory. Beyond memory efficiency, we also establish scaling laws showing that LST scales similarly to QLoRA. We exploit Ladder's architectural flexibility by introducing xLadder, a depth-extended variant that increases effective depth via cross-connections and shortens chain-of-thought (CoT) at fixed parameter count. Ladder is strong when memory is the bottleneck; xLadder builds on this by enabling deeper reasoning without additional memory overhead.

</details>


### [162] [Two CFG Nahuatl for automatic corpora expansion](https://arxiv.org/abs/2512.14239)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Ligia Quintana-Torres,Graham Ranger Martha-Lorena Avendaño-Garrido*

Main category: cs.CL

TL;DR: 本文介绍了两种上下文无关文法（CFG），用于扩展纳瓦特语（一种低资源美洲原住民语言）语料库，以生成大量人工句子，从而改善非上下文嵌入的学习和评估。


<details>
  <summary>Details</summary>
Motivation: 纳瓦特语是一种低资源语言，缺乏数字语料库，这给大型语言模型（LLMs）的学习带来了巨大挑战。研究旨在通过扩展语料库来解决这一问题，以便学习非上下文嵌入。

Method: 引入了两种新的纳瓦特语上下文无关文法（CFG），并以生成模式使用它们来产生大量语法有效的人工纳瓦特语句。

Result: 通过使用这些文法，纳瓦特语语料库得到了显著扩展。扩展后的语料库被用于学习嵌入，并在句子语义相似性任务中评估其相关性。结果显示，与仅使用原始语料库相比，性能有所提升，并且经济型嵌入通常优于某些大型语言模型。

Conclusion: 上下文无关文法能有效扩展低资源语言的语料库，显著改善嵌入学习效果，并证明了经济型嵌入在某些任务中可以表现出色。

Abstract: The aim of this article is to introduce two Context-Free Grammars (CFG) for Nawatl Corpora expansion. Nawatl is an Amerindian language (it is a National Language of Mexico) of the $π$-language type, i.e. a language with few digital resources. For this reason the corpora available for the learning of Large Language Models (LLMs) are virtually non-existent, posing a significant challenge. The goal is to produce a substantial number of syntactically valid artificial Nawatl sentences and thereby to expand the corpora for the purpose of learning non contextual embeddings. For this objective, we introduce two new Nawatl CFGs and use them in generative mode. Using these grammars, it is possible to expand Nawatl corpus significantly and subsequently to use it to learn embeddings and to evaluate their relevance in a sentences semantic similarity task. The results show an improvement compared to the results obtained using only the original corpus without artificial expansion, and also demonstrate that economic embeddings often perform better than some LLMs.

</details>


### [163] [From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition](https://arxiv.org/abs/2512.14244)
*Yiqing Zhou,Yu Lei,Shuzheng Si,Qingyan Sun,Wei Wang,Yifei Wu,Hao Wen,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出了一种名为EDU-based Context Compressor的显式上下文压缩框架，它将线性文本转换为基本语篇单元（EDU）的关系树，并通过选择相关子树来保留全局结构和细节，显著提高了LLM处理长上下文的性能并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理长上下文时面临计算成本高昂、引入噪声等瓶颈，尤其是在长文档问答和自主代理等应用中。现有压缩技术常破坏局部连贯性或存在位置偏差，且与闭源API不兼容。

Method: 本研究引入了EDU-based Context Compressor框架，将上下文压缩重构为“结构化-然后-选择”的过程：首先，LingoEDU将线性文本转换为基本语篇单元（EDU）的关系树，并严格锚定源索引以消除幻觉；其次，一个轻量级排名模块选择与查询相关的子树进行线性化。同时，发布了StructBench数据集用于评估结构理解。

Result: 实验结果表明，该方法在结构预测准确性上达到了最先进水平，显著优于前沿LLMs并降低了成本。此外，其结构感知的压缩显著提升了从长上下文任务到复杂深度搜索场景的下游任务性能。

Conclusion: EDU-based Context Compressor通过将上下文重构为EDU关系树并进行显式选择性压缩，有效解决了LLMs处理长上下文的挑战，在保持结构和细节的同时，显著提升了性能并降低了成本，为长上下文应用提供了强大的解决方案。

Abstract: Managing extensive context remains a critical bottleneck for Large Language Models (LLMs), particularly in applications like long-document question answering and autonomous agents where lengthy inputs incur high computational costs and introduce noise. Existing compression techniques often disrupt local coherence through discrete token removal or rely on implicit latent encoding that suffers from positional bias and incompatibility with closed-source APIs. To address these limitations, we introduce the EDU-based Context Compressor, a novel explicit compression framework designed to preserve both global structure and fine-grained details. Our approach reformulates context compression as a structure-then-select process. First, our LingoEDU transforms linear text into a structural relation tree of Elementary Discourse Units (EDUs) which are anchored strictly to source indices to eliminate hallucination. Second, a lightweight ranking module selects query-relevant sub-trees for linearization. To rigorously evaluate structural understanding, we release StructBench, a manually annotated dataset of 248 diverse documents. Empirical results demonstrate that our method achieves state-of-the-art structural prediction accuracy and significantly outperforms frontier LLMs while reducing costs. Furthermore, our structure-aware compression substantially enhances performance across downstream tasks ranging from long-context tasks to complex Deep Search scenarios.

</details>


### [164] [Inflation Attitudes of Large Language Models](https://arxiv.org/abs/2512.14306)
*Nikoleta Anesti,Edward Hill,Andreas Joseph*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs，特别是GPT-3.5-turbo）根据宏观经济价格信号形成通胀感知和预期的能力，发现它在短期内能跟踪调查数据并复制家庭通胀感知的一些规律，但缺乏一致的消费者价格通胀模型。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）能否像人类一样，根据宏观经济价格信号形成通胀感知和预期，并将其表现与家庭调查数据和官方统计数据进行比较。同时，探索LLMs在社会科学中应用的潜力。

Method: 使用GPT-3.5-turbo模型，模拟英格兰银行通胀态度调查（IAS）的信息集和人口统计学特征。采用准实验设计，利用GPT模型训练截止日期（2021年9月）早于英国通胀飙升的时间点。通过Shapley值分解方法分析LLM输出的驱动因素。

Result: GPT模型在短期内能跟踪总体的调查预测和官方统计数据。在细分层面，它能复制家庭通胀感知的关键经验规律，尤其是在收入、住房所有权和社会阶层方面。GPT对食品通胀信息表现出与人类受访者相似的高度敏感性。然而，研究也发现GPT缺乏一个一致的消费者价格通胀模型。

Conclusion: LLMs能够根据宏观经济信号形成通胀感知和预期，并在一定程度上复制人类的感知模式，但其对通胀的理解仍存在局限性。本文提出的方法可用于评估LLMs在社会科学中的行为、比较不同模型或辅助调查设计。

Abstract: This paper investigates the ability of Large Language Models (LLMs), specifically GPT-3.5-turbo (GPT), to form inflation perceptions and expectations based on macroeconomic price signals. We compare the LLM's output to household survey data and official statistics, mimicking the information set and demographic characteristics of the Bank of England's Inflation Attitudes Survey (IAS). Our quasi-experimental design exploits the timing of GPT's training cut-off in September 2021 which means it has no knowledge of the subsequent UK inflation surge. We find that GPT tracks aggregate survey projections and official statistics at short horizons. At a disaggregated level, GPT replicates key empirical regularities of households' inflation perceptions, particularly for income, housing tenure, and social class. A novel Shapley value decomposition of LLM outputs suited for the synthetic survey setting provides well-defined insights into the drivers of model outputs linked to prompt content. We find that GPT demonstrates a heightened sensitivity to food inflation information similar to that of human respondents. However, we also find that it lacks a consistent model of consumer price inflation. More generally, our approach could be used to evaluate the behaviour of LLMs for use in the social sciences, to compare different models, or to assist in survey design.

</details>


### [165] [Step-Tagging: Toward controlling the generation of Language Reasoning Models through step monitoring](https://arxiv.org/abs/2512.14332)
*Yannis Belkhiter,Seshu Tirupathi,Giulio Zizzo,John D. Kelleher*

Main category: cs.CL

TL;DR: 本文提出Step-Tagging框架，通过实时标记语言推理模型（LRM）的推理步骤类型，并结合ReasonType分类法，实现在线监控和早期停止，从而将LRM的token生成量减少20-50%，同时保持相似的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管语言推理模型（LRMs）在推理能力上取得了显著进展，但现有研究表明它们仍然效率低下，经常过度生成验证和反思步骤，导致资源浪费。

Method: 研究引入了Step-Tagging框架，这是一个轻量级的句子分类器，能够实时标注LRM生成的推理步骤类型。为此，他们还提出了ReasonType，一个新颖的推理步骤分类法。基于此框架，研究证明通过在线监测特定步骤的数量可以产生有效且可解释的LRM推理早期停止标准。

Result: 在MATH500、GSM8K、AIME、GPQA和MMLU-Pro等基准数据集上对三个开源推理模型进行评估，Step-Tagging框架在保持与标准生成相当的准确性的同时，实现了20%到50%的token减少，其中在计算量较大的任务上获得了最大的收益。

Conclusion: 这项工作提供了一种增强对LRM生成过程控制的新方法，以及一个研究LRM行为的新工具，有效提升了LRM的效率并减少了token消耗。

Abstract: The field of Language Reasoning Models (LRMs) has been very active over the past few years with advances in training and inference techniques enabling LRMs to reason longer, and more accurately. However, a growing body of studies show that LRMs are still inefficient, over-generating verification and reflection steps. To address this challenge, we introduce the Step-Tagging framework, a lightweight sentence-classifier enabling real-time annotation of the type of reasoning steps that an LRM is generating. To monitor reasoning behaviors, we introduced ReasonType: a novel taxonomy of reasoning steps. Building on this framework, we demonstrated that online monitoring of the count of specific steps can produce effective interpretable early stopping criteria of LRM inferences. We evaluate the Step-tagging framework on three open-source reasoning models across standard benchmark datasets: MATH500, GSM8K, AIME and non-mathematical tasks (GPQA and MMLU-Pro). We achieve 20 to 50\% token reduction while maintaining comparable accuracy to standard generation, with largest gains observed on more computation-heavy tasks. This work offers a novel way to increase control over the generation of LRMs, and a new tool to study behaviors of LRMs.

</details>


### [166] [Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2512.14427)
*Gabriele Prato,Shagun Sodhani,Alessandro Sordoni,Sarath Chandar*

Main category: cs.CL

TL;DR: 研究发现，在大型语言模型训练中，文档打包策略可以提升模型的潜在多跳推理能力，但需更多计算资源。通过消融研究揭示了其优势的关键因素，为优化模型开发提供了见解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练中，为优化计算效率常将多个文档打包。然而，这种做法对模型能力的影响，特别是对潜在多跳推理能力的影响，尚未得到充分探索。

Method: 研究者调查了不同的文档打包策略如何影响LLM的潜在多跳推理能力。为了理解其内在机制，还进行了一项消融研究，以识别解释打包优势的关键因素。

Result: 研究结果表明，与单独文档训练相比，文档打包可以提高模型性能（多跳推理能力），但需要更多的计算资源。消融研究进一步确定了导致打包优势的关键因素。

Conclusion: 本研究加深了对大型语言模型训练动态的理解，并为优化模型开发提供了实用的见解。

Abstract: The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.

</details>


### [167] [SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models](https://arxiv.org/abs/2512.14481)
*Shizhuo Mao,Song Chen,Yi Kang*

Main category: cs.CL

TL;DR: 为解决大语言模型部署中模型过大的问题，本文提出SASQ框架，一种轻量级量化感知训练方法，专门优化激活量化因子。SASQ在不改变预训练权重的情况下，实现了高精度和高效的静态推理，甚至超越了FP16模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的规模不断增长，超出了GPU内存的提升速度，导致部署困难。现有的量化方案存在权衡：动态量化计算开销大、边缘设备部署困难；静态量化牺牲精度；量化感知训练（QAT）则涉及高昂的权重训练成本。

Method: SASQ是一个轻量级的量化感知训练（QAT）框架，专门针对激活量化因子进行优化。它仅优化量化因子，不改变预训练权重，从而实现高精度静态推理。SASQ还自适应地截断异常值，在保留激活分布特性的同时降低了量化难度。

Result: SASQ不仅超越了现有的最先进量化方案，甚至优于对应的FP16模型。在LLaMA2-7B模型上，它在WikiText2数据集上的困惑度比QuaRot低5.2%，比FP16模型低4.7%。

Conclusion: SASQ提供了一种高效且高精度的激活量化方法，有效解决了大语言模型部署的挑战。通过仅优化量化因子并自适应处理异常值，SASQ在保持部署效率的同时，实现了优于现有最佳量化方案和全精度模型的性能。

Abstract: Large language models (LLMs) excel at natural language tasks but face deployment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation precision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accuracy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the distributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 models. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.

</details>


### [168] [C-ing Clearly: Enhanced Binary Code Explanations using C code](https://arxiv.org/abs/2512.14500)
*Teodor Poncu,Ioana Pintilie,Marius Dragoi,Dragos Tantaru,Florin Brad*

Main category: cs.CL

TL;DR: 本文提出了一种名为C-ing Clearly的合成数据生成方法，利用对应的C代码增强大型语言模型(LLM)对汇编语言的理解，从而提高了LLM在二进制代码摘要和漏洞检测任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常擅长高级编程语言的编码任务，但在汇编等低级编程语言方面表现不佳。研究动机是提高LLM对汇编代码的理解能力。

Method: 提出C-ing Clearly合成数据生成方法。该方法利用对应的C代码来增强LLM对汇编的理解。通过使用这种方法生成的数据进行微调，来改进LLM的性能。

Result: 通过我们的方法生成的数据进行微调后，LLM在二进制代码摘要和漏洞检测方面的性能得到了提高。该方法在不同LLM家族和模型尺寸上都显示出持续的性能提升。

Conclusion: C-ing Clearly方法通过利用C代码有效地提高了LLM对汇编的理解和处理能力，从而在二进制代码摘要和漏洞检测等任务上取得了显著且一致的性能提升。

Abstract: Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.

</details>


### [169] [Linguists should learn to love speech-based deep learning models](https://arxiv.org/abs/2512.14506)
*Marianne de Heer Kloots,Paul Boersma,Willem Zuidema*

Main category: cs.CL

TL;DR: 本文批评了现有连接深度学习与语言学框架过于侧重生成式文本大语言模型（LLM），并主张应纳入基于音频的深度学习模型以实现更全面的互动。


<details>
  <summary>Details</summary>
Motivation: 许多关于人类语言的有趣问题无法仅通过书面文本捕捉，而现有框架对基于文本的LLM的关注从根本上限制了与语言学的有效互动。

Method: （本文的论证方法）提出并倡导将基于音频的深度学习模型纳入连接技术导向的深度学习系统和解释导向的语言学理论的框架中。

Result: 基于文本的生成式大语言模型在捕捉人类语言的丰富性方面存在根本性局限。

Conclusion: 基于音频的深度学习模型能够并且应该在促进深度学习与语言学之间更富有成效的互动中发挥关键作用。

Abstract: Futrell and Mahowald present a useful framework bridging technology-oriented deep learning systems and explanation-oriented linguistic theories. Unfortunately, the target article's focus on generative text-based LLMs fundamentally limits fruitful interactions with linguistics, as many interesting questions on human language fall outside what is captured by written text. We argue that audio-based deep learning models can and should play a crucial role.

</details>


### [170] [VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse](https://arxiv.org/abs/2512.14531)
*Ying Nie,Kai Han,Hongguang Li,Hang Zhou,Tianyu Guo,Enhua Wu,Xinghao Chen,Yunhe Wang*

Main category: cs.CL

TL;DR: VersatileFFN是一种新型前馈网络，通过在宽度和深度维度灵活重用参数，在不增加内存成本的情况下提升大型语言模型的架构容量和性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）性能卓越但内存成本高昂。现有参数高效方法（如剪枝和量化）主要压缩预训练模型，但未能增强架构容量，从而达到基础模型的表示上限。

Method: VersatileFFN受认知双加工理论启发，包含两个自适应路径：宽度多功能路径（从一个共享FFN生成子专家混合，模拟稀疏专家路由）和深度多功能路径（递归应用同一FFN以模拟对复杂token的深度处理）。一个难度感知门控动态平衡这两个路径，将“简单”token引导至高效的宽度路径，将“困难”token分配给深度迭代细化。两个路径都重用相同的参数，因此所有额外容量都来自计算而非内存。

Result: 在不同基准和模型规模上的实验证明了该方法的有效性。

Conclusion: VersatileFFN通过在固定参数预算内灵活重用参数，在计算而非内存上增加容量，有效解决了LLM的内存成本问题，并提升了模型性能。

Abstract: The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering "easy" tokens through the efficient width-wise route and allocating deeper iterative refinement to "hard" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN.

</details>


### [171] [VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models](https://arxiv.org/abs/2512.14554)
*Nguyen Tien Dong,Minh-Anh Nguyen,Thanh Dat Hoang,Nguyen Tuan Ngoc,Dao Xuan Quang Minh,Phan Phi Hai,Nguyen Thi Ngoc Anh,Dang Van Tu,Binh Vu*

Main category: cs.CL

TL;DR: VLegal-Bench是首个全面评估大型语言模型在越南法律任务中表现的基准，通过专家标注的10,450个样本，涵盖多层次法律理解和实际应用场景。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在法律领域有潜力，但越南立法的复杂性、层级性和频繁修订，使得评估LLMs解释和利用越南法律知识的能力面临巨大挑战。现有研究缺乏针对此的系统性评估工具。

Method: 引入了VLegal-Bench，一个基于布鲁姆认知分类法设计的综合基准，旨在评估LLMs在多层次法律理解上的表现。该基准包含10,450个样本，通过严格的标注流程生成，由法律专家使用标注系统进行标签和交叉验证，确保样本基于权威法律文件并反映真实世界的法律助手工作流，如通用问答、检索增强生成、多步推理和情景问题解决。

Result: 创建了VLegal-Bench，这是第一个全面的越南法律基准，包含10,450个高质量、专家标注的样本。它提供了一个标准化、透明且认知导向的评估框架，用于评估LLMs在越南法律背景下的性能。

Conclusion: VLegal-Bench为评估大型语言模型在越南法律环境中的表现奠定了坚实基础，并支持开发更可靠、可解释且符合道德规范的AI辅助法律系统。

Abstract: The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.

</details>


### [172] [Dual Language Models: Balancing Training Efficiency and Overfitting Resilience](https://arxiv.org/abs/2512.14549)
*David Samuel,Lucas Georges Gabriel Charpentier*

Main category: cs.CL

TL;DR: 本文结合自回归和掩码扩散训练目标，无需架构修改，创建出性能更优、更灵活的语言模型。


<details>
  <summary>Details</summary>
Motivation: 自回归模型训练高效但易过拟合，而掩码扩散模型训练效率较低但抗过拟合能力强。研究旨在结合两者的优点，克服各自的缺点。

Method: 在不修改架构的情况下，将自回归和掩码扩散训练目标结合起来。通过在不同数据重复水平下训练和评估50个语言模型，以确定两种目标之间的最佳比例。

Result: 双目标训练模型优于单一目标模型。在所有评估设置下，结合两种目标都是最优的。此外，无论是针对自回归还是掩码扩散的下游性能，最佳比例都相似。

Conclusion: 双目标训练能同时实现自回归模型的效率和掩码扩散模型的抗过拟合能力，从而获得更优越的语言模型性能。

Abstract: This paper combines autoregressive and masked-diffusion training objectives without any architectural modifications, resulting in flexible language models that outperform single-objective models. Autoregressive modeling has been a popular approach, partly because of its training efficiency; however, that comes at the cost of sensitivity to overfitting. On the other hand, masked-diffusion models are less efficient to train while being more resilient to overfitting. In this work, we demonstrate that dual-objective training achieves the best of both worlds. To derive the optimal ratio between both objectives, we train and evaluate 50 language models under varying levels of data repetition. We show that it is optimal to combine both objectives under all evaluated settings and that the optimal ratio is similar whether targeting autoregressive or masked-diffusion downstream performance.

</details>


### [173] [Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis](https://arxiv.org/abs/2512.14561)
*Hongli Li,Che Han Chen,Kevin Fan,Chiho Young-Johnson,Soyoung Lim,Yali Feng*

Main category: cs.CL

TL;DR: 本研究综合分析了65项关于大型语言模型（LLMs）在自动论文评分（AES）中与人类评分者一致性的研究，发现LLM-人类一致性普遍为中等到良好，但存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自动论文评分方面潜力巨大，但关于其与人类评分者相比的可靠性，现有实证研究结果不一。

Method: 遵循PRISMA 2020指南，本研究综合了2022年1月至2025年8月期间发表和未发表的65项研究，这些研究均考察了LLMs与人类评分者在AES中的一致性。

Result: 研究发现，LLM-人类评分一致性普遍为中等到良好，一致性指数（如二次加权Kappa、皮尔逊相关系数、斯皮尔曼秩相关系数）大多在0.30到0.80之间。不同研究之间的一致性水平存在显著差异，这反映了研究特定因素的差异以及缺乏标准化报告实践的问题。

Conclusion: LLM在自动论文评分中与人类评分者的一致性总体上处于中等到良好水平，但其变异性表明需要考虑研究特定因素和改进标准化报告。未来研究方向和影响已进行讨论。

Abstract: Despite the growing promise of large language models (LLMs) in automatic essay scoring (AES), empirical findings regarding their reliability compared to human raters remain mixed. Following the PRISMA 2020 guidelines, we synthesized 65 published and unpublished studies from January 2022 to August 2025 that examined agreement between LLMs and human raters in AES. Across studies, reported LLM-human agreement was generally moderate to good, with agreement indices (e.g., Quadratic Weighted Kappa, Pearson correlation, and Spearman's rho) mostly ranging between 0.30 and 0.80. Substantial variability in agreement levels was observed across studies, reflecting differences in study-specific factors as well as the lack of standardized reporting practices. Implications and directions for future research are discussed.

</details>


### [174] [Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies](https://arxiv.org/abs/2512.14576)
*Ekaterina Artemova,Laurie Burchell,Daryna Dementieva,Shu Okabe,Mariya Shmatova,Pedro Ortiz Suarez*

Main category: cs.CL

TL;DR: 该教程旨在为处理多语言和低资源语言的NLP从业者提供构建端到端NLP管道的实用工具包和策略。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了创建更公平、更具社会影响力的语言技术，解决低资源语言的数据稀缺性和文化差异挑战。

Method: 教程提供构建端到端NLP管道的实用工具包，涵盖数据收集、网络爬取、并行句子挖掘、机器翻译以及文本分类、多模态推理等下游应用。重点关注公平、可复现和社区知情的开发方法，并提供动手实践方法和建模框架。

Result: 参与者将获得构建低资源语言NLP管道的实用工具包和应对数据稀缺、文化差异的策略。教程将展示涵盖10多种语言的多元用例。

Conclusion: 该教程旨在使NLP从业者能够为代表性不足的语言开发公平、可复现且社区知情的语言技术，从而推动更具社会影响力的NLP应用。

Abstract: This tutorial (https://tum-nlp.github.io/low-resource-tutorial) is designed for NLP practitioners, researchers, and developers working with multilingual and low-resource languages who seek to create more equitable and socially impactful language technologies. Participants will walk away with a practical toolkit for building end-to-end NLP pipelines for underrepresented languages -- from data collection and web crawling to parallel sentence mining, machine translation, and downstream applications such as text classification and multimodal reasoning. The tutorial presents strategies for tackling the challenges of data scarcity and cultural variance, offering hands-on methods and modeling frameworks. We will focus on fair, reproducible, and community-informed development approaches, grounded in real-world scenarios. We will showcase a diverse set of use cases covering over 10 languages from different language families and geopolitical contexts, including both digitally resource-rich and severely underrepresented languages.

</details>


### [175] [Polypersona: Persona-Grounded LLM for Synthetic Survey Responses](https://arxiv.org/abs/2512.14562)
*Tejaswani Dash,Dinesh Karri,Anudeep Vurity,Gautam Datla,Tazeem Ahmad,Saima Rafi,Rohith Tangudu*

Main category: cs.CL

TL;DR: 本文提出了PolyPersona框架，利用参数高效的微调技术，使小型语言模型能够生成多领域、基于特定角色设定的合成调查问卷回复，其性能可与大型模型媲美。


<details>
  <summary>Details</summary>
Motivation: 研究动机是需要一种高效、可复现的方法来生成可靠且连贯的合成调查数据，以支持可扩展的评估并促进偏见分析。

Method: PolyPersona框架通过资源自适应训练，使用参数高效的LoRA适配器和4位量化技术，对紧凑型聊天模型进行指令微调。它采用对话式数据管道来保留角色特征，确保生成回复的行为一致性。研究构建了一个包含3,568个合成回复的跨10个领域和433个不同角色的数据集。评估采用多指标套件，结合了BLEU、ROUGE、BERTScore等标准文本生成指标和专门用于评估结构连贯性、风格一致性及情感对齐的调查特定指标。

Result: 实验结果显示，TinyLlama 1.1B和Phi-2等紧凑型模型表现出与7B至8B大型基线模型相当的性能，最高BLEU分数为0.090，ROUGE-1分数为0.429。这些发现表明，基于角色设定的微调能够使小型语言模型生成可靠且连贯的合成调查数据。

Conclusion: 所提出的PolyPersona框架为调查数据生成提供了一种高效、可复现的方法，支持可扩展的评估，并通过透明开放的协议促进偏见分析。

Abstract: This paper introduces PolyPersona, a generative framework for synthesizing persona-conditioned survey responses across multiple domains. The framework instruction-tunes compact chat models using parameter-efficient LoRA adapters with 4-bit quantization under a resource-adaptive training setup. A dialogue-based data pipeline explicitly preserves persona cues, ensuring consistent behavioral alignment across generated responses. Using this pipeline, we construct a dataset of 3,568 synthetic survey responses spanning ten domains and 433 distinct personas, enabling controlled instruction tuning and systematic multi-domain evaluation. We evaluate the generated responses using a multi-metric evaluation suite that combines standard text generation metrics, including BLEU, ROUGE, and BERTScore, with survey-specific metrics designed to assess structural coherence, stylistic consistency, and sentiment alignment.Experimental results show that compact models such as TinyLlama 1.1B and Phi-2 achieve performance comparable to larger 7B to 8B baselines, with a highest BLEU score of 0.090 and ROUGE-1 of 0.429. These findings demonstrate that persona-conditioned fine-tuning enables small language models to generate reliable and coherent synthetic survey data. The proposed framework provides an efficient and reproducible approach for survey data generation, supporting scalable evaluation while facilitating bias analysis through transparent and open protocols.

</details>


### [176] [Towards Nepali-language LLMs: Efficient GPT training with a Nepali BPE tokenizer](https://arxiv.org/abs/2512.14585)
*Adarsha Shrestha,Basanta Pokharel,Binit Shrestha,Smriti Adhikari,Dinesh Gothe*

Main category: cs.CL

TL;DR: 该研究提出了一个基于GPT-2的尼泊尔语语言模型，采用受GPT-3启发的训练策略、定制的BPE分词器和FlashAttention，成功实现了连贯的尼泊尔语新闻风格文本生成，克服了该低资源语言的挑战。


<details>
  <summary>Details</summary>
Motivation: 尼泊尔语作为一种低资源语言，因其复杂的语法、粘着语形态和高质量语料库的匮乏，在自然语言处理（NLP）中面临挑战，尤其现有基于编码器的架构不足以进行尼泊尔语文本生成。

Method: 该研究构建了一个基于GPT-2的尼泊尔语语言模型，采用了受GPT-3启发的多种训练策略，包括优化的学习率调度、批量缩放和架构改进。训练了一个专门针对尼泊尔语文本的自定义16k字节对编码（BPE）分词器。模型在一个结合了10.75GB清洗过的NepBERTa语料库和额外网络抓取的尼泊尔语新闻文章的混合数据集上进行预训练。同时集成了FlashAttention以减少内存使用并稳定训练。

Result: 经过两个epoch的训练，模型达到了3.168177的训练损失、3.081982的验证损失以及21.80的最终困惑度。模型展示了生成连贯的尼泊尔语新闻风格文本的能力。

Conclusion: 该GPT-2模型及其训练方法有效解决了尼泊尔语文本生成的挑战，能够生成高质量、连贯的尼泊尔语新闻风格文本。

Abstract: Nepali, a low-resource language spoken by over 32 million people, continues to face challenges in natural language processing (NLP) due to its complex grammar, agglutinative morphology, and limited availability of high-quality corpora. Most efforts to date have centered on basic encoder architectures; they remain insufficient for Nepali-specific text generation. This study presents a GPT-2-based Nepali language model trained using several training strategies inspired by GPT-3, including optimized learning rate schedules, batch scaling, and architectural refinements. A custom 16k Byte-Pair Encoding (BPE) tokenizer was trained exclusively on Nepali text to ensure more consistent segmentation and improved input representation. The model was pretrained on a combined dataset comprising a 10.75GB cleaned NepBERTa corpus and additional web-scraped Nepali news articles. FlashAttention was integrated to reduce memory usage and stabilize training. After two epochs, the model achieved a training loss of 3.168177, a validation loss of 3.081982, and a final perplexity of 21.80, demonstrating its capability to generate coherent Nepali news-style text.

</details>


### [177] [JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction](https://arxiv.org/abs/2512.14620)
*Atsuyuki Miyai,Shota Onohara,Jeonghun Baek,Kiyoharu Aizawa*

Main category: cs.CL

TL;DR: 本文介绍了JMMMU-Pro，一个图像化的日语多学科多模态理解基准，以及Vibe基准构建方法，该方法利用图像生成模型和人工验证来高效创建高质量基准。


<details>
  <summary>Details</summary>
Motivation: 现有LMMs在日语集成视觉-文本理解方面存在显著困难，需要一个更严格、更具挑战性的评估工具来推动开源社区在该领域的发展。

Method: JMMMU-Pro通过将问题图像和问题文本组合成单个图像来扩展JMMMU，要求通过视觉感知进行集成视听理解。为构建JMMMU-Pro，论文提出了Vibe基准构建方法，该方法利用图像生成模型（如Nano Banana Pro）生成候选视觉问题，然后由人工进行验证，并在必要时调整提示词以确保质量和多样性。

Result: 实验结果显示，所有开源LMMs在JMMMU-Pro上的表现都非常挣扎，这表明JMMMU-Pro是一个具有挑战性的基准，对指导开源社区未来的研究工作至关重要。

Conclusion: JMMMU-Pro为评估LMMs的日语能力提供了一个更严格的评估工具。同时，Vibe基准构建方法也为未来开发基于图像的VQA基准提供了高效的指导方针。

Abstract: This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and humans verify the outputs and, when necessary, regenerate with adjusted prompts to ensure quality. By leveraging Nano Banana Pro's highly realistic image generation capabilities and its ability to embed clean Japanese text, we construct a high-quality benchmark at low cost, covering a wide range of background and layout designs. Experimental results show that all open-source LMMs struggle substantially with JMMMU-Pro, underscoring JMMMU-Pro as an important benchmark for guiding future efforts in the open-source community. We believe that JMMMU-Pro provides a more rigorous evaluation tool for assessing the Japanese capabilities of LMMs and that our Vibe Benchmark Construction also offers an efficient guideline for future development of image-based VQA benchmarks.

</details>


### [178] [TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines](https://arxiv.org/abs/2512.14645)
*David Schulmeister,Valentin Hartmann,Lars Klein,Robert West*

Main category: cs.CL

TL;DR: 本文提出TiME（Tiny Monolingual Encoders），一种通过蒸馏等现代技术训练的小型单语模型，旨在为效率关键型应用提供高性能、低延迟、低能耗的解决方案，并支持低资源语言。


<details>
  <summary>Details</summary>
Motivation: 当前大型通用语言模型虽然功能强大，但对于仅需特定能力、要求实时响应、处理大量数据或部署于电池供电设备的效率关键型NLP应用而言，它们速度慢、能耗高且资源浪费。

Method: 研究者通过蒸馏等现代训练技术来训练小型模型（命名为TiME），并使其支持低资源语言。具体方法包括从多语言教师模型蒸馏出单语模型，以及从使用相对位置嵌入的教师模型蒸馏出使用绝对位置嵌入的模型。

Result: TiME模型在一系列常见NLP任务上展现出性能、吞吐量、延迟和能耗之间更好的权衡。研究还证明了从多语言教师模型蒸馏单语模型，以及从使用相对位置嵌入的教师模型蒸馏出使用绝对位置嵌入的模型的可行性。

Conclusion: 通过使用蒸馏等现代训练技术，可以为效率关键型应用训练出小型、高效的单语模型（TiME），这些模型在保持良好性能的同时，显著提高了吞吐量、降低了延迟和能耗，并支持低资源语言。

Abstract: Today, a lot of research on language models is focused on large, general-purpose models. However, many NLP pipelines only require models with a well-defined, small set of capabilities. While large models are capable of performing the tasks of those smaller models, they are simply not fast enough to process large amounts of data or offer real-time responses. Furthermore, they often use unnecessarily large amounts of energy, leading to sustainability concerns and problems when deploying them on battery-powered devices. In our work, we show how to train small models for such efficiency-critical applications. As opposed to many off-the-shelf NLP pipelines, our models use modern training techniques such as distillation, and offer support for low-resource languages. We call our models TiME (Tiny Monolingual Encoders) and comprehensively evaluate them on a range of common NLP tasks, observing an improved trade-off between benchmark performance on one hand, and throughput, latency and energy consumption on the other. Along the way, we show that distilling monolingual models from multilingual teachers is possible, and likewise distilling models with absolute positional embeddings from teachers with relative positional embeddings.

</details>


### [179] [Fast and Accurate Causal Parallel Decoding using Jacobi Forcing](https://arxiv.org/abs/2512.14681)
*Lanxiang Hu,Siqi Kou,Yichao Fu,Samyam Rajbhandari,Tajana Rosing,Yuxiong He,Zhijie Deng,Hao Zhang*

Main category: cs.CL

TL;DR: 本文提出Jacobi Forcing范式，通过渐进式蒸馏将自回归(AR)模型转化为高效的并行解码器，解决了现有扩散式大语言模型(dLLM)在多token生成中存在的预训练与后训练不匹配问题，显著提升了推理速度，并引入了多块解码与拒绝回收机制进一步加速。


<details>
  <summary>Details</summary>
Motivation: 现有用于加速Transformer模型推理的多token生成方法（如dLLM）通过并行解码降低延迟，但由于预训练到后训练的数据分布不匹配（掩码数据与真实数据差异大）和双向注意力与因果先验冲突，导致KV缓存复用受阻，其相较于AR模型的加速效果有限。

Method: 本文引入Jacobi Forcing，一种渐进式蒸馏范式。该范式训练模型学习其自身生成的并行解码轨迹，从而平滑地将AR模型转换为高效的并行解码器，同时保留其预训练的因果推理特性。在此基础上，根据Jacobi Forcing模型的轨迹特点，进一步提出了带有拒绝回收的多块解码（multi-block decoding with rejection recycling）机制。

Result: 通过Jacobi Forcing范式训练的模型（Jacobi Forcing Model）在编码和数学基准测试上实现了3.8倍的实际时钟加速，且性能损失极小。基于Jacobi Forcing模型轨迹特性的多块解码与拒绝回收机制，使得每次迭代的token接受计数提高了4.5倍，并带来了近4.0倍的实际时钟加速，有效地通过增加计算量换取了更低的推理延迟。

Conclusion: Jacobi Forcing范式成功解决了dLLM在多token生成中遇到的预训练与后训练不匹配问题，将AR模型高效转化为并行解码器，在保持性能的同时大幅提升了推理速度。结合多块解码与拒绝回收，进一步优化了推理延迟，为大型模型推理加速提供了有效途径。

Abstract: Multi-token generation has emerged as a promising paradigm for accelerating transformer-based large model inference. Recent efforts primarily explore diffusion Large Language Models (dLLMs) for parallel decoding to reduce inference latency. To achieve AR-level generation quality, many techniques adapt AR models into dLLMs to enable parallel decoding. However, they suffer from limited speedup compared to AR models due to a pretrain-to-posttrain mismatch. Specifically, the masked data distribution in post-training deviates significantly from the real-world data distribution seen during pretraining, and dLLMs rely on bidirectional attention, which conflicts with the causal prior learned during pretraining and hinders the integration of exact KV cache reuse. To address this, we introduce Jacobi Forcing, a progressive distillation paradigm where models are trained on their own generated parallel decoding trajectories, smoothly shifting AR models into efficient parallel decoders while preserving their pretrained causal inference property. The models trained under this paradigm, Jacobi Forcing Model, achieves 3.8x wall-clock speedup on coding and math benchmarks with minimal loss in performance. Based on Jacobi Forcing Models' trajectory characteristics, we introduce multi-block decoding with rejection recycling, which enables up to 4.5x higher token acceptance count per iteration and nearly 4.0x wall-clock speedup, effectively trading additional compute for lower inference latency. Our code is available at https://github.com/hao-ai-lab/JacobiForcing.

</details>


### [180] [Spoken DialogSum: An Emotion-Rich Conversational Dataset for Spoken Dialogue Summarization](https://arxiv.org/abs/2512.14687)
*Yen-Ju Lu,Kunxiao Gao,Mingrui Liang,Helin Wang,Thomas Thebaud,Laureano Moro-Velazquez,Najim Dehak,Jesus Villalba*

Main category: cs.CL

TL;DR: 本文介绍了Spoken DialogSum，首个将原始对话音频与事实摘要、情感丰富摘要以及说话人年龄、性别和情感等语篇级标签对齐的数据集，并展示了端到端语音模型在情感摘要方面的优势。


<details>
  <summary>Details</summary>
Motivation: 当前针对情感感知或口语对话摘要的研究受限于缺乏同时包含语音、摘要和副语言线索的数据。

Method: 数据集构建分两阶段：首先，一个LLM改写DialogSum脚本，加入Switchboard风格的填充词和反馈，并标记每个话语的情感、音高和语速；其次，一个富有表现力的TTS引擎根据标记脚本合成语音，并与副语言标签对齐。

Result: Spoken DialogSum包含13,460个情感多样化的对话，每个对话都配有事实摘要和情感聚焦摘要。基线测试显示，相对于级联ASR-LLM系统，Audio-LLM将情感摘要的ROUGE-L提高了28%，证实了端到端语音模型的价值。

Conclusion: 该研究证实了端到端语音建模对于情感感知口语对话摘要的重要性，并提供了宝贵的数据集来推动相关研究。

Abstract: Recent audio language models can follow long conversations. However, research on emotion-aware or spoken dialogue summarization is constrained by the lack of data that links speech, summaries, and paralinguistic cues. We introduce Spoken DialogSum, the first corpus aligning raw conversational audio with factual summaries, emotion-rich summaries, and utterance-level labels for speaker age, gender, and emotion. The dataset is built in two stages: first, an LLM rewrites DialogSum scripts with Switchboard-style fillers and back-channels, then tags each utterance with emotion, pitch, and speaking rate. Second, an expressive TTS engine synthesizes speech from the tagged scripts, aligned with paralinguistic labels. Spoken DialogSum comprises 13,460 emotion-diverse dialogues, each paired with both a factual and an emotion-focused summary. The dataset is available online at https://fatfat-emosum.github.io/EmoDialog-Sum-Audio-Samples/. Baselines show that an Audio-LLM raises emotional-summary ROUGE-L by 28% relative to a cascaded ASR-LLM system, confirming the value of end-to-end speech modeling.

</details>


### [181] [MMGR: Multi-Modal Generative Reasoning](https://arxiv.org/abs/2512.14691)
*Zefan Cai,Haoyi Qiu,Tianyi Ma,Haozhe Zhao,Gengze Zhou,Kung-Hsiang Huang,Parisa Kordjamshidi,Minjia Zhang,Xiao Wen,Jiuxiang Gu,Nanyun Peng,Junjie Hu*

Main category: cs.CL

TL;DR: 现有视频生成模型评估指标忽视推理能力。MMGR是一个新的多模态生成推理评估框架，涵盖物理、逻辑、空间和时间五种推理能力，并在抽象推理、具身导航和物理常识三个领域进行评估。基准测试显示，当前模型在抽象推理和长距离空间规划方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 视频基础模型虽然能生成逼真内容，但其作为世界模拟器的可靠性受限于未能捕捉物理、逻辑和空间约束。现有指标（如FVD）侧重感知质量，忽视因果关系、物理定律和全局一致性等推理失败。

Method: 引入MMGR（Multi-Modal Generative Reasoning Evaluation and Benchmark）评估框架，基于物理、逻辑、3D空间、2D空间和时间五种推理能力。MMGR在抽象推理（ARC-AGI、数独）、具身导航（真实世界3D导航和定位）和物理常识（体育、组合互动）三个领域进行评估。采用精细化指标，要求视频和图像生成都具备整体正确性。对主流视频模型（Veo-3, Sora-2, Wan-2.2）和图像模型（Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image）进行了基准测试。

Result: 模型在不同领域表现出显著的性能差距。在物理常识任务上取得中等成功，但在抽象推理任务（ARC-AGI准确率低于10%）上表现不佳，并且在具身设置中难以进行长距离空间规划。分析揭示了当前模型的关键局限性，包括过度依赖感知数据、全局状态一致性弱以及目标函数奖励视觉合理性而非因果正确性。

Conclusion: MMGR提供了一个统一的诊断基准，揭示了当前模型的关键局限性，并为开发具有推理能力的生成式世界模型指明了方向。

Abstract: Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models.

</details>


### [182] [MultiBanAbs: A Comprehensive Multi-Domain Bangla Abstractive Text Summarization Dataset](https://arxiv.org/abs/2511.19317)
*Md. Tanzim Ferdous,Naeem Ahsan Chowdhury,Prithwiraj Bhattacharjee*

Main category: cs.CL

TL;DR: 本研究开发了一个新的孟加拉语抽象式摘要数据集，包含来自博客和报纸等多个来源的54,000多篇文章及其摘要，以解决现有新闻领域数据集的局限性，并为孟加拉语NLP研究建立了强大的基线。


<details>
  <summary>Details</summary>
Motivation: 现有孟加拉语摘要研究主要集中在新闻文章，其写作风格固定，难以适应真实世界中多样化的孟加拉语文本。数字时代海量的孟加拉语内容（博客、报纸、社交媒体）导致信息过载，迫切需要能快速理解内容的摘要系统。

Method: 开发了一个包含超过54,000篇孟加拉语文章和摘要的数据集，数据来源于Cinegolpo等博客以及Samakal和The Business Standard等报纸。该数据集涵盖了多个领域和写作风格。研究还使用LSTM、BanglaT5-small和MTS-small等深度学习和迁移学习模型对该数据集进行了训练和评估，以建立强大的基线。

Result: 通过深度学习和迁移学习模型对新数据集进行评估，结果突显了其作为孟加拉语自然语言处理未来研究基准的潜力。

Conclusion: 该数据集为构建强大的摘要系统提供了坚实基础，并有助于扩展低资源语言的NLP资源。

Abstract: This study developed a new Bangla abstractive summarization dataset to generate concise summaries of Bangla articles from diverse sources. Most existing studies in this field have concentrated on news articles, where journalists usually follow a fixed writing style. While such approaches are effective in limited contexts, they often fail to adapt to the varied nature of real-world Bangla texts. In today's digital era, a massive amount of Bangla content is continuously produced across blogs, newspapers, and social media. This creates a pressing need for summarization systems that can reduce information overload and help readers understand content more quickly. To address this challenge, we developed a dataset of over 54,000 Bangla articles and summaries collected from multiple sources, including blogs such as Cinegolpo and newspapers such as Samakal and The Business Standard. Unlike single-domain resources, our dataset spans multiple domains and writing styles. It offers greater adaptability and practical relevance. To establish strong baselines, we trained and evaluated this dataset using several deep learning and transfer learning models, including LSTM, BanglaT5-small, and MTS-small. The results highlight its potential as a benchmark for future research in Bangla natural language processing. This dataset provides a solid foundation for building robust summarization systems and helps expand NLP resources for low-resource languages.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [183] [PrediFlow: A Flow-Based Prediction-Refinement Framework for Real-Time Human Motion Prediction in Human-Robot Collaboration](https://arxiv.org/abs/2512.13903)
*Sibo Tian,Minghui Zheng,Xiao Liang*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的预测-细化框架，用于工业再制造中人机协作（HRC）的实时、逼真且考虑交互的随机人体运动预测，通过整合机器人运动来提高预测质量和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动预测方法在人机协作中存在局限性：早期方法虽然强调多样性但常生成不真实的运动；近期方法侧重准确性和实时性但仍有提升空间；更重要的是，当前研究通常孤立地考虑人体运动，忽略了机器人运动对人类行为的影响。

Method: 本文提出了一种新颖的预测-细化框架。该框架将人类和机器人观察到的运动整合起来，以细化由预训练的最新预测器生成的初始预测。细化模块采用流匹配（Flow Matching）结构来处理不确定性。

Result: 在HRC桌面拆卸数据集上的实验表明，所提出的方法显著提高了预测准确性，同时保留了人体运动的不确定性和多模态。此外，总推理时间保持在时间预算内，证明了该方法的有效性和实用性。

Conclusion: 该预测-细化框架能够实现实时、逼真且考虑交互的人体运动预测，有效解决了现有方法的不足，为工业再制造中的安全有效人机协作提供了实用方案。

Abstract: Stochastic human motion prediction is critical for safe and effective human-robot collaboration (HRC) in industrial remanufacturing, as it captures human motion uncertainties and multi-modal behaviors that deterministic methods cannot handle. While earlier works emphasize highly diverse predictions, they often generate unrealistic human motions. More recent methods focus on accuracy and real-time performance, yet there remains potential to improve prediction quality further without exceeding time budgets. Additionally, current research on stochastic human motion prediction in HRC typically considers human motion in isolation, neglecting the influence of robot motion on human behavior. To address these research gaps and enable real-time, realistic, and interaction-aware human motion prediction, we propose a novel prediction-refinement framework that integrates both human and robot observed motion to refine the initial predictions produced by a pretrained state-of-the-art predictor. The refinement module employs a Flow Matching structure to account for uncertainty. Experimental studies on the HRC desktop disassembly dataset demonstrate that our method significantly improves prediction accuracy while preserving the uncertainties and multi-modalities of human motion. Moreover, the total inference time of the proposed framework remains within the time budget, highlighting the effectiveness and practicality of our approach.

</details>


### [184] [Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer VLM-LLM Pipeline](https://arxiv.org/abs/2512.13974)
*Hossein Naderi,Alireza Shojaei,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 本文提出一个多层框架，结合机器人技术和人工智能（VLM/LLM），使机器人在自主导航时能自动识别施工现场安全规则并生成安全检查报告，以解决传统手动检查和现有自动化方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 建筑施工安全检查目前仍主要依赖人工，自动化方法则受限于难以维护的特定任务数据集，且机器人现场检查仍需人工遥控和报告，效率低下。

Method: 该研究提出了一个多层框架，包含机器人和AI两个主要模块。机器人模块通过SLAM和自主导航实现重复覆盖和定点回访。AI模块则由多个层组成：基于VLM生成场景描述；检索组件将描述与OSHA及现场政策关联；另一个VLM层评估安全状况；最后，LLM层根据前述输出生成安全报告。

Result: 该框架通过概念验证实现，并在模拟常见危险的实验室环境中进行了评估。结果显示，与现有闭源模型相比，该框架展现出高召回率和有竞争力的精确度。

Conclusion: 本文提出了一种透明、可泛化的安全检查流程，通过暴露各层的中间产物并保留人工参与，超越了传统黑盒模型。这项工作为未来在建筑内外扩展到更多任务和场景奠定了基础。

Abstract: Construction safety inspection remains mostly manual, and automated approaches still rely on task-specific datasets that are hard to maintain in fast-changing construction environments due to frequent retraining. Meanwhile, field inspection with robots still depends on human teleoperation and manual reporting, which are labor-intensive. This paper aims to connect what a robot sees during autonomous navigation to the safety rules that are common in construction sites, automatically generating a safety inspection report. To this end, we proposed a multi-layer framework with two main modules: robotics and AI. On the robotics side, SLAM and autonomous navigation provide repeatable coverage and targeted revisits via waypoints. On AI side, a Vision Language Model (VLM)-based layer produces scene descriptions; a retrieval component powered grounds those descriptions in OSHA and site policies; Another VLM-based layer assesses the safety situation based on rules; and finally Large Language Model (LLM) layer generates safety reports based on previous outputs. The framework is validated with a proof-of-concept implementation and evaluated in a lab environment that simulates common hazards across three scenarios. Results show high recall with competitive precision compared to state-of-the-art closed-source models. This paper contributes a transparent, generalizable pipeline that moves beyond black-box models by exposing intermediate artifacts from each layer and keeping the human in the loop. This work provides a foundation for future extensions to additional tasks and settings within and beyond construction context.

</details>


### [185] [Impact of Robot Facial-Audio Expressions on Human Robot Trust Dynamics and Trust Repair](https://arxiv.org/abs/2512.13981)
*Hossein Naderi,Alireza Shojaei,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 本研究调查了机器人的任务表现和表情反馈如何影响人类信任动态，发现成功提升信任，失败导致信任急剧下降，而道歉能部分修复信任，且信任修复受互动、沟通、能力及用户特征调节。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人技术和人机协作在建筑、工程和施工（AEC）行业有所进展，但信任大多被视为一个静态因素，缺乏关于其在协作过程中如何随事件变化而改变的指导。

Method: 采用受控的被试内研究设计，设置了两个建筑灵感任务（物料运送和信息收集）。通过14项人机交互信任感知量表和重新委派选择，在每个任务中重复测量了四次信任。机器人产生两种多模态表情：成功后的“高兴”确认和失败后的“悲伤”道歉及二次机会请求。研究在实验室环境中进行，有30名参与者和一个四足平台。

Result: 机器人成功可靠地增加信任，失败导致信任急剧下降。基于道歉的表情能部分恢复信任（物料运送任务中恢复44%，信息收集任务中恢复38%）。项目层面分析表明，恢复的信任主要由互动和沟通因素驱动，能力部分恢复，而自主性方面变化最小。此外，年龄组和先前的态度调节了信任动态：年轻参与者表现出更大但更短暂的变化，20多岁的参与者展现出最持久的修复，而老年参与者表现出最保守的动态。

Conclusion: 本研究为未来根据任务需求和用户画像调整修复策略，以支持机器人在建筑工地安全、高效地应用奠定了基础。

Abstract: Despite recent advances in robotics and human-robot collaboration in the AEC industry, trust has mostly been treated as a static factor, with little guidance on how it changes across events during collaboration. This paper investigates how a robot's task performance and its expressive responses after outcomes shape the dynamics of human trust over time. To this end, we designed a controlled within-subjects study with two construction-inspired tasks, Material Delivery (physical assistance) and Information Gathering (perceptual assistance), and measured trust repeatedly (four times per task) using the 14-item Trust Perception Scale for HRI plus a redelegation choice. The robot produced two multimodal expressions, a "glad" display with a brief confirmation after success, and a "sad" display with an apology and a request for a second chance after failure. The study was conducted in a lab environment with 30 participants and a quadruped platform, and we evaluated trust dynamics and repair across both tasks. Results show that robot success reliably increases trust, failure causes sharp drops, and apology-based expressions partially restores trust (44% recovery in Material Delivery; 38% in Information Gathering). Item-level analysis indicates that recovered trust was driven mostly by interaction and communication factors, with competence recovering partially and autonomy aspects changing least. Additionally, age group and prior attitudes moderated trust dynamics with younger participants showed larger but shorter-lived changes, mid-20s participants exhibited the most durable repair, and older participants showed most conservative dynamics. This work provides a foundation for future efforts that adapt repair strategies to task demands and user profiles to support safe, productive adoption of robots on construction sites.

</details>


### [186] [CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth](https://arxiv.org/abs/2512.14001)
*Zhuo Zhang,Yonghui Liu,Meijie Zhang,Feiyang Tan,Yikang Ding*

Main category: cs.RO

TL;DR: 本文提出CLAIM，一种新颖的相机-激光雷达标定方法，利用单目深度模型和粗到细搜索策略，通过最小化基于皮尔逊相关性的结构损失和基于互信息的纹理损失，实现简单且自适应的高性能对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的相机-激光雷达标定方法通常需要复杂的数据处理、特征提取或特征匹配步骤，且未能充分发挥强大单目深度模型的潜力。研究旨在开发一种更简单、自适应且高效的相机-激光雷达数据对齐方法。

Method: CLAIM方法利用初始猜测和图像-激光雷达点云对，采用粗到细的搜索策略来寻找最优变换。它通过最小化两种损失实现：一种是基于补丁皮尔逊相关性的结构损失，另一种是基于互信息的纹理损失。这两种损失作为良好的对齐度量，无需复杂的特征提取或匹配步骤，使其方法简单且适应性强。

Result: CLAIM在公开的KITTI、Waymo和MIAS-LCEC数据集上进行了验证，实验结果表明其性能优于现有最先进的方法。

Conclusion: CLAIM是一种简单、自适应且性能卓越的相机-激光雷达标定方法，它通过利用单目深度模型、粗到细搜索以及两种新颖且简化的损失函数，实现了优于现有技术的数据对齐效果。

Abstract: In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.

</details>


### [187] [E-Navi: Environmental Adaptive Navigation for UAVs on Resource Constrained Platforms](https://arxiv.org/abs/2512.14046)
*Boyang Li,Zhongpeng Jin,Shuai Zhao,Jiahui Liao,Tian Liu,Han Liu,Yuanhai Zhang,Kai Huang*

Main category: cs.RO

TL;DR: 本文提出E-Navi，一种环境自适应的无人机导航系统，它根据环境复杂度和可用计算资源，动态调整感知-规划任务的执行配置（如地图分辨率和执行频率），以提高导航性能、减少计算负荷并实现更稳定的飞行。


<details>
  <summary>Details</summary>
Motivation: 现有无人机导航系统采用固定的执行配置，不考虑环境动态性和计算资源，导致飞行策略僵化、计算量过大，从而降低飞行性能甚至导致故障。尽管需要自适应系统，但量化环境复杂度和建模环境与系统配置之间的关系仍然具有挑战性。

Method: E-Navi系统通过量化环境复杂性评估，动态调整无人机导航系统中感知-规划流水线的地图分辨率和执行频率，以响应环境变化并利用可用计算资源。此外，E-Navi支持在不同计算能力的硬件平台上灵活部署。

Result: 大量的硬件在环和真实世界实验表明，E-Navi系统在各种硬件平台上均显著优于基线方法，实现了高达53.9%的导航任务工作负载减少，高达63.8%的飞行时间节省，并提供了更稳定的速度控制。

Conclusion: E-Navi成功地解决了无人机在动态环境中自适应导航的挑战，通过动态调整任务执行配置，显著提升了无人机的导航性能、计算效率和飞行稳定性，证明了其在实际应用中的优越性。

Abstract: The ability to adapt to changing environments is crucial for the autonomous navigation systems of Unmanned Aerial Vehicles (UAVs). However, existing navigation systems adopt fixed execution configurations without considering environmental dynamics based on available computing resources, e.g., with a high execution frequency and task workload. This static approach causes rigid flight strategies and excessive computations, ultimately degrading flight performance or even leading to failures in UAVs. Despite the necessity for an adaptive system, dynamically adjusting workloads remains challenging, due to difficulties in quantifying environmental complexity and modeling the relationship between environment and system configuration. Aiming at adapting to dynamic environments, this paper proposes E-Navi, an environmental-adaptive navigation system for UAVs that dynamically adjusts task executions on the CPUs in response to environmental changes based on available computational resources. Specifically, the perception-planning pipeline of UAVs navigation system is redesigned through dynamic adaptation of mapping resolution and execution frequency, driven by the quantitative environmental complexity evaluations. In addition, E-Navi supports flexible deployment across hardware platforms with varying levels of computing capability. Extensive Hardware-In-the-Loop and real-world experiments demonstrate that the proposed system significantly outperforms the baseline method across various hardware platforms, achieving up to 53.9% navigation task workload reduction, up to 63.8% flight time savings, and delivering more stable velocity control.

</details>


### [188] [Expert Switching for Robust AAV Landing: A Dual-Detector Framework in Simulation](https://arxiv.org/abs/2512.14054)
*Humaira Tasnim,Ashik E Rasul,Bruce Jo,Hyung-Jin Yoon*

Main category: cs.RO

TL;DR: 为解决自主飞行器（AAV）在下降过程中直升机停机坪检测面临的极端尺度变化问题，本文提出了一种尺度自适应双专家感知框架。该框架使用两个YOLOv8专家模型分别处理远距离和近距离检测，并通过几何门控机制选择最佳预测，显著提高了着陆稳定性、精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GPS受限或视觉退化条件下，自主飞行器（AAV）着陆时需要可靠的直升机停机坪检测。现代检测器（如YOLOv8）在单一模型下难以应对下降过程中极端的尺度变化——停机坪在高空时很小，靠近着陆点时很大，导致鲁棒性不足。

Method: 本文提出一个尺度自适应双专家感知框架，将检测任务分解为远距离和近距离两种模式。训练了两个YOLOv8专家模型，分别针对HelipadCat数据集的尺度专用版本进行优化，一个擅长检测小尺寸、低分辨率停机坪，另一个提供高精度定位。推理时，两个专家并行运行，通过一个几何门控机制根据AAV的视角选择最一致的预测。该模块在集成CARLA渲染和NASA GUAM飞行动力学引擎的闭环着陆环境中进行评估。

Result: 与单一检测器基线相比，该双专家感知模块在对准稳定性、着陆精度和整体鲁棒性方面均显示出显著改进，有效避免了单一检测器系统在宽广高度范围内操作时常见的性能下降。

Conclusion: 通过引入针对着陆问题量身定制的尺度感知专家路由策略，本工作提升了自主下降中基于视觉的感知弹性，并为未来多专家AAV框架奠定了基础。

Abstract: Reliable helipad detection is essential for Autonomous Aerial Vehicle (AAV) landing, especially under GPS-denied or visually degraded conditions. While modern detectors such as YOLOv8 offer strong baseline performance, single-model pipelines struggle to remain robust across the extreme scale transitions that occur during descent, where helipads appear small at high altitude and large near touchdown. To address this limitation, we propose a scale-adaptive dual-expert perception framework that decomposes the detection task into far-range and close-range regimes. Two YOLOv8 experts are trained on scale-specialized versions of the HelipadCat dataset, enabling one model to excel at detecting small, low-resolution helipads and the other to provide high-precision localization when the target dominates the field of view. During inference, both experts operate in parallel, and a geometric gating mechanism selects the expert whose prediction is most consistent with the AAV's viewpoint. This adaptive routing prevents the degradation commonly observed in single-detector systems when operating across wide altitude ranges. The dual-expert perception module is evaluated in a closed-loop landing environment that integrates CARLA's photorealistic rendering with NASA's GUAM flight-dynamics engine. Results show substantial improvements in alignment stability, landing accuracy, and overall robustness compared to single-detector baselines. By introducing a scale-aware expert routing strategy tailored to the landing problem, this work advances resilient vision-based perception for autonomous descent and provides a foundation for future multi-expert AAV frameworks.

</details>


### [189] [Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model](https://arxiv.org/abs/2512.14031)
*Zhaofeng Hu,Hongrui Yu,Vaidhyanathan Chandramouli,Ci-Jyun Liang*

Main category: cs.RO

TL;DR: 本研究评估了两种主流的机器人技能教学方法——视觉-语言-动作 (VLA) 模型和强化学习 (RL) 方法，以了解它们在建筑自动化中的适用性。结果表明，VLA 在泛化能力、少样本学习和减少编程工作方面具有优势，而 RL（DQN）在充分调优的情况下也是可行的基线。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估 VLA 模型和强化学习方法在教授建筑机器人新技能方面的适用性，并理解它们在实际任务中的性能和部署所需的实际工作量，以推动建筑自动化发展。

Method: 研究开发了两种遥操作界面来控制机器人并收集演示数据。评估分为三个阶段：1) 比较多层感知器 (MLP) 策略与深度 Q 网络 (DQN) 模仿模型，以确定更强的 RL 基线，重点关注模型性能、泛化能力和抓取实验。2) 训练和比较三种不同的 VLA 模型在两种场景下的表现。3) 将选定的 RL 基线与 VLA 模型进行基准测试，衡量计算和样本效率，并通过多阶段面板安装机器人实验进行验证。

Result: VLA 模型展现出强大的泛化能力和少样本学习能力，在抓取阶段取得了 60% 和 100% 的成功率。相比之下，DQN 可以变得鲁棒，但需要额外的噪声进行调优，这增加了工作量。总体而言，VLA 通过减少编程工作量和在少量数据下实现有效性能，为任务变更提供了实际优势。

Conclusion: 研究结果表明，VLA 模型在处理多变任务时具有实际优势，因为它能减少编程工作并以最少的数据实现有效性能。而当充足的调优工作量可以接受时，DQN 也能提供一个可行的基线方案。

Abstract: This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.

</details>


### [190] [Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field](https://arxiv.org/abs/2512.14111)
*Chenzui Li,Yiming Chen,Xi Wu,Tao Teng,Sylvain Calinon,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: 本文提出配置空间人体工程学场 (CSEF)，用于工业人机协作中的实时、符合人体工程学的运动规划。CSEF通过提供梯度实现无碰撞、响应式且符合人体工程学的安全规划，并在基准测试和硬件实验中显示出优越的性能，显著降低了人体工程学成本和肌肉激活。


<details>
  <summary>Details</summary>
Motivation: 工业人机协作需要无碰撞、响应迅速且符合人体工程学安全的运动规划，以减少疲劳和肌肉骨骼损伤风险。

Method: 提出配置空间人体工程学场 (CSEF)，这是一个在人体关节空间上连续可微的场，用于量化人体工程学质量并提供实时人体工程学感知规划的梯度。该方法通过高效算法从既定指标构建CSEF，并结合关节加权和任务条件，将其集成到兼容阻抗控制机器人的基于梯度的规划器中。

Result: 在2自由度基准测试中，基于CSEF的规划器比任务空间人体工程学规划器具有更高的成功率、更低的人体工程学成本和更快的计算速度。在双臂机器人的硬件实验中（单臂引导、协作钻孔、双手共搬运），CSEF显示出比点对点基线更快的人体工程学成本降低、更接近优化的关节目标跟踪和更低的肌肉激活。协作钻孔任务的人体工程学分数平均降低高达10.31%，双手共搬运任务降低5.60%，同时关键肌肉群的激活减少。

Conclusion: 基于CSEF的规划方法通过显著降低人体工程学分数和肌肉激活，为实际部署中的人机协作提供了实际益处。

Abstract: Industrial human-robot collaboration requires motion planning that is collision-free, responsive, and ergonomically safe to reduce fatigue and musculoskeletal risk. We propose the Configuration Space Ergonomic Field (CSEF), a continuous and differentiable field over the human joint space that quantifies ergonomic quality and provides gradients for real-time ergonomics-aware planning. An efficient algorithm constructs CSEF from established metrics with joint-wise weighting and task conditioning, and we integrate it into a gradient-based planner compatible with impedance-controlled robots. In a 2-DoF benchmark, CSEF-based planning achieves higher success rates, lower ergonomic cost, and faster computation than a task-space ergonomic planner. Hardware experiments with a dual-arm robot in unimanual guidance, collaborative drilling, and bimanual cocarrying show faster ergonomic cost reduction, closer tracking to optimized joint targets, and lower muscle activation than a point-to-point baseline. CSEF-based planning method reduces average ergonomic scores by up to 10.31% for collaborative drilling tasks and 5.60% for bimanual co-carrying tasks while decreasing activation in key muscle groups, indicating practical benefits for real-world deployment.

</details>


### [191] [Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning](https://arxiv.org/abs/2512.14057)
*Amir M. Soufi Enayati,Homayoun Honari,Homayoun Najjaran*

Main category: cs.RO

TL;DR: 本文提出CRAFT模型，通过仅基于状态和奖励序列推断任务表示，解耦任务推断与策略优化，从而在机器人控制中实现更快的适应、更好的泛化和更有效的探索。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习在未知任务上泛化能力差。现有的上下文自适应元强化学习方法依赖完整的动作信息进行任务推断，导致任务推断与特定策略紧密耦合。

Method: CRAFT（Context Representation via Action Free Transformer encoder decoder）是一个信念模型，它仅从状态和奖励序列推断任务表示，从而去除了对动作的依赖。该模型利用摊销变分推断进行信念更新，并基于带有旋转位置嵌入的Transformer编解码器来捕捉长期时间依赖性和编码任务变异性。

Result: 在MetaWorld ML-10机器人操作基准测试中，CRAFT与现有基线相比，实现了更快的适应、改进的泛化能力和更有效的探索。

Conclusion: 研究结果表明，无动作推断（如CRAFT）作为可扩展机器人控制强化学习的基础具有巨大潜力。

Abstract: Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.

</details>


### [192] [SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry](https://arxiv.org/abs/2512.14189)
*Johannes A. Gaus,Daniel Häufle,Woo-Jeong Baek*

Main category: cs.RO

TL;DR: 本文提出了SUPER框架，一个通用且可解释的实时风险评估系统，用于VIO和SLAM，通过敏感度传播不确定性以预测轨迹退化并触发干预措施。


<details>
  <summary>Details</summary>
Motivation: 尽管许多VO、VIO和SLAM系统精度很高，但大多数现有方法未能评估运行时风险，导致系统在性能下降时无法及时预警或采取措施。

Method: SUPER框架通过利用高斯-牛顿法正规矩阵的舒尔补块来传播不确定性，推导出一个实时、与后端无关的风险指标。它基于残差大小、几何条件和短期时间趋势来估计风险，无需地面真值。舒尔补捕捉了不确定性对风险发生影响的敏感度。

Result: SUPER能够可靠地提前50帧预测轨迹退化，比基线提高了20%。它以89.1%的召回率启动停止或重定位策略。该框架与后端无关，实时运行，CPU开销增加不到0.2%。实验表明SUPER提供了一致的不确定性估计，并适用于长距离建图。

Conclusion: SUPER提供了一个通用、可解释且高效的框架，用于VIO中的实时性能和风险评估，显著提高了轨迹退化预测能力和决策制定（如停止或重定位），且具有极低的计算开销。

Abstract: While many visual odometry (VO), visual-inertial odometry (VIO), and SLAM systems achieve high accuracy, the majority of existing methods miss to assess risks at runtime. This paper presents SUPER (Sensitivity-based Uncertainty-aware PErformance and Risk assessment) that is a generic and explainable framework that propagates uncertainties via sensitivities for real-time risk assessment in VIO. The scientific novelty lies in the derivation of a real-time risk indicator that is backend-agnostic and exploits the Schur complement blocks of the Gauss-Newton normal matrix to propagate uncertainties. Practically, the Schur complement captures the sensitivity that reflects the influence of the uncertainty on the risk occurrence. Our framework estimates risks on the basis of the residual magnitudes, geometric conditioning, and short horizon temporal trends without requiring ground truth knowledge. Our framework enables to reliably predict trajectory degradation 50 frames ahead with an improvement of 20% to the baseline. In addition, SUPER initiates a stop or relocalization policy with 89.1% recall. The framework is backend agnostic and operates in real time with less than 0.2% additional CPU cost. Experiments show that SUPER provides consistent uncertainty estimates. A SLAM evaluation highlights the applicability to long horizon mapping.

</details>


### [193] [CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics](https://arxiv.org/abs/2512.14270)
*Zixin Tang,Yiming Chen,Quentin Rouxel,Dianxi Li,Shuang Wu,Fei Chen*

Main category: cs.RO

TL;DR: 本文提出CaFe-TeleVision，一个粗到精的遥操作系统，结合沉浸式情境可视化，显著提升了遥操作的效率和人体工程学，尤其在复杂任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前的遥操作系统在效率和人体工程学方面存在局限性，尤其是在挑战性场景下表现不佳，这促使研究人员寻求更优的解决方案。

Method: CaFe-TeleVision系统核心包含：1) 在重定向模块中采用粗到精的控制机制，以弥合工作空间差异，优化效率和物理人体工程学；2) 在感知模块中集成按需情境可视化技术，提供沉浸式反馈和充足视觉线索，降低多视角处理的认知负荷。该系统基于人形协作机器人构建，并用六个具有挑战性的双手操作任务进行验证。

Result: 用户研究（24名参与者）证实CaFe-TeleVision显著增强了人体工程学，降低了任务负荷，提高了用户接受度。定量结果显示，在六项任务中，系统性能优于对比方法，成功率提高了28.89%，完成时间加快了26.81%。

Conclusion: CaFe-TeleVision通过其创新的粗到精控制和沉浸式情境可视化技术，有效解决了现有遥操作系统的局限性，显著提升了遥操作的人体工程学和整体性能。

Abstract: Teleoperation presents a promising paradigm for remote control and robot proprioceptive data collection. Despite recent progress, current teleoperation systems still suffer from limitations in efficiency and ergonomics, particularly in challenging scenarios. In this paper, we propose CaFe-TeleVision, a coarse-to-fine teleoperation system with immersive situated visualization for enhanced ergonomics. At its core, a coarse-to-fine control mechanism is proposed in the retargeting module to bridge workspace disparities, jointly optimizing efficiency and physical ergonomics. To stream immersive feedback with adequate visual cues for human vision systems, an on-demand situated visualization technique is integrated in the perception module, which reduces the cognitive load for multi-view processing. The system is built on a humanoid collaborative robot and validated with six challenging bimanual manipulation tasks. User study among 24 participants confirms that CaFe-TeleVision enhances ergonomics with statistical significance, indicating a lower task load and a higher user acceptance during teleoperation. Quantitative results also validate the superior performance of our system across six tasks, surpassing comparative methods by up to 28.89% in success rate and accelerating by 26.81% in completion time. Project webpage: https://clover-cuhk.github.io/cafe_television/

</details>


### [194] [ARCADE: Adaptive Robot Control with Online Changepoint-Aware Bayesian Dynamics Learning](https://arxiv.org/abs/2512.14331)
*Rishabh Dev Yadav,Avirup Das,Hongyu Song,Samuel Kaski,Wei Pan*

Main category: cs.RO

TL;DR: 本文提出一个实时自适应框架，通过离线学习的潜在表示和在线贝叶斯更新来建模机器人非线性动力学。该框架具有变点感知机制，能区分连续性或突变，实现对不断变化的机器人动力学的高效适应，并具有理论上的自适应遗憾保证和实际应用中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人必须在不断变化的动力学条件下运行，这些变化可能由操作条件改变、外部干扰或未建模效应引起，表现为缓慢漂移、瞬态波动或突然转变。这要求机器人系统具备实时适应能力，既要对短期变化具有鲁棒性，又要对持久性变化做出快速响应。

Method: 该方法将表示学习与在线适应解耦，离线学习潜在表示以支持在线闭式贝叶斯更新。为处理不断变化的条件，引入了一种变点感知机制，通过从数据似然推断的潜在变量来指示连续性或转变。当可能连续时，证据会累积以改进预测；当检测到转变时，过去的信息会被淡化以实现快速重新学习。这保持了校准的不确定性，并支持对瞬态、渐进或结构性变化的概率推理。

Result: 该框架的自适应遗憾（regret）随时间呈对数增长，并随转变次数呈线性增长，与知道转变时机的预言者（oracle）相当。在倒立摆模拟和带有摆动载荷及空中掉落的真实四旋翼飞行中进行了验证，结果显示，与相关基线相比，预测精度更高，恢复速度更快，闭环跟踪更准确。

Conclusion: 所提出的框架为机器人系统在不断变化的动力学条件下提供了鲁棒的实时适应能力。通过解耦表示学习和在线适应，并结合变点感知机制，该方法在理论上具有竞争性的自适应遗憾保证，并在模拟和真实机器人实验中展现出卓越的预测、恢复和跟踪性能。

Abstract: Real-world robots must operate under evolving dynamics caused by changing operating conditions, external disturbances, and unmodeled effects. These may appear as gradual drifts, transient fluctuations, or abrupt shifts, demanding real-time adaptation that is robust to short-term variation yet responsive to lasting change. We propose a framework for modeling the nonlinear dynamics of robotic systems that can be updated in real time from streaming data. The method decouples representation learning from online adaptation, using latent representations learned offline to support online closed-form Bayesian updates. To handle evolving conditions, we introduce a changepoint-aware mechanism with a latent variable inferred from data likelihoods that indicates continuity or shift. When continuity is likely, evidence accumulates to refine predictions; when a shift is detected, past information is tempered to enable rapid re-learning. This maintains calibrated uncertainty and supports probabilistic reasoning about transient, gradual, or structural change. We prove that the adaptive regret of the framework grows only logarithmically in time and linearly with the number of shifts, competitive with an oracle that knows timings of shift. We validate on cartpole simulations and real quadrotor flights with swinging payloads and mid-flight drops, showing improved predictive accuracy, faster recovery, and more accurate closed-loop tracking than relevant baselines.

</details>


### [195] [Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments](https://arxiv.org/abs/2512.14206)
*Mayank Sewlia,Christos K. Verginis,Dimos V. Dimarogonas*

Main category: cs.RO

TL;DR: 本文提出了一种多速率规划与控制框架，用于移动多机械臂系统在复杂受限环境中协同操作，以满足时空任务规范，实现抓取物体运输。该框架结合离线轨迹生成与在线逆运动学和反馈控制，并在高保真模拟中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决移动多机械臂系统在障碍物密集和高度受限环境中进行协同操作的挑战，特别是在满足时空任务规范、连续机器人动力学和离散几何约束（如障碍物和狭窄通道）的混合结构问题。

Method: 本文提出了一种多速率规划与控制框架。该框架结合了：1) 离线生成满足STL规范的物体轨迹和无碰撞的基座足迹；2) 在线受限逆运动学和连续时间反馈控制。由此形成的闭环系统能够实现多个机械臂的协调重构，同时跟踪期望的物体运动。

Result: 所提出的闭环系统能够实现多个机械臂的协调重构，同时有效跟踪所需的物体运动。该方法在包含三个Frank Emika Panda移动机械臂刚性抓取物体的高保真物理模拟中得到了评估和验证。

Conclusion: 该多速率规划与控制框架成功解决了在复杂受限环境中移动多机械臂系统的协同操作问题，实现了对抓取物体的有效运输，并确保了机器人动力学和几何约束的遵守，展现了在混合结构任务下的有效性。

Abstract: We consider the problem of cooperative manipulation by a mobile multi-manipulator system operating in obstacle-cluttered and highly constrained environments under spatio-temporal task specifications. The task requires transporting a grasped object while respecting both continuous robot dynamics and discrete geometric constraints arising from obstacles and narrow passages. To address this hybrid structure, we propose a multi-rate planning and control framework that combines offline generation of an STL-satisfying object trajectory and collision-free base footprints with online constrained inverse kinematics and continuous-time feedback control. The resulting closed-loop system enables coordinated reconfiguration of multiple manipulators while tracking the desired object motion. The approach is evaluated in high-fidelity physics simulations using three Franka Emika Panda mobile manipulators rigidly grasping an object.

</details>


### [196] [Field evaluation and optimization of a lightweight lidar-based UAV navigation system for dense boreal forest environments](https://arxiv.org/abs/2512.14340)
*Aleksi Karhunen,Teemu Hakala,Väinö Karjalainen,Eija Honkavaara*

Main category: cs.RO

TL;DR: 本研究开发并测试了一种基于轻型激光雷达的自主飞行四旋翼无人机，用于林下导航，并提出了一套标准化的测试和评估方法，以提高该领域研究的严谨性和可比性。


<details>
  <summary>Details</summary>
Motivation: 林下导航对于无人机来说是一个重大挑战，而现有的研究在实验设计和结果报告上缺乏严谨性，很少报告测试森林的密度、难度、多次飞行的成功率等，这阻碍了该领域的发展。

Method: 研究人员实现了一个基于轻型激光雷达的自主飞行四旋翼无人机原型，采用了IPC路径规划器和LTA-OM SLAM算法。通过33次初步飞行后对系统进行了优化，并在此基础上进行了60次飞行测试，总计93次飞行。此外，还提出了一套标准化的测试设置和评估标准。

Result: 优化后的系统在可靠性和任务完成时间方面表现显著更好。在中等密度森林中，目标飞行速度为1米/秒时成功率为12/15，在密集森林中成功率为15/15。当目标飞行速度为2米/秒时，成功率分别为12/15和5/15。研究还提出了标准化的测试和评估方法，以实现系统性能的一致比较。

Conclusion: 本研究成功实现并优化了基于轻型激光雷达的林下自主飞行无人机系统，并在真实森林环境中进行了严格测试。同时，提出了一套标准化的测试和评估框架，有望提高林业机器人研究的可重复性、指导系统改进并加速该领域的发展。

Abstract: The interest in the usage of uncrewed aerial vehicles (UAVs) for forest applications has increased in recent years. While above-canopy flight has reached a high level of autonomy, navigating under-canopy remains a significant challenge. The use of autonomous UAVs could reduce the burden of data collection, which has motivated the development of numerous solutions for under-canopy autonomous flight. However, the experiments conducted in the literature and their reporting lack rigor. Very rarely, the density and the difficulty of the test forests are reported, or multiple flights are flown, and the success rate of those flights is reported. The aim of this study was to implement an autonomously flying quadrotor based on a lightweight lidar using openly available algorithms and test its behavior in real forest environments. A set of rigorous experiments was conducted with a quadrotor prototype utilizing the IPC path planner and LTA-OM SLAM algorithm. Based on the results of the first 33 flights, the original system was further enhanced. With the optimized system, 60 flights were performed, resulting in a total of 93 test flights. The optimized system performed significantly better in terms of reliability and flight mission completion times, achieving success rates of 12/15 in a medium-density forest and 15/15 in a dense forest, at a target flight velocity of 1 m/s. At a target flight velocity of 2 m/s, it had a success rate of 12/15 and 5/15, respectively. Furthermore, a standardized testing setup and evaluation criteria were proposed, enabling consistent performance comparisons of autonomous under-canopy UAV systems, enhancing reproducibility, guiding system improvements, and accelerating progress in forest robotics.

</details>


### [197] [Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization](https://arxiv.org/abs/2512.14350)
*Henrik Hose,Paul Brunzema,Alexander von Rohr,Alexander Gräfe,Angela P. Schoellig,Sebastian Trimpe*

Main category: cs.RO

TL;DR: 本文提出使用贝叶斯优化，通过实验数据自动且高效地调整近似模型预测控制（AMPC）策略参数，从而在硬件上实现卓越性能，解决了传统AMPC在MPC参数调整时需要重复训练的问题。


<details>
  <summary>Details</summary>
Motivation: 近似模型预测控制（AMPC）在部署时，底层MPC参数通常需要微调，这导致需要反复生成新数据集并重新训练神经网络，使其不切实际。现有无需重新训练的AMPC自适应方法需要手动调整，对于高维系统而言费时且不直观。

Method: 本文提出使用贝叶斯优化（Bayesian optimization）基于实验数据来调整AMPC策略的参数。该方法结合了基于模型的控制与直接的局部学习。

Result: 与标称AMPC相比，该方法在硬件上以最少的实验实现了卓越的性能。它允许AMPC自动且数据高效地适应新的系统实例，并对难以直接在MPC中实现的成本函数进行微调。该方法在倒立摆的摆动控制和欠驱动平衡独轮车机器人的偏航控制硬件实验中得到了验证。

Conclusion: 通过结合贝叶斯优化、模型基控制和局部学习，该方法实现了AMPC策略的自动、数据高效适应，显著提升了在硬件上的性能，解决了AMPC在实际应用中参数微调的挑战，使其更加实用。

Abstract: Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.

</details>


### [198] [CoLD Fusion: A Real-time Capable Spline-based Fusion Algorithm for Collective Lane Detection](https://arxiv.org/abs/2512.14355)
*Jörg Gamerdinger,Sven Teufel,Georg Volk,Oliver Bringmann*

Main category: cs.RO

TL;DR: 本文提出了一种基于车对车通信和样条曲线估计的车道协同感知方法，旨在实时扩展自动驾驶车辆在传感器受限或无高清地图情况下的车道感知范围。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要全面的环境感知（包括动态和静态物体，如车道），但现有传感器受限于范围、遮挡和弯道，导致感知不完整。在无法精确本地化或没有高清地图的情况下，车辆必须完全依赖感知信息。因此，通过车对车通信进行协同感知以扩展局部感知能力，尤其是在车道检测方面，是一个尚未充分探索但很有前景的策略。

Method: 提出了一种实时的车道协同感知方法，该方法利用车对车（V2V）通信，并通过基于样条曲线的估计来预测未被检测到的路段。

Result: 所提出的融合算法在各种情况和路况下均能实现实时性能，并将感知范围扩展了高达200%。

Conclusion: 通过车对车通信结合样条曲线估计的协同感知方法，能够有效扩展自动驾驶车辆的车道感知范围，克服了传统感知限制，并具有实时性。

Abstract: Comprehensive environment perception is essential for autonomous vehicles to operate safely. It is crucial to detect both dynamic road users and static objects like traffic signs or lanes as these are required for safe motion planning. However, in many circumstances a complete perception of other objects or lanes is not achievable due to limited sensor ranges, occlusions, and curves. In scenarios where an accurate localization is not possible or for roads where no HD maps are available, an autonomous vehicle must rely solely on its perceived road information. Thus, extending local sensing capabilities through collective perception using vehicle-to-vehicle communication is a promising strategy that has not yet been explored for lane detection. Therefore, we propose a real-time capable approach for collective perception of lanes using a spline-based estimation of undetected road sections. We evaluate our proposed fusion algorithm in various situations and road types. We were able to achieve real-time capability and extend the perception range by up to 200%.

</details>


### [199] [A Comprehensive Safety Metric to Evaluate Perception in Autonomous Systems](https://arxiv.org/abs/2512.14367)
*Georg Volk,Jörg Gamerdinger,Alexander von Bernuth,Oliver Bringmann*

Main category: cs.RO

TL;DR: 本文提出了一种新的自动驾驶物体感知安全评估指标，该指标综合考虑了物体的速度、方向、距离、大小及潜在碰撞损害，以提供更全面的安全评估。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要准确感知环境并正确解释，其中物体感知是关键。现有物体感知评估指标未能充分考虑物体重要性的差异（例如，基于速度、方向、距离、大小或潜在碰撞损害），而这些因素对安全评估至关重要。

Method: 本文提出了一种新的安全指标，该指标将物体的速度、方向、距离、大小以及潜在碰撞损害等所有参数纳入考量，并输出一个单一且易于解释的物体感知安全评估分数。

Result: 该新指标已使用真实世界和虚拟数据集进行了评估，并与现有最先进的指标进行了比较。

Conclusion: 本文成功提出并评估了一种新的物体感知安全指标，该指标通过整合多个关键参数，为自动驾驶车辆提供了更全面、更具解释性的安全评估方法。

Abstract: Complete perception of the environment and its correct interpretation is crucial for autonomous vehicles. Object perception is the main component of automotive surround sensing. Various metrics already exist for the evaluation of object perception. However, objects can be of different importance depending on their velocity, orientation, distance, size, or the potential damage that could be caused by a collision due to a missed detection. Thus, these additional parameters have to be considered for safety evaluation. We propose a new safety metric that incorporates all these parameters and returns a single easily interpretable safety assessment score for object perception. This new metric is evaluated with both real world and virtual data sets and compared to state of the art metrics.

</details>


### [200] [Synthetic Data Pipelines for Adaptive, Mission-Ready Militarized Humanoids](https://arxiv.org/abs/2512.14411)
*Mohammed Ayman Habib,Aldo Petruzzelli*

Main category: cs.RO

TL;DR: Omnia是一个合成数据驱动的管道，旨在加速军事化类人机器人的训练、验证和部署，通过将真实世界的第一人称空间观测转换为可扩展的合成数据集，从而实现快速迭代和高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了加速军事化类人机器人的训练、验证和部署，同时避免传统广泛实地试验所带来的高成本、高风险和时间限制。

Method: 该方法将从第一人称视角记录（如POV录像、智能眼镜、增强现实头显等）捕获的空间观测转换为可扩展、任务特定的合成数据集。通过生成大量高保真模拟场景，并结合自动化标签和模型训练，该管道能够快速迭代类人机器人的感知、导航和决策能力。

Result: 生成的合成数据集可以快速调整以适应新的操作环境和威胁条件，从而支持类人机器人的基线性能以及多模态传感、反探测生存能力和CBRNE相关侦察行为等高级子系统。这使得类人系统在开发早期就能接触到广泛的场景多样性。

Conclusion: 该工作旨在通过在开发过程早期让类人系统接触广泛的场景多样性，从而实现更快的开发周期，并在复杂、有争议的环境中提高类人系统的鲁棒性。

Abstract: Omnia presents a synthetic data driven pipeline to accelerate the training, validation, and deployment readiness of militarized humanoids. The approach converts first-person spatial observations captured from point-of-view recordings, smart glasses, augmented reality headsets, and spatial browsing workflows into scalable, mission-specific synthetic datasets for humanoid autonomy. By generating large volumes of high-fidelity simulated scenarios and pairing them with automated labeling and model training, the pipeline enables rapid iteration on perception, navigation, and decision-making capabilities without the cost, risk, or time constraints of extensive field trials. The resulting datasets can be tuned quickly for new operational environments and threat conditions, supporting both baseline humanoid performance and advanced subsystems such as multimodal sensing, counter-detection survivability, and CBRNE-relevant reconnaissance behaviors. This work targets faster development cycles and improved robustness in complex, contested settings by exposing humanoid systems to broad scenario diversity early in the development process.

</details>


### [201] [Geometric Parameter Optimization of a Novel 3-(PP(2-(UPS))) Redundant Parallel Mechanism based on Workspace Determination](https://arxiv.org/abs/2512.14434)
*Quan Yuan,Daqian Cao,Weibang Bai*

Main category: cs.RO

TL;DR: 本文提出了一种新型冗余并联机器人3-(PP(2-(UPS)))，并研究了其关键几何参数对工作空间特性（体积、形状、边界完整性）和姿态能力（扭转和倾斜能力指数）的影响，通过数值模拟为参数优化提供了参考。


<details>
  <summary>Details</summary>
Motivation: 冗余并联机器人通常用于需要高精度、高负载和大工作空间的场景，但其基本构型和几何参数优化仍然具有挑战性。

Method: 提出了一种新型3-(PP(2-(UPS)))冗余并联机构，并通过分析关键几何参数如何影响工作空间的体积、形状、边界完整性和姿态能力来研究运动学优化问题。定义了扭转能力指数TI_1和倾斜能力指数TI_2来评估机构的姿态性能。通过数值模拟研究来验证分析。

Result: 数值模拟研究表明，所提出的分析是有效的，为3-(PP(2-(UPS)))及其他类似冗余并联机构的参数优化提供了合理且必要的参考。

Conclusion: 该研究为3-(PP(2-(UPS)))及其他类似冗余并联机构的参数优化提供了关键的分析和参考，有助于解决其构型和优化难题。

Abstract: Redundant parallel robots are normally employed in scenarios requiring good precision, high load capability, and large workspace compared to traditional parallel mechanisms. However, the elementary robotic configuration and geometric parameter optimization are still quite challenging. This paper proposes a novel 3-(PP(2-(UPS))) redundant parallel mechanism, with good generalizability first, and further investigates the kinematic optimization issue by analyzing and investigating how its key geometric parameters influence the volume, shape, boundary completeness, and orientation capabilities of its workspace. The torsional capability index TI_1 and tilting capability index TI_2 are defined to evaluate the orientation performance of the mechanism. Numerical simulation studies are completed to indicate the analysis, providing reasonable but essential references for the parameter optimization of 3-(PP(2-(UPS))) and other similar redundant parallel mechanisms.

</details>


### [202] [Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations](https://arxiv.org/abs/2512.14428)
*Aaron Kurda,Simon Steuernagel,Lukas Jung,Marcus Baum*

Main category: cs.RO

TL;DR: 本文提出了Odyssey数据集，一个专注于GNSS拒绝环境（如隧道、停车场）及其他复杂场景的Lidar-Inertial Odometry (LIO) 数据集。其地面真值由配备环形激光陀螺仪（RLG）的导航级惯性导航系统（INS）提供，具有卓越的偏置稳定性，是首个公开的RLG-based INS数据集。


<details>
  <summary>Details</summary>
Motivation: Lidar-Inertial Odometry (LIO) 和 Simultaneous Localization and Mapping (SLAM) 系统的开发和评估需要精确的地面真值。全球导航卫星系统（GNSS）在受阻环境中（如多径效应或信号丢失）不可靠。现有数据集中的惯性测量单元（IMU）通常基于MEMS或FOG，无法支持对GNSS拒绝环境的长时间研究，且缺乏对特定挑战性场景（如走走停停的交通、颠簸路段）的覆盖。

Method: 研究人员创建了Odyssey数据集。其核心方法是使用配备环形激光陀螺仪（RLG）的导航级惯性导航系统（INS）来生成地面真值，RLG相比现有数据集中使用的IMU具有出色的偏置稳定性，能够长时间准确地研究GNSS拒绝环境。数据集包含了隧道、停车场、走走停停的交通、颠簸路段和开阔地带等场景。所有轨迹都进行了三次重复，并提供了精确的大地坐标，以支持地点识别等任务。

Result: 研究成果是Odyssey数据集的发布，它是第一个公开可用、采用RLG-based INS提供地面真值的LIO数据集。该数据集专门针对GNSS拒绝环境和其他代表性不足但普遍存在的复杂场景。它不仅支持LIO任务，还通过重复轨迹和提供地理坐标来支持地点识别等任务。

Conclusion: Odyssey数据集通过提供由RLG-based INS生成的、具有卓越精度和持续时间的地面真值，填补了现有LIO/SLAM数据集在GNSS拒绝环境和挑战性场景方面的空白。这使得研究人员能够更准确、更长时间地开发和评估LIO/SLAM系统在这些复杂条件下的性能。

Abstract: The development and evaluation of Lidar-Inertial Odometry (LIO) and Simultaneous Localization and Mapping (SLAM) systems requires a precise ground truth. The Global Navigation Satellite System (GNSS) is often used as a foundation for this, but its signals can be unreliable in obstructed environments due to multi-path effects or loss-of-signal. While existing datasets compensate for the sporadic loss of GNSS signals by incorporating Inertial Measurement Unit (IMU) measurements, the commonly used Micro-Electro-Mechanical Systems (MEMS) or Fiber Optic Gyroscope (FOG)-based systems do not permit the prolonged study of GNSS-denied environments. To close this gap, we present Odyssey, a LIO dataset with a focus on GNSS-denied environments such as tunnels and parking garages as well as other underrepresented, yet ubiquitous situations such as stop-and-go-traffic, bumpy roads and wide open fields. Our ground truth is derived from a navigation-grade Inertial Navigation System (INS) equipped with a Ring Laser Gyroscope (RLG), offering exceptional bias stability characteristics compared to IMUs used in existing datasets and enabling the prolonged and accurate study of GNSS-denied environments. This makes Odyssey the first publicly available dataset featuring a RLG-based INS. Besides providing data for LIO, we also support other tasks, such as place recognition, through the threefold repetition of all trajectories as well as the integration of external mapping data by providing precise geodetic coordinates. All data, dataloader and other material is available online at https://odyssey.uni-goettingen.de/ .

</details>


### [203] [EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models](https://arxiv.org/abs/2512.14666)
*Zechen Bai,Chen Gao,Mike Zheng Shou*

Main category: cs.RO

TL;DR: EVOLVE-VLA是一个测试时训练框架，使VLA模型能够通过环境交互持续适应，克服了监督微调（SFT）的局限性，通过学习进度估计器和鲁棒的反馈机制，实现了显著的性能提升和新的能力。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉-语言-动作（VLA）模型受限于监督微调（SFT），需要大量演示，死记硬背轨迹，并且在部署条件偏离训练时无法适应。研究旨在使VLA模型能够像人类一样通过环境交互持续学习和改进，而非仅仅模仿静态演示。

Method: EVOLVE-VLA是一个测试时训练框架，使VLA模型能够通过环境交互持续适应，且只需最少或零任务特定演示。核心挑战是替换测试时不可用的预言者奖励信号。本文通过一个学习到的进度估计器提供密集反馈来解决此问题，并通过两种机制来“驯服”这种固有的噪声信号：(1) 累积进度估计机制平滑噪声点状估计；(2) 渐进式视野扩展策略实现策略的逐步演化。

Result: EVOLVE-VLA取得了显著的性能提升：在长周期任务上提高了8.6%，在单次学习中提高了22.0%，并实现了跨任务泛化——在没有任务特定演示训练的情况下，在未见任务上取得了20.8%的成功率（而纯SFT为0%）。定性分析揭示了演示中不存在的紧急能力，包括错误恢复和新颖策略。

Conclusion: 这项工作代表了VLA模型迈向真正学习和适应的关键一步，超越了静态模仿，实现了持续的自我改进。

Abstract: Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\% on long-horizon tasks, +22.0\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\% success on unseen tasks without task-specific demonstrations training (vs. 0\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.

</details>


### [204] [CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation](https://arxiv.org/abs/2512.14689)
*Sirui Chen,Zi-ang Cao,Zhengyi Luo,Fernando Castañeda,Chenran Li,Tingwu Wang,Ye Yuan,Linxi "Jim" Fan,C. Karen Liu,Yuke Zhu*

Main category: cs.RO

TL;DR: 本文提出CHIP模块，使人形机器人能在保持敏捷运动追踪的同时，实现末端执行器可控的柔顺性，从而执行多种需要施力的操作任务。


<details>
  <summary>Details</summary>
Motivation: 尽管人形机器人在敏捷运动方面取得了进展，但在需要施力的操作任务（如搬运、擦拭、推车）方面仍面临挑战。

Method: 本文提出自适应柔顺人形机器人控制模块（CHIP），这是一个即插即用的模块，能在保持对动态参考运动敏捷追踪的同时，实现末端执行器可控的刚度。CHIP易于实现，无需数据增强或额外的奖励调优。

Result: 经过CHIP训练的通用运动追踪控制器能够执行多种需要不同末端执行器柔顺性的施力操作任务，包括多机器人协作、擦拭、箱子递送和开门。

Conclusion: CHIP模块成功地使人形机器人能够有效地执行各种需要施力的操作任务，通过提供自适应的末端执行器柔顺性，同时不牺牲敏捷的运动追踪能力。

Abstract: Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [205] [A Convex Obstacle Avoidance Formulation](https://arxiv.org/abs/2512.13836)
*Ricardo Tapia,Iman Soltani*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的凸障碍物避障公式，通过创新的逻辑整合，首次实现了在凸模型预测控制器（MPC）框架中进行通用障碍物避障，显著提高了计算效率和实时部署能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶在动态环境中需要可靠且高频率的碰撞避免。非线性模型预测控制器（NMPC）虽适用但计算耗时，现有简化方法（如线性化、缩短预测范围或减少时间节点）会牺牲精度或可靠性，无法满足时间关键场景的需求。

Method: 通过一种新颖的逻辑整合方法，作者提出了首个通用的凸障碍物避障公式。这使得该公式能够被整合到凸MPC方案中，从而构建一个计算效率远高于传统非凸方法的凸优化框架。

Result: 该方法相对于传统的非凸方法，计算效率显著提高。其关键特性是即使障碍物位于预测范围之外，避障效果依然有效，从而允许使用更短的预测范围进行实时部署。在非凸公式不可避免的场景中，该方法的性能达到或超过了具有代表性的非凸替代方案。该方法已在高度非线性的自动驾驶应用中进行了评估。

Conclusion: 所提出的凸障碍物避障公式为自动驾驶提供了计算高效且可靠的碰撞避免解决方案，即使在短预测范围下也能保持有效性，解决了传统NMPC在时间关键场景中的挑战。

Abstract: Autonomous driving requires reliable collision avoidance in dynamic environments. Nonlinear Model Predictive Controllers (NMPCs) are suitable for this task, but struggle in time-critical scenarios requiring high frequency. To meet this demand, optimization problems are often simplified via linearization, narrowing the horizon window, or reduced temporal nodes, each compromising accuracy or reliability. This work presents the first general convex obstacle avoidance formulation, enabled by a novel approach to integrating logic. This facilitates the incorporation of an obstacle avoidance formulation into convex MPC schemes, enabling a convex optimization framework with substantially improved computational efficiency relative to conventional nonconvex methods. A key property of the formulation is that obstacle avoidance remains effective even when obstacles lie outside the prediction horizon, allowing shorter horizons for real-time deployment. In scenarios where nonconvex formulations are unavoidable, the proposed method meets or exceeds the performance of representative nonconvex alternatives. The method is evaluated in autonomous vehicle applications, where system dynamics are highly nonlinear.

</details>


### [206] [Delay Optimization in a Simple Offloading System: Extended Version](https://arxiv.org/abs/2512.13810)
*Darin Jeff,Eytan Modiano*

Main category: eess.SY

TL;DR: 该研究旨在优化一个包含本地和云服务器的顺序计算卸载系统中的任务分配和服务模式，并通过资源划分来最小化延迟，并发现了一种与系统负载相关的最优分配策略。


<details>
  <summary>Details</summary>
Motivation: 在任务按序处理的计算卸载系统中，存在本地服务器和更高容量的云服务器。系统提供两种不同的服务模式，其处理方式在服务器之间有所不同。研究的动机是设计一个最优策略，用于将任务分配给服务模式并划分服务器资源，以最小化系统延迟。

Method: 研究首先描述了系统的稳定性区域，并建立了最大化吞吐量的服务模式设计原则。对于任何给定的任务分配策略，推导了最优的资源划分方案，并给出了由此产生的延迟的闭式表达式。此外，研究还确定了延迟最优的分配策略具有独特的“分离”结构。最后，通过数值评估验证了理论洞察。

Result: 研究刻画了系统的稳定性区域，并建立了最大化吞吐量的服务模式设计原则。对于任意任务分配策略，推导出了最优的资源划分方案和相应的延迟闭式表达式。最重要的是，研究发现延迟最优的分配策略呈现出一种独特的“分离”结构：在低系统负载下，所有任务通过单一服务模式路由是最优的；而一旦超过临界负载阈值，任务必须分配到两种模式中。

Conclusion: 通过数值评估，验证了关于顺序卸载系统中任务分配和服务模式以最小化延迟的理论见解，特别是其负载依赖的最优分配策略。

Abstract: We consider a computation offloading system where jobs are processed sequentially at a local server followed by a higher-capacity cloud server. The system offers two service modes, differing in how the processing is split between the servers. Our goal is to design an optimal policy for assigning jobs to service modes and partitioning server resources in order to minimize delay. We begin by characterizing the system's stability region and establishing design principles for service modes that maximize throughput. For any given job assignment strategy, we derive the optimal resource partitioning and present a closed-form expression for the resulting delay. Moreover, we establish that the delay-optimal assignment policy exhibits a distinct breakaway structure: at low system loads, it is optimal to route all jobs through a single service mode, whereas beyond a critical load threshold, jobs must be assigned across both modes. We conclude by validating these theoretical insights through numerical evaluation.

</details>


### [207] [Safe Online Control-Informed Learning](https://arxiv.org/abs/2512.13868)
*Tianyu Zhou,Zihao Liang,Zehui Lu,Shaoshuai Mou*

Main category: eess.SY

TL;DR: 本文提出了一种安全在线控制启发式学习框架，用于安全关键型自主系统，该框架将最优控制、参数估计和安全约束统一到在线学习过程中，并提供收敛性和安全性保证。


<details>
  <summary>Details</summary>
Motivation: 在不确定性下，安全关键型自主系统需要鲁棒、数据高效的适应能力，同时确保安全性，并且不依赖高质量的初始猜测。

Method: 该框架通过以下方式实现：1) 采用扩展卡尔曼滤波器实时增量更新系统参数；2) 使用softplus障碍函数在学习和控制过程中强制满足约束，同时消除对高质量初始猜测的依赖；3) 将最优控制、参数估计和安全约束整合到在线学习过程中。

Result: 理论分析建立了收敛性和安全性保证。该框架在倒立摆和机械臂系统上的有效性得到了验证。

Conclusion: 该框架为安全关键型自主系统提供了一种有效的解决方案，实现了在不确定性下的鲁棒和数据高效适应，并确保了学习和控制过程中的安全性，且无需高质量的初始猜测。

Abstract: This paper proposes a Safe Online Control-Informed Learning framework for safety-critical autonomous systems. The framework unifies optimal control, parameter estimation, and safety constraints into an online learning process. It employs an extended Kalman filter to incrementally update system parameters in real time, enabling robust and data-efficient adaptation under uncertainty. A softplus barrier function enforces constraint satisfaction during learning and control while eliminating the dependence on high-quality initial guesses. Theoretical analysis establishes convergence and safety guarantees, and the framework's effectiveness is demonstrated on cart-pole and robot-arm systems.

</details>


### [208] [A Fair, Flexible, Zero-Waste Digital Electricity Market: A First-Principles Approach Combining Automatic Market Making, Holarchic Architectures and Shapley Theory](https://arxiv.org/abs/2512.13871)
*Shaun Sweeney,Robert Shorten,Mark O'Malley*

Main category: eess.SY

TL;DR: 本论文提出了一种全新的电力市场设计，将其重构为基于电网物理学的事件驱动动态控制系统，并开发了一种分层自动做市商（AMM），以实现更稳健的定价和资源分配。


<details>
  <summary>Details</summary>
Motivation: 现有电力市场设计（如仅能源、容量增强和分区市场）在现实不确定性下无法实现抗冲击的纳什均衡，需依赖价格上限、补贴和监管干预来维持偿付能力和安全性。这促使研究者寻求更根本的设计变革。

Method: 研究开发了一种分层自动做市商（AMM），其中价格是基于物理紧缺度而非市场均衡结果的有限外生控制信号。该AMM通过从节点到区域再到系统的嵌套稀缺层推广了节点和分区定价。它还作为一个稀缺感知控制系统和一个数字可执行的规则手册，用于在短缺时公平访问和按比例分配。燃料成本通过按出价支付的能源调度回收，非燃料运营和资本成本则根据充足性、灵活性和位置贡献进行分配。

Result: 大规模模拟表明，该设计具有有界输入有界输出稳定性、可控的采购成本、零结构性浪费和改进的分配结果。该架构符合气候目标且可配置策略。

Conclusion: 该新的电力市场架构在理论和模拟上表现出优越的鲁棒性、效率和公平性，并与气候目标相符。然而，它的实施需要一个有管理的过渡以及系统运营商和市场参与者的新操作工具。

Abstract: This thesis presents a fundamental rethink of electricity market design at the wholesale and balancing layers. Rather than treating markets as static spot clearing mechanisms, it reframes them as a continuously online, event driven dynamical control system: a two sided marketplace operating directly on grid physics.
  Existing energy only, capacity augmented, and zonal market designs are shown to admit no shock robust Nash equilibrium under realistic uncertainty, instead relying on price caps, uplift, and regulatory intervention to preserve solvency and security. In response, the thesis develops a holarchic Automatic Market Maker (AMM) in which prices are bounded, exogenous control signals derived from physical tightness rather than emergent equilibrium outcomes.
  The AMM generalises nodal and zonal pricing through nested scarcity layers, from node to cluster to zone to region to system, such that participant facing prices inherit from the tightest binding constraint. Nodal and zonal pricing therefore emerge as special cases of a unified scarcity propagation rule.
  Beyond pricing, the AMM functions as a scarcity aware control system and a digitally enforceable rulebook for fair access and proportional allocation under shortage. Fuel costs are recovered through pay as bid energy dispatch consistent with merit order, while non fuel operating and capital costs are allocated according to adequacy, flexibility, and locational contribution.
  Large scale simulations demonstrate bounded input bounded output stability, controllable procurement costs, zero structural waste, and improved distributional outcomes. The architecture is climate aligned and policy configurable, but requires a managed transition and new operational tools for system operators and market participants.

</details>


### [209] [Data-Driven Control via Conditional Mean Embeddings: Formal Guarantees via Uncertain MDP Abstraction](https://arxiv.org/abs/2512.13940)
*Ibon Gracia,Morteza Lahijanian*

Main category: eess.SY

TL;DR: 本文提出一个数据驱动的策略合成框架，利用条件均值嵌入（CME）和不确定马尔可夫决策过程（UMDP），为具有未知动力学和复杂规范的随机系统提供形式化的性能保证。


<details>
  <summary>Details</summary>
Motivation: 在安全关键环境中，控制具有未知动力学和复杂规范的随机系统极具挑战性，尤其是在性能保证至关重要的情况下。

Method: 该方法首先从轨迹数据中学习系统的转移核作为条件均值嵌入（CME）。然后，构建一个有限状态的不确定马尔可夫决策过程（UMDP）抽象，其转移不确定性捕获学习和离散化误差。最后，通过鲁棒动态规划生成具有形式化性能界限的策略。

Result: 通过一个温度调节基准对所提出的方法进行了演示和经验验证。

Conclusion: 该框架能够为具有未知动力学和复杂规范的随机系统提供数据驱动的策略合成和形式化的性能保证。

Abstract: Controlling stochastic systems with unknown dynamics and under complex specifications is specially challenging in safety-critical settings, where performance guarantees are essential. We propose a data-driven policy synthesis framework that yields formal performance guarantees for such systems using conditional mean embeddings (CMEs) and uncertain Markov decision processes (UMDPs). From trajectory data, we learn the system's transition kernel as a CME, then construct a finite-state UMDP abstraction whose transition uncertainties capture learning and discretization errors. Next, we generate a policy with formal performance bounds through robust dynamic programming. We demonstrate and empirically validate our method through a temperature regulation benchmark.

</details>


### [210] [Fast Frequency Response Potential of Data Centers through Workload Modulation and UPS Coordination](https://arxiv.org/abs/2512.14128)
*Xiaojie Tao,Rajit Gadh*

Main category: eess.SY

TL;DR: 本文研究了利用数据中心通过实时工作负载调节和UPS协调来提供快速频率响应的可行性，以支持低惯量电网的频率稳定。


<details>
  <summary>Details</summary>
Motivation: 可再生能源的快速增长降低了系统惯量，增加了对快速频率响应的需求。数据中心作为大型灵活的电力消费者，凭借其可控的IT工作负载和现场UPS系统，在频率稳定方面具有巨大潜力。

Method: 开发了一个结合数据中心功耗和电网频率动态的动态模型，捕捉IT服务器、冷却系统和储能之间的相互作用。实施了基于频率偏差的控制策略，以在频率事件期间调整服务器功率和放电UPS电池。

Result: 在修改后的IEEE 39节点系统上的案例研究表明，所提出的策略可以有效地降低频率谷值并缩短恢复时间，同时不影响服务质量。

Conclusion: 结果突出了数据中心在未来低惯量系统中作为电网支持资源的 перспективная 作用。

Abstract: The rapid growth of renewable energy sources has significantly reduced system inertia and increased the need for fast frequency response (FFR) in modern power systems. Data centers, as large and flexible electrical consumers, hold great potential to contribute to frequency stabilization due to their controllable IT workloads and on-site uninterruptible power supply (UPS) systems. This paper investigates the feasibility of leveraging data centers for providing fast frequency response through real-time workload modulation and UPS coordination. A dynamic model combining data center power consumption and grid frequency dynamics is developed, capturing the interactions between IT servers, cooling systems, and energy storage. Control strategies based on frequency deviation are implemented to adjust server power and discharge UPS batteries during frequency events. Case studies on a modified IEEE 39-bus system demonstrate that the proposed strategy can effectively reduce frequency nadir and shorten recovery time without compromising service quality. The results highlight the promising role of data centers as grid-supporting resources in future low-inertia systems.

</details>


### [211] [Coordinated Fast Frequency Response from Electric Vehicles, Data Centers, and Battery Energy Storage Systems](https://arxiv.org/abs/2512.14136)
*Xiaojie Tao,Rajit Gadh*

Main category: eess.SY

TL;DR: 该论文提出了一种协调控制框架，整合电动汽车、数据中心和电池储能系统，以提供快速频率响应，有效提高低惯量电网的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现代电网高可再生能源渗透率导致系统惯量显著降低，对分布式和非传统资源的快速频率响应（FFR）需求增加。尽管电动汽车、数据中心和电池储能系统各自展示了提供亚秒级有功功率支持的能力，但其组合频率响应潜力尚未得到系统评估。

Method: 本文提出了一种协调控制框架，用于聚合电动汽车车队、数据中心（通过UPS和工作负载调制）和电池储能系统，以提供快速、稳定和可靠的FFR。开发了这些资源的动态模型，明确捕捉其响应时间、功率限制和运行约束。引入了分层控制架构，其中上层协调器根据响应速度和可用容量动态分配FFR，下层控制器实现实际功率响应。通过IEEE 39节点测试系统进行案例研究。

Result: 与单一资源FFR相比，协调的电动汽车-数据中心-电池储能系统框架将频率最低点提高了0.2 Hz，降低了频率变化率（RoCoF），并加速了频率恢复。结果证实，协同协调显著增强了电网稳定性，尤其是在低惯量场景下。

Conclusion: 这项工作突出了多资源聚合对于未来可再生能源主导电网中频率调节市场的价值，能够显著增强电网稳定性。

Abstract: High renewable penetration has significantly reduced system inertia in modern power grids, increasing the need for fast frequency response (FFR) from distributed and non-traditional resources. While electric vehicles (EVs), data centers, and battery energy storage systems (BESS) have each demonstrated the capability to provide sub-second active power support, their combined frequency response potential has not been systematically evaluated. This paper proposes a coordinated control framework that aggregates these heterogeneous resources to provide fast, stable, and reliable FFR. Dynamic models for EV fleets, data center UPS and workload modulation, and BESS are developed, explicitly capturing their response times, power limits, and operational constraints. A hierarchical control architecture is introduced, where an upper-level coordinator dynamically allocates FFR among resources based on response speed and available capacity, and lower-level controllers implement the actual power response. Case studies based on the IEEE 39-bus test system demonstrate that the coordinated EV-DC-BESS framework improves frequency nadir by up to 0.2 Hz, reduces RoCoF, and accelerates frequency recovery compared with single-resource FFR. Results confirm that synergistic coordination significantly enhances grid stability, especially in low-inertia scenarios. This work highlights the value of multi-resource aggregation for future frequency regulation markets in renewable-dominated grids.

</details>


### [212] [KalMRACO: Unifying Kalman Filter and Model Reference Adaptive Control for Robust Control and Estimation of Uncertain Systems](https://arxiv.org/abs/2512.14175)
*Lauritz Rismark Fosso,Christian Holden,Sveinung Johan Ohrem*

Main category: eess.SY

TL;DR: 本文提出KalMRACO，将卡尔曼滤波器与模型参考自适应控制器(MRAC)结合，利用MRAC的参考模型作为卡尔曼滤波器的系统模型，从而在很大程度上消除了应用卡尔曼滤波器时对先验系统参数知识的需求。


<details>
  <summary>Details</summary>
Motivation: 卡尔曼滤波器通常需要系统参数的先验知识，但在实际应用中这些参数不一定已知，这限制了卡尔曼滤波器的实际应用。

Method: 提出KalMRACO，将卡尔曼滤波器与MRAC统一。它利用MRAC的已知参考模型作为卡尔曼滤波器的系统模型，以消除对底层系统参数知识的需求。此外，引入了在反馈律中混合估计状态和测量值的概念，以解决初始瞬态期间的稳定性问题。

Result: 通过水下航行器的仿真和实验室试验验证了KalMRACO。结果显示，它在参考模型状态跟踪、观测器状态收敛和噪声抑制方面表现出卓越的性能。

Conclusion: KalMRACO成功地统一了卡尔曼滤波器和MRAC，极大地减少了卡尔曼滤波器对系统参数先验知识的依赖，并展现出优异的跟踪和噪声抑制能力。

Abstract: A common assumption when applying the Kalman filter is a priori knowledge of the system parameters. These parameters are not necessarily known, and this may limit real-world applications of the Kalman filter. The well-established Model Reference Adaptive Controller (MRAC) utilizes a known reference model and ensures that the input-output behavior of a potentially unknown system converges to that of the reference model. We present KalMRACO, a unification of the Kalman filter and MRAC leveraging the reference model of MRAC as the Kalman filter system model, thus eliminating, to a large degree, the need for knowledge of the underlying system parameters in the application of the Kalman filter. We also introduce the concept of blending estimated states and measurements in the feedback law to handle stability issues during the initial transient. KalMRACO is validated through simulations and lab trials on an underwater vehicle. Results show superior tracking of the reference model state, observer state convergence, and noise mitigation properties.

</details>


### [213] [A Data-Driven Approach for Electric Vehicle Powertrain Modeling](https://arxiv.org/abs/2512.14344)
*Eymen Ipek,Mario Hirz*

Main category: eess.SY

TL;DR: 本文提出一个模块化框架，通过定义标准化接口，将各种类型的组件模型（数据驱动、物理或经验模型）集成到系统级动力总成仿真中，以加速电动汽车开发。


<details>
  <summary>Details</summary>
Motivation: 汽车行业电气化和动力总成复杂性增加，要求加速且经济高效的开发周期。尽管数据驱动模型已在组件层面得到研究，但将其系统地集成到连贯的、系统级仿真中进行虚拟验证仍存在空白。

Method: 本文提出了一个模块化框架，通过为电池、逆变器和电机等关键组件定义标准化接口，使得独立开发的模型（无论是数据驱动、基于物理还是经验模型）能够轻松集成，从而实现动力总成仿真。

Result: 该方法实现了可扩展的系统级建模，并促进了独立开发的模型（无论其性质如何）的轻松集成。

Conclusion: 该方法旨在缩短开发周期，满足现代汽车行业敏捷开发的需求。

Abstract: Electrification in the automotive industry and increasing powertrain complexity demand accelerated, cost-effective development cycles. While data-driven models are recently investigated at component level, a gap exists in systematically integrating them into cohesive, system-level simulations for virtual validation. This paper addresses this gap by presenting a modular framework for developing powertrain simulations. By defining standardized interfaces for key components-the battery, inverter, and electric motor-our methodology enables independently developed models, whether data-driven, physics-based, or empirical, to be easily integrated. This approach facilitates scalable system-level modeling, aims to shorten development timelines and to meet the agile demands of the modern automotive industry.

</details>


### [214] [Equivariant Filter Cascade for Relative Attitude, Target's Angular Velocity, and Gyroscope Bias Estimation](https://arxiv.org/abs/2512.14412)
*Gil Serrano,Pedro Lourenço,Bruno J. Guerreiro,Rita Cunha*

Main category: eess.SY

TL;DR: 本文提出一种级联等变滤波器（EqF）来解决追踪器航天器与非合作目标（如失效卫星）交会和对接时，在陀螺仪偏差存在下，估计目标相对姿态和角速度的问题。


<details>
  <summary>Details</summary>
Motivation: 与非合作目标（如失效卫星）进行交会和对接需要追踪器航天器与目标之间的同步。在这种情况下，追踪器必须使用机载传感器估计目标的相对姿态和角速度，同时还要考虑陀螺仪偏差的影响。

Method: 本文提出一种级联等变滤波器（EqF）来解决此问题。第一阶段使用星敏感器测量估计追踪器的姿态和偏差；第二阶段使用目标坐标系中两个已知非共线向量的观测值估计相对姿态和目标的角速度。

Result: 对等变滤波器级联的稳定性进行了理论分析，仿真结果证明了该滤波器级联的性能。

Conclusion: 所提出的级联等变滤波器能够有效估计追踪器航天器与非合作目标之间的相对姿态和角速度，并在存在陀螺仪偏差的情况下表现良好。

Abstract: Rendezvous and docking between a chaser spacecraft and an uncooperative target, such as an inoperative satellite, require synchronization between the chaser spacecraft and the target. In these scenarios, the chaser must estimate the relative attitude and angular velocity of the target using onboard sensors, in the presence of gyroscope bias. In this work, we propose a cascade of Equivariant Filters (EqF) to address this problem. The first stage of the cascade estimates the chaser's attitude and the bias, using measurements from a star tracker, while the second stage of the cascade estimates the relative attitude and the target's angular velocity, using observations of two known, non-collinear vectors fixed in the target frame. The stability of the EqF cascade is theoretically analyzed and simulation results demonstrate the filter cascade's performance.

</details>


### [215] [A Geometric Task-Space Port-Hamiltonian Formulation for Redundant Manipulators](https://arxiv.org/abs/2512.14349)
*Federico Califano,Camilla Rota,Riccardo Zanella,Antonio Franchi*

Main category: eess.SY

TL;DR: 本文提出了一种冗余机械臂微分运动学任务的新型几何端口-哈密顿（port-Hamiltonian）建模方法，通过坐标变换将哈密顿动量分解为任务空间动量和零空间动量，并应用于控制设计。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为执行微分运动学任务的冗余机械臂提供一种新的几何端口-哈密顿动力学模型，以更好地理解其特性并应用于控制设计。

Method: 该研究方法基于对标准哈密顿动力学进行坐标变换，从而得到一种将哈密顿动量变量分解为任务空间动量变量和零空间动量变量的几何端口-哈密顿模型。该模型还探讨了其性质以及与现有拉格朗日公式的关系。最后，通过互连和阻尼分配无源性控制（IDA-PBC）设计，在仿真中稳定并塑造了一个7自由度Emika Panda机器人的阻抗。

Result: 研究结果包括：1) 提出了一种新型几何端口-哈密顿模型，能够将冗余机械臂的动量分解为任务空间和零空间分量；2) 阐明了该模型的特性及其与文献中拉格朗日公式的关系；3) 成功将该模型应用于IDA-PBC设计，在仿真中实现了7自由度Emika Panda机器人的稳定性和阻抗整形。

Conclusion: 该研究成功提出了一种针对冗余机械臂微分运动学任务的有效几何端口-哈密顿建模方法，并通过仿真验证了其在IDA-PBC控制设计中的应用潜力，为冗余机械臂的建模与控制提供了新途径。

Abstract: We present a novel geometric port-Hamiltonian formulation of redundant manipulators performing a differential kinematic task $η=J(q)\dot{q}$, where $q$ is a point on the configuration manifold, $η$ is a velocity-like task space variable, and $J(q)$ is a linear map representing the task, for example the classical analytic or geometric manipulator Jacobian matrix. The proposed model emerges from a change of coordinates from canonical Hamiltonian dynamics, and splits the standard Hamiltonian momentum variable into a task-space momentum variable and a null-space momentum variable. Properties of this model and relation to Lagrangian formulations present in the literature are highlighted. Finally, we apply the proposed model in an \textit{Interconnection and Damping Assignment Passivity-Based Control} (IDA-PBC) design to stabilize and shape the impedance of a 7-DOF Emika Panda robot in simulation.

</details>


### [216] [Nonlinear System Identification Nano-drone Benchmark](https://arxiv.org/abs/2512.14450)
*Riccardo Busetto,Elia Cereda,Marco Forgione,Gabriele Maroni,Dario Piga,Daniele Palossi*

Main category: eess.SY

TL;DR: 本文为一个基于Crazyflie 2.1纳米四旋翼无人机的系统辨识引入了一个新基准，包含75k个真实世界样本、多步预测评估指标和基线模型，旨在促进敏捷、小型化空中机器人研究。


<details>
  <summary>Details</summary>
Motivation: Crazyflie 2.1平台具有多输入多输出、开环不稳定和非线性动力学特性，对系统辨识构成挑战。为实现辨识方法的公平比较并支持敏捷、小型化空中机器人研究，需要一个标准化的真实世界基准。

Method: 研究者从Crazyflie 2.1无刷纳米四旋翼无人机收集了75k个真实世界样本，构建了一个包含四种激进轨迹、同步4维电机输入和13维输出测量的数据集。该基准还包括一套多步预测指标，用于评估单步和多步误差传播。此外，还提供了平台和实验设置的详细描述，以及突出挑战的基线模型。所有数据、脚本和参考实现均已开源。

Result: 本文成功引入了一个针对纳米无人机的系统辨识基准。通过基线模型，研究展示了在真实世界噪声和执行器非线性下实现准确预测的挑战性。

Conclusion: 该基准将促进系统辨识算法的透明比较，并支持敏捷、小型化空中机器人领域的研究与发展。

Abstract: We introduce a benchmark for system identification based on 75k real-world samples from the Crazyflie 2.1 Brushless nano-quadrotor, a sub-50g aerial vehicle widely adopted in robotics research. The platform presents a challenging testbed due to its multi-input, multi-output nature, open-loop instability, and nonlinear dynamics under agile maneuvers. The dataset comprises four aggressive trajectories with synchronized 4-dimensional motor inputs and 13-dimensional output measurements. To enable fair comparison of identification methods, the benchmark includes a suite of multi-horizon prediction metrics for evaluating both one-step and multi-step error propagation. In addition to the data, we provide a detailed description of the platform and experimental setup, as well as baseline models highlighting the challenge of accurate prediction under real-world noise and actuation nonlinearities. All data, scripts, and reference implementations are released as open-source at https://github.com/idsia-robotics/nanodrone-sysid-benchmark to facilitate transparent comparison of algorithms and support research on agile, miniaturized aerial robotics.

</details>


### [217] [Equivariant Observer for Bearing Estimation with Linear and Angular Velocity Inputs](https://arxiv.org/abs/2512.14451)
*Gil Serrano,Marcelo Jacinto,Bruno J. Guerreiro,Rita Cunha*

Main category: eess.SY

TL;DR: 本文设计了一种针对单位球上的一阶动力学系统的等变观测器，通过引入线性速度输入扩展了现有模型，并证明了其几乎全局渐近稳定性。


<details>
  <summary>Details</summary>
Motivation: 在图像视觉伺服等场景中，需要稳定的方位估计，并且必须考虑车辆与目标特征之间的相对速度。现有模型主要处理角速度输入，缺乏对线性速度的考虑。

Method: 该研究在现有单位方位矢量动力学的基础上，引入了一个投影到单位球切空间的附加线性速度输入。利用提升运动学到特殊正交群的方法，设计了一个方位矢量观测器，并证明了其几乎全局渐近稳定性。同时，展示了如何在原始状态流形中表达该等变观测器。

Result: 所设计的方位矢量观测器实现了几乎全局渐近稳定性。数值仿真结果验证了所提出算法的有效性。

Conclusion: 成功设计并验证了一种针对单位球上一阶动力学系统的等变观测器，该观测器通过考虑线性速度输入扩展了应用范围，并具有几乎全局渐近稳定性。

Abstract: This work addresses the problem of designing an equivariant observer for a first order dynamical system on the unit-sphere. Building upon the established case of unit bearing vector dynamics with angular velocity inputs, we introduce an additional linear velocity input projected onto the unit-sphere tangent space. This extended formulation is particularly useful in image-based visual servoing scenarios where stable bearing estimates are required and the relative velocity between the vehicle and target features must be accounted for. Leveraging lifted kinematics to the Special Orthogonal group, we design an observer for the bearing vector and prove its almost global asymptotic stability. Additionally, we demonstrate how the equivariant observer can be expressed in the original state manifold. Numerical simulation results validate the effectiveness of the proposed algorithm.

</details>


### [218] [Scalable Nonlinear DeePC: Bridging Direct and Indirect Methods and Basis Reduction](https://arxiv.org/abs/2512.14535)
*Thomas O. de Jong,Mircea Lazar,Siep Weiland,Florian Dörfler*

Main category: eess.SY

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: This paper studies regularized data-enabled predictive control (DeePC) within a nonlinear framework and its relationship to subspace predictive control (SPC). The $Π$-regularization is extended to general basis functions and it is shown that, under suitable conditions, the resulting basis functions DeePC formulation constitutes a relaxation of basis functions SPC. To improve scalability, we introduce an SVD-based dimensionality reduction that preserves the equivalence with SPC, and we derive a reduced Π-regularization. A LASSO based sparse basis selection method is proposed to obtain a reduced basis from lifted data. Simulations on a nonlinear van der Pol oscillator model indicate that, in the absence of noise, DeePC and SPC yield equivalent absolute mean tracking errors (AMEs) when large penalties are applied. In contrast, under noisy measurements, careful tuning of the DeePC regularization results in a reduced AME, outperforming SPC.

</details>


### [219] [Closed-Loop Consistent, Causal Data-Driven Predictive Control via SSARX](https://arxiv.org/abs/2512.14510)
*Aihui Liu,Magnus Jansson*

Main category: eess.SY

TL;DR: 本文提出了一种名为SSARX的无基本引理数据驱动预测控制（DDPC）方案，它通过多步预测器直接从输入输出数据合成模型预测控制（MPC）策略，避免了DeePC等方法中堆叠Hankel表示和决策变量g的复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动预测控制（DDPC）方法（如DeePC）通常依赖Willems的基本引理和堆叠Hankel表示，这可能带来复杂性。研究动机是开发一种不依赖基本引理、闭环一致且因果的DDPC方案，以更直接地从数据中学习MPC策略。

Method: 该方法基于多步预测器Subspace-ARX (SSARX)。具体步骤包括：(i) 通过高阶ARX模型估计预测器/观测器马尔可夫参数以解耦噪声；(ii) 通过回归学习多步过去-未来映射，可选地施加降秩约束。SSARX预测器是严格因果的，可自然地集成到MPC框架中。

Result: 实验结果表明，当应用于受测量和过程噪声影响的闭环数据时，SSARX方案的性能与其他方法具有竞争力。

Conclusion: SSARX是一种有效且具有竞争力的无基本引理数据驱动预测控制方案，能够直接从输入输出数据合成MPC策略，尤其在存在测量和过程噪声的闭环数据环境下表现良好。

Abstract: We propose a fundamental-lemma-free data-driven predictive control (DDPC) scheme for synthesizing model predictive control (MPC)-like policies directly from input-output data. Unlike the well-known DeePC approach and other DDPC methods that rely on Willems' fundamental lemma, our method avoids stacked Hankel representations and the DeePC decision variable g. Instead, we develop a closed-loop consistent, causal DDPC scheme based on the multi-step predictor Subspace-ARX (SSARX). The method first (i) estimates predictor/observer Markov parameters via a high-order ARX model to decouple the noise, then (ii) learns a multi-step past-to-future map by regression, optionally with a reduced-rank constraint. The SSARX predictor is strictly causal, which allows it to be integrated naturally into an MPC formulation. Our experimental results show that SSARX performs competitively with other methods when applied to closed-loop data affected by measurement and process noise.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [220] [Improving the Plausibility of Pressure Distributions Synthesized from Depth through Generative Modeling](https://arxiv.org/abs/2512.13757)
*Neevkumar Manavar,Hanno Gerd Meyer,Joachim Waßmuth,Barbara Hammer,Axel Schneider*

Main category: eess.IV

TL;DR: 该研究提出一个框架，结合生成模型、Informed Latent Space (ILS) 和 Weight Optimization Loss (WOL)，以及扩散模型（BBDM和LBBDM），以生成物理上更合理、高保真度的医院病床压力图，用于预防压疮和实时患者监测。


<details>
  <summary>Details</summary>
Motivation: 现有压力图预测方法常缺乏物理合理性，限制了其临床可靠性，无法有效用于预防压疮和实时患者评估。

Method: 本研究提出一个框架，通过 Informed Latent Space (ILS) 和 Weight Optimization Loss (WOL) 结合生成模型来增强物理合理性。它还应用了基于扩散的条件布朗桥扩散模型 (BBDM)，并为其潜在对应模型 Latent Brownian Bridge Diffusion Model (LBBDM) 提出了专门的训练策略，用于躺卧姿势的压力合成。

Result: 实验结果表明，所提出的方法在物理合理性和性能上均优于基线。其中，结合 ILS 的 BBDM 能够生成高度详细的压力图，但计算成本和推理时间较高；而 LBBDM 则能以更快的推理速度提供具有竞争力的性能。

Conclusion: 该方法支持在临床环境中进行非侵入性、基于视觉的实时患者监测，有助于预防压疮。

Abstract: Monitoring contact pressure in hospital beds is essential for preventing pressure ulcers and enabling real-time patient assessment. Current methods can predict pressure maps but often lack physical plausibility, limiting clinical reliability. This work proposes a framework that enhances plausibility via Informed Latent Space (ILS) and Weight Optimization Loss (WOL) with generative modeling to produce high-fidelity, physically consistent pressure estimates. This study also applies diffusion based conditional Brownian Bridge Diffusion Model (BBDM) and proposes training strategy for its latent counterpart Latent Brownian Bridge Diffusion Model (LBBDM) tailored for pressure synthesis in lying postures. Experiment results shows proposed method improves physical plausibility and performance over baselines: BBDM with ILS delivers highly detailed maps at higher computational cost and large inference time, whereas LBBDM provides faster inference with competitive performance. Overall, the approach supports non-invasive, vision-based, real-time patient monitoring in clinical environments.

</details>


### [221] [Synthetic Aperture for High Spatial Resolution Acoustoelectric Imaging](https://arxiv.org/abs/2512.14094)
*Wei Yi Oon,Yuchen Tang,Baiqian Qi,Wei-Ning Lee*

Main category: eess.IV

TL;DR: 该研究提出了一种合成孔径声电成像（SA-AE）方法，通过动态合成声电调制区域并结合相干因子加权，显著提高了声电成像的景深、分辨率、对比度和信噪比，克服了传统聚焦超声声电成像的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的聚焦超声声电（FUS-AE）成像的景深（DOF）受限于焦点大小，无法覆盖器官的厘米级范围，导致对离焦电场的成像质量差。因此，需要一种能够改善景深并提高整体成像性能的方法。

Method: 研究提出合成孔径声电（SA-AE）方法，通过像素级延迟和叠加重建未聚焦声电信号，动态合成声电调制区域。为了抑制背景噪声并进一步提升图像质量，该方法还利用信号的空间相干性，计算了相干因子（CF）和脉冲长度相干因子（CFPL）图，并用这些相干因子对SA-AE图像进行加权。

Result: FUS-AE在焦点深度表现良好，但对离焦电场分辨率差。SA-AE普遍改善了整个景深范围内的空间分辨率，但引入了较强的背景噪声。通过相干因子（CF和CFPL）加权SA-AE图像，进一步提高了图像分辨率和对比度，并显著提升了信噪比，甚至超过了FUS-AE。其中，CFPL在噪声抑制方面优于CF。

Conclusion: 所提出的相干加权合成孔径声电（SA-AE）策略，利用未聚焦超声波传输，为生物快速电流的实际成像提供了一种高分辨率且噪声鲁棒的解决方案。

Abstract: Acoustoelectric (AE) imaging provides electro-anatomical contrast by mapping the distribution of electric fields in biological tissues, by delivering ultrasound waves which spatially modulate the medium resistivity via the AE effect. The conventional method in AE imaging is to transmit focused ultrasound (FUS) beams; however, the depth-of-field (DOF) of FUS-AE is limited to the size of the focal spot, which does not span across the centimeter-scale of organs. Instead of fixing the focal depth on transmission, we propose to dynamically synthesize the AE modulation regions via a Synthetic Aperture approach (SA-AE). SA-AE involves a straightforward pixel-based delay-and-sum reconstruction of AE images from unfocused AE signals. In saline and ex vivo lobster nerve experiments, FUS-AE was shown to perform well only at the focal depth, with poor spatial resolution for out-of-focus electric sources. Meanwhile, SA-AE generally improved spatial resolution throughout the DOF, but introduced strong background noise. The flexibility of uncoupled, single-element induced AE signals in SA-AE was further leveraged to quantify their spatial coherence across the transmit aperture, obtaining maps of the coherence factor (CF) and pulse-length coherence factor (CFPL). Weighting SA-AE images with their derived CF and CFPL maps resulted in further improvement in image resolution and contrast, and notably, boosted the image SNR beyond that of FUS-AE. CFPL exhibited stronger noise suppression over CF. Using unfocused wave transmissions, the proposed coherence-weighted SA-AE strategy offers a high resolution yet noise-robust solution towards the practical imaging of fast biological currents.

</details>


### [222] [Towards Deep Learning Surrogate for the Forward Problem in Electrocardiology: A Scalable Alternative to Physics-Based Models](https://arxiv.org/abs/2512.13765)
*Shaheim Ogbomo-Harmitt,Cesare Magnetti,Chiara Spota,Jakub Grzelak,Oleg Aslanidi*

Main category: eess.IV

TL;DR: 该研究提出一个深度学习框架，作为心电学正向问题的传统物理模型的替代方案，能高效地从心脏电压传播图预测心电图信号，并在模拟数据上取得了高精度。


<details>
  <summary>Details</summary>
Motivation: 传统的心电学正向问题求解器（如bidomain或monodomain方程）计算成本高昂，限制了它们在实时和大规模临床应用中的使用。因此，需要一个更高效的替代方案。

Method: 研究提出一个概念验证的深度学习框架。该模型采用时间依赖的、基于注意力的序列到序列架构，从心脏电压传播图预测心电图（ECG）信号。引入了一种结合Huber损失和频谱熵项的混合损失函数，以保持时间和频率域的保真度。模型在包含健康、纤维化和间隙连接重塑条件的2D组织模拟数据上进行训练和评估。

Result: 该模型实现了高精度（平均 $R^2 = 0.99 \pm 0.01$）。消融研究证实了卷积编码器、时间感知注意力机制和频谱熵损失项的贡献。

Conclusion: 研究结果表明，深度学习是物理求解器的一种可扩展、经济高效的替代方案，在临床和数字孪生应用中具有巨大潜力。

Abstract: The forward problem in electrocardiology, computing body surface potentials from cardiac electrical activity, is traditionally solved using physics-based models such as the bidomain or monodomain equations. While accurate, these approaches are computationally expensive, limiting their use in real-time and large-scale clinical applications. We propose a proof-of-concept deep learning (DL) framework as an efficient surrogate for forward solvers. The model adopts a time-dependent, attention-based sequence-to-sequence architecture to predict electrocardiogram (ECG) signals from cardiac voltage propagation maps. A hybrid loss combining Huber loss with a spectral entropy term was introduced to preserve both temporal and frequency-domain fidelity. Using 2D tissue simulations incorporating healthy, fibrotic, and gap junction-remodelled conditions, the model achieved high accuracy (mean $R^2 = 0.99 \pm 0.01$). Ablation studies confirmed the contributions of convolutional encoders, time-aware attention, and spectral entropy loss. These findings highlight DL as a scalable, cost-effective alternative to physics-based solvers, with potential for clinical and digital twin applications.

</details>


### [223] [Test Time Optimized Generalized AI-based Medical Image Registration Method](https://arxiv.org/abs/2512.14556)
*Sneha Sree C.,Dattesh Shanbhag,Sudhanya Chatterjee*

Main category: eess.IV

TL;DR: 本文提出了一种新型AI驱动的3D非刚性医学图像配准框架，该框架具有跨成像模态和解剖区域的泛化能力，无需特定定制。


<details>
  <summary>Details</summary>
Motivation: 现有非刚性配准方法存在局限性：传统方法计算成本高、参数调优复杂；深度学习方法需要任务特定再训练，缺乏可扩展性和适应性。因此，需要一个高效、通用且能处理异构成像环境的配准框架。

Method: 本文引入了一种新型AI驱动的3D非刚性配准框架。与依赖特定应用模型的方法不同，该方法消除了对解剖或模态的特定定制。

Result: 该框架能够跨多种成像模态和解剖区域进行泛化，并能简化集成到多样化的临床环境中。

Conclusion: 该工作提供了一个高效、可泛化的3D非刚性配准解决方案，克服了传统和现有深度学习方法的局限性，适用于异构医学成像环境。

Abstract: Medical image registration is critical for aligning anatomical structures across imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and ultrasound. Among existing techniques, non-rigid registration (NRR) is particularly challenging due to the need to capture complex anatomical deformations caused by physiological processes like respiration or contrast-induced signal variations. Traditional NRR methods, while theoretically robust, often require extensive parameter tuning and incur high computational costs, limiting their use in real-time clinical workflows. Recent deep learning (DL)-based approaches have shown promise; however, their dependence on task-specific retraining restricts scalability and adaptability in practice. These limitations underscore the need for efficient, generalizable registration frameworks capable of handling heterogeneous imaging contexts. In this work, we introduce a novel AI-driven framework for 3D non-rigid registration that generalizes across multiple imaging modalities and anatomical regions. Unlike conventional methods that rely on application-specific models, our approach eliminates anatomy- or modality-specific customization, enabling streamlined integration into diverse clinical environments.

</details>


### [224] [An Energy-Efficient Adiabatic Capacitive Neural Network Chip](https://arxiv.org/abs/2512.14642)
*Himadri Singh Raghav,Sachin Maheshwari,Mike Smart,Patrick Foster,Alex Serb*

Main category: eess.IV

TL;DR: 本文提出了一种混合信号绝热电容神经网络芯片，采用130纳米CMOS技术，在保持高图像分类准确性的同时，显著降低了能耗，适用于电池供电和边缘设备。


<details>
  <summary>Details</summary>
Motivation: 人工智能的最新进展以及视频处理和高分辨率传感等应用中不断增长的数据带宽需求，对计算性能提出了更高要求，尤其是在严格的能耗限制下，如电池供电和边缘设备。

Method: 研究人员设计并实现了一款双层混合信号绝热电容神经网络芯片，采用130纳米CMOS工艺。该芯片集成了16个单周期乘法累加引擎。

Result: 该硬件芯片能可靠地区分4类8x8 1比特图像，分类结果超过95%，与等效软件版本相比仅有2.7%的差异。能量测量显示，与等效的CMOS电容实现相比，平均能耗节省了2.1倍至6.8倍。

Conclusion: 该混合信号绝热电容神经网络芯片在实现高图像分类准确性的同时，展现了显著的能耗节省，有效解决了边缘设备在AI应用中的能耗挑战。

Abstract: Recent advances in artificial intelligence, coupled with increasing data bandwidth requirements, in applications such as video processing and high-resolution sensing, have created a growing demand for high computational performance under stringent energy constraints, especially for battery-powered and edge devices. To address this, we present a mixed-signal adiabatic capacitive neural network chip, designed in a 130$nm$ CMOS technology, to demonstrate significant energy savings coupled with high image classification accuracy. Our dual-layer hardware chip, incorporating 16 single-cycle multiply-accumulate engines, can reliably distinguish between 4 classes of 8x8 1-bit images, with classification results over 95\%, within 2.7\% of an equivalent software version. Energy measurements reveal average energy savings between 2.1x and 6.8x, compared to an equivalent CMOS capacitive implementation.

</details>


### [225] [Configurable γ Photon Spectrometer to Enable Precision Radioguided Tumor Resection](https://arxiv.org/abs/2512.14667)
*Rahul Lall,Youngho Seo,Ali M. Niknejad,Mekhail Anwar*

Main category: eess.IV

TL;DR: 本文提出了一种9.9 mm²的CMOS集成电路伽马能谱仪，用于放射引导手术(RGS)，以亚keV能量分辨率和1.315 MeV动态范围高特异性定位癌细胞。


<details>
  <summary>Details</summary>
Motivation: 手术切除肿瘤时，微观癌细胞团难以在术中可视化，常被遗留，导致癌症复发风险显著增加。放射引导手术(RGS)能利用伽马放射性同位素标记癌细胞，但需要毫米级的伽马能谱仪以高特异性定位这些细胞。

Method: 研究人员开发了一种9.9 mm²的集成电路(IC)伽马能谱仪，采用180 nm CMOS工艺实现。该能谱仪使用小型2x2微米的反向偏置二极管，其低耗尽区电容能对入射伽马光子产生的微小电荷产生毫伏级电压信号。能量谱测量方法创新性地通过测量电压信号在伽马探测事件后恢复直流电平所需的衰减时间，而非直接测量电压降，从而实现低功耗。该方法在三种不同的像素架构中实现，以适应RGS中多样化的手术和患者需求，提供可配置的像素灵敏度、能量分辨率和能量动态范围。

Result: 该能谱仪使用三种常见的伽马发射放射性同位素（64Cu、133Ba、177Lu）进行了测试，在5分钟的采集时间内，能够分辨低至1 uCi的活度，实现亚keV的能量分辨率和1.315 MeV的能量动态范围。

Conclusion: 该小尺寸、高分辨率的集成伽马能谱仪有望显著提高放射引导手术中癌细胞的定位特异性，从而降低癌症复发风险。

Abstract: Surgical tumor resection aims to remove all cancer cells in the tumor margin and at centimeter-scale depths below the tissue surface. During surgery, microscopic clusters of disease are intraoperatively difficult to visualize and are often left behind, significantly increasing the risk of cancer recurrence. Radioguided surgery (RGS) has shown the ability to selectively tag cancer cells with gamma (γ) photon emitting radioisotopes to identify them, but require a mm-scale γ photon spectrometer to localize the position of these cells in the tissue margin (i.e., a function of incident γ photon energy) with high specificity. Here we present a 9.9 mm2 integrated circuit (IC)-based γ spectrometer implemented in 180 nm CMOS, to enable the measurement of single γ photons and their incident energy with sub-keV energy resolution. We use small 2 2 um reverse-biased diodes that have low depletion region capacitance, and therefore produce millivolt-scale voltage signals in response to the small charge generated by incident γ photons. A low-power energy spectrometry method is implemented by measuring the decay time it takes for the generated voltage signal to settle back to DC after a γ detection event, instead of measuring the voltage drop directly. This spectrometry method is implemented in three different pixel architectures that allow for configurable pixel sensitivity, energy-resolution, and energy dynamic range based on the widely heterogenous surgical and patient presentation in RGS. The spectrometer was tested with three common γ-emitting radioisotopes (64Cu, 133Ba, 177Lu), and is able to resolve activities down to 1 uCi with sub-keV energy resolution and 1.315 MeV energy dynamic range, using 5-minute acquisitions.

</details>
