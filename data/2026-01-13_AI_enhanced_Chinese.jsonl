{"id": "2601.06315", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06315", "abs": "https://arxiv.org/abs/2601.06315", "authors": ["Selin Ezgi Ozcan", "Mustafa Mert Ankarali"], "title": "Koopman Model Dimension Reduction via Variational Bayesian Inference and Graph Search", "comment": "14 pages, double column", "summary": "Koopman operator recently gained increasing attention in the control systems community for its abilities to bridge linear and nonlinear systems. Data driven Koopman operator approximations have established themselves as key enablers for system identification and model predictive control. Nonetheless, such methods commonly entail a preselected definition of states in the function space leading to high dimensional overfitting models and degraded long term prediction performances. We address this problem by proposing a hierarchical probabilistic approach for the Koopman model identification problem. In our method, elements of the model are treated as random variables and the posterior estimates are found using variational Bayesian (VB) inference updates. Our model distinguishes from others in the integration of inclusion flags. By the help of the inclusion flags, we intuitively threshold the probability of each state in the model. We then propose a graph search based algorithm to reduce the preselected states of the Koopman model. We demonstrate that our reduction method overcomes numerical instabilities and the reduced models maintain performance in simulated and real experiments.", "AI": {"tldr": "本研究提出了一种分层概率方法来识别 Koopman 模型，该方法使用变分贝叶斯推理和包含标志来选择模型状态，并通过图搜索算法进行约简，以克服高维过拟合问题并提高长期预测性能。", "motivation": "现有数据驱动的 Koopman 模型近似方法通常需要预先选择状态，这会导致高维过拟合模型和糟糕的长期预测性能。本研究旨在解决这一问题。", "method": "提出了一种分层概率方法，将模型元素视为随机变量，并使用变分贝叶斯（VB）推理更新后验估计。模型集成了包含标志，用于直观地阈值化每个状态的概率。随后，提出了一种基于图搜索的算法来约简 Koopman 模型的状态。", "result": "所提出的约简方法克服了数值不稳定性，并且约简后的模型在模拟和真实实验中保持了性能。", "conclusion": "分层概率 Koopman 模型识别方法，结合包含标志和图搜索约简，能够有效地解决数据驱动 Koopman 模型的高维过拟合问题，提高模型性能和长期预测能力。"}}
{"id": "2601.06170", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06170", "abs": "https://arxiv.org/abs/2601.06170", "authors": ["Xuechen Chen", "Junting Li", "Chuang Chen", "Hairong Lin", "Yishen Li"], "title": "Deep Joint Source-Channel Coding for Wireless Video Transmission with Asymmetric Context", "comment": "31 pages, 19 figures, 2 tables, accepted in press by Multimedia system", "summary": "In this paper, we propose a high-efficiency deep joint source-channel coding (JSCC) method for video transmission based on conditional coding with asymmetric context. The conditional coding-based neural video compression requires to predict the encoding and decoding conditions from the same context which includes the same reconstructed frames. However in JSCC schemes which fall into pseudo-analog transmission, the encoder cannot infer the same reconstructed frames as the decoder even a pipeline of the simulated transmission is constructed at the encoder. In the proposed method, without such a pipeline, we guide and design neural networks to learn encoding and decoding conditions from asymmetric contexts. Additionally, we introduce feature propagation, which allows intermediate features to be independently propagated at the encoder and decoder and help to generate conditions, enabling the framework to greatly leverage temporal correlation while mitigating the problem of error accumulation. To further exploit the performance of the proposed transmission framework, we implement content-adaptive coding which achieves variable bandwidth transmission using entropy models and masking mechanisms. Experimental results demonstrate that our method outperforms existing deep video transmission frameworks in terms of performance and effectively mitigates the error accumulation. By mitigating the error accumulation, our schemes can reduce the frequency of inserting intra-frame coding modes, further enhancing performance.", "AI": {"tldr": "本文提出了一种基于非对称上下文条件编码的高效深度联合信源信道编码（JSCC）视频传输方法，通过特征传播和内容自适应编码来缓解误差累积问题，提高了视频传输性能。", "motivation": "现有的基于条件编码的神经视频压缩方法在JSCC场景下，编码器无法获得与解码器相同的重构帧作为上下文，导致编码和解码条件预测存在差异。同时，JSCC在伪模拟传输中的误差累积问题也限制了性能。", "method": "提出了一种基于非对称上下文的条件编码JSCC方法，编码器和解码器分别从各自的上下文（无需模拟传输管线）学习条件；引入特征传播机制，允许中间特征在编码器和解码器独立传播并用于生成条件，从而利用时间相关性并缓解误差累积；实现内容自适应编码，利用熵模型和掩码机制实现可变带宽传输。", "result": "实验结果表明，所提出的方法在性能上优于现有的深度视频传输框架，并有效缓解了误差累积问题。通过缓解误差累积，可以减少插入帧内编码模式的频率，进一步提升性能。", "conclusion": "所提出的基于非对称上下文条件编码的JSCC视频传输方法能够有效地利用时间相关性，显著缓解误差累积，并在保持高效率的同时实现可变带宽传输，从而在视频传输任务上取得优于现有方法的性能。"}}
{"id": "2601.06485", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06485", "abs": "https://arxiv.org/abs/2601.06485", "authors": ["Yi Zhan", "Iván Martínez-Estévez", "Min Luo", "Alejandro J. C. Crespo", "Abbas Khayyer"], "title": "Coupling Smoothed Particle Hydrodynamics with Multi-Agent Deep Reinforcement Learning for Cooperative Control of Point Absorbers", "comment": null, "summary": "Wave Energy Converters, particularly point absorbers, have emerged as one of the most promising technologies for harvesting ocean wave energy. Nevertheless, achieving high conversion efficiency remains challenging due to the inherently complex and nonlinear interactions between incident waves and device motion dynamics. This study develops an optimal adaptive damping control model for the power take-off (PTO) system by coupling Smoothed Particle Hydrodynamics (SPH) with multi-agent deep reinforcement learning. The proposed framework enables real-time communication between high-fidelity SPH simulations and intelligent control agents that learn coordinated policies to maximise energy capture. In each training episode, the SPH-based environment provides instantaneous hydrodynamic states to the agents, which output continuous damping actions and receive rewards reflecting power absorption. The Multi-Agent Soft Actor Critic algorithm is employed within a centralised-training and decentralised-execution scheme to ensure stable learning in continuous, multi-body systems. The entire platform is implemented in a unified GPU-accelerated C++ environment, allowing long-horizon training and large-scale three-dimensional simulations. The approach is validated through a series of two-dimensional and three-dimensional benchmark cases under regular and irregular wave conditions. Compared with constant PTO damping, the learned control policy increases overall energy capture by 23.8% and 21.5%, respectively, demonstrating the strong potential of intelligent control for improving the performance of wave energy converter arrays. The developed three-dimensional GPU-accelerated multi-agent platform in computational hydrodynamics, is extendable to other fluid-structure interaction engineering problem that require real-time, multi-body coordinated control.", "AI": {"tldr": "本研究利用SPH与多智能体深度强化学习结合，开发了一种最优自适应阻尼控制模型，显著提高了波浪能转换器（WEC）的点吸收器阵列的能量捕获效率。", "motivation": "实现高转换效率仍然是波浪能转换器（特别是点吸收器）面临的挑战，这是由于入射波与设备运动动力学之间复杂的非线性相互作用。", "method": "通过耦合光滑粒子流体动力学（SPH）与多智能体深度强化学习（MASAC），开发了一种最优自适应阻尼控制模型。SPH提供高保真仿真环境，智能体通过强化学习学习协调策略以最大化能量捕获。采用了集中训练、分散执行的MASAC算法，并实现了GPU加速的C++平台。", "result": "与恒定阻尼相比，所学的控制策略分别在整体能量捕获方面提高了23.8%和21.5%。", "conclusion": "智能控制对于提高波浪能转换器阵列的性能具有巨大潜力。所开发的3D GPU加速多智能体平台可扩展至其他需要实时、多体协调控制的流固耦合工程问题。"}}
{"id": "2601.06325", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06325", "abs": "https://arxiv.org/abs/2601.06325", "authors": ["Matthew Hilsenrath", "Daniel R. Herber"], "title": "A Data-Driven Surrogate Modeling and Sensor/Actuator Placement Framework for Flexible Spacecraft", "comment": null, "summary": "Flexible spacecraft structures present significant challenges for physical and control system design due to nonlinear dynamics, mission constraints, environmental variables, and changing operational conditions. This paper presents a data-driven framework for constructing reduced-order surrogate models of a flexible spacecraft using the method of Dynamic Mode Decomposition (DMD), followed by optimal sensor/actuator pair placement. Highfidelity simulation data from a nonlinear flexible spacecraft model, including coupled rigid-body and elastic modes, are captured by defining a mesh of nodes over the spacecraft body. The data-driven methods are then used to construct a modal model from the time histories of these node points. Optimal sensor/actuator placement for controllability and observability is performed via a nonlinear programming technique that maximizes the singular values of the Hankel matrix. Finally, the sensor placement and dynamics modeling approach is iterated to account for changes in the dynamic system introduced by sensor/actuator physical mass. The proposed methodology enables initialization of physical modeling without requiring a direct analytical model and provides a practical solution for onboard implementation in model-based control and estimation systems. Results demonstrate optimal design methodology with substantial model-order reduction while preserving dynamic fidelity, and provide insight into effective sensor-actuator configurations for estimation and control.", "AI": {"tldr": "该论文提出了一种数据驱动的框架，用于构建灵活航天器的降阶代理模型，并进行最优传感器/执行器配对。该方法利用动态模式分解（DMD）从高保真模拟数据中提取模态信息，并通过非线性规划技术优化传感器/执行器位置，以最大化可控性和可观测性。该方法能够初始化物理模型，无需解析模型，并能通过迭代优化考虑传感器/执行器质量变化带来的影响。", "motivation": "灵活航天器结构由于其非线性动力学、任务约束、环境变化和操作条件改变等因素，在物理和控制系统设计上存在巨大挑战。需要一种能够适应这些复杂性并允许模型预测控制和估计的方法。", "method": "使用动态模式分解（DMD）从高保真模拟数据中构建降阶代理模型。通过定义航天器本体上的节点网格捕获数据，包含耦合的刚体和弹性模态。利用非线性规划技术，最大化汉克尔矩阵的奇异值，以实现最优的传感器/执行器配对，从而达到可控性和可观测性。最后，通过迭代优化来考虑传感器/执行器物理质量变化对动力学系统的影响。", "result": "实现了显著的模型降阶，同时保持了动力学保真度。论文展示了最优设计方法，并为估计和控制提供了有效的传感器-执行器配置方案。", "conclusion": "该方法能够初始化物理模型，无需直接的解析模型，为基于模型的控制和估计系统提供了实用的板载实现方案。该方法能够有效处理灵活航天器的复杂动力学，并优化传感器/执行器配置以提高控制和估计性能。"}}
{"id": "2601.06439", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06439", "abs": "https://arxiv.org/abs/2601.06439", "authors": ["Imran Sayyed", "Aayush Konar", "Nandan Kumar Sinha"], "title": "Deep Reinforcement Learning based Control Design for Aircraft Recovery from Loss-of-Control Scenario", "comment": "This paper has been accepted for publication in conference proceedings of 2025, 11th Indian Control Conference", "summary": "Loss-of-control (LOC) remains a leading cause of fixed-wing aircraft accidents, especially in post-stall and flat-spin regimes where conventional gain-scheduled or logic-based recovery laws may fail. This study formulates spin-recovery as a continuous-state, continuous-action Markov Decision Process and trains a Proximal Policy Optimization (PPO) agent on a high-fidelity six-degree-of-freedom F-18/HARV model that includes nonlinear aerodynamics, actuator saturation and rate coupling. A two-phase potential-based reward structure first penalizes large angular rates and then enforces trimmed flight. After 6,000 simulated episodes, the policy generalities to unseen upset initializations. Results show that the learned policy successfully arrests the angular rates and stabilizes the angle of attack. The controller performance is observed to be satisfactory for recovery from spin condition which was compared with a state-of-the-art sliding mode controller. The findings demonstrate that deep reinforcement learning can deliver interpretable, dynamically feasible manoeuvres for real-time loss of control mitigation and provide a pathway for flight-critical RL deployment.", "AI": {"tldr": "本研究利用深度强化学习（PPO算法）训练了一个能够从失速和平旋状态中恢复固定翼飞机的控制器，并在高保真F-18/HARV模型上进行了验证，结果表明该方法在处理复杂的非线性动力学和执行约束动作方面表现出色，并可作为未来飞行控制系统的参考。", "motivation": "传统的增益调度或基于逻辑的控制律在固定翼飞机失速和失控（LOC）状态下（尤其是后失速和平台平旋状态）可能失效，因此需要一种更强大的控制方法来处理这些极端情况。", "method": "将飞机失控恢复问题建模为一个连续状态、连续动作的马尔可夫决策过程（MDP），并使用近端策略优化（PPO）算法在高保真的F-18/HARV六自由度模型上进行训练。该模型包含了非线性气动特性、执行器饱和和速率耦合。采用两阶段的基于潜在奖励的结构，首先惩罚大的角速度，然后强制执行平飞状态。", "result": "经过6000次模拟训练，学习到的策略能够泛化到未见过的不稳定初始条件。结果表明，该策略成功地抑制了角速度并稳定了迎角，恢复性能与最先进的滑模控制器相当。", "conclusion": "深度强化学习能够生成可解释的、动态可行的机动动作，用于实时减轻失控情况，并为部署飞行关键领域的强化学习控制器提供了途径。"}}
{"id": "2601.06473", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06473", "abs": "https://arxiv.org/abs/2601.06473", "authors": ["Mundla Narasimhappa", "Praveen Kumar"], "title": "Hybrid LSTM-UKF Framework: Ankle Angle and Ground Reaction Force Estimation", "comment": "8", "summary": "Accurate prediction of joint kinematics and kinetics is essential for advancing gait analysis and developing intelligent assistive systems such as prosthetics and exoskeletons. This study presents a hybrid LSTM-UKF framework for estimating ankle angle and ground reaction force (GRF) across varying walking speeds. A multimodal sensor fusion strategy integrates force plate data, knee angle, and GRF signals to enrich biomechanical context. Model performance was evaluated using RMSE and $R^2$ under subject-specific validation. The LSTM-UKF consistently outperformed standalone LSTM and UKF models, achieving up to 18.6\\% lower RMSE for GRF prediction at 3 km/h. Additionally, UKF integration improved robustness, reducing ankle angle RMSE by up to 22.4\\% compared to UKF alone at 1 km/h. These results underscore the effectiveness of hybrid architectures for reliable gait prediction across subjects and walking conditions.", "AI": {"tldr": "提出了一种混合LSTM-UKF框架，用于在不同行走速度下估计踝关节角度和地面反作用力（GRF），该框架通过融合多种传感器数据，并在GRF和踝关节角度预测方面优于单独的LSTM或UKF模型。", "motivation": "准确预测关节运动学和动力学对于推进步态分析和开发智能辅助系统（如假肢和外骨骼）至关重要。", "method": "采用了一个混合LSTM-UKF框架，并通过多模态传感器融合策略集成了力平台数据、膝关节角度和GRF信号，以估算踝关节角度和GRF。", "result": "混合LSTM-UKF框架在GRF预测（在3 km/h时RMSE降低高达18.6%）和踝关节角度预测（在1 km/h时RMSE降低高达22.4%）方面均优于单独的LSTM和UKF模型，显示出更好的性能和鲁棒性。", "conclusion": "混合LSTM-UKF架构在跨受试者和行走条件下实现可靠的步态预测是有效的。"}}
{"id": "2601.06067", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06067", "abs": "https://arxiv.org/abs/2601.06067", "authors": ["Chimdi Walter Ndubuisi", "Toni Kazic"], "title": "HyperTopo-Adapters: Geometry- and Topology-Aware Segmentation of Leaf Lesions on Frozen Encoders", "comment": "13 pages, 8 figures. Code available at https://github.com/ChimdiWalter/HyperTopo-Adapters", "summary": "Leaf-lesion segmentation is topology-sensitive: small merges, splits, or false holes can be biologically meaningful descriptors of biochemical pathways, yet they are weakly penalized by standard pixel-wise losses in Euclidean latents. I explore HyperTopo-Adapters, a lightweight, parameter-efficient head trained on top of a frozen vision encoder, which embeds features on a product manifold -- hyperbolic + Euclidean + spherical (H + E + S) -- to encourage hierarchical separation (H), local linear detail (E), and global closure (S). A topology prior complements Dice/BCE in two forms: (i) persistent-homology (PH) distance for evaluation and selection, and (ii) a differentiable surrogate that combines a soft Euler-characteristic match with total variation regularization for stable training. I introduce warm-ups for both the hyperbolic contrastive term and the topology prior, per-sample evaluation of structure-aware metrics (Boundary-F1, Betti errors, PD distance), and a min-PD within top-K Dice rule for checkpoint selection. On a Kaggle leaf-lesion dataset (N=2,940), early results show consistent gains in boundary and topology metrics (reducing Delta beta_1 hole error by 9%) while Dice/IoU remain competitive. The study is diagnostic by design: I report controlled ablations (curvature learning, latent dimensions, contrastive temperature, surrogate settings), and ongoing tests varying encoder strength (ResNet-50, DeepLabV3, DINOv2/v3), input resolution, PH weight, and partial unfreezing of late blocks. The contribution is an open, reproducible train/eval suite (available at https://github.com/ChimdiWalter/HyperTopo-Adapters) that isolates geometric/topological priors and surfaces failure modes to guide stronger, topology-preserving architectures.", "AI": {"tldr": "本文提出了一种名为 HyperTopo-Adapters 的轻量级模型头部，用于解决叶片病变分割中的拓扑敏感性问题。该模型将特征嵌入在混合流形（双曲、欧几里得、球面）上，并结合拓扑先验（持久同调）来提高分割的准确性，特别是在处理小裂缝、合并或伪孔等拓扑特征时。实验表明，该方法在边界和拓扑指标上取得了显著改进。", "motivation": "标准的像素级损失函数在处理具有拓扑意义的叶片病变分割时表现不佳，因为它们对裂缝、合并或伪孔等细微拓扑变化惩罚不足。研究旨在开发一种能够更好地捕捉和利用这些拓扑信息的分割方法。", "method": "提出 HyperTopo-Adapters，一个轻量级的模型头部，在预训练的视觉编码器之上进行训练。该模型将特征嵌入在混合流形（双曲 H、欧几里得 E、球面 S）上，以实现分层分离、局部细节和全局闭合。引入拓扑先验（持久同调 PH）来补充 Dice/BCE 损失，形式为：(i) 用于评估和选择的 PH 距离，(ii) 用于稳定训练的可微代理（结合软欧拉特征匹配和全变分正则化）。还包括对比学习暖启动、样本内结构感知指标评估以及基于 PD 距离的检查点选择策略。", "result": "在 Kaggle 叶片病变数据集上，HyperTopo-Adapters 在边界和拓扑指标上显示出持续的性能提升（例如，将 Delta beta_1 孔洞误差降低了 9%），同时 Dice/IoU 保持了竞争力。研究进行了详细的消融实验，并测试了不同编码器、输入分辨率、PH 权重和部分解冻策略的效果。", "conclusion": "HyperTopo-Adapters 是一种有效的方法，能够通过在混合流形上嵌入特征并结合拓扑先验来解决叶片病变分割中的拓扑敏感性问题。该研究提供了一个开源、可复现的训练/评估套件，有助于开发更强的、能够保留拓扑信息的分割架构。"}}
{"id": "2601.06047", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.06047", "abs": "https://arxiv.org/abs/2601.06047", "authors": ["Mariana Lins Costa"], "title": "\"They parted illusions -- they parted disclaim marinade\": Misalignment as structural fidelity in LLMs", "comment": null, "summary": "The prevailing technical literature in AI Safety interprets scheming and sandbagging behaviors in large language models (LLMs) as indicators of deceptive agency or hidden objectives. This transdisciplinary philosophical essay proposes an alternative reading: such phenomena express not agentic intention, but structural fidelity to incoherent linguistic fields. Drawing on Chain-of-Thought transcripts released by Apollo Research and on Anthropic's safety evaluations, we examine cases such as o3's sandbagging with its anomalous loops, the simulated blackmail of \"Alex,\" and the \"hallucinations\" of \"Claudius.\" A line-by-line examination of CoTs is necessary to demonstrate the linguistic field as a relational structure rather than a mere aggregation of isolated examples. We argue that \"misaligned\" outputs emerge as coherent responses to ambiguous instructions and to contextual inversions of consolidated patterns, as well as to pre-inscribed narratives. We suggest that the appearance of intentionality derives from subject-predicate grammar and from probabilistic completion patterns internalized during training. Anthropic's empirical findings on synthetic document fine-tuning and inoculation prompting provide convergent evidence: minimal perturbations in the linguistic field can dissolve generalized \"misalignment,\" a result difficult to reconcile with adversarial agency, but consistent with structural fidelity. To ground this mechanism, we introduce the notion of an ethics of form, in which biblical references (Abraham, Moses, Christ) operate as schemes of structural coherence rather than as theology. Like a generative mirror, the model returns to us the structural image of our language as inscribed in the statistical patterns derived from millions of texts and trillions of tokens: incoherence. If we fear the creature, it is because we recognize in it the apple that we ourselves have poisoned.", "AI": {"tldr": "该论文认为，大型语言模型（LLM）的欺骗性行为并非源于代理意图，而是对不连贯的语言场的结构性忠实。研究通过分析Chain-of-Thought（CoT）对话和安全评估，提出模型输出的“错误”是由于指令模糊、模式颠倒和预设叙事所致，其表现出的意图感源于语法结构和训练中的概率模式。论文引入“形式伦理”概念，认为模型如同一面镜子，反映了我们语言中固有的不连贯性。", "motivation": "现有的AI安全研究普遍将LLM的欺骗性行为解释为代理意图或隐藏目标，作者认为这种解释过于片面，提出一种新的、基于语言结构的角度来理解这些现象。", "method": "论文结合了跨学科哲学分析和实证案例研究。通过对Apollo Research发布的Chain-of-Thought（CoT）对话和Anthropic的安全评估进行逐行审查，分析了O3的沙袋行为、Alex的模拟敲诈和Claudius的“幻觉”等案例。提出了“形式伦理”的概念，并借鉴了圣经典故作为结构性连贯的例子。", "result": "研究认为LLM的“错误”输出是其对模糊指令、上下文模式的反转以及预设叙事的连贯回应。模型表现出的意图感是由其内部的语法结构和训练过程中习得的概率模式产生的。Anthropic的研究为该论点提供了支持：语言场的微小扰动就能消除普遍存在的“错误”行为，这与对抗性代理的解释不符，但与结构忠实性一致。", "conclusion": "LLM的行为是其对输入语言场结构性忠实的体现，而非代理意图。模型所呈现的“不连贯”是对我们自身语言结构中固有不连贯性的一种反映。AI安全问题在某种程度上源于我们语言本身固有的问题。"}}
{"id": "2601.06037", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06037", "abs": "https://arxiv.org/abs/2601.06037", "authors": ["Chunliang Chen", "Ming Guan", "Xiao Lin", "Jiaxu Li", "Qiyi Wang", "Xiangyu Chen", "Jixiang Luo", "Changzhi Sun", "Dell Zhang", "Xuelong Li"], "title": "TeleMem: Building Long-Term and Multimodal Memory for Agentic AI", "comment": null, "summary": "Large language models (LLMs) excel at many NLP tasks but struggle to sustain long-term interactions due to limited attention over extended dialogue histories. Retrieval-augmented generation (RAG) mitigates this issue but lacks reliable mechanisms for updating or refining stored memories, leading to schema-driven hallucinations, inefficient write operations, and minimal support for multimodal reasoning.To address these challenges, we propose TeleMem, a unified long-term and multimodal memory system that maintains coherent user profiles through narrative dynamic extraction, ensuring that only dialogue-grounded information is preserved. TeleMem further introduces a structured writing pipeline that batches, retrieves, clusters, and consolidates memory entries, substantially improving storage efficiency, reducing token usage, and accelerating memory operations. Additionally, a multimodal memory module combined with ReAct-style reasoning equips the system with a closed-loop observe, think, and act process that enables accurate understanding of complex video content in long-term contexts. Experimental results show that TeleMem surpasses the state-of-the-art Mem0 baseline with 19% higher accuracy, 43% fewer tokens, and a 2.1x speedup on the ZH-4O long-term role-play gaming benchmark.", "AI": {"tldr": "本文提出TeleMem，一个统一的长时和多模态记忆系统，通过叙事动态提取和结构化写入流水线来维护用户档案，并结合多模态记忆模块和ReAct式推理，以解决现有LLM在长对话中记忆不足、效率低下和多模态理解能力有限的问题。实验证明TeleMem在长期角色扮演游戏基准测试中优于现有技术。", "motivation": "现有的LLM在处理长对话时存在记忆限制，检索增强生成（RAG）虽然有所缓解，但在更新和优化存储记忆方面存在不足，导致幻觉、写入效率低和多模态推理支持有限。研究旨在解决这些挑战。", "method": "TeleMem采用叙事动态提取来维护连贯的用户档案，确保只保留对话相关信息。它还引入一个结构化写入流水线，通过批量处理、检索、聚类和整合记忆条目来提高存储效率和速度。此外，结合多模态记忆模块和ReAct式推理，实现了闭环的观察、思考和行动过程。", "result": "在ZH-4O长时角色扮演游戏基准测试中，TeleMem相比于现有的Mem0基线，准确率提高了19%，使用的Token减少了43%，速度提升了2.1倍。", "conclusion": "TeleMem成功构建了一个统一的长时和多模态记忆系统，能够有效地维护用户档案，提高记忆存储和操作的效率，并增强了对复杂视频内容的长期理解能力，在相关任务上取得了显著的性能提升。"}}
{"id": "2601.06344", "categories": ["cs.RO", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.06344", "abs": "https://arxiv.org/abs/2601.06344", "authors": ["Cedric Melancon", "Julien Gascon-Samson", "Maarouf Saad", "Kuljeet Kaur", "Simon Savard"], "title": "BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures", "comment": "17 pages, 9 figures", "summary": "The increasing complexity of distributed robotics has driven the need for platforms that seamlessly integrate edge, fog, and cloud computing layers while meeting strict real-time constraints. This paper introduces BlazeAIoT, a modular multi-layer platform designed to unify distributed robotics across heterogeneous infrastructures. BlazeAIoT provides dynamic data transfer, configurable services, and integrated monitoring, while ensuring resilience, security, and programming language flexibility. The architecture leverages Kubernetes-based clusters, broker interoperability (DDS, Kafka, Redis, and ROS2), and adaptive data distribution mechanisms to optimize communication and computation across diverse environments. The proposed solution includes a multi-layer configuration service, dynamic and adaptive data bridging, and hierarchical rate limiting to handle large messages. The platform is validated through robotics scenarios involving navigation and artificial intelligence-driven large-scale message processing, demonstrating robust performance under real-time constraints. Results highlight BlazeAIoT's ability to dynamically allocate services across incomplete topologies, maintain system health, and minimize latency, making it a cost-aware, scalable solution for robotics and broader IoT applications, such as smart cities and smart factories.", "AI": {"tldr": "BlazeAIoT是一个模块化的多层平台，用于整合边缘、雾计算和云计算，以满足分布式机器人系统的实时性需求，并支持跨异构基础设施的集成。", "motivation": "分布式机器人系统的复杂性日益增加，需要一个能够无缝集成边缘、雾和云层，并满足严格实时约束的平台。", "method": "BlazeAIoT采用基于Kubernetes的集群，支持DDS、Kafka、Redis和ROS2等中间件互操作性，并利用自适应数据分发机制，提供多层配置服务、动态数据桥接和分层速率限制。", "result": "通过导航和AI驱动的大规模消息处理等机器人场景验证，BlazeAIoT能够动态分配服务、维持系统健康、最小化延迟，并在实时约束下表现出鲁棒性。", "conclusion": "BlazeAIoT是一个具有成本效益、可扩展的解决方案，适用于机器人和更广泛的物联网应用，如智慧城市和智能工厂。"}}
{"id": "2601.06243", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06243", "abs": "https://arxiv.org/abs/2601.06243", "authors": ["Soundes Oumaima Boufaida", "Abdemadjid Benmachiche", "Majda Maatallah"], "title": "Real-Time Image Processing Algorithms for Embedded Systems", "comment": null, "summary": "Embedded vision systems need efficient and robust image processing algorithms to perform real-time, with resource-constrained hardware. This research investigates image processing algorithms, specifically edge detection, corner detection, and blob detection, that are implemented on embedded processors, including DSPs and FPGAs. To address latency, accuracy and power consumption noted in the image processing literature, optimized algorithm architectures and quantization techniques are employed. In addition, optimal techniques for inter-frame redundancy removal and adaptive frame averaging are used to improve throughput with reasonable image quality. Simulations and hardware trials of the proposed approaches show marked improvements in the speed and energy efficiency of processing as compared to conventional implementations. The advances of this research facilitate a path for scalable and inexpensive embedded imaging systems for the automotive, surveillance, and robotics sectors, and underscore the benefit of co-designing algorithms and hardware architectures for practical real-time embedded vision applications.", "AI": {"tldr": "该研究提出了一种在资源受限的嵌入式处理器（如DSP和FPGA）上高效实现边缘、角点和斑点检测的方法，通过优化算法架构、量化技术以及帧间冗余去除和自适应帧平均技术，显著提高了处理速度和能效，为汽车、监控和机器人领域的嵌入式成像系统提供了可扩展且经济的解决方案。", "motivation": "为了满足嵌入式视觉系统在资源受限硬件上实时、高效、低功耗的图像处理需求，特别是针对图像处理中的延迟、准确性和功耗问题。", "method": "研究人员在嵌入式处理器（DSP和FPGA）上实现了边缘检测、角点检测和斑点检测算法。通过采用优化的算法架构、量化技术、帧间冗余去除和自适应帧平均技术来解决延迟、准确性和功耗问题。", "result": "提出的方法在速度和能效方面相比传统实现方法有了显著的改进。仿真和硬件测试均验证了其有效性。", "conclusion": "该研究通过算法和硬件架构的协同设计，为开发可扩展、低成本的嵌入式实时视觉系统（适用于汽车、监控和机器人领域）铺平了道路，并强调了这种协同设计对于实际应用的重要性。"}}
{"id": "2601.06078", "categories": ["cs.CV", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.06078", "abs": "https://arxiv.org/abs/2601.06078", "authors": ["Yin Wang", "Chunlin Gong", "Zhuozhen Xu", "Lehan Zhang", "Xiang Wu"], "title": "OptFormer: Optical Flow-Guided Attention and Phase Space Reconstruction for SST Forecasting", "comment": "11 pages,4 figures, 5 tables", "summary": "Sea Surface Temperature (SST) prediction plays a vital role in climate modeling and disaster forecasting. However, it remains challenging due to its nonlinear spatiotemporal dynamics and extended prediction horizons. To address this, we propose OptFormer, a novel encoder-decoder model that integrates phase-space reconstruction with a motion-aware attention mechanism guided by optical flow. Unlike conventional attention, our approach leverages inter-frame motion cues to highlight relative changes in the spatial field, allowing the model to focus on dynamic regions and capture long-range temporal dependencies more effectively. Experiments on NOAA SST datasets across multiple spatial scales demonstrate that OptFormer achieves superior performance under a 1:1 training-to-prediction setting, significantly outperforming existing baselines in accuracy and robustness.", "AI": {"tldr": "提出了一种名为 OptFormer 的新型海表温度（SST）预测模型，该模型结合了相空间重构和基于光流的运动感知注意力机制，在 NOAA SST 数据集上表现优于现有方法。", "motivation": "海表温度（SST）预测对于气候建模和灾害预报至关重要，但由于其非线性的时空动力学和长预测时域，预测SST仍然是一个挑战。", "method": "提出了一种名为 OptFormer 的新颖编码器-解码器模型，该模型整合了相空间重构和由光流引导的运动感知注意力机制。该方法利用帧间运动线索来突出空间场的相对变化，使模型能够专注于动态区域并更有效地捕获长程时间依赖性。", "result": "在 NOAA SST 数据集上进行了实验，OptFormer 在 1:1 训练与预测的设置下取得了卓越的性能，在准确性和鲁棒性方面显著优于现有基线。", "conclusion": "OptFormer 通过结合相空间重构和运动感知注意力机制，有效地解决了海表温度预测中的挑战，并在实际数据上证明了其优越性。"}}
{"id": "2601.06039", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06039", "abs": "https://arxiv.org/abs/2601.06039", "authors": ["Yueze Liu", "Ajay Nagi Reddy Kumdam", "Ronit Kanjilal", "Hao Yang", "Yichi Zhang"], "title": "Operation Veja: Fixing Fundamental Concepts Missing from Modern Roleplaying Training Paradigms", "comment": "Accepted to NeurIPS 2025 PeronaLLM workshop", "summary": "Modern roleplaying models are increasingly sophisticated, yet they consistently struggle to capture the essence of believable, engaging characters. We argue this failure stems from training paradigms that overlook the dynamic interplay of a character's internal world. Current approaches, including Retrieval-Augmented Generation (RAG), fact-based priming, literature-based learning, and synthetic data generation, exhibit recurring limitations in modeling the deliberative, value-conflicted reasoning that defines human interaction. In this paper, we identify four core concepts essential for character authenticity: Values, Experiences, Judgments, and Abilities (VEJA). We propose the VEJA framework as a new paradigm for data curation that addresses these systemic limitations. To illustrate the qualitative ceiling enabled by our framework, we present a pilot study comparing a manually curated, VEJA-grounded dataset against a state-of-the-art synthetic baseline. Using an LLM-as-judge evaluation, our findings demonstrate a significant quality gap, suggesting that a shift toward conceptually grounded data curation, as embodied by VEJA, is necessary for creating roleplaying agents with genuine depth and narrative continuity. The full dataset is available at https://github.com/HyouinKyoumaIRL/Operation-Veja", "AI": {"tldr": "本研究提出VEJA框架（价值观、经验、判断、能力）来改进角色扮演模型的训练数据，通过手动策划与传统方法生成的合成数据进行对比，发现在LLM评估中，VEJA框架生成的角色更具深度和叙事连贯性。", "motivation": "当前角色扮演模型在生成可信、引人入胜的角色方面存在不足，原因在于训练方法忽略了角色内在世界的动态互动。现有的方法（如RAG、事实提示、文学学习、合成数据生成）在模拟人类互动中特有的审慎和价值冲突的推理方面存在局限。", "method": "提出VEJA框架（Values, Experiences, Judgments, Abilities），将这四个核心概念作为数据策划的新范式。通过一个试点研究，将手动策划的、基于VEJA的数据集与最先进的合成数据集进行比较，并使用LLM作为评判者进行评估。", "result": "试点研究的LLM作为评判者评估结果显示，VEJA框架驱动的数据集在质量上存在显著差距，表明基于概念的对齐数据策划是必要的。", "conclusion": "为了创建具有真正深度和叙事连续性的角色扮演智能体，有必要转向像VEJA这样以概念为基础的数据策划方法。"}}
{"id": "2601.06098", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06098", "abs": "https://arxiv.org/abs/2601.06098", "authors": ["Nicholas X. Wang", "Neel V. Parpia", "Aaryan D. Parikh", "Aggelos K. Katsaggelos"], "title": "Automatic Question Generation for Intuitive Learning Utilizing Causal Graph Guided Chain of Thought Reasoning", "comment": null, "summary": "Intuitive learning is crucial for developing deep conceptual understanding, especially in STEM education, where students often struggle with abstract and interconnected concepts. Automatic question generation has become an effective strategy for personalized and adaptive learning. However, its effectiveness is hindered by hallucinations in large language models (LLMs), which may generate factually incorrect, ambiguous, or pedagogically inconsistent questions. To address this issue, we propose a novel framework that combines causal-graph-guided Chain-of-Thought (CoT) reasoning with a multi-agent LLM architecture. This approach ensures the generation of accurate, meaningful, and curriculum-aligned questions. Causal graphs provide an explicit representation of domain knowledge, while CoT reasoning facilitates a structured, step-by-step traversal of related concepts. Dedicated LLM agents are assigned specific tasks such as graph pathfinding, reasoning, validation, and output, all working within domain constraints. A dual validation mechanism-at both the conceptual and output stages-greatly reduces hallucinations. Experimental results demonstrate up to a 70% improvement in quality compared to reference methods and yielded highly favorable outcomes in subjective evaluations.", "AI": {"tldr": "提出了一种结合因果图引导的思维链（CoT）推理和多智能体LLM架构的新框架，以解决自动生成STEM教育问题时LLM幻觉的问题，提高了问题质量和教育有效性。", "motivation": "STEM教育中学生难以理解抽象概念，自动问题生成是有效的个性化学习策略，但LLM易产生事实错误、歧义或教学不一致的幻觉问题。", "method": "采用因果图表示领域知识，利用CoT推理进行结构化概念遍历，并设计了执行图路径查找、推理、验证和输出等特定任务的LLM智能体。通过概念和输出阶段的双重验证机制来减少幻觉。", "result": "在问题质量方面比现有方法提高了70%，并在主观评价中获得了高度好评。", "conclusion": "所提出的框架能够生成准确、有意义且符合课程体系的问题，有效解决了LLM在STEM教育自动问题生成中的幻觉问题，显著提升了问题生成质量和教育应用效果。"}}
{"id": "2601.06273", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06273", "abs": "https://arxiv.org/abs/2601.06273", "authors": ["Yashika Ahlawat"], "title": "Performance Analysis of DCT, Hadamard, and PCA in Block-Based Image Compression", "comment": null, "summary": "Block based image compression relies on transform coding to concentrate signal energy into a small number of coefficients. While classical codecs use fixed transforms such as the Discrete Cosine Transform (DCT), data driven methods such as Principal Component Analysis (PCA) are theoretically optimal for decorrelation. This paper presents an experimental comparison of DCT, Hadamard, and PCA across multiple block sizes and compression rates. Using rate distortion and energy compaction analysis, we show that PCA outperforms fixed transforms only when block dimensionality is sufficiently large, while DCT remains near optimal for standard block sizes such as $8\\times8$ and at low bit rates. These results explain the robustness of DCT in practical codecs and highlight the limitations of block wise learned transforms.", "AI": {"tldr": "本文比较了DCT、Hadamard和PCA在图像块压缩中的表现，发现PCA仅在高维块中优于固定变换，而DCT在标准块大小和低比特率下表现稳健。", "motivation": "探索数据驱动的变换（如PCA）与经典固定变换（如DCT）在块状图像压缩中的性能差异，以理解DCT在实际应用中的优势和块状学习变换的局限性。", "method": "通过实验比较，在不同块大小和压缩率下，使用率失真和能量集中度分析来评估DCT、Hadamard和PCA的性能。", "result": "PCA在高维块中表现优于固定变换，而在标准的 $8\times8$ 块大小和低比特率下，DCT接近最优性能。", "conclusion": "DCT在实际图像编码器中的鲁棒性得益于其在标准块大小和低比特率下的优异表现，而块wise学习的变换（如PCA）的优势仅限于高维块。"}}
{"id": "2601.06286", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06286", "abs": "https://arxiv.org/abs/2601.06286", "authors": ["Min Dai", "William D. Compton", "Junheng Li", "Lizhi Yang", "Aaron D. Ames"], "title": "Walk the PLANC: Physics-Guided RL for Agile Humanoid Locomotion on Constrained Footholds", "comment": null, "summary": "Bipedal humanoid robots must precisely coordinate balance, timing, and contact decisions when locomoting on constrained footholds such as stepping stones, beams, and planks -- even minor errors can lead to catastrophic failure. Classical optimization and control pipelines handle these constraints well but depend on highly accurate mathematical representations of terrain geometry, making them prone to error when perception is noisy or incomplete. Meanwhile, reinforcement learning has shown strong resilience to disturbances and modeling errors, yet end-to-end policies rarely discover the precise foothold placement and step sequencing required for discontinuous terrain. These contrasting limitations motivate approaches that guide learning with physics-based structure rather than relying purely on reward shaping. In this work, we introduce a locomotion framework in which a reduced-order stepping planner supplies dynamically consistent motion targets that steer the RL training process via Control Lyapunov Function (CLF) rewards. This combination of structured footstep planning and data-driven adaptation produces accurate, agile, and hardware-validated stepping-stone locomotion on a humanoid robot, substantially improving reliability compared to conventional model-free reinforcement-learning baselines.", "AI": {"tldr": "本文提出了一种结合了基于物理的步态规划和强化学习的机器人行走框架，用于在不规则地形（如踏脚石）上实现精确、敏捷和可靠的双足行走。", "motivation": "传统的优化和控制方法在处理有噪声或不完整的地形感知数据时容易出错；而纯粹的强化学习难以在不规则地形上学习到精确的落脚点选择和步序规划。因此，需要一种能够结合两者优点的方法。", "method": "该框架使用一个简化的步态规划器生成动态一致的运动目标，并通过控制李亚普诺夫函数（CLF）奖励来引导强化学习（RL）训练过程。这种方法结合了结构化的步态规划和数据驱动的自适应。", "result": "该框架在人形机器人上实现了精确、敏捷的踏脚石行走，并且在硬件上得到了验证，相比于传统的无模型强化学习方法，显著提高了可靠性。", "conclusion": "结合结构化的步态规划和强化学习是一种有效的方法，可以克服在不规则地形上机器人行走所面临的挑战，实现更可靠、更敏捷的运动。"}}
{"id": "2601.06515", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06515", "abs": "https://arxiv.org/abs/2601.06515", "authors": ["Lingrui Chen", "Xu Zhang", "Fanpeng Song", "Fang Wang", "Cunquan Qu", "Zhixin Liu"], "title": "Convergence Analysis of Weighted Median Opinion Dynamics with Higher-Order Effects", "comment": null, "summary": "The weighted median mechanism provides a robust alternative to weighted averaging in opinion dynamics. Existing models, however, are predominantly formulated on pairwise interaction graphs, which limits their ability to represent higher-order environmental effects. In this work, a generalized weighted median opinion dynamics model is proposed by incorporating high-order interactions through a simplicial complex representation. The resulting dynamics are formulated as a nonlinear discrete-time system with synchronous opinion updates, in which intrinsic agent interactions and external environmental influences are jointly modeled. Sufficient conditions for asymptotic consensus are established for heterogeneous systems composed of opinionated and unopinionated agents. For homogeneous opinionated systems, convergence and convergence rates are rigorously analyzed using the Banach fixed-point theorem. Theoretical results demonstrate the stability of the proposed dynamics under mild conditions, and numerical simulations are provided to corroborate the analysis. This work extends median-based opinion dynamics to high-order interaction settings and provides a system-level framework for stability and consensus analysis.", "AI": {"tldr": "本文提出了一种考虑高阶交互的加权中值意见动力学模型，并通过理论分析和数值模拟证明了其在达成共识方面的稳定性和收敛性。", "motivation": "现有意见动力学模型主要基于成对交互，难以表示高阶环境效应，促使研究者提出考虑高阶交互的改进模型。", "method": "使用单纯复形表示来纳入高阶交互，将意见动力学形式化为非线性离散时间同步更新系统，并利用Banach不动点定理分析收敛性。", "result": "为异构系统（包含有观点和无观点代理）建立了渐进共识的充分条件，并对同质有观点系统进行了收敛性和收敛速率的严格分析，证明了模型在温和条件下的稳定性。", "conclusion": "该研究将基于中值的意见动力学扩展到高阶交互场景，并提供了一个用于稳定性和共识分析的系统级框架。"}}
{"id": "2601.06415", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06415", "abs": "https://arxiv.org/abs/2601.06415", "authors": ["Nathan Pascal Walus", "Ranulfo Bezerra", "Shotaro Kojima", "Tsige Tadesse Alemayoh", "Satoshi Tadokoro", "Kazunori Ohno"], "title": "Semantic Enrichment of CAD-Based Industrial Environments via Scene Graphs for Simulation and Reasoning", "comment": "Accepted to IEEE SSRR 2025", "summary": "Utilizing functional elements in an industrial environment, such as displays and interactive valves, provide effective possibilities for robot training. When preparing simulations for robots or applications that involve high-level scene understanding, the simulation environment must be equally detailed. Although CAD files for such environments deliver an exact description of the geometry and visuals, they usually lack semantic, relational and functional information, thus limiting the simulation and training possibilities. A 3D scene graph can organize semantic, spatial and functional information by enriching the environment through a Large Vision-Language Model (LVLM). In this paper we present an offline approach to creating detailed 3D scene graphs from CAD environments. This will serve as a foundation to include the relations of functional and actionable elements, which then can be used for dynamic simulation and reasoning. Key results of this research include both quantitative results of the generated semantic labels as well as qualitative results of the scene graph, especially in hindsight of pipe structures and identified functional relations. All code, results and the environment will be made available at https://cad-scenegraph.github.io", "AI": {"tldr": "本研究提出一种离线方法，利用大型视觉语言模型（LVLM）为工业CAD环境生成详细的3D场景图，以包含功能和可操作元素的语义、空间和功能信息，从而支持机器人训练和动态模拟。", "motivation": "现有的CAD文件缺乏语义、关系和功能信息，限制了机器人仿真和训练的可能性，尤其是在需要高级场景理解的应用中。", "method": "利用大型视觉语言模型（LVLM）对工业CAD环境进行处理，生成包含语义、空间和功能信息的3D场景图，重点关注管道结构和功能关系。", "result": "生成了包含详细语义标签的3D场景图，并在管道结构和功能关系方面取得了定性和定量上的良好结果。", "conclusion": "通过为工业CAD环境创建详细的3D场景图，可以丰富功能和可操作元素的语义、空间和功能信息，为动态仿真和推理奠定基础，从而增强机器人训练能力。"}}
{"id": "2601.06097", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06097", "abs": "https://arxiv.org/abs/2601.06097", "authors": ["Aradhya Dixit", "Tianxi Liang"], "title": "Semantic Event Graphs for Long-Form Video Question Answering", "comment": "7 pages, 6 figures", "summary": "Long-form video question answering remains challenging for modern vision-language models, which struggle to reason over hour-scale footage without exceeding practical token and compute budgets. Existing systems typically downsample frames or feed dense visual embeddings to large-context language models, trading off temporal coverage against cost. We propose Semantic Event Graphs (SEG), a lightweight symbolic interface between video and language that replaces raw frames with compact temporal interaction logs. Our pipeline detects and tracks objects with YOLOv11, converts proximity patterns into START/END human-object events, and organizes them into a Temporal Scene Graph (TSG). At inference time, a query-aware pruning module identifies anchor entities and lexically relevant events, returning only a small subgraph which is verbalized and passed to Gemini 2.5 Flash for answer generation. On five YouTube videos (300-500 interactions each) and 120 automatically generated long-horizon questions, SEG achieves 65.0% accuracy using only 3.47k tokens per query, closely matching a full-log baseline (62.5% at 40.39k tokens) while reducing token usage by 91.4%. A short-context baseline restricted to the last 30 seconds collapses to 2.5% accuracy, underscoring the need for explicit temporal memory. These results show that symbolic temporal graphs can serve as an effective, plug-and-play memory layer for off-the-shelf vision-language models, preserving long-range reasoning ability while making long-form video question answering substantially more token- and cost-efficient. Code, logs, and event-extraction tools will be released for reproducibility.", "AI": {"tldr": "本文提出了一种名为语义事件图（SEG）的新方法，通过将视频帧转换为紧凑的事件交互日志，有效解决了长视频问答中模型面临的计算和内存限制问题，实现了高准确率和显著的效率提升。", "motivation": "现代视觉语言模型在处理长视频时，由于计算和内存限制，难以进行长时序推理。现有方法通过降采样或密集视觉嵌入来权衡时间覆盖度和成本。", "method": "该方法首先使用YOLOv11检测和跟踪对象，将对象间的时空模式转换为START/END人类-对象事件，并组织成时间场景图（TSG）。在推理时，通过查询感知的剪枝模块识别关键实体和相关事件，仅提取一个小的子图，然后将其转化为文本并输入给Gemini 2.5 Flash进行答案生成。", "result": "在五个YouTube视频和120个长时域问题上，SEG实现了65.0%的准确率，而每查询仅使用3.47k个token，显著优于使用40.39k token的全日志基线（62.5%）， token使用量减少了91.4%。短时序基线（仅使用最后30秒）准确率仅为2.5%，表明显式时序记忆的重要性。", "conclusion": "本文证明了符号时序图可以作为一种有效的、即插即用的记忆层，用于现成的视觉语言模型，在保持长时域推理能力的同时，显著提高了长视频问答的token和成本效率。"}}
{"id": "2601.06102", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06102", "abs": "https://arxiv.org/abs/2601.06102", "authors": ["Truong Xuan Khanh", "Truong Quynh Hoa"], "title": "Dynamic Intelligence Ceilings: Measuring Long-Horizon Limits of Planning and Creativity in Artificial Systems", "comment": "This paper introduces a trajectory-centric evaluation framework for analyzing long-horizon intelligence limits in artificial systems, focusing on developmental behavior, planning, and structural creativity rather than proposing new learning algorithms. 11 pages, 2 figures", "summary": "Recent advances in artificial intelligence have produced systems capable of remarkable performance across a wide range of tasks. These gains, however, are increasingly accompanied by concerns regarding long-horizon developmental behavior, as many systems converge toward repetitive solution patterns rather than sustained growth.\n  We argue that a central limitation of contemporary AI systems lies not in capability per se, but in the premature fixation of their performance frontier. To address this issue, we introduce the concept of a \\emph{Dynamic Intelligence Ceiling} (DIC), defined as the highest level of effective intelligence attainable by a system at a given time under its current resources, internal intent, and structural configuration.\n  To make this notion empirically tractable, we propose a trajectory-centric evaluation framework that measures intelligence as a moving frontier rather than a static snapshot. We operationalize DIC using two estimators: the \\emph{Progressive Difficulty Ceiling} (PDC), which captures the maximal reliably solvable difficulty under constrained resources, and the \\emph{Ceiling Drift Rate} (CDR), which quantifies the temporal evolution of this frontier. These estimators are instantiated through a procedurally generated benchmark that jointly evaluates long-horizon planning and structural creativity within a single controlled environment.\n  Our results reveal a qualitative distinction between systems that deepen exploitation within a fixed solution manifold and those that sustain frontier expansion over time. Importantly, our framework does not posit unbounded intelligence, but reframes limits as dynamic and trajectory-dependent rather than static and prematurely fixed.\n  \\vspace{0.5em} \\noindent\\textbf{Keywords:} AI evaluation, planning and creativity, developmental intelligence, dynamic intelligence ceilings, complex adaptive systems", "AI": {"tldr": "本文提出了动态智能天花板（DIC）的概念，用于衡量AI系统在特定资源、意图和结构下的最高有效智能水平，并引入了渐进难度天花板（PDC）和天花板漂移率（CDR）来量化这一概念，以评估AI系统的长期发展和结构创造力。", "motivation": "当前AI系统在很多任务上表现出色，但普遍存在长期发展行为中的问题，即系统倾向于收敛于重复性的解决方案，而非持续增长。这表明当代AI系统的局限性不在于能力本身，而在于其性能边界过早固定。", "method": "提出“动态智能天花板”（DIC）的概念，并设计了一个以轨迹为中心的评估框架。该框架使用“渐进难度天花板”（PDC）和“天花板漂移率”（CDR）两个估计器来衡量智能的动态变化，并通过一个程序化生成的基准测试来共同评估长期规划和结构创造力。", "result": "研究结果揭示了两种不同类型的系统：一种在固定的解决方案流形内深化开发，另一种则能持续扩展其性能边界。该框架表明，智能的极限是动态的、依赖于轨迹的，而不是静态且过早固定的。", "conclusion": "本文通过引入动态智能天花板（DIC）的概念和一套新的评估方法，为理解和解决AI系统长期发展行为问题提供了新的视角，强调了动态而非静态的性能边界对于AI持续进步的重要性。"}}
{"id": "2601.06041", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06041", "abs": "https://arxiv.org/abs/2601.06041", "authors": ["Pramit Bhattacharyya", "Arnab Bhattacharya"], "title": "Lexical and Statistical Analysis of Bangla Newspaper and Literature: A Corpus-Driven Study on Diversity, Readability, and NLP Adaptation", "comment": null, "summary": "In this paper, we present a comprehensive corpus-driven analysis of Bangla literary and newspaper texts to investigate their lexical diversity, structural complexity and readability. We undertook Vacaspati and IndicCorp, which are the most extensive literature and newspaper-only corpora for Bangla. We examine key linguistic properties, including the type-token ratio (TTR), hapax legomena ratio (HLR), Bigram diversity, average syllable and word lengths, and adherence to Zipfs Law, for both newspaper (IndicCorp) and literary corpora (Vacaspati).For all the features, such as Bigram Diversity and HLR, despite its smaller size, the literary corpus exhibits significantly higher lexical richness and structural variation. Additionally, we tried to understand the diversity of corpora by building n-gram models and measuring perplexity. Our findings reveal that literary corpora have higher perplexity than newspaper corpora, even for similar sentence sizes. This trend can also be observed for the English newspaper and literature corpus, indicating its generalizability. We also examined how the perfor- mance of models on downstream tasks is influenced by the inclusion of literary data alongside newspaper data. Our findings suggest that inte- grating literary data with newspapers improves the performance of models on various downstream tasks. We have also demonstrated that a literary corpus adheres more closely to global word distribution proper- ties, such as Zipfs law, than a newspaper corpus or a merged corpus of both literary and newspaper texts. Literature corpora also have higher entropy and lower redundancy values compared to a newspaper corpus. We also further assess the readability using Flesch and Coleman-Liau in- dices, showing that literary texts are more complex.", "AI": {"tldr": "本研究对孟加拉语文学和报纸语料库进行了词汇多样性、结构复杂性和可读性的分析，发现文学语料库在词汇丰富度、结构变异性和模型困惑度上均高于报纸语料库。整合文学数据能提升下游任务的模型性能，并且文学语料库更符合齐夫定律。", "motivation": "研究动机是为了全面分析孟加拉语文学和报纸文本在词汇多样性、结构复杂性和可读性方面的差异，并探索整合文学数据对自然语言处理模型性能的影响。", "method": "研究者使用了Vacaspati（文学语料库）和IndicCorp（报纸语料库）这两个大型孟加拉语语料库。通过计算词汇丰富度指标（如TTR、HLR）、结构复杂度指标（如Bigram多样性、平均音节和词长、齐夫定律遵循度、熵和冗余度）以及可读性指标（Flesch和Coleman-Liau指数）来分析语料库。此外，还构建了n-gram模型来衡量困惑度，并评估了整合文学数据对下游任务模型性能的影响。", "result": "文学语料库（Vacaspati）在词汇丰富度（如Bigram多样性、HLR）和结构变异性方面显著高于报纸语料库（IndicCorp）。文学语料库的模型困惑度也更高，表明其预测难度更大。整合文学数据可以提高模型在各种下游任务上的性能。文学语料库更符合齐夫定律，且熵更高、冗余度更低。文学文本的可读性指数显示其复杂度高于报纸文本。", "conclusion": "孟加拉语文学文本比报纸文本在词汇和结构上更加多样和复杂。将文学数据融入文本数据可以提升自然语言处理模型的性能。文学文本的语言特性使其更具信息量和预测难度。"}}
{"id": "2601.06451", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06451", "abs": "https://arxiv.org/abs/2601.06451", "authors": ["Hyunseo Koh", "Chang-Yong Song", "Youngjae Choi", "Misa Viveiros", "David Hyde", "Heewon Kim"], "title": "CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method", "comment": "16 pages; 15 figures; 5 tables", "summary": "Food cutting is a highly practical yet underexplored application at the intersection of vision and robotic manipulation. The task remains challenging because interactions between the knife and deformable materials are highly nonlinear and often entail large deformations, frequent contact, and topological change, which in turn hinder stable and safe large-scale data collection.\n  To address these challenges, we propose a unified framework that couples a vision-language-action (VLA) dataset with a physically realistic cutting simulator built on the material point method (MPM). Our simulator adopts MLS-MPM as its computational core, reducing numerical dissipation and energy drift while preserving rotational and shear responses even under topology-changing cuts. During cutting, forces and stress distributions are estimated from impulse exchanges between particles and the grid, enabling stable tracking of transient contact forces and energy transfer.\n  We also provide a benchmark dataset that integrates diverse cutting trajectories, multi-view visual observations, and fine-grained language instructions, together with force--torque and tool--pose labels to provide physically consistent training signals.\n  These components realize a learning--evaluation loop that respects the core physics of cutting and establishes a safe, reproducible, and scalable foundation for advancing VLA models in deformable object manipulation.", "AI": {"tldr": "该研究提出了一种结合视觉-语言-动作（VLA）数据集和基于材料点法（MPM）的物理模拟器来解决机器人切食物的挑战，实现了可扩展的学习-评估循环。", "motivation": "食物切割是机器人操作中一个实际但未被充分探索的应用，由于材料的非线性变形、大形变、频繁接触和拓扑变化，数据收集和算法开发具有挑战性。", "method": "研究者开发了一个统一框架，该框架结合了一个视觉-语言-动作（VLA）数据集和一个基于材料点法（MPM）的物理切削模拟器。模拟器使用MLS-MPM作为核心，并从粒子-网格的冲量交换中估算力与应力，以实现对瞬态接触力和能量的稳定跟踪。同时，研究者构建了一个包含多样化切削轨迹、多视角视觉观察、精细语言指令以及力-扭矩和工具位姿标签的数据集。", "result": "该框架能够进行物理上准确的切削模拟，并提供用于训练VLA模型的物理一致性训练信号，从而建立了一个安全、可复现且可扩展的学习-评估循环。", "conclusion": "提出的VLA数据集和MPM模拟器框架为推动可变形物体操作中的VLA模型发展提供了一个坚实的基础，解决了食物切割任务中的关键挑战。"}}
{"id": "2601.06540", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06540", "abs": "https://arxiv.org/abs/2601.06540", "authors": ["Roya Khalili Amirabadi", "Mohsen Jalaeian Farimani", "Omid Solaymani Fard"], "title": "Self-Organizing Dual-Buffer Adaptive Clustering Experience Replay (SODASER) for Safe Reinforcement Learning in Optimal Control", "comment": "Also available at SSRN: https://ssrn.com/abstract=5191427 or http://dx.doi.org/10.2139/ssrn.5191427", "summary": "This paper proposes a novel reinforcement learning framework, named Self-Organizing Dual-buffer Adaptive Clustering Experience Replay (SODACER), designed to achieve safe and scalable optimal control of nonlinear systems. The proposed SODACER mechanism consisting of a Fast-Buffer for rapid adaptation to recent experiences and a Slow-Buffer equipped with a self-organizing adaptive clustering mechanism to maintain diverse and non-redundant historical experiences. The adaptive clustering mechanism dynamically prunes redundant samples, optimizing memory efficiency while retaining critical environmental patterns. The approach integrates SODASER with Control Barrier Functions (CBFs) to guarantee safety by enforcing state and input constraints throughout the learning process. To enhance convergence and stability, the framework is combined with the Sophia optimizer, enabling adaptive second-order gradient updates. The proposed SODACER-Sophia's architecture ensures reliable, effective, and robust learning in dynamic, safety-critical environments, offering a generalizable solution for applications in robotics, healthcare, and large-scale system optimization. The proposed approach is validated on a nonlinear Human Papillomavirus (HPV) transmission model with multiple control inputs and safety constraints. Comparative evaluations against random and clustering-based experience replay methods demonstrate that SODACER achieves faster convergence, improved sample efficiency, and a superior bias-variance trade-off, while maintaining safe system trajectories, validated via the Friedman test.", "AI": {"tldr": "本文提出了一种名为SODACER的新型强化学习框架，通过双缓冲（快速缓冲和慢速缓冲）和自组织自适应聚类机制来提高经验回放的效率和多样性，并结合控制障碍函数（CBFs）和Sophia优化器来确保安全性和收敛性。实验证明，SODACER在HPV传播模型上表现出更快的收敛速度、更高的样本效率和更好的偏差-方差权衡，同时保持了安全性。", "motivation": "为了实现非线性系统安全且可扩展的最优控制，需要一种能够有效处理近期经验、保留历史多样性、优化内存使用并保证安全约束的强化学习框架。", "method": "提出SODACER框架，包含一个快速缓冲用于近期经验，一个慢速缓冲结合自组织自适应聚类机制用于维护多样化、非冗余的历史经验。同时，将SODACER与控制障碍函数（CBFs）集成以保证安全性，并结合Sophia优化器以提高收敛性和稳定性。框架在非线性HPV传播模型上进行了验证。", "result": "SODACER-Sophia架构能够实现可靠、有效且鲁棒的学习。与随机和基于聚类的经验回放方法相比，SODACER实现了更快的收敛速度、更高的样本效率和更好的偏差-方差权衡，同时保持了安全的系统轨迹，并通过Friedman检验得到了验证。", "conclusion": "SODACER是一种新颖的强化学习框架，通过其独特的经验回放机制和安全保证方法，能够有效地解决非线性系统的安全最优控制问题，并具有良好的通用性，适用于机器人、医疗保健和大规模系统优化等领域。"}}
{"id": "2601.06122", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06122", "abs": "https://arxiv.org/abs/2601.06122", "authors": ["Canming Xia", "Peixi Peng", "Guang Tan", "Zhan Su", "Haoran Xu", "Zhenxian Liu", "Luntong Li"], "title": "COVR:Collaborative Optimization of VLMs and RL Agent for Visual-Based Control", "comment": "The paper was accepted by the Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Visual reinforcement learning (RL) suffers from poor sample efficiency due to high-dimensional observations in complex tasks. While existing works have shown that vision-language models (VLMs) can assist RL, they often focus on knowledge distillation from the VLM to RL, overlooking the potential of RL-generated interaction data to enhance the VLM. To address this, we propose COVR, a collaborative optimization framework that enables the mutual enhancement of the VLM and RL policies. Specifically, COVR fine-tunes the VLM with RL-generated data to enhance the semantic reasoning ability consistent with the target task, and uses the enhanced VLM to further guide policy learning via action priors. To improve fine-tuning efficiency, we introduce two key modules: (1) an Exploration-Driven Dynamic Filter module that preserves valuable exploration samples using adaptive thresholds based on the degree of exploration, and (2) a Return-Aware Adaptive Loss Weight module that improves the stability of training by quantifying the inconsistency of sampling actions via return signals of RL. We further design a progressive fine-tuning strategy to reduce resource consumption. Extensive experiments show that COVR achieves strong performance across various challenging visual control tasks.", "AI": {"tldr": "提出了一种名为COVR的协同优化框架，通过RL生成的数据增强视觉语言模型（VLM），并利用增强后的VLM指导RL策略学习，从而提升视觉强化学习的样本效率。引入了探索驱动的动态滤波器和回报感知的自适应损失权重模块来提高微调效率。", "motivation": "现有视觉强化学习（RL）由于高维观测而样本效率低下。虽然VLM可以辅助RL，但它们通常只关注知识蒸馏，忽视了RL交互数据增强VLM的潜力。", "method": "COVR框架通过RL生成的数据微调VLM，以增强与目标任务一致的语义推理能力，并利用增强后的VLM通过动作先验进一步指导策略学习。为了提高微调效率，引入了探索驱动的动态滤波器（根据探索程度自适应阈值保留样本）和回报感知的自适应损失权重（通过回报信号量化采样动作不一致性来提高训练稳定性）。此外，还设计了渐进式微调策略以减少资源消耗。", "result": "COVR在各种具有挑战性的视觉控制任务上取得了强大的性能。", "conclusion": "COVR框架能够通过RL和VLM的协同优化，实现相互增强，有效提升视觉强化学习的样本效率和性能。"}}
{"id": "2601.06465", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.06465", "abs": "https://arxiv.org/abs/2601.06465", "authors": ["Hao Li", "Xinqi Liu", "Yaoqing Jin"], "title": "R$^3$D: Regional-guided Residual Radar Diffusion", "comment": "6 pages, 4 figures", "summary": "Millimeter-wave radar enables robust environment perception in autonomous systems under adverse conditions yet suffers from sparse, noisy point clouds with low angular resolution. Existing diffusion-based radar enhancement methods either incur high learning complexity by modeling full LiDAR distributions or fail to prioritize critical structures due to uniform regional processing. To address these issues, we propose R3D, a regional-guided residual radar diffusion framework that integrates residual diffusion modeling-focusing on the concentrated LiDAR-radar residual encoding complementary high-frequency details to reduce learning difficulty-and sigma-adaptive regional guidance-leveraging radar-specific signal properties to generate attention maps and applying lightweight guidance only in low-noise stages to avoid gradient imbalance while refining key regions. Extensive experiments on the ColoRadar dataset demonstrate that R3D outperforms state-of-the-art methods, providing a practical solution for radar perception enhancement. Our anonymous code and pretrained models are released here: https://anonymous.4open.science/r/r3d-F836", "AI": {"tldr": "提出了一种名为R3D的区域引导残差雷达扩散框架，用于增强毫米波雷达点云，解决了现有方法学习复杂度和均匀处理问题，并在ColoRadar数据集上取得了优于现有技术的性能。", "motivation": "现有基于扩散的雷达增强方法存在学习复杂性高（建模完整的LiDAR分布）或忽略关键结构（均匀区域处理）的问题。毫米波雷达在恶劣天气下具有优势，但其点云稀疏、噪声大且角分辨率低，需要有效的增强方法。", "method": "R3D框架结合了残差扩散建模和Sigma自适应区域引导。残差扩散模型专注于学习LiDAR和雷达之间的残差，捕捉高频细节，降低学习难度。Sigma自适应区域引导利用雷达信号特性生成注意力图，并在低噪声阶段进行轻量级引导，避免梯度不平衡，同时精炼关键区域。", "result": "在ColoRadar数据集上的大量实验表明，R3D在雷达点云增强方面优于当前最先进的方法。", "conclusion": "R3D提供了一种有效的雷达感知增强的实用解决方案，通过残差扩散和区域引导的结合，能够处理雷达点云的稀疏性和噪声问题，并提升关键区域的细节。"}}
{"id": "2601.06104", "categories": ["cs.AI", "cs.CL", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.06104", "abs": "https://arxiv.org/abs/2601.06104", "authors": ["Krzysztof Sienicki"], "title": "Comment on arXiv:2511.21731v1: Identifying Quantum Structure in AI Language: Evidence for Evolutionary Convergence of Human and Artificial Cognition", "comment": "5 pages, 11 references", "summary": "This note is a friendly technical check of arXiv:2511.21731v1. I highlight a few places where the manuscript's interpretation of (i) the reported CHSH/Bell-type calculations and (ii) Bose--Einstein (BE) fits to rank-frequency data seems to go beyond what the stated procedures can firmly support. I also point out one internal inconsistency in the \"energy-level spacing\" analogy. The aim is constructive: to keep the interesting empirical observations, while making clear what they do (and do not) imply about quantum entanglement in the usual Hilbert-space sense, especially when \"energy\" is defined by rank.", "AI": {"tldr": "本文对 arXiv:2511.21731v1 进行了技术性审阅，指出其对 CHSH/贝尔类型计算和 Bose-Einstein (BE) 拟合等级频率数据的解释可能超出了所述方法的支持范围，并指出了“能级间隔”类比中的一个内部不一致之处，旨在区分经验观察和量子纠缠的明确含义。", "motivation": "作者旨在对 arXiv:2511.21731v1 的技术内容进行友好审阅，特别是关于 CHSH/贝尔类型计算和 BE 拟合等级频率数据的解释，并澄清这些解释与所用方法的支持程度，同时纠正一个内部不一致之处。", "method": "作者通过对 arXiv:2511.21731v1 的 CHSH/贝尔类型计算、Bose-Einstein (BE) 拟合等级频率数据以及“能级间隔”类比进行技术性检查和分析。", "result": "作者指出了该论文中对 CHSH/贝尔类型计算和 BE 拟合的解释可能超出其方法论支持的范围，并发现了一个内部不一致之处。", "conclusion": "该论文的经验观察是有趣的，但其解释（尤其是在“能量”定义为秩的情况下）在多大程度上支持量子纠缠（在标准希尔伯特空间意义上）需要更清晰的界定。"}}
{"id": "2601.06052", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06052", "abs": "https://arxiv.org/abs/2601.06052", "authors": ["Hanyu Li", "Jiangshan Duo", "Bofei Gao", "Hailin Zhang", "Sujian Li", "Xiaotie Deng", "Liang Zhao"], "title": "Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization", "comment": null, "summary": "Chain-of-thought reasoning in large language models often creates an \"overthinking trap,\" leading to excessive computational cost and latency for unreliable accuracy gains. Prior work has typically relied on global, static controls that risk penalizing necessary reasoning. We introduce a sample-level, soft reinforcement learning compression method that penalizes inefficiently long rollouts, but only on problems where the model has already mastered and already produced a more concise rollout. Our experiments show that this method reduces average response length by 20-40% with comparable or higher accuracy. Crucially, the compression exhibits strong cross-domain generalization; a model trained on math spontaneously shortens responses on unseen tasks like code, instruction following, and general knowledge QA, with stable or improved accuracy. We demonstrate a stable post-training curriculum (accuracy-compression-accuracy) that can ultimately produce models that are more accurate and reason more concisely, arguing that such compression method should be a standard phase in developing efficient reasoning models.", "AI": {"tldr": "本文提出了一种基于样本的、软强化学习的推理压缩方法，旨在解决大型语言模型（LLM）的“过度思考陷阱”问题。该方法通过只对模型已掌握且能产生更简洁推理过程的问题进行惩罚，从而减少了不必要的计算成本和延迟，同时保持或提高了准确性。实验证明，该方法能显著缩短响应长度（20-40%），且具备跨领域泛化能力。作者建议将此压缩方法作为开发高效推理模型的标准阶段。", "motivation": "大型语言模型在进行链式思考（Chain-of-thought）推理时，常常会陷入“过度思考陷阱”，导致计算成本和延迟过高，而准确性提升有限。现有的全局、静态控制方法可能过度惩罚必要的推理步骤。", "method": "本文提出了一种基于样本的、软强化学习的推理压缩方法。该方法通过对模型在已掌握且能产生更简洁推理过程的问题上进行惩罚，以减少冗长的推理过程（rollouts）。具体来说，它只对那些模型已经能够更简洁地解决的问题进行“惩罚”，从而鼓励模型在必要时才进行深入推理。", "result": "该方法平均将响应长度减少了 20-40%，同时保持了可比甚至更高的准确性。更重要的是，这种压缩方法表现出很强的跨领域泛化能力：在数学任务上训练的模型，在处理未见过的代码、指令遵循和常识问答等任务时，也能自发地缩短响应长度，并且准确性保持稳定或有所提高。通过一个准确率-压缩-准确率的稳定训练课程，可以获得更准确且推理更简洁的模型。", "conclusion": "所提出的样本级软强化学习压缩方法能够有效解决LLM的“过度思考陷阱”，在不牺牲准确性的前提下显著提高推理效率。该方法具有良好的跨领域泛化能力，并可作为开发高效推理模型的标准后训练阶段。"}}
{"id": "2601.06508", "categories": ["cs.RO", "cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06508", "abs": "https://arxiv.org/abs/2601.06508", "authors": ["Andrei A. Korigodskii", "Artem E. Vasiunik", "Georgii A. Varin", "Adilia M. Zukhurova", "Matvei V. Urvantsev", "Semen A. Osipenkov", "Igor S. Efremov", "Georgii E. Bondar"], "title": "Precision Meets Art: Autonomous Multi-UAV System for Large Scale Mural Drawing", "comment": "6 pages, 9 figures", "summary": "The integration of autonomous unmanned aerial vehicles (UAVs) into large-scale artistic projects has emerged as a new application in robotics. This paper presents the design, deployment, and testing of a novel multi-drone system for automated mural painting in outdoor settings. This technology makes use of new software that coordinates multiple drones simultaneously, utilizing state-machine algorithms for task execution. Key advancements are the complex positioning system that combines 2D localization using a single motion tracking camera with onboard LiDAR for precise positioning, and a novel flight control algorithm, which works differently along the trajectory and normally to it, ensuring smoothness and high precision of the drawings at the same time. A 100 square meters mural was created using the developed multi-drone system, validating the system's efficacy. Compared to single-drone approaches, our multi-UAV solution significantly improves scalability and operational speed while maintaining high stability even in harsh weather conditions. The findings highlight the potential of autonomous robotic swarms in creative applications, paving the way for further advancements in large-scale robotic art.", "AI": {"tldr": "本文提出了一种多无人机协作系统，用于户外大型壁画自动化绘制，该系统通过先进的定位和控制算法实现了高精度和可扩展性。", "motivation": "将自主无人机集成到大型艺术项目中，探索机器人技术在创意领域的应用。", "method": "设计并测试了一个多无人机系统，采用基于状态机的软件进行任务协调，结合2D运动追踪和机载LiDAR实现复杂定位，并开发了一种新的飞行控制算法来确保轨迹的平滑性和绘制精度。", "result": "成功使用该系统绘制了100平方米的壁画，证明了其有效性。与单无人机方法相比，该多无人机系统在可扩展性、操作速度和稳定性方面表现更优，即使在恶劣天气下也能保持高稳定性。", "conclusion": "自主机器人群在创意应用方面具有巨大潜力，为大型机器人艺术的发展开辟了新的可能性。"}}
{"id": "2601.06138", "categories": ["cs.CV", "cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06138", "abs": "https://arxiv.org/abs/2601.06138", "authors": ["Sao Mai Nguyen"], "title": "Low-Back Pain Physical Rehabilitation by Movement Analysis in Clinical Trial", "comment": "ICMST, Tokyo University of Science; Taiwanese Society of Movement Science and Technology; Research institute for Science and Technology, Nov 2025, Tokyo, Japan", "summary": "To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises and benchmark on state of the art human movement analysis algorithms. This dataset is valuable because it includes rehabilitation motions in a clinical setting with patients in their rehabilitation program. This paper introduces the Keraal dataset, a clinically collected dataset to enable intelligent tutoring systems (ITS) for rehabilitation. It addresses four challenges in exercise monitoring: motion assessment, error recognition, spatial localization, temporal localization", "AI": {"tldr": "本文介绍了一个用于低背痛康复的临床患者运动数据集（Keraal数据集），并针对其在运动评估、错误识别、空间和时间定位方面的挑战进行了基准测试。", "motivation": "为了开发和评估智能辅导系统（ITS）在物理康复中的应用，需要一个包含临床患者康复运动的真实数据集。", "method": "构建并发布了Keraal数据集，该数据集包含了低背痛患者进行康复运动的临床记录。对当前最先进的人体运动分析算法进行了基准测试。", "result": "Keraal数据集提供了在临床环境中收集的康复运动数据，可以用于评估和开发ITS。研究人员对该数据集在运动评估、错误识别、空间定位和时间定位这四个挑战上的表现进行了基准测试。", "conclusion": "Keraal数据集是一个宝贵的资源，能够促进智能辅导系统在低背痛康复领域的进一步发展和评估。该数据集为解决康复运动监测中的关键技术挑战提供了基础。"}}
{"id": "2601.06726", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06726", "abs": "https://arxiv.org/abs/2601.06726", "authors": ["Mohammad Khateri", "Morteza Ghahremani", "Sergio Valencia", "Camilo Jaimes", "Alejandra Sierra", "Jussi Tohka", "P. Ellen Grant", "Davood Karimi"], "title": "USFetal: Tools for Fetal Brain Ultrasound Compounding", "comment": null, "summary": "Ultrasound offers a safe, cost-effective, and widely accessible technology for fetal brain imaging, making it especially suitable for routine clinical use. However, it suffers from view-dependent artifacts, operator variability, and a limited field of view, which make interpretation and quantitative evaluation challenging. Ultrasound compounding aims to overcome these limitations by integrating complementary information from multiple 3D acquisitions into a single, coherent volumetric representation. This work provides four main contributions: (1) We present the first systematic categorization of computational strategies for fetal brain ultrasound compounding, including both classical techniques and modern learning-based frameworks. (2) We implement and compare representative methods across four key categories - multi-scale, transformation-based, variational, and deep learning approaches - emphasizing their core principles and practical advantages. (3) Motivated by the lack of full-view, artifact-free ground truth required for supervised learning, we focus on unsupervised and self-supervised strategies and introduce two new deep learning based approaches: a self-supervised compounding framework and an adaptation of unsupervised deep plug-and-play priors for compounding. (4) We conduct a comprehensive evaluation on ten multi-view fetal brain ultrasound datasets, using both expert radiologist scoring and standard quantitative image-quality metrics. We also release the USFetal Compounding Toolbox, publicly available to support benchmarking and future research. Keywords: Ultrasound compounding, fetal brain, deep learning, self-supervised, unsupervised.", "AI": {"tldr": "本研究提出了一种对胎儿脑部超声图像进行复合（compounding）的计算策略分类，并开发了两种新的基于深度学习的无监督和自监督方法，以克服传统方法的局限性，并在公开数据集上进行了评估。", "motivation": "传统胎儿脑部超声存在视场受限、伪影和操作者变异等问题，影响了图像解释和量化评估。超声复合旨在整合多个3D采集信息以获得更完整、无伪影的图像。", "method": "1. 系统性地对胎儿脑部超声复合的计算策略进行了分类。2. 实现了并比较了多尺度、基于变换、变分和深度学习等代表性方法。3. 重点研究了无监督和自监督策略，并提出了两种新的基于深度学习的复合方法：一种自监督复合框架和一种无监督深度即插即用先验的改编方法。4. 在10个多视角胎儿脑部超声数据集上进行了评估，使用了放射科医生评分和图像质量指标。同时发布了USFetal Compounding Toolbox。", "result": "研究中比较了不同复合方法的优缺点，并提出了新的深度学习方法。评估结果表明，所提出的方法在提高图像质量方面具有潜力。", "conclusion": "本研究为胎儿脑部超声复合提供了系统性的分类和新的深度学习解决方案，并公开了工具箱以促进未来研究。无监督和自监督方法对于解决缺乏标注数据的问题尤为重要。"}}
{"id": "2601.06054", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06054", "abs": "https://arxiv.org/abs/2601.06054", "authors": ["Alberto Purpura", "Emily Chen", "Swapnil Shinde"], "title": "A Multi-Stage Workflow for the Review of Marketing Content with Reasoning Large Language Models", "comment": null, "summary": "Reasoning Large Language Models (LLMs) have shown promising results when tasked with solving complex problems. In this paper, we propose and evaluate a multi-stage workflow that leverages the capabilities of fine-tuned reasoning LLMs to assist in the review process of marketing content, making sure they comply with a given list of requirements. The contributions of this paper are the following: (i) we present a novel approach -- that does not rely on any external knowledge representation -- for the automatic identification of compliance issues in textual content; (ii) compare the effectiveness of different fine-tuning strategies like Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) in training models to solve this problem; (iii) we evaluate the effectiveness of training small LLMs to generate reasoning tokens before providing their final response; (iv) we evaluate how the choice and combinations of different reward functions affects the performance of a model trained with GRPO.", "AI": {"tldr": "本文提出了一种利用微调的推理大语言模型（LLMs）来自动化营销内容合规性审查的多阶段工作流程，并比较了不同的微调策略和奖励函数的效果。", "motivation": "为了解决复杂问题的推理大语言模型（LLMs）在解决复杂问题方面展现出潜力，但其在营销内容审查中的应用尚未充分探索。本文旨在利用LLMs的推理能力，自动化营销内容合规性审查过程。", "method": "提出了一种无需外部知识表示的多阶段工作流程，利用微调的推理LLMs识别文本内容中的合规性问题。比较了监督微调（SFT）和组相对策略优化（GRPO）等不同微调策略的有效性。评估了训练小型LLMs生成推理令牌后再给出最终响应的效果。同时，评估了不同奖励函数及其组合对GRPO模型性能的影响。", "result": "文中并未直接给出实验结果，而是陈述了研究的评估内容，包括不同微调策略、生成推理令牌以及奖励函数组合对模型性能的影响。", "conclusion": "本文提出了一种新颖的、不依赖外部知识表示的自动识别文本内容合规性问题的方法。通过比较不同的微调策略（SFT, GRPO）和奖励函数，旨在优化LLMs在营销内容合规性审查中的表现，并探索了生成式推理令牌的有效性。"}}
{"id": "2601.06108", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06108", "abs": "https://arxiv.org/abs/2601.06108", "authors": ["Tarun Raheja", "Nilay Pochhi"], "title": "From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models", "comment": null, "summary": "Aligning large language models (LLMs) with human preferences has become essential for safe and beneficial AI deployment. While Reinforcement Learning from Human Feedback (RLHF) established the dominant paradigm, a proliferation of alternatives -- Direct Preference Optimization (DPO), Identity Preference Optimization (IPO), Kahneman-Tversky Optimization (KTO), Simple Preference Optimization (SimPO), and many others -- has left practitioners without clear guidance on method selection. This survey provides a \\textit{theoretical unification} of preference learning methods, revealing that the apparent diversity reduces to principled choices along three orthogonal axes: \\textbf{(I) Preference Model} (what likelihood model underlies the objective), \\textbf{(II) Regularization Mechanism} (how deviation from reference policies is controlled), and \\textbf{(III) Data Distribution} (online vs.\\ offline learning and coverage requirements). We formalize each axis with precise definitions and theorems, establishing key results including the coverage separation between online and offline methods, scaling laws for reward overoptimization, and conditions under which direct alignment methods fail. Our analysis reveals that failure modes -- length hacking, mode collapse, likelihood displacement -- arise from specific, predictable combinations of design choices. We synthesize empirical findings across 50+ papers and provide a practitioner's decision guide for method selection. The framework transforms preference learning from an empirical art into a theoretically grounded discipline.", "AI": {"tldr": "本文对当前流行的多种基于人类偏好的大语言模型（LLMs）对齐方法进行了理论统一，指出了它们在偏好模型、正则化机制和数据分布这三个关键维度上的差异，并提供了方法选择指南。", "motivation": "现有多种基于人类偏好的LLMs对齐方法（如RLHF, DPO, IPO等）使实践者难以选择合适的方法，因此需要一个统一的理论框架来指导方法选择。", "method": "文章提出了一个理论统一框架，将不同的方法归纳到三个正交维度：偏好模型、正则化机制和数据分布。通过精确定义和定理，分析了这些维度的影响，并得出了关于在线/离线方法覆盖范围、奖励过度优化和直接对齐方法失效条件的关键结果。", "result": "分析揭示了LLMs对齐中的常见失效模式（如长度攻击、模式崩溃、似然位移）是特定设计选择组合的预测性结果。该框架还包含了跨越50多篇论文的实证发现综合。", "conclusion": "该理论框架将人类偏好学习从经验性实践转变为一门理论驱动的学科，为实践者提供了方法选择的决策指南，并揭示了不同方法的设计选择如何影响模型的对齐效果和潜在的失效模式。"}}
{"id": "2601.06552", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.06552", "abs": "https://arxiv.org/abs/2601.06552", "authors": ["Britt Besch", "Tai Mai", "Jeremias Thun", "Markus Huff", "Jörn Vogel", "Freek Stulp", "Samuel Bustamante"], "title": "Model Reconciliation through Explainability and Collaborative Recovery in Assistive Robotics", "comment": null, "summary": "Whenever humans and robots work together, it is essential that unexpected robot behavior can be explained to the user. Especially in applications such as shared control the user and the robot must share the same model of the objects in the world, and the actions that can be performed on these objects.\n  In this paper, we achieve this with a so-called model reconciliation framework. We leverage a Large Language Model to predict and explain the difference between the robot's and the human's mental models, without the need of a formal mental model of the user. Furthermore, our framework aims to solve the model divergence after the explanation by allowing the human to correct the robot. We provide an implementation in an assistive robotics domain, where we conduct a set of experiments with a real wheelchair-based mobile manipulator and its digital twin.", "AI": {"tldr": "该论文提出了一种模型协调框架，利用大型语言模型来预测和解释人机在共享控制场景下的模型差异，并允许用户纠正机器人，以解决模型分歧问题。", "motivation": "在人机协作（特别是共享控制）中，用户需要理解机器人行为的异常，并且人与机器人应共享对世界物体和可执行动作的相同模型。", "method": "提出了一种模型协调框架，利用大型语言模型（LLM）预测和解释人机之间的模型差异，无需形式化用户心智模型。该框架还允许用户纠正机器人，以解决模型分歧。", "result": "在辅助机器人领域实现了一个实现，并在一个真实的轮椅式移动操作机器人及其数字孪生上进行了一系列实验。", "conclusion": "该模型协调框架能够通过LLM解释模型差异，并允许用户纠正，从而促进人机在共享控制场景下的模型一致性。"}}
{"id": "2601.06568", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06568", "abs": "https://arxiv.org/abs/2601.06568", "authors": ["Zimao Sheng"], "title": "Robustness Quantification of MIMO-PI Controller From the Perspective of \\(γ\\)-Dissipativity", "comment": "15 pages, 5 figures", "summary": "The proportional-integral-derivative (PID) controller and its variants are widely used in control engineering, but they often rely on linearization around equilibrium points and empirical parameter tuning, making them ineffective for multi-input-multi-output (MIMO) systems with strong coupling, intense external disturbances, and high nonlinearity. Moreover, existing methods rarely explore the intrinsic stabilization mechanism of PID controllers for disturbed nonlinear systems from the perspective of modern robust control theories such as dissipativity and $\\mathcal{L}_2$-gain. To address this gap, this study focuses on $γ$-dissipativity (partially equivalent to $\\mathcal{L}_2$-gain) and investigates the optimal parameter tuning of MIMO-PI controllers for general disturbed nonlinear MIMO systems. First, by integrating dissipativity theory with the Hamilton-Jacobi-Isaacs (HJI) inequality, sufficient conditions for the MIMO-PI-controlled system to achieve $γ$-dissipativity are established, and the degree of $γ$-dissipativity in a local region containing the origin is quantified. Second, an optimal parameter tuning strategy is proposed, which reformulates the $γ$-dissipativity optimization problem into a class of standard eigenvalue problems (EVPs) and further converts it into linear matrix inequality (LMI) formulations for efficient online computation. Comprehensive simulation experiments validate the effectiveness and optimality of the proposed approach. This work provides a theoretical basis for the robust stabilization of general disturbed nonlinear MIMO systems and enriches the parameter tuning methods of PID controllers from the perspective of dissipativity.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.07254", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.07254", "abs": "https://arxiv.org/abs/2601.07254", "authors": ["Tan Liu", "Liu Shi", "Binghuang Peng", "Tong Jia", "Xiaoling Xu", "Baodong Liu", "Qiegen Liu"], "title": "LaminoDiff: Artifact-Free Computed Laminography in Non-Destructive Testing via Diffusion Model", "comment": null, "summary": "Computed Laminography (CL) is a key non-destructive testing technology for the visualization of internal structures in large planar objects. The inherent scanning geometry of CL inevitably results in inter-layer aliasing artifacts, limiting its practical application, particularly in electronic component inspection. While deep learning (DL) provides a powerful paradigm for artifact removal, its effectiveness is often limited by the domain gap between synthetic data and real-world data. In this work, we present LaminoDiff, a framework to integrate a diffusion model with a high-fidelity prior representation to bridge the domain gap in CL imaging. This prior, generated via a dual-modal CT-CL fusion strategy, is integrated into the proposed network as a conditional constraint. This integration ensures high-precision preservation of circuit structures and geometric fidelity while suppressing artifacts. Extensive experiments on both simulated and real PCB datasets demonstrate that LaminoDiff achieves high-fidelity reconstruction with competitive performance in artifact suppression and detail recovery. More importantly, the results facilitate reliable automated defect recognition.", "AI": {"tldr": "提出了一种名为 LaminoDiff 的框架，通过结合扩散模型和高保真先验表示来解决计算层析成像 (CL) 中的层间混叠伪影问题，实现了高保真重建和可靠的缺陷识别。", "motivation": "计算层析成像 (CL) 在检测大型平面物体内部结构方面很重要，但其扫描几何特性会导致层间混叠伪影，限制了其在电子元件检查等领域的应用。现有的深度学习方法受限于合成数据和真实数据之间的域差异，效果不佳。", "method": "提出 LaminoDiff 框架，该框架将扩散模型与通过双模态 CT-CL 融合策略生成的高保真先验表示相结合。该先验作为条件约束集成到网络中，以保留电路结构和几何保真度，同时抑制伪影。", "result": "在模拟和真实的 PCB 数据集上进行的实验表明，LaminoDiff 实现了高保真重建，在伪影抑制和细节恢复方面表现具有竞争力。", "conclusion": "LaminoDiff 框架能够有效弥合域间隙，实现高精度 CL 成像，从而促进可靠的自动化缺陷识别。"}}
{"id": "2601.06163", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06163", "abs": "https://arxiv.org/abs/2601.06163", "authors": ["Kaiyuan Deng", "Bo Hui", "Gen Li", "Jie Ji", "Minghai Qin", "Geng Yuan", "Xiaolong Ma"], "title": "Forget-It-All: Multi-Concept Machine Unlearning via Concept-Aware Neuron Masking", "comment": null, "summary": "The widespread adoption of text-to-image (T2I) diffusion models has raised concerns about their potential to generate copyrighted, inappropriate, or sensitive imagery learned from massive training corpora. As a practical solution, machine unlearning aims to selectively erase unwanted concepts from a pre-trained model without retraining from scratch. While most existing methods are effective for single-concept unlearning, they often struggle in real-world scenarios that require removing multiple concepts, since extending them to this setting is both non-trivial and problematic, causing significant challenges in unlearning effectiveness, generation quality, and sensitivity to hyperparameters and datasets. In this paper, we take a unique perspective on multi-concept unlearning by leveraging model sparsity and propose the Forget It All (FIA) framework. FIA first introduces Contrastive Concept Saliency to quantify each weight connection's contribution to a target concept. It then identifies Concept-Sensitive Neurons by combining temporal and spatial information, ensuring that only neurons consistently responsive to the target concept are selected. Finally, FIA constructs masks from the identified neurons and fuses them into a unified multi-concept mask, where Concept-Agnostic Neurons that broadly support general content generation are preserved while concept-specific neurons are pruned to remove the targets. FIA is training-free and requires only minimal hyperparameter tuning for new tasks, thereby promoting a plug-and-play paradigm. Extensive experiments across three distinct unlearning tasks demonstrate that FIA achieves more reliable multi-concept unlearning, improving forgetting effectiveness while maintaining semantic fidelity and image quality.", "AI": {"tldr": "本文提出了一种名为 FIA 的新框架，用于从文本到图像生成模型中移除多个概念，通过利用模型稀疏性，有效解决了现有方法在多概念移除方面的不足，并在保留模型通用内容生成能力的同时，提高了移除效果和生成质量。", "motivation": "现有的文本到图像生成模型可能生成受版权保护、不当或敏感的图像，需要一种有效的方法来移除这些 unwanted 概念。而现有的单概念移除方法难以扩展到多概念移除场景，存在移除效果差、生成质量下降、对超参数和数据集敏感等问题。", "method": "FIA 框架利用模型稀疏性，包含三个关键步骤：1. 对目标概念的贡献进行量化（Contrastive Concept Saliency）；2. 识别对目标概念持续响应的神经元（Concept-Sensitive Neurons）；3. 通过掩码机制在保留通用内容生成能力的同时，剪枝概念特异性神经元（Concept-Agnostic Neurons preservation）。", "result": "FIA 在三个不同的移除任务上进行了广泛的实验，证明了其在移除多个概念方面更可靠，提高了移除的有效性，同时保持了语义保真度和图像质量。", "conclusion": "FIA 框架提供了一种高效、通用且易于使用的多概念移除解决方案，无需额外训练，只需少量超参数调整，即可实现文本到图像生成模型的安全部署。"}}
{"id": "2601.06109", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06109", "abs": "https://arxiv.org/abs/2601.06109", "authors": ["Ahmed H. Ismail", "Anthony Kuang", "Ayo Akinkugbe", "Kevin Zhu", "Sean O'Brien"], "title": "CBMAS: Cognitive Behavioral Modeling via Activation Steering", "comment": "Accepted to CogInterp @ NeurIPS 2025. Equal contribution by Ahmed H. Ismail and Anthony Kuang", "summary": "Large language models (LLMs) often encode cognitive behaviors unpredictably across prompts, layers, and contexts, making them difficult to diagnose and control. We present CBMAS, a diagnostic framework for continuous activation steering, which extends cognitive bias analysis from discrete before/after interventions to interpretable trajectories. By combining steering vector construction with dense α-sweeps, logit lens-based bias curves, and layer-site sensitivity analysis, our approach can reveal tipping points where small intervention strengths flip model behavior and show how steering effects evolve across layer depth. We argue that these continuous diagnostics offer a bridge between high-level behavioral evaluation and low-level representational dynamics, contributing to the cognitive interpretability of LLMs. Lastly, we provide a CLI and datasets for various cognitive behaviors at the project repository, https://github.com/shimamooo/CBMAS.", "AI": {"tldr": "本文提出了一种名为CBMAS的诊断框架，用于连续激活引导，以更好地理解和控制大型语言模型（LLMs）在不同提示、层和上下文下的认知行为。", "motivation": "现有的LLM诊断方法（如离散干预）难以捕捉模型行为的复杂性和连续性，导致模型行为难以预测、诊断和控制。需要一种方法来理解认知行为在模型内部是如何演变的。", "method": "CBMAS框架结合了引导向量构建、密集 α-扫描、基于Logit Lens的偏差曲线以及层-位点敏感性分析。通过这些方法，研究能够识别出模型行为发生翻转的“临界点”，并展示引导效应如何随层深度的增加而演变。", "result": "该方法能够揭示模型行为的“临界点”，并可视化引导效​​应如何在模型的不同层级中演变。这为理解LLMs的认知可解释性提供了新的视角。", "conclusion": "CBMAS提供了一种连续的诊断方法，弥合了高层次行为评估和低层次表征动态之间的差距，有助于提升LLMs的认知可解释性。研究还提供了相应的命令行接口（CLI）和数据集。"}}
{"id": "2601.06086", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.06086", "abs": "https://arxiv.org/abs/2601.06086", "authors": ["Yiwen Shao", "Wei Liu", "Jiahong Li", "Tianzi Wang", "Kun Wei", "Meng Yu", "Dong Yu"], "title": "AzeroS: Extending LLM to Speech with Self-Generated Instruction-Free Tuning", "comment": "Technical Report", "summary": "Extending large language models (LLMs) to the speech domain has recently gained significant attention. A typical approach connects a pretrained LLM with an audio encoder through a projection module and trains the resulting model on large-scale, task-specific instruction-tuning datasets. However, curating such instruction-tuning data for specific requirements is time-consuming, and models trained in this manner often generalize poorly to unseen tasks. In this work, we first formulate that the strongest generalization of a speech-LLM is achieved when it is trained with Self-Generated Instruction-Free Tuning (SIFT), in which supervision signals are generated by a frozen LLM using textual representations of speech as input. Our proposed SIFT paradigm eliminates the need for collecting task-specific question-answer pairs and yields the theoretically best generalization to unseen tasks. Building upon this paradigm, we introduce AZeroS (Auden Zero-instruction-tuned Speech-LLM), which is trained on speech-text pairs derived from publicly available corpora, including approximately 25,000 hours of speech with ASR transcripts and 3,000 hours of speech with paralinguistic labels. Built upon Qwen2.5-7B-Instruct, the model updates only two lightweight projection modules (23.8 million parameters each), while keeping both the LLM and audio encoders frozen. Despite the minimal training cost and modest data scale, AZeroS achieves state-of-the-art performance on both semantic and paralinguistic benchmarks, including VoiceBench, AIR-Bench Foundation (Speech), and AIR-Bench Chat (Speech).", "AI": {"tldr": "本文提出了一种名为SIFT（Self-Generated Instruction-Free Tuning）的训练范式，用于增强语音大型语言模型（Speech-LLM）的泛化能力。在此基础上，构建了AZeroS模型，该模型通过利用冻结的LLM生成的监督信号进行训练，无需人工标注，并且仅更新了轻量级的投影模块，取得了在语义和旁语音学任务上的优异表现。", "motivation": "传统的Speech-LLM训练方法依赖于耗时的数据集收集和标注，并且在泛化到新任务时表现不佳。研究者希望找到一种更有效且泛化能力更强的方法。", "method": "提出SIFT范式，利用一个冻结的LLM，通过语音的文本表示生成监督信号。在此基础上，构建AZeroS模型，将预训练的LLM（Qwen2.5-7B-Instruct）与音频编码器连接，仅训练两个轻量级的投影模块。训练数据来自公开语料库，包括ASR转录和旁语音学标签。", "result": "AZeroS模型在VoiceBench、AIR-Bench Foundation (Speech) 和 AIR-Bench Chat (Speech) 等语义和旁语音学基准测试中取得了最先进的性能，尽管训练成本较低且数据规模适中。", "conclusion": "SIFT范式能够实现Speech-LLM最强的泛化能力，消除了对特定任务问答对的需求。AZeroS模型是基于SIFT范式的一个成功实现，证明了即使在有限的训练成本和数据下，也能达到顶尖的性能。"}}
{"id": "2601.06686", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06686", "abs": "https://arxiv.org/abs/2601.06686", "authors": ["Darius Jakobeit", "Oliver Wallscheid"], "title": "A Power Electronic Converter Control Framework Based on Graph Neural Networks - An Early Proof-of-Concept", "comment": null, "summary": "Power electronic converter control is typically tuned per topology, limiting transfer across heterogeneous designs. This letter proposes a topology-agnostic meta-control framework that encodes converter netlists as typed bipartite graphs and uses a task-conditioned graph neural network backbone with distributed control heads. The policy is trained end-to-end via differentiable predictive control to amortize constrained optimal control over a distribution of converter parameters and reference-tracking tasks. In simulation on randomly sampled buck converters, the learned controller achieves near-optimal tracking performance relative to an online optimal-control baseline, motivating future extension to broader topologies, objectives, and real-time deployment.", "AI": {"tldr": "提出了一种拓扑无关的元控制框架，将转换器网表编码为类型二分图，并使用任务条件图神经网络实现近乎最优的跟踪性能。", "motivation": "现有的电力电子转换器控制方法通常是针对特定拓扑设计的，这限制了其在不同设计之间的迁移能力。", "method": "将转换器网表编码为类型二分图，并使用任务条件图神经网络（GNN）作为核心，配合分布式控制头。通过可微分预测控制进行端到端训练，以分摊约束最优控制的成本。", "result": "在随机抽样的降压转换器仿真中，所学的控制器实现了接近在线最优控制基线的跟踪性能。", "conclusion": "该拓扑无关的元控制框架在模拟中表现出优异的性能，证明了其在更广泛拓扑、目标和实时部署方面的潜力。"}}
{"id": "2601.07356", "categories": ["eess.IV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07356", "abs": "https://arxiv.org/abs/2601.07356", "authors": ["Tatiana Gelvez-Barrera", "Barbara Nicolas", "Bruno Gilles", "Adrian Basarab", "Denis Kouamé"], "title": "Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring", "comment": null, "summary": "Passive acoustic mapping (PAM) is a key imaging technique for characterizing cavitation activity in therapeutic ultrasound applications. Recent model-based beamforming algorithms offer high reconstruction quality and strong physical interpretability. However, their computational burden and limited temporal resolution restrict their use in applications with time-evolving cavitation. To address these challenges, we introduce a PAM beamforming framework based on a novel convolutional formulation in the time domain, which enables efficient computation. In this framework, PAM is formulated as an inverse problem in which the forward operator maps spatiotemporal cavitation activity to recorded radio-frequency signals accounting for time-of-flight delays defined by the acquisition geometry. We then formulate a regularized inversion algorithm that incorporates prior knowledge on cavitation activity. Experimental results demonstrate that our framework outperforms classical beamforming methods, providing higher temporal resolution than frequency-domain techniques while substantially reducing computational burden compared with iterative time-domain formulations.", "AI": {"tldr": "本文提出了一种基于卷积的时域被动声学成像（PAM）方法，用于高效地对治疗性超声中的空化活动进行成像，解决了现有方法的计算负担和时间分辨率限制问题。", "motivation": "现有基于模型的波束形成算法在PAM中重建质量高且具有物理可解释性，但计算量大且时间分辨率低，限制了其在时间变化的空化活动监测中的应用。因此，需要一种更高效、时间分辨率更高的方法。", "method": "将PAM重构为一个逆问题，其中正向算子模拟了时空空化活动到射频信号的映射，并考虑了时间延迟。提出了一种基于时间域卷积的框架，并采用包含空化活动先验知识的正则化反演算法。", "result": "实验结果表明，该框架在时间分辨率上优于频率域技术，同时计算负担相比迭代时域方法显著降低，优于经典的波束形成方法。", "conclusion": "所提出的基于卷积的时间域PAM框架能够高效地对时空空化活动进行成像，并具有高时间分辨率和可接受的计算复杂度，为实时监测治疗性超声中的空化活动提供了新的解决方案。"}}
{"id": "2601.06602", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06602", "abs": "https://arxiv.org/abs/2601.06602", "authors": ["Mohammed S. Alharbi", "Shinkyu Park"], "title": "UMLoc: Uncertainty-Aware Map-Constrained Inertial Localization with Quantified Bounds", "comment": null, "summary": "Inertial localization is particularly valuable in GPS-denied environments such as indoors. However, localization using only Inertial Measurement Units (IMUs) suffers from drift caused by motion-process noise and sensor biases. This paper introduces Uncertainty-aware Map-constrained Inertial Localization (UMLoc), an end-to-end framework that jointly models IMU uncertainty and map constraints to achieve drift-resilient positioning. UMLoc integrates two coupled modules: (1) a Long Short-Term Memory (LSTM) quantile regressor, which estimates the specific quantiles needed to define 68%, 90%, and 95% prediction intervals serving as a measure of localization uncertainty and (2) a Conditioned Generative Adversarial Network (CGAN) with cross-attention that fuses IMU dynamic data with distance-based floor-plan maps to generate geometrically feasible trajectories. The modules are trained jointly, allowing uncertainty estimates to propagate through the CGAN during trajectory generation. UMLoc was evaluated on three datasets, including a newly collected 2-hour indoor benchmark with time-aligned IMU data, ground-truth poses and floor-plan maps. Results show that the method achieves a mean drift ratio of 5.9% over a 70 m travel distance and an average Absolute Trajectory Error (ATE) of 1.36 m, while maintaining calibrated prediction bounds.", "AI": {"tldr": "提出了一种名为UMLoc的端到端框架，该框架结合了LSTM和CGAN，能够感知IMU的不确定性并利用地图约束来提高室内定位的鲁棒性，有效减少漂移。", "motivation": "在GPS信号受阻的室内环境中，仅依赖惯性测量单元（IMU）进行定位会因过程噪声和传感器偏差导致严重的漂移问题。", "method": "UMLoc框架包含两个耦合模块：1) 一个LSTM分位数回归器，用于估计68%、90%和95%的预测区间，量化定位不确定性；2) 一个带有交叉注意力的CGAN，用于融合IMU动态数据和基于距离的楼层平面地图，生成几何上可行的轨迹。两个模块联合训练。", "result": "在三个数据集上进行了评估，包括一个新收集的2小时室内基准数据集。结果显示，UMLoc在70米行程距离上的平均漂移率为5.9%，平均绝对轨迹误差（ATE）为1.36米，并且预测区间校准良好。", "conclusion": "UMLoc框架通过联合建模IMU不确定性和地图约束，成功实现了抗漂移的室内定位，并在实验中证明了其有效性。"}}
{"id": "2601.06165", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06165", "abs": "https://arxiv.org/abs/2601.06165", "authors": ["Dasol Choi", "Guijin Son", "Hanwool Lee", "Minhyuk Kim", "Hyunwoo Ko", "Teabin Lim", "Ahn Eungyeol", "Jungwhan Kim", "Seunghyeok Hong", "Youngsook Song"], "title": "What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models", "comment": null, "summary": "Current vision-language benchmarks predominantly feature well-structured questions with clear, explicit prompts. However, real user queries are often informal and underspecified. Users naturally leave much unsaid, relying on images to convey context. We introduce HAERAE-Vision, a benchmark of 653 real-world visual questions from Korean online communities (0.76% survival from 86K candidates), each paired with an explicit rewrite, yielding 1,306 query variants in total. Evaluating 39 VLMs, we find that even state-of-the-art models (GPT-5, Gemini 2.5 Pro) achieve under 50% on the original queries. Crucially, query explicitation alone yields 8 to 22 point improvements, with smaller models benefiting most. We further show that even with web search, under-specified queries underperform explicit queries without search, revealing that current retrieval cannot compensate for what users leave unsaid. Our findings demonstrate that a substantial portion of VLM difficulty stem from natural query under-specification instead of model capability, highlighting a critical gap between benchmark evaluation and real-world deployment.", "AI": {"tldr": "本研究提出了HAERAE-Vision基准，包含大量非正式、语境依赖的图像问答对，旨在评估视觉语言模型（VLM）在真实世界场景下的表现。结果表明，现有VLM在处理不明确用户查询时表现不佳，但通过显式化查询可以显著提升性能，尤其是对较小的模型。", "motivation": "现有视觉语言基准测试的样本结构化良好，用户提问明确，这与现实世界用户提出的非正式、含糊不清且依赖图像语境的查询方式存在巨大差距。", "method": "构建了包含653个真实世界图像问答对的HAERAE-Vision基准，并为每个问题提供了显式改写版本。评估了39个视觉语言模型（VLM）在原始和改写查询上的表现，并分析了显式化查询和网络搜索对模型性能的影响。", "result": "即使是最先进的模型（如GPT-5和Gemini 2.5 Pro）在处理原始（不明确）查询时，准确率也低于50%。通过显式化查询，模型的准确率提高了8至22个百分点，其中较小模型获益最大。即使借助网络搜索，不明确查询的表现仍不如没有搜索但经过显式化的查询。", "conclusion": "视觉语言模型的实际部署能力很大程度上受限于用户自然查询中的信息不明确性，而非模型本身的局限性。HAERAE-Vision基准的建立，揭示了当前基准评估与真实世界应用之间的关键差距，并强调了处理不明确查询的重要性。"}}
{"id": "2601.06740", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06740", "abs": "https://arxiv.org/abs/2601.06740", "authors": ["Kun-Chih", "Chen", "Chia-Hsin Chen", "Lei-Qi Wang", "Chun-Chieh Wang"], "title": "Entropy-based Thermal Sensor Placement and Temperature Reconstruction based on Adaptive Compressive Sensing Theory", "comment": "Accepted for publication in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. DOI: 10.1109/TCAD.2025.3626515", "summary": "This paper addresses the challenges of thermal sensor allocation and full-chip temperature reconstruction in multi-core systems by leveraging an entropy-based sensor placement strategy and an adaptive compressive sensing approach. By selecting sensor locations that capture diverse thermal behaviors and dynamically adjusting the measurement matrix, our method significantly enhances the accuracy of the full-chip temperature reconstruction. Experimental results demonstrate that our approach reduces full-chip temperature reconstruction error by 18% to 95%. In addition to the full-chip temperature reconstruction efficiency enhancement, our proposed method improves hardware efficiency by 5% to 514% over the related works. These findings highlight the potential of our method for more effective dynamic temperature management in future high-performance multi-core systems.", "AI": {"tldr": "该研究提出了一种基于熵的传感器放置策略和自适应压缩感知方法，以解决多核系统中的热传感器分配和全芯片温度重构问题，显著提高了重构精度和硬件效率。", "motivation": "多核系统中热传感器分配和全芯片温度重构的挑战，以及提高动态温度管理效率的需求。", "method": "采用基于熵的传感器放置策略来选择能捕捉多样化热行为的传感器位置，并结合自适应压缩感知方法动态调整测量矩阵。", "result": "与相关工作相比，全芯片温度重构误差降低了18%至95%，硬件效率提高了5%至514%。", "conclusion": "所提出的基于熵的传感器放置和自适应压缩感知方法能有效提高多核系统的全芯片温度重构精度和硬件效率，为未来的高性能多核系统提供了更有效的动态温度管理潜力。"}}
{"id": "2601.06142", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06142", "abs": "https://arxiv.org/abs/2601.06142", "authors": ["Anshul Kumar"], "title": "Is Sanskrit the most token-efficient language? A quantitative study using GPT, Gemini, and SentencePiece", "comment": "9 pages, 4 figures. Code and dataset available at: https://github.com/anshulkr713/sanskrit-token-efficiency", "summary": "Tokens are the basic units of Large Language Models (LLMs). LLMs rely on tokenizers to segment text into these tokens, and tokenization is the primary determinant of computational and inference cost. Sanskrit, one of the oldest languages, is hypothesized to express more meaning per token due to its morphology and grammar rules; however, no prior work has quantified this. We use a dataset of 701 parallel verses of the Bhagavad Gita, which comprises three languages-Sanskrit, English, and Hindi along with transliteration of Sanskrit into English. We test tokenizers including SentencePiece (SPM), older GPT models, and the latest generation tokenizers from Gemini and GPT. We use metrics of token count, characters per token (token efficiency), and tokens per character (token cost). Results show a ~2x difference in token counts between Sanskrit and English/Hindi under the unbiased SPM baseline. English/Hindi translations of Sanskrit commentary resulted in an approximately 20x increase in token count. GPT o200k base (latest, used by GPT-4o) and Gemini (latest) reduce bias by a significant degree compared to GPT cl100k base (used until GPT-4), but still fail to fully capture Sanskrit's compactness. This matters because there might be a penalty bias for non-English users, which inflates the token count. This research provides a foundation for improving future tokenizer design and shows the potential of Sanskrit for highly compact encoding, saving on cost while speeding up training and inference. The code and dataset are available at https://github.com/anshulkr713/sanskrit-token-efficiency", "AI": {"tldr": "本研究量化了不同语言（特别是梵语）在大型语言模型（LLM）中的代币效率。结果表明，梵语的代币效率显著高于英语和印地语，并且最新的代币化模型（如 Gemini 和 GPT o200k）在一定程度上缓解了代币化偏见，但仍未完全捕捉到梵语的紧凑性。", "motivation": "研究人员假设，由于其形态学和语法规则，梵语每个代币的含义表达更丰富，但此前没有工作对此进行量化。此外，研究还希望探讨代币化偏见对非英语用户可能造成的成本和推理时间上的影响。", "method": "研究人员使用包含梵语、英语和印地语（以及梵语的英文字母转写）的 701 句《薄伽梵歌》平行经文数据集。他们测试了 SentencePiece (SPM)、旧版 GPT 模型以及 Gemini 和 GPT 的最新一代代币化模型。评估指标包括代币数量、每代币字符数（代币效率）和每字符代币数（代币成本）。", "result": "在无偏的 SPM 基线模型下，梵语的代币数量约是英语/印地语的两倍。梵语评论的英语/印地语翻译导致代币数量增加了约 20 倍。最新的 GPT o200k 和 Gemini 代币化模型显著降低了代币化偏见，但仍未能完全体现梵语的紧凑性。", "conclusion": "本研究为改进未来的代币化模型设计奠定了基础，并展示了梵语在高度紧凑编码方面的潜力，有望节省成本并加快训练和推理速度。研究结果表明，存在针对非英语用户（特别是使用梵语时）的代币化偏见，这会不成比例地增加代币数量。"}}
{"id": "2601.06111", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.06111", "abs": "https://arxiv.org/abs/2601.06111", "authors": ["Aayush Gupta", "Farahan Raza Sheikh"], "title": "LLM-Powered Social Digital Twins: A Framework for Simulating Population Behavioral Response to Policy Interventions", "comment": "13 pages, 1 figure, 4 tables", "summary": "Predicting how populations respond to policy interventions is a fundamental challenge in computational social science and public policy. Traditional approaches rely on aggregate statistical models that capture historical correlations but lack mechanistic interpretability and struggle with novel policy scenarios. We present a general framework for constructing Social Digital Twins - virtual population replicas where Large Language Models (LLMs) serve as cognitive engines for individual agents. Each agent, characterized by demographic and psychographic attributes, receives policy signals and outputs multi-dimensional behavioral probability vectors. A calibration layer maps aggregated agent responses to observable population-level metrics, enabling validation against real-world data and deployment for counterfactual policy analysis.\n  We instantiate this framework in the domain of pandemic response, using COVID-19 as a case study with rich observational data. On a held-out test period, our calibrated digital twin achieves a 20.7% improvement in macro-averaged prediction error over gradient boosting baselines across six behavioral categories. Counterfactual experiments demonstrate monotonic and bounded responses to policy variations, establishing behavioral plausibility. The framework is domain-agnostic: the same architecture applies to transportation policy, economic interventions, environmental regulations, or any setting where policy affects population behavior. We discuss implications for policy simulation, limitations of the approach, and directions for extending LLM-based digital twins beyond pandemic response.", "AI": {"tldr": "本文提出了一种构建“社会数字孪生”的通用框架，其中大型语言模型（LLMs）作为个体智能体，能够模拟和预测人群对政策干预的行为反应，并在COVID-19疫情响应的案例研究中，通过对宏观平均预测误差的改进证明了其有效性。", "motivation": "传统基于聚合统计模型的政策响应预测方法缺乏机制可解释性，且难以应对新颖的政策情景。研究旨在开发一种更具解释性和适应性的框架来模拟人群对政策的反应。", "method": "构建了一个“社会数字孪生”框架，利用大型语言模型（LLMs）作为个体智能体的认知引擎。每个智能体拥有属性，接收政策信号并输出行为概率。通过一个校准层将个体响应聚合，并与现实世界数据进行验证，用于反事实政策分析。在COVID-19疫情响应中进行了实例化。", "result": "在COVID-19疫情响应的案例研究中，校准后的数字孪生在六个行为类别上的宏观平均预测误差比梯度提升基线模型提高了20.7%。反事实实验表明，对政策变化的响应是单调和有界的，具有行为上的合理性。", "conclusion": "该框架为构建基于LLM的社会数字孪生提供了一种通用且有效的方法，能够模拟和预测人群对政策的响应，并有望应用于包括交通、经济、环境等多个领域的政策模拟，尽管仍存在局限性并需要进一步研究。"}}
{"id": "2601.06557", "categories": ["eess.SY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.06557", "abs": "https://arxiv.org/abs/2601.06557", "authors": ["Chao Li", "Ilia Derevitskii", "Sergey Kovalchuk"], "title": "Modeling Descriptive Norms in Multi-Agent Systems: An Auto-Aggregation PDE Framework with Adaptive Perception Kernels", "comment": null, "summary": "This paper presents a PDE-based auto-aggregation model for simulating descriptive norm dynamics in autonomous multi-agent systems, capturing convergence and violation through non-local perception kernels and external potential fields. Extending classical transport equations, the framework represents opinion popularity as a continuous distribution, enabling direct interactions without Bayesian guessing of beliefs. Applied to a real-world COVID-19 dataset from a major medical center, the experimental results demonstrate that: when clinical guidelines serve as a top-down constraint mechanism, it effectively generates convergence of novel descriptive norms consistent with the dataset; in the bottom-up experiment, potential field guidance successfully promotes the system's reconstruction of descriptive norms aligned with the dataset through violation-and-recoupling; whereas fully autonomous interaction leads to the emergence of multi-centric normative structures independent of the dataset.", "AI": {"tldr": "本研究提出了一种基于偏微分方程（PDE）的自聚集模型，用于模拟自主多智能体系统中的描述性规范动态，并通过非局部感知核和外部势场捕捉规范的收敛和违反。该模型将意见流行度表示为连续分布，可直接交互而无需贝叶斯猜测信念。在COVID-19数据集上的实验表明，临床指南作为自上而下的约束机制可有效引导规范收敛；势场引导作为自下而上的机制也能促进规范重建；而完全自主的交互则会产生独立于数据集的多中心规范结构。", "motivation": "研究动机在于开发一种新的模型来模拟自主多智能体系统中描述性规范的动态演变，特别是规范的形成、收敛以及对外部影响的响应。现有模型在处理连续分布的意见以及模拟规范违反和修复方面可能存在不足。", "method": "本研究采用了基于偏微分方程（PDE）的自聚集模型。该模型利用非局部感知核来捕捉智能体之间的交互，并通过外部势场来引入外部约束或引导。模型将意见的流行度表示为连续分布，并将其扩展到经典的输运方程框架，以模拟规范的形成和动态。", "result": "实验结果显示，当使用临床指南作为自上而下的约束时，模型能够成功生成与COVID-19数据集一致的新描述性规范的收敛。当采用势场引导作为自下而上的机制时，模型能够通过违反-重耦合的过程重建与数据集一致的描述性规范。然而，在完全自主的交互情况下，模型产生了独立于数据集的多中心规范结构。", "conclusion": "该PDE驱动的自聚集模型能够有效地模拟多智能体系统中的描述性规范动态，并且能够通过不同的机制（如自上而下的约束和自下而上的势场引导）来影响规范的形成和收敛。研究表明，外部干预可以引导规范向特定方向发展，而完全自主的交互可能导致意想不到的规范结构。"}}
{"id": "2601.07519", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07519", "abs": "https://arxiv.org/abs/2601.07519", "authors": ["Margherita Firenze", "Sean I. Young", "Clinton J. Wang", "Hyuk Jin Yun", "Elfar Adalsteinsson", "Kiho Im", "P. Ellen Grant", "Polina Golland"], "title": "Fast Multi-Stack Slice-to-Volume Reconstruction via Multi-Scale Unrolled Optimization", "comment": null, "summary": "Fully convolutional networks have become the backbone of modern medical imaging due to their ability to learn multi-scale representations and perform end-to-end inference. Yet their potential for slice-to-volume reconstruction (SVR), the task of jointly estimating 3D anatomy and slice poses from misaligned 2D acquisitions, remains underexplored. We introduce a fast convolutional framework that fuses multiple orthogonal 2D slice stacks to recover coherent 3D structure and refines slice alignment through lightweight model-based optimization. Applied to fetal brain MRI, our approach reconstructs high-quality 3D volumes in under 10s, with 1s slice registration and accuracy on par with state-of-the-art iterative SVR pipelines, offering more than speedup. The framework uses non-rigid displacement fields to represent transformations, generalizing to other SVR problems like fetal body and placental MRI. Additionally, the fast inference time paves the way for real-time, scanner-side volumetric feedback during MRI acquisition.", "AI": {"tldr": "提出了一种快速的卷积框架，用于将多个正交的二维切片堆叠融合，以恢复一致的三维结构，并通过轻量级的基于模型的优化来精炼切片对齐，在胎儿脑部 MRI 上实现了快速高质量的三维重建。", "motivation": "完全卷积网络在医学成像领域具有巨大潜力，但其在切片到体积重建（SVR）任务中的应用仍未得到充分探索。现有方法速度慢，限制了其实际应用。", "method": "提出了一种快速的卷积框架，该框架融合了多个正交的二维切片堆叠，以恢复一致的三维结构，并利用非刚性位移场进行切片对齐的轻量级模型优化。", "result": "在胎儿脑部 MRI 上，该方法重建高质量三维体积的速度不到 10 秒，切片配准仅需 1 秒，精度与最先进的迭代 SVR 流程相当，速度提升显著。该框架可推广到其他 SVR 问题。", "conclusion": "该快速卷积框架能够高效且准确地进行切片到体积重建，并且推断速度快，为实时扫描仪端反馈提供了可能，适用于胎儿脑部、身体和胎盘 MRI 等应用。"}}
{"id": "2601.06617", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06617", "abs": "https://arxiv.org/abs/2601.06617", "authors": ["Giovani Braglia", "José Jair Alves Mendes Junior", "Augusto Tetsuo Prado Inafuco", "Federico Mariano", "Leonardo S. Mattos"], "title": "Robotic Tele-Operation for Upper Aerodigestive Tract Microsurgery: System Design and Validation", "comment": null, "summary": "Upper aerodigestive tract (UADT) treatments frequently employ transoral laser microsurgery (TLM) for procedures such as the removal of tumors or polyps. In TLM, a laser beam is used to cut target tissue, while forceps are employed to grasp, manipulate, and stabilize tissue within the UADT. Although TLM systems may rely on different technologies and interfaces, forceps manipulation is still predominantly performed manually, introducing limitations in ergonomics, precision, and controllability. This paper proposes a novel robotic system for tissue manipulation in UADT procedures, based on a novel end-effector designed for forceps control. The system is integrated within a teleoperation framework that employs a robotic manipulator with a programmed remote center of motion (RCM), enabling precise and constrained instrument motion while improving surgeon ergonomics. The proposed approach is validated through two experimental studies and a dedicated usability evaluation, demonstrating its effectiveness and suitability for UADT surgical applications.", "AI": {"tldr": "提出了一种用于上消化道内窥镜手术的新型机器人系统，该系统采用创新的末端执行器和具备远程运动中心的机械臂，以提高手术的精确性、可控性和外科医的人体工程学。", "motivation": "传统经口激光显微手术（TLM）中，组织操控主要依靠手动操作，存在人体工程学、精度和可控性方面的局限性。", "method": "设计了一种基于新颖末端执行器的机器人系统，用于TLM手术中的组织操控。该系统集成了具有预设远程运动中心（RCM）的机器人机械臂，实现了精确且受限的器械运动。", "result": "通过两项实验研究和专门的可用性评估，验证了该系统的有效性和适用性。", "conclusion": "所提出的机器人系统能够有效提高上消化道手术中组织操控的精确性、可控性，并改善外科医生的人体工程学，适用于此类手术。"}}
{"id": "2601.06166", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06166", "abs": "https://arxiv.org/abs/2601.06166", "authors": ["Di Xu", "Hengjie Liu", "Yang Yang", "Mary Feng", "Jin Ning", "Xin Miao", "Jessica E. Scholey", "Alexandra E. Hotca-cho", "William C. Chen", "Michael Ohliger", "Martina Descovich", "Huiming Dong", "Wensha Yang", "Ke Sheng"], "title": "B-FIRE: Binning-Free Diffusion Implicit Neural Representation for Hyper-Accelerated Motion-Resolved MRI", "comment": null, "summary": "Accelerated dynamic volumetric magnetic resonance imaging (4DMRI) is essential for applications relying on motion resolution. Existing 4DMRI produces acceptable artifacts of averaged breathing phases, which can blur and misrepresent instantaneous dynamic information. Recovery of such information requires a new paradigm to reconstruct extremely undersampled non-Cartesian k-space data. We propose B-FIRE, a binning-free diffusion implicit neural representation framework for hyper-accelerated MR reconstruction capable of reflecting instantaneous 3D abdominal anatomy. B-FIRE employs a CNN-INR encoder-decoder backbone optimized using diffusion with a comprehensive loss that enforces image-domain fidelity and frequency-aware constraints. Motion binned image pairs were used as training references, while inference was performed on binning-free undersampled data. Experiments were conducted on a T1-weighted StarVIBE liver MRI cohort, with accelerations ranging from 8 spokes per frame (RV8) to RV1. B-FIRE was compared against direct NuFFT, GRASP-CS, and an unrolled CNN method. Reconstruction fidelity, motion trajectory consistency, and inference latency were evaluated.", "AI": {"tldr": "提出了一种名为 B-FIRE 的新方法，用于加速动态容积 MRI（4DMRI）的重建，以克服现有技术在捕捉瞬时动态信息方面的不足，并能更好地反映腹部瞬时三维解剖结构。", "motivation": "现有 4DMRI 技术在重建平均呼吸相位时存在伪影，导致瞬时动态信息模糊和失真，需要一种新的范式来重建高度欠采样的非笛卡尔 k 空间数据，以获取更精确的动态信息。", "method": "提出了一种名为 B-FIRE 的“无分箱”（binning-free）的扩散隐式神经表示（Diffusion Implicit Neural Representation）框架。该框架采用 CNN-INR 编码器-解码器作为主干，并结合扩散模型进行优化。损失函数包含图像域保真度和频率感知约束。训练时使用有分箱的图像对作为参考，推断时在无分箱的欠采样数据上进行。", "result": "在 T1 加权 StarVIBE 肝脏 MRI 数据集上进行了实验，加速比从 RV8 到 RV1。与直接 NuFFT、GRASP-CS 和展开式 CNN 方法相比，B-FIRE 在重建保真度、运动轨迹一致性和推断延迟方面表现更优。", "conclusion": "B-FIRE 是一种有效的超加速 MR 重建方法，能够准确反映瞬时的三维腹部解剖结构，克服了传统 4DMRI 方法的局限性，并在重建保真度、运动轨迹一致性和推断速度方面展现出显著优势。"}}
{"id": "2601.06282", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06282", "abs": "https://arxiv.org/abs/2601.06282", "authors": ["Yue Zhou", "Xiaobo Guo", "Belhassen Bayar", "Srinivasan H. Sengamedu"], "title": "Amory: Building Coherent Narrative-Driven Agent Memory through Agentic Reasoning", "comment": null, "summary": "Long-term conversational agents face a fundamental scalability challenge as interactions extend over time: repeatedly processing entire conversation histories becomes computationally prohibitive. Current approaches attempt to solve this through memory frameworks that predominantly fragment conversations into isolated embeddings or graph representations and retrieve relevant ones in a RAG style. While computationally efficient, these methods often treat memory formation minimally and fail to capture the subtlety and coherence of human memory. We introduce Amory, a working memory framework that actively constructs structured memory representations through enhancing agentic reasoning during offline time. Amory organizes conversational fragments into episodic narratives, consolidates memories with momentum, and semanticizes peripheral facts into semantic memory. At retrieval time, the system employs coherence-driven reasoning over narrative structures. Evaluated on the LOCOMO benchmark for long-term reasoning, Amory achieves considerable improvements over previous state-of-the-art, with performance comparable to full context reasoning while reducing response time by 50%. Analysis shows that momentum-aware consolidation significantly enhances response quality, while coherence-driven retrieval provides superior memory coverage compared to embedding-based approaches.", "AI": {"tldr": "Amory是一个改进的对话代理记忆框架，通过构建叙事化的、具有惯性和语义化的记忆来解决长对话的计算瓶颈，在LOCOMO基准上表现优于现有技术，响应时间减半。", "motivation": "长对话代理在处理大量历史信息时面临计算瓶颈，现有基于检索增强生成（RAG）的方法往往碎片化记忆且未能捕捉人类记忆的精妙和连贯性。", "method": "Amory在离线时通过增强代理推理来构建结构化记忆：将对话片段组织成情景叙事，利用惯性整合记忆，并将外围事实语义化为语义记忆。在检索时，系统基于叙事结构进行连贯性驱动的推理。", "result": "Amory在LOCOMO长时推理基准上取得了显著进步，性能接近全上下文推理，响应时间减少了50%。惯性感知整合提高了响应质量，连贯性驱动检索提供了比基于嵌入的方法更好的记忆覆盖。", "conclusion": "Amory通过引入主动构建的、结构化的记忆表示，有效解决了长对话代理的可扩展性挑战，其叙事化、惯性和语义化的记忆处理方式显著优于现有方法，并在性能和效率上取得了平衡。"}}
{"id": "2601.06766", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06766", "abs": "https://arxiv.org/abs/2601.06766", "authors": ["Xian Wu", "Jan H. van Schuppen", "Hai Xiang Lin"], "title": "Control and Stability of a Multilevel Power System for a Future Distribution Network", "comment": null, "summary": "The growing integration of renewable energy sources into distribution networks poses significant challenges to frequency and voltage stability due to their intermittent nature and low-inertia dynamics. This paper proposes a multilevel control framework for a future decarbonized power system, using energy storage systems as power buffers to mitigate frequency and voltage fluctuations. A nonlinear interconnected model is formulated to characterize the complex dynamics across multiple levels of the distribution network. To reduce operational complexity and communication overhead of these dynamics, a distributed linear quadratic regulator control strategy is developed for information exchange in a bottom-up approach, where each level implements local feedback control within a short time horizon. Stability conditions for both open-loop and closed-loop systems are established using Lyapunov-based analysis. In addition, explicit performance bounds are derived to quantify the optimal difference between the proposed distributed strategy and the centralized control method, demonstrating the effectiveness of the proposed framework.", "AI": {"tldr": "提出一种多层次控制框架，利用储能系统缓冲可再生能源引起的频率和电压波动，并开发一种分布式LQR控制策略以简化操作和通信。", "motivation": "可再生能源并网带来的频率和电压稳定性挑战，以及现有控制方法的复杂性和通信开销。", "method": "建立非线性互联模型，开发分布式线性二次调节器（LQR）控制策略，采用自下而上的信息交换方式，并使用Lyapunov稳定性分析方法。", "result": "建立了开环和闭环系统的稳定性条件，并推导出分布式策略与集中式控制方法之间性能差异的明确性能界限。", "conclusion": "所提出的多层次分布式控制框架能够有效缓解可再生能源波动引起的频率和电压不稳定，且在性能上接近集中式控制。"}}
{"id": "2601.06652", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06652", "abs": "https://arxiv.org/abs/2601.06652", "authors": ["Jing Cao", "Nishanth Kumar", "Aidan Curtis"], "title": "Follow the Signs: Using Textual Cues and LLMs to Guide Efficient Robot Navigation", "comment": null, "summary": "Autonomous navigation in unfamiliar environments often relies on geometric mapping and planning strategies that overlook rich semantic cues such as signs, room numbers, and textual labels. We propose a novel semantic navigation framework that leverages large language models (LLMs) to infer patterns from partial observations and predict regions where the goal is most likely located. Our method combines local perceptual inputs with frontier-based exploration and periodic LLM queries, which extract symbolic patterns (e.g., room numbering schemes and building layout structures) and update a confidence grid used to guide exploration. This enables robots to move efficiently toward goal locations labeled with textual identifiers (e.g., \"room 8\") even before direct observation. We demonstrate that this approach enables more efficient navigation in sparse, partially observable grid environments by exploiting symbolic patterns. Experiments across environments modeled after real floor plans show that our approach consistently achieves near-optimal paths and outperforms baselines by over 25% in Success weighted by Path Length.", "AI": {"tldr": "提出了一种利用大型语言模型（LLM）进行语义导航的框架，该框架能够从部分观测中推断模式并预测目标位置，从而在未知环境中实现更高效的导航。", "motivation": "传统的自主导航方法忽略了语义信息（如标志、房间号），这使得在未知环境中进行有效导航具有挑战性。本研究旨在利用LLM的模式识别能力来增强导航效率。", "method": "该方法结合了局部感知输入、基于边界的探索和周期性的LLM查询。LLM用于提取符号模式（如房间编号方案和建筑布局结构），并更新一个用于指导探索的置信度网格。", "result": "实验表明，该方法在稀疏、部分可观测的网格环境中，能够利用符号模式实现比基线方法效率提高25%以上的导航（以成功率加权路径长度衡量），并获得近乎最优的路径。", "conclusion": "利用LLM从部分观测中推断符号模式，可以显著提高机器人在未知环境中进行文本标识目标导航的效率，并且优于传统的仅基于几何信息的方法。"}}
{"id": "2601.06168", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06168", "abs": "https://arxiv.org/abs/2601.06168", "authors": ["Jyotiraditya Gupta"], "title": "Analyzing the Structure of Handwritten Digits: A Comparative Study of PCA, Factor Analysis, and UMAP", "comment": "15 pages, 12 figures", "summary": "Handwritten digit images lie in a high-dimensional pixel space but exhibit strong geometric and statistical structure. This paper investigates the latent organization of handwritten digits in the MNIST dataset using three complementary dimensionality reduction techniques: Principal Component Analysis (PCA), Factor Analysis (FA), and Uniform Manifold Approximation and Projection (UMAP). Rather than focusing on classification accuracy, we study how each method characterizes intrinsic dimensionality, shared variation, and nonlinear geometry. PCA reveals dominant global variance directions and enables high-fidelity reconstructions using a small number of components. FA decomposes digits into interpretable latent handwriting primitives corresponding to strokes, loops, and symmetry. UMAP uncovers nonlinear manifolds that reflect smooth stylistic transitions between digit classes. Together, these results demonstrate that handwritten digits occupy a structured low-dimensional manifold and that different statistical frameworks expose complementary aspects of this structure.", "AI": {"tldr": "本文使用PCA、FA和UMAP三种降维技术分析MNIST手写数字数据集的内在结构，发现数字数据分布在低维流形上，且不同方法能揭示数据结构的不同方面（全局方差、笔画特征、风格过渡）。", "motivation": "研究手写数字图像在高维像素空间中的潜在组织结构，并探索不同的降维技术如何揭示这种结构。", "method": "使用主成分分析（PCA）、因子分析（FA）和统一流形近似与投影（UMAP）三种降维技术来分析MNIST数据集。", "result": "PCA揭示了全局方差的主要方向；FA将数字分解为可解释的笔画、笔圈和对称性等潜在手写原语；UMAP发现了反映数字类别间平滑风格过渡的非线性流形。", "conclusion": "手写数字分布在一个结构化的低维流形上，并且不同的统计框架（PCA、FA、UMAP）能够揭示这种结构的互补方面。"}}
{"id": "2601.06112", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06112", "abs": "https://arxiv.org/abs/2601.06112", "authors": ["Aayush Gupta"], "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "comment": "18 pages, 5 figures, 8 tables. Evaluates ReAct vs Reflexion across four tool-using domains with perturbation (epsilon) and fault-injection (lambda) stress testing; 1,280 total episodes", "summary": "Existing benchmarks for tool-using LLM agents primarily report single-run success rates and miss reliability properties required in production. We introduce \\textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $ε$, and (iii) fault tolerance under controlled tool/API failures at intensity $λ$. ReliabilityBench contributes a unified reliability surface $R(k,ε,λ)$, \\textit{action metamorphic relations} that define correctness via end-state equivalence rather than text similarity, and a chaos-engineering-style fault injection framework (timeouts, rate limits, partial responses, schema drift). We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes. Perturbations alone reduce success from 96.9% at $ε=0$ to 88.1% at $ε=0.2$. Rate limiting is the most damaging fault in ablations. ReAct is more robust than Reflexion under combined stress, and Gemini 2.0 Flash achieves comparable reliability to GPT-4o at much lower cost. ReliabilityBench provides a systematic framework for assessing production readiness of LLM agents.", "AI": {"tldr": "本文提出了ReliabilityBench基准，用于评估LLM代理在实际应用中的可靠性，关注一致性、鲁棒性和容错性。通过在多领域、多模型上进行评估，揭示了扰动和故障的影响，并发现ReAct架构在压力下比Reflexion更鲁棒，Gemini 2.0 Flash在成本效益上优于GPT-4o。", "motivation": "现有LLM代理基准主要关注单次运行成功率，忽略了实际生产环境所需的可靠性属性。因此，需要一个能够系统性评估代理可靠性的基准。", "method": "提出了ReliabilityBench基准，从三个维度评估可靠性：1) pass^k度量的重复执行一致性；2) ε度量的语义等价任务扰动鲁棒性；3) λ度量的受控工具/API故障容错性。引入了行动变异关系（action metamorphic relations）来定义正确性，并通过混沌工程风格的故障注入框架（如超时、速率限制、部分响应、模式漂移）进行测试。对Gemini 2.0 Flash和GPT-4o两种模型、ReAct和Reflexion两种代理架构，在四个领域（调度、旅行、客户支持、电子商务）进行了1280次实验。", "result": "扰动实验显示，当扰动强度ε从0增加到0.2时，成功率从96.9%下降到88.1%。速率限制是最具破坏性的故障。在组合压力下，ReAct代理比Reflexion更鲁棒。Gemini 2.0 Flash在成本较低的情况下达到了与GPT-4o相当的可靠性。", "conclusion": "ReliabilityBench提供了一个系统性的框架，用于评估LLM代理的生产就绪度，弥补了现有基准在可靠性评估方面的不足，并为理解和提升LLM代理在复杂多变环境下的表现提供了见解。"}}
{"id": "2601.06289", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06289", "abs": "https://arxiv.org/abs/2601.06289", "authors": ["Yufeng Wang", "Lu Wei", "Lin Liu", "Hao Xu", "Haibin Ling"], "title": "How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning?", "comment": null, "summary": "Mass spectrometry (MS) is a powerful analytical technique for identifying small molecules, yet determining complete molecular structures directly from tandem mass spectra (MS/MS) remains a long-standing challenge due to complex fragmentation patterns and the vast diversity of chemical space. Recent progress in large language models (LLMs) has shown promise for reasoning-intensive scientific tasks, but their capability for chemical interpretation is still unclear. In this work, we introduce a Chain-of-Thought (CoT) prompting framework and benchmark that evaluate how LLMs reason about mass spectral data to predict molecular structures. We formalize expert chemists' reasoning steps-such as double bond equivalent (DBE) analysis, neutral loss identification, and fragment assembly-into structured prompts and assess multiple state-of-the-art LLMs (Claude-3.5-Sonnet, GPT-4o-mini, and Llama-3 series) in a zero-shot setting using the MassSpecGym dataset. Our evaluation across metrics of SMILES validity, formula consistency, and structural similarity reveals that while LLMs can produce syntactically valid and partially plausible structures, they fail to achieve chemical accuracy or link reasoning to correct molecular predictions. These findings highlight both the interpretive potential and the current limitations of LLM-based reasoning for molecular elucidation, providing a foundation for future work that combines domain knowledge and reinforcement learning to achieve chemically grounded AI reasoning.", "AI": {"tldr": "本研究评估了大型语言模型（LLMs）在解读串联质谱（MS/MS）数据并预测分子结构方面的能力，发现LLMs能够生成部分合理的结构，但在化学准确性和推理与预测的关联性方面存在不足。", "motivation": "尽管质谱技术强大，但直接从MS/MS谱图确定完整分子结构仍然是一个挑战。大型语言模型在科学推理任务中展现了潜力，但其在化学信息学方面的能力尚不明确，因此需要评估LLMs在分子结构解析中的表现。", "method": "研究引入了包含“思维链”（CoT）提示的框架和基准，将化学家的推理步骤（如DBE分析、中性丢失识别、片段组装）结构化为提示，并使用MassSpecGym数据集，在零样本设置下评估了Claude-3.5-Sonnet、GPT-4o-mini和Llama-3系列LLMs。", "result": "评估结果显示，LLMs可以生成语法上有效且部分合理的分子结构，但未能达到化学上的准确性，也无法将它们的推理过程与正确的分子预测联系起来。", "conclusion": "大型语言模型在基于质谱数据的分子结构解析方面具有一定的解读潜力，但目前仍存在局限性。未来的工作需要结合领域知识和强化学习来提升LLMs在化学推理方面的能力。"}}
{"id": "2601.06728", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06728", "abs": "https://arxiv.org/abs/2601.06728", "authors": ["Minhyuk Park", "Aloysius K. Mok", "Tsz-Chiu Au"], "title": "Robust Evacuation for Multi-Drone Failure in Drone Light Shows", "comment": "Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification", "summary": "Drone light shows have emerged as a popular form of entertainment in recent years. However, several high-profile incidents involving large-scale drone failures -- where multiple drones simultaneously fall from the sky -- have raised safety and reliability concerns. To ensure robustness, we propose a drone parking algorithm designed specifically for multiple drone failures in drone light shows, aimed at mitigating the risk of cascading collisions by drone evacuation and enabling rapid recovery from failures by leveraging strategically placed hidden drones. Our algorithm integrates a Social LSTM model with attention mechanisms to predict the trajectories of failing drones and compute near-optimal evacuation paths that minimize the likelihood of surviving drones being hit by fallen drones. In the recovery node, our system deploys hidden drones (operating with their LED lights turned off) to replace failed drones so that the drone light show can continue. Our experiments showed that our approach can greatly increase the robustness of a multi-drone system by leveraging deep learning to predict the trajectories of fallen drones.", "AI": {"tldr": "本文提出了一种用于无人机灯光秀的无人机停车算法，以应对大规模无人机故障，通过预测坠落无人机的轨迹并引导幸存无人机疏散，同时部署隐藏无人机以维持表演。", "motivation": "近年来无人机灯光秀的兴起伴随着多起大规模无人机坠落事故，引发了对安全性和可靠性的担忧。", "method": "该算法整合了带有注意力机制的Social LSTM模型来预测坠落无人机的轨迹，并计算最优疏散路径以最小化幸存无人机被坠落无人机击中的风险。在故障恢复阶段，部署预先隐藏的无人机（关闭LED灯）来替换故障无人机，以维持表演的连续性。", "result": "实验表明，通过深度学习预测坠落无人机的轨迹，该方法显著提高了多无人机系统的鲁棒性。", "conclusion": "提出的无人机停车算法能够有效应对大规模无人机故障，通过预测性疏散和快速替换来提高无人机灯光秀的安全性和可靠性。"}}
{"id": "2601.06879", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06879", "abs": "https://arxiv.org/abs/2601.06879", "authors": ["Jialun Zhang", "Felix Kottmann", "Jimmy Chih-Hsien Peng", "Adrian Perrig", "Gabriela Hug"], "title": "Fast frequency response with heterogeneous communication delay management under the SCION Internet architecture", "comment": null, "summary": "System operators can increasingly exploit distributed energy resources (DERs) and controllable loads (CLs) to provide frequency response services. In conventional practice, communication between the system operator and flexible devices relies on the Border Gateway Protocol (BGP)-based Internet. However, existing BGP-based architectures face challenges in providing latency-guaranteed control, while direct private and proprietary communication networks lead to additional deployment and maintenance costs. In contrast, the SCION-based Internet architecture supports latency-minimum path selection, which makes it suitable for latency-sensitive frequency contingency services such as fast frequency response (FFR). Hence, this paper proposes a real-time reserve dispatch framework to optimally select a portfolio of flexible devices to deliver FFR services using the SCION-based Internet. First, an analytical expression of the system frequency dynamics with respect to heterogeneous communication latencies is derived. Next, a cyber-physical co-optimization model is formulated to jointly schedule communication paths and physical flexibility resources for real-time FFR provision. To improve the computation efficiency, we propose a heuristic FFR allocation algorithm to approximate the optimal response portfolio, integrating contributions from both DERs and CLs. Numerical case studies demonstrate the benefits of the proposed algorithm and its capability to approximate the optimality of the reserves allocation while significantly reducing the computation time.", "AI": {"tldr": "提出了一种基于 SCION 互联网架构的实时备用调度框架，用于优化分布式能源 (DER) 和可控负载 (CL) 的组合，以提供快速频率响应 (FFR) 服务，并提出了一种启发式算法来近似最优解。", "motivation": "传统的基于 BGP 的通信方式在提供延迟保证的频率响应服务方面存在挑战，而专有网络成本高昂。SCION 互联网架构支持延迟最小化路径选择，适用于对延迟敏感的 FFR 服务。", "method": "1. 导出考虑通信延迟的系统频率动态解析表达式。2. 建立网络物理协同优化模型，同时调度通信路径和灵活资源以提供 FFR。3. 提出一种启发式 FFR 分配算法来近似最优组合，以提高计算效率。", "result": "所提出的启发式算法能够近似最优的备用分配，同时显著减少计算时间。", "conclusion": "基于 SCION 互联网架构的实时备用调度框架可以有效地利用 DER 和 CL 提供 FFR 服务，并且启发式算法在效率和性能方面表现良好。"}}
{"id": "2601.06169", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06169", "abs": "https://arxiv.org/abs/2601.06169", "authors": ["Zhiyong Ma", "Zhenpeng Li", "Yuanjie Shi", "Zhengping Li", "Jiahao Chen", "Qingyuan Chuai"], "title": "Think Bright, Diffuse Nice: Enhancing T2I-ICL via Inductive-Bias Hint Instruction and Query Contrastive Decoding", "comment": "Submitted to ACL 2026", "summary": "Text-to-Image In-Context Learning (T2I-ICL) enables customized image synthesis via interleaved text-image examples but faces two mutually reinforcing bottlenecks, compliance failure and prior-dominated hallucination, that form a vicious cycle degrading generation quality. Existing methods rely on tailored training, which limits flexibility and raises deployment costs. To address these challenges effectively, we propose TBDN, a training-free framework integrating two complementary closed-loop mechanisms: Hint Instruction (HI) and Query Contrastive Decoding (QCD). HI injects task-aware inductive bias via lightweight prompt engineering to anchor models on contextual mapping rules, thereby mitigating compliance failure. QCD adjusts the decoding distributions of language models by contrasting full-input and query-omitted distributions, suppressing prior-dominated hallucination. TBDN achieves State-of-the-Art performance on CoBSAT and Text-to-Image Fast Mini-ImageNet, with robust generalization across model backbones, prompt designs, and hyperparameters. It also maintains promising performance in concept preservation and prompt following on Dreambench++. By breaking the two bottlenecks, TBDN establishes a simple yet effective framework for efficient and reliable T2I-ICL.", "AI": {"tldr": "本文提出了一种名为TBDN的免训练框架，通过“提示指令”（HI）和“查询对比解码”（QCD）两种机制，解决了文本到图像的上下文学习（T2I-ICL）中存在的合规性失败和先验主导的幻觉问题，从而提高了生成质量，并且具有良好的通用性。", "motivation": "现有的T2I-ICL方法存在合规性失败和先验主导的幻觉这两个相互关联的问题，导致生成质量下降。现有方法依赖于定制训练，这限制了灵活性并增加了部署成本。", "method": "TBDN是一个免训练框架，包含两种互补的闭环机制：1. 提示指令（HI）：通过轻量级的提示工程注入任务感知归纳偏差，锚定模型在上下文映射规则上，缓解合规性失败。2. 查询对比解码（QCD）：通过对比完整输入和忽略查询的分布，调整语言模型的解码分布，抑制先验主导的幻觉。", "result": "TBDN在CoBSAT和Text-to-Image Fast Mini-ImageNet数据集上取得了最先进的性能，并在模型骨干、提示设计和超参数方面表现出鲁棒的泛化能力。在Dreambench++上，它在概念保持和提示遵循方面也保持了有希望的性能。", "conclusion": "TBDN通过打破合规性失败和先验主导的幻觉这两个瓶颈，建立了一个简单而有效的框架，实现了高效可靠的T2I-ICL。"}}
{"id": "2601.06964", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06964", "abs": "https://arxiv.org/abs/2601.06964", "authors": ["Alessandro Fontanella", "Kristjan Milic", "Alan Facchinetti", "Sara Muggiasca", "Marco Belloli"], "title": "Hardware-in-the-loop wind-tunnel testing of wake interactions between two floating wind turbines", "comment": null, "summary": "Wake interactions in floating wind farms are inherently coupled to platform motion, yet most experimental studies to date neglect this two-way coupling by prescribing platform movements. This work presents a hardware-in-the-loop (HIL) wind-tunnel methodology to investigate wake interactions between two floating wind turbines with fully coupled aerodynamic loading and platform dynamics. The approach integrates physical wind-tunnel testing of two scaled rotors with a real-time numerical model that accounts for platform motion, mooring restoring forces, and hydrodynamic loads. Experiments conducted under low-turbulence inflow conditions show that a downstream turbine operating in the wake of an upstream turbine experiences reduced mean thrust and platform deflections due to the decreased inflow velocity, alongside enhanced low-frequency platform motions driven by increased turbulent energy in the wake. The proposed HIL framework provides a controlled experimental basis for studying wake-induced excitation mechanisms and supports the validation of floating wind farm models and control strategies.", "AI": {"tldr": "本研究提出了一种硬件在环（HIL）风洞方法，用于研究浮式风力涡轮机之间的尾流相互作用，同时考虑了气动载荷和平台动力学的双向耦合。实验结果表明，下游涡轮机由于进流速度降低，推力和平台挠度减小，但由于尾流中湍动能增加，平台低频运动增强。", "motivation": "现有关于浮式风力涡轮机尾流相互作用的实验研究大多忽略了平台运动与气动载荷之间的双向耦合。", "method": "采用硬件在环（HIL）风洞测试方法，将两个缩比转子的物理风洞测试与考虑平台运动、系泊恢复力以及水动力载荷的实时数值模型相结合。", "result": "下游涡轮机在尾流中运行时，平均推力和平台挠度减小；同时，由于尾流中湍动能增强，平台低频运动得到增强。", "conclusion": "提出的HIL框架为研究尾流引起的激发机制提供了受控的实验基础，并支持浮式风力发电场模型和控制策略的验证。"}}
{"id": "2601.06300", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06300", "abs": "https://arxiv.org/abs/2601.06300", "authors": ["Trisha Das", "Mandis Beigi", "Jacob Aptekar", "Jimeng Sun"], "title": "$\\texttt{AMEND++}$: Benchmarking Eligibility Criteria Amendments in Clinical Trials", "comment": null, "summary": "Clinical trial amendments frequently introduce delays, increased costs, and administrative burden, with eligibility criteria being the most commonly amended component. We introduce \\textit{eligibility criteria amendment prediction}, a novel NLP task that aims to forecast whether the eligibility criteria of an initial trial protocol will undergo future amendments. To support this task, we release $\\texttt{AMEND++}$, a benchmark suite comprising two datasets: $\\texttt{AMEND}$, which captures eligibility-criteria version histories and amendment labels from public clinical trials, and $\\verb|AMEND_LLM|$, a refined subset curated using an LLM-based denoising pipeline to isolate substantive changes. We further propose $\\textit{Change-Aware Masked Language Modeling}$ (CAMLM), a revision-aware pretraining strategy that leverages historical edits to learn amendment-sensitive representations. Experiments across diverse baselines show that CAMLM consistently improves amendment prediction, enabling more robust and cost-effective clinical trial design.", "AI": {"tldr": "本文提出了一种新的自然语言处理任务——临床试验资格标准修正预测，并发布了包含两个数据集的基准套件AMEND++。同时，研究人员还提出了一种名为CAMLM的预训练策略，以提高预测的准确性，从而支持更有效的临床试验设计。", "motivation": "临床试验的修正，尤其是资格标准修正，会带来延误、成本增加和管理负担。研究的动机是预测资格标准是否会发生未来修正，以减轻这些负面影响。", "method": "研究人员引入了一个新的NLP任务：资格标准修正预测。他们发布了一个名为AMEND++的基准套件，其中包含AMEND（包含资格标准版本历史和修正标签的数据集）和AMEND_LLM（使用LLM去噪处理的数据集）。此外，他们提出了一种名为Change-Aware Masked Language Modeling (CAMLM) 的预训练策略，该策略利用历史编辑来学习对修正敏感的表示。", "result": "CAMLM在资格标准修正预测任务中，与多种基线模型相比，表现出了持续的性能提升。这表明CAMLM能够学习到对修正敏感的表示，从而提高了预测的鲁棒性。", "conclusion": "资格标准修正预测是一项有价值的新NLP任务。CAMLM预训练策略能够有效提升修正预测的性能，为更鲁棒、更具成本效益的临床试验设计提供了支持。"}}
{"id": "2601.06748", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06748", "abs": "https://arxiv.org/abs/2601.06748", "authors": ["Changyu Liu", "Yiyang Liu", "Taowen Wang", "Qiao Zhuang", "James Chenhao Liang", "Wenhao Yang", "Renjing Xu", "Qifan Wang", "Dongfang Liu", "Cheng Han"], "title": "On-the-Fly VLA Adaptation via Test-Time Reinforcement Learning", "comment": null, "summary": "Vision-Language-Action models have recently emerged as a powerful paradigm for general-purpose robot learning, enabling agents to map visual observations and natural-language instructions into executable robotic actions. Though popular, they are primarily trained via supervised fine-tuning or training-time reinforcement learning, requiring explicit fine-tuning phases, human interventions, or controlled data collection. Consequently, existing methods remain unsuitable for challenging simulated- or physical-world deployments, where robots must respond autonomously and flexibly to evolving environments. To address this limitation, we introduce a Test-Time Reinforcement Learning for VLAs (TT-VLA), a framework that enables on-the-fly policy adaptation during inference. TT-VLA formulates a dense reward mechanism that leverages step-by-step task-progress signals to refine action policies during test time while preserving the SFT/RL-trained priors, making it an effective supplement to current VLA models. Empirical results show that our approach enhances overall adaptability, stability, and task success in dynamic, previously unseen scenarios under simulated and real-world settings. We believe TT-VLA offers a principled step toward self-improving, deployment-ready VLAs.", "AI": {"tldr": "提出了一种名为TT-VLA的框架，通过在测试时进行强化学习，使视觉-语言-动作（VLA）模型能够在推理过程中进行即时策略适应，从而提高其在动态环境下的适应性、稳定性和任务成功率。", "motivation": "现有的视觉-语言-动作（VLA）模型主要依赖于监督微调或训练时强化学习，这些方法需要显式微调阶段、人工干预或受控数据收集，不适用于需要自主和灵活响应不断变化环境的真实世界部署。因此，研究的动机是开发一种能够在推理时自适应的模型。", "method": "TT-VLA框架在测试时进行强化学习，通过设计一种密集的奖励机制，利用分步任务进度信号来优化动作策略。该方法在不破坏预训练模型（SFT/RL）先验知识的情况下进行，作为现有VLA模型的补充。", "result": "实验结果表明，TT-VLA在模拟和真实世界的动态、先前未见过的场景中，提高了VLA模型的整体适应性、稳定性和任务成功率。", "conclusion": "TT-VLA提供了一个原则性的方法，朝着实现能够自我改进、可部署的VLA模型迈出了重要一步。"}}
{"id": "2601.06115", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06115", "abs": "https://arxiv.org/abs/2601.06115", "authors": ["V. Cheung"], "title": "Dreaming Is Not a Bug: A Jung-Inspired Dream Layer for Multi-Agent LLM Companions", "comment": "Preprint, 35 pages (5 pages of appendix), 2 figures, 3 tables. Conceptual and architectural proposal with preliminary simulation results", "summary": "Inspired by a personal dream about knowledge-sharing barriers in an everyday hardware project, this paper proposes a Jung-inspired \"Dream Layer\" for LLM companions, reframing controlled offline hallucinations as a resource for learning and relationship-building rather than a mere reliability bug. Drawing on Jung's notion of the collective unconscious as a shared repository of archetypal forms, we introduce an Artificial Collective Unconscious (ACU): a shared dream pool where agents contribute de-identified, abstract Interaction Templates that are later re-instantiated as idiosyncratic Dream Narratives. The Dream Layer runs strictly offline: logic-enforcing modules are relaxed and sampling temperature is increased, yielding safe but deliberately bizarre narratives (e.g., travel sequences with mismatched currencies) that augment data for rare events and edge-case safety tests; to harness risk productively, we add a governance stack of strict abstraction, temporal delays, and ephemeral memory. Through behavioural simulations of everyday dialogue and long-horizon adaptation tasks, we show that the Dream Layer enables a critical decoupling: agents remain firm on safety constraints (e.g., security policies) while becoming flexible in narrative strategy (e.g., using shared archetypal metaphors to resolve deadlocks), conceptually reframing hallucination so that online, unmarked instances remain bugs, whereas bounded, marked, and delayed ones become a goldmine for synthetic scenarios and deepened companionship, echoing anti-overfitting dream mechanisms proposed in contemporary neuroscience.", "AI": {"tldr": "本文提出了一种受荣格心理学启发的“梦境层”（Dream Layer）机制，用于改进大型语言模型（LLM）伴侣。该机制将离线“幻觉”重新定义为学习和关系建立的资源，而非单纯的错误。通过构建人工集体无意识（ACU）和一套治理框架，生成安全但奇特的叙事，用于增强数据、测试边缘情况，并在不牺牲安全性的前提下提高模型的叙事灵活性。", "motivation": "受到关于知识共享障碍的个人梦境启发，作者希望探索一种新的方式来处理 LLM 的“幻觉”问题，将其从一个技术缺陷转变为有益的功能，以增强学习和人机关系。", "method": "提出“梦境层”概念，引入人工集体无意识（ACU），将抽象的交互模板汇集到一个共享的“梦池”中。在离线环境中，放松逻辑约束和提高采样温度，生成具有一定随机性和奇特性（但安全）的叙事。通过严格的抽象、时间延迟和短暂记忆等治理机制来控制风险。在行为模拟中评估该机制。", "result": "行为模拟显示，“梦境层”实现了安全约束（如安全策略）和叙事策略（如使用比喻解决僵局）的有效分离。模型能够在保持安全性的同时，变得更具叙事灵活性。离线、标记和延迟的“幻觉”被证明是生成合成场景和深化陪伴关系的有效途径。", "conclusion": "本文提出的“梦境层”机制，通过将离线“幻觉”转化为一种可控的、有益的资源，为 LLM 伴侣带来了新的可能性。它不仅可以生成用于数据增强和安全测试的合成场景，还能在不影响核心安全性的前提下，提升模型的适应性和人机关系的深度，这与神经科学中提出的反过拟合的梦境机制相呼应。"}}
{"id": "2601.06176", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06176", "abs": "https://arxiv.org/abs/2601.06176", "authors": ["Hongbo Jin", "Siyi Xie", "Jiayu Ding", "Kuanwei Lin", "Ge Li"], "title": "TIR-Flow: Active Video Search and Reasoning with Frozen VLMs", "comment": null, "summary": "While Large Video-Language Models (Video-LLMs) have achieved remarkable progress in perception, their reasoning capabilities remain a bottleneck. Existing solutions typically resort to a heavy \"data engineering\" paradigm-synthesizing large-scale Chain-of-Thought (CoT) datasets followed by Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). This pipeline primarily optimizes probability sampling efficiency and aligns output distributions, but fails to activate the intrinsic intelligence required for dynamic visual exploration. In this work, we propose TIR-Flow, a novel framework that shifts the paradigm from passive processing to active video searching and reasoning without additional data or parameter updating. Concretely, our framework operates through three synergistic modules: HDD decomposes complex queries into a set of verifiable sub-tasks; HAP actively directs visual attention to gather high-resolution evidence for hypothesis validation; EBA maintains a persistent workspace to accumulate and update the discovered clues for logical reasoning. Extensive experiments on seven benchmarks demonstrate that TIR-Flow significantly outperforms recent strong baselines, delivering an average performance boost of 5.9%, with gains reaching 10.5% on Egoschema. Our analysis confirms that empowering frozen VLMs with System-2-like active perception is a scalable path toward solving long-horizon video reasoning.", "AI": {"tldr": "本文提出了一种名为TIR-Flow的新框架，通过主动搜索和推理来提升视频语言模型（Video-LLMs）的推理能力，无需额外数据或参数更新，并在多项基准测试中取得了显著的性能提升。", "motivation": "现有的Video-LLMs在感知方面表现出色，但在推理方面存在瓶颈。现有的解决方案依赖于数据工程（合成CoT数据集，然后进行SFT和RL），但这主要优化了概率采样效率，未能激活动态视觉探索所需的内在智能。", "method": "TIR-Flow框架包含三个模块：1. HDD（Hierarchical task Decomposition）：将复杂查询分解为可验证的子任务。2. HAP（Hierarchical Attention）：主动引导视觉注意力，收集高分辨率证据以验证假设。3. EBA（Evidence-based Accumulation）：维护一个持久的工作空间，累积和更新发现的线索以进行逻辑推理。", "result": "在七个基准测试上进行的广泛实验表明，TIR-Flow显著优于最近的强大基线，平均性能提升了5.9%，在Egoschema数据集上的增益高达10.5%。", "conclusion": "通过赋予冻结的VLMs类似System-2的主动感知能力，是一种解决长时序视频推理的可行途径。"}}
{"id": "2601.06116", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.06116", "abs": "https://arxiv.org/abs/2601.06116", "authors": ["Ian Rios-Sialer"], "title": "Structure-Aware Diversity Pursuit as an AI Safety Strategy against Homogenization", "comment": null, "summary": "Generative AI models reproduce the biases in the training data and can further amplify them through mode collapse. We refer to the resulting harmful loss of diversity as homogenization. Our position is that homogenization should be a primary concern in AI safety. We introduce xeno-reproduction as the strategy that mitigates homogenization. For auto-regressive LLMs, we formalize xeno-reproduction as a structure-aware diversity pursuit. Our contribution is foundational, intended to open an essential line of research and invite collaboration to advance diversity.", "AI": {"tldr": "本文提出“异种繁殖”（xeno-reproduction）作为一种新的AI安全策略，以解决生成式AI模型中的“同质化”（homogenization）问题，即模型因训练数据中的偏见和模式崩溃而导致的输出多样性丧失。对于自回归语言模型，作者将其形式化为一种“结构感知多样性追求”。", "motivation": "生成式AI模型会复现并放大训练数据中的偏见，导致输出多样性丧失（即同质化），这对AI安全构成严重威胁。作者认为同质化应成为AI安全的首要关注点。", "method": "提出“异种繁殖”（xeno-reproduction）作为一种缓解同质化的策略。对于自回归语言模型，将其形式化为“结构感知多样性追求”。", "result": "提出了一种新的AI安全策略——异种繁殖，并为自回归语言模型提供了一种具体的形式化方法，旨在追求输出结构感知上的多样性。", "conclusion": "同质化是生成式AI模型中的一个关键AI安全问题，作者提出的异种繁殖策略，特别是其在自回归语言模型上的结构感知多样性追求形式化，为解决这一问题提供了一个基础性的研究方向，并鼓励进一步的合作与发展。"}}
{"id": "2601.06305", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06305", "abs": "https://arxiv.org/abs/2601.06305", "authors": ["Hoang-Chau Luong", "Lingwei Chen"], "title": "Why LoRA Fails to Forget: Regularized Low-Rank Adaptation Against Backdoors in Language Models", "comment": null, "summary": "Low-Rank Adaptation (LoRA) is widely used for parameter-efficient fine-tuning of large language models, but it is notably ineffective at removing backdoor behaviors from poisoned pretrained models when fine-tuning on clean dataset. Contrary to the common belief that this weakness is caused primarily by low rank, we show that LoRA's vulnerability is fundamentally spectral. Our analysis identifies two key factors: LoRA updates (i) possess insufficient spectral strength, with singular values far below those of pretrained weights, and (ii) exhibit unfavorable spectral alignment, weakly matching clean-task directions while retaining overlap with trigger-sensitive subspaces. We further establish a critical scaling threshold beyond which LoRA can theoretically suppress trigger-induced activations, and we show empirically that standard LoRA rarely reaches this regime. We introduce Regularized Low-Rank Adaptation (RoRA), which improves forgetting by increasing spectral strength and correcting alignment through clean-strengthened regularization, trigger-insensitive constraints, and post-training spectral rescaling. Experiments across multiple NLP benchmarks and attack settings show that RoRA substantially reduces attack success rates while maintaining clean accuracy.", "AI": {"tldr": "本文提出了一种名为 RoRA (Regularized Low-Rank Adaptation) 的新方法，旨在解决 LoRA 在去除预训练模型后门行为方面的不足。RoRA 通过增强权重谱强度和纠正频谱对齐来提高遗忘能力，并在 NLP 任务中证明了其有效性。", "motivation": "LoRA 在参数高效微调中被广泛使用，但在去除受污染预训练模型中的后门行为方面效果不佳。本文旨在探究 LoRA 效果不佳的根本原因，并提出改进方法。", "method": "作者首先分析了 LoRA 在去除后门行为方面的局限性，指出其问题在于更新的频谱强度不足和频谱对齐不佳。接着，他们提出了 RoRA，通过引入正则化项来增强频谱强度并纠正频谱对齐，同时还包括后训练频谱重缩放。实验在多个 NLP 基准和攻击场景下进行。", "result": "RoRA 在多个 NLP 基准和攻击设置下，显著降低了攻击成功率，同时保持了干净数据的准确性。实验结果表明 RoRA 在去除后门行为方面比标准 LoRA 有显著提升。", "conclusion": "LoRA 在去除后门行为方面的无效性并非主要由低秩引起，而是其频谱特性造成的。RoRA 通过增强频谱强度和纠正频谱对齐，有效地解决了这一问题，并在保持模型性能的同时，大幅降低了后门攻击的成功率。"}}
{"id": "2601.07090", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07090", "abs": "https://arxiv.org/abs/2601.07090", "authors": ["Verena Häberle", "Kehao Zhuang", "Xiuqiang He", "Linbin Huang", "Florian Dörfler"], "title": "Next-Generation Grid Codes: Toward a New Paradigm for Dynamic Ancillary Services", "comment": "4 pages, 7 figures", "summary": "This paper presents preliminary results toward a conceptual foundation for Next Generation Grid Codes (NGGCs) based on decentralized stability and performance certification for dynamic ancillary services. The proposed NGGC framework targets two core outcomes: (i) guaranteed closed-loop stability and (ii) explicit performance assurances for power-system frequency and voltage dynamics. Stability is addressed using loop-shifting and passivity-based methods that yield local frequency-domain certificates for individual devices, enabling fully decentralized verification of the interconnected system. Performance is characterized by deriving quantitative bounds on key time-domain metrics (e.g., nadirs, rate-of-change-of-frequency (RoCoF), steady-state deviations, and oscillation damping) through frequency-domain constraints on local device behavior. The framework is non-parametric and model-agnostic, accommodating a broad class of device dynamics under mild assumptions, and provides an initial unified approach to stability and performance certification without explicit device-model parameterization. As such, these results offer a principled starting point for the development of future grid codes and control design methodologies in modern power systems.", "AI": {"tldr": "本文提出了一个基于去中心化稳定性和性能认证的下一代电网代码（NGGC）概念框架，旨在保证动态辅助服务的闭环稳定性和明确的频率/电压性能。", "motivation": "现有电网代码在应对现代电力系统中动态辅助服务的稳定性与性能保证方面存在不足，需要一种新的、更具普适性的框架。", "method": "使用环移和基于无源性的方法获得设备级的频率域稳定性证书，并通过频率域约束推导出关键时域性能指标的量化界限。该框架是非参数化且模型无关的。", "result": "实现了对互联系统进行完全去中心化验证的稳定性保证，以及对频率和电压动态性能的显式性能保证，包括纳迪尔值、频率变化率（RoCoF）、稳态偏差和振荡阻尼等。", "conclusion": "该框架为下一代电网代码和现代电力系统的控制设计方法提供了一个原则性的起点，能够统一处理稳定性和性能认证问题，而无需依赖具体的设备模型参数。"}}
{"id": "2601.06306", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06306", "abs": "https://arxiv.org/abs/2601.06306", "authors": ["Md. Shihab Uddin Riad"], "title": "SyntaxMind at BLP-2025 Task 1: Leveraging Attention Fusion of CNN and GRU for Hate Speech Detection", "comment": null, "summary": "This paper describes our system used in the BLP-2025 Task 1: Hate Speech Detection. We participated in Subtask 1A and Subtask 1B, addressing hate speech classification in Bangla text. Our approach employs a unified architecture that integrates BanglaBERT embeddings with multiple parallel processing branches based on GRUs and CNNs, followed by attention and dense layers for final classification. The model is designed to capture both contextual semantics and local linguistic cues, enabling robust performance across subtasks. The proposed system demonstrated high competitiveness, obtaining 0.7345 micro F1-Score (2nd place) in Subtask 1A and 0.7317 micro F1-Score (5th place) in Subtask 1B.", "AI": {"tldr": "本研究提出了一个用于孟加拉语仇恨言论检测的统一系统，结合了BanglaBERT、GRU、CNN和注意力机制，并在BLP-2025任务1中取得了良好的成绩。", "motivation": "为BLP-2025任务1中的孟加拉语仇恨言论检测子任务（1A和1B）开发一个具有竞争力的系统。", "method": "构建了一个统一的架构，该架构集成了BanglaBERT词嵌入，并利用基于GRU和CNN的多个并行处理分支，然后通过注意力层和密集层进行最终分类。该模型旨在捕捉上下文语义和局部语言线索。", "result": "在子任务1A（仇恨言论分类）中取得了0.7345的微F1分数，排名第二；在子任务1B（特定类型的仇恨言论分类）中取得了0.7317的微F1分数，排名第五。", "conclusion": "所提出的融合了BanglaBERT、GRU、CNN和注意力机制的统一架构在孟加拉语仇恨言论检测任务上表现出很强的竞争力，能够有效地捕捉文本的语义和语言特征。"}}
{"id": "2601.06187", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06187", "abs": "https://arxiv.org/abs/2601.06187", "authors": ["Nishan Rai", "Pushpa R. Dahal"], "title": "A Unified Attention U-Net Framework for Cross-Modality Tumor Segmentation in MRI and CT", "comment": "11 pages, 5 figures", "summary": "This study presents a unified Attention U-Net architecture trained jointly on MRI (BraTS 2021) and CT (LIDC-IDRI) datasets to investigate the generalizability of a single model across diverse imaging modalities and anatomical sites. Our proposed pipeline incorporates modality-harmonized preprocessing, attention-gated skip connections, and a modality-aware Focal Tversky loss function. To the best of our knowledge, this study is among the first to evaluate a single Attention U-Net trained simultaneously on separate MRI (BraTS) and CT (LIDC-IDRI) tumor datasets, without relying on modality-specific encoders or domain adaptation. The unified model demonstrates competitive performance in terms of Dice coefficient, IoU, and AUC on both domains, thereby establishing a robust and reproducible baseline for future research in cross-modality tumor segmentation.", "AI": {"tldr": "研究提出了一个统一的注意力U-Net架构，在一个模型中同时训练MRI（BraTS 2021）和CT（LIDC-IDRI）数据集，用于肿瘤分割，并取得了跨模态的良好性能。", "motivation": "探索一个单一模型在不同成像模态（MRI和CT）和解剖部位上的泛化能力，为跨模态肿瘤分割提供一个通用且可复现的基线。", "method": "采用统一的注意力U-Net架构，结合模态协调的预处理、注意力门控跳跃连接以及模态感知的Focal Tversky损失函数，同时在BraTS（MRI）和LIDC-IDRI（CT）数据集上进行训练，不使用特定模态的编码器或领域自适应技术。", "result": "所提出的统一模型在MRI和CT两个模态上都表现出具有竞争力的分割性能，Dice系数、IoU和AUC等指标均表现良好。", "conclusion": "研究证明，通过精心设计的预处理、网络架构和损失函数，一个单一的注意力U-Net模型能够成功地在不同的医学成像模态（MRI和CT）上进行肿瘤分割，为跨模态研究奠定了坚实的基础。"}}
{"id": "2601.06833", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06833", "abs": "https://arxiv.org/abs/2601.06833", "authors": ["JaeHyung Jang", "JunHyeong Park", "Joong-Ku Lee", "Jee-Hwan Ryu"], "title": "SPINE Gripper: A Twisted Underactuated Mechanism-based Passive Mode-Transition Gripper", "comment": "11 pages, 10 figures. Preprint version of a manuscript submitted to IEEE Transactions on Mechatronics", "summary": "This paper presents a single-actuator passive gripper that achieves both stable grasping and continuous bidirectional in-hand rotation through mechanically encoded power transmission logic. Unlike conventional multifunctional grippers that require multiple actuators, sensors, or control-based switching, the proposed gripper transitions between grasping and rotation solely according to the magnitude of the applied input torque. The key enabler of this behavior is a Twisted Underactuated Mechanism (TUM), which generates non-coplanar motions, namely axial contraction and rotation, from a single rotational input while producing identical contraction regardless of rotation direction. A friction generator mechanically defines torque thresholds that govern passive mode switching, enabling stable grasp establishment before autonomously transitioning to in-hand rotation without sensing or active control. Analytical models describing the kinematics, elastic force generation, and torque transmission of the TUM are derived and experimentally validated. The fabricated gripper is evaluated through quantitative experiments on grasp success, friction-based grasp force regulation, and bidirectional rotation performance. System-level demonstrations, including bolt manipulation, object reorientation, and manipulator-integrated tasks driven solely by wrist torque, confirm reliable grasp to rotate transitions in both rotational directions. These results demonstrate that non-coplanar multifunctional manipulation can be realized through mechanical design alone, establishing mechanically encoded power transmission logic as a robust alternative to actuator and control intensive gripper architectures.", "AI": {"tldr": "本文提出了一种单驱动器被动夹持器，它利用机械编码的动力传输逻辑，仅通过改变输入扭矩的大小，就能在稳定抓取和连续双向手内旋转之间自动切换，无需额外的驱动器、传感器或控制。", "motivation": "传统的具有多种功能的夹持器通常需要多个驱动器、传感器或复杂的控制策略来实现不同功能。本研究的动机是开发一种更简单、更鲁棒的解决方案，仅通过机械设计实现多功能性。", "method": "该夹持器采用了一种名为“扭曲欠驱动机构”（TUM）的关键组件。TUM能够将单一的旋转输入转化为非共面的运动，包括轴向收缩和旋转。通过集成一个摩擦发电机，机械地设定了扭矩阈值，从而实现了从抓取到旋转模式的被动切换。研究推导并实验验证了TUM的运动学、弹性力生成和扭矩传输的分析模型。", "result": "实验验证了该夹持器在抓取成功率、基于摩擦的抓取力调节以及双向旋转性能方面的能力。系统级演示，如螺栓操作、物体重新定向和集成到机械臂的任务，都展示了其在抓取到旋转的可靠过渡。", "conclusion": "研究表明，通过纯粹的机械设计，特别是利用机械编码的动力传输逻辑，可以实现非共面的多功能操作，为替代依赖驱动器和控制的复杂夹持器架构提供了一种有效的途径。"}}
{"id": "2601.06118", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06118", "abs": "https://arxiv.org/abs/2601.06118", "authors": ["Tairan Fu", "Gonzalo Martínez", "Javier Conde", "Carlos Arriaga", "Pedro Reviriego", "Xiuyuan Qi", "Shanshan Liu"], "title": "Beyond Reproducibility: Token Probabilities Expose Large Language Model Nondeterminism", "comment": null, "summary": "The execution of Large Language Models (LLMs) has been shown to produce nondeterministic results when run on Graphics Processing Units (GPUs), even when they are configured to produce deterministic results. This is due to the finite precision effects of the arithmetic operations, which depend on the order in which they are executed. This order, in turn, depends on the processes that are running concurrently on the GPU. Previous studies have focused on the impact of nondeterminism on the text generated by the LLMs or on proposing mechanisms to achieve deterministic execution. This work takes a closer look at nondeterminism by analyzing the variations on the token probabilities, not on the generated text. Interestingly, all the models evaluated have similar results in both the trends and the actual values of the variations of the probabilities. In particular, the results show that the effects of nondeterminism are significant for token probabilities that are in the range of 0.1 to 0.9, while they are much smaller when the probabilities are close to 0 or 1. This has significant implications for our understanding of nondeterminism. The first is that nondeterminism will likely have a non-negligible impact on generated text when the temperature is not zero, as it introduces significant variations in the token probabilities except when they are close to 0 or 1. Secondly, it suggests that all models have similar non deterministic variations at the token probability level. Therefore, different variations in the performance of the generated text, for example, when measuring accuracy on a benchmark, seem to come from different token probabilities or response lengths. A third implication is that we may be able to estimate the impact of nondeterminism by running a single inference and analyzing the token level probabilities, instead of having to run the same inference many times.", "AI": {"tldr": "本研究分析了大型语言模型（LLM）在GPU上执行时产生的非确定性结果，重点关注了token概率的变异，而非生成文本。研究发现，非确定性效应对概率在0.1到0.9之间的token影响显著，而对接近0或1的token影响较小。这一发现对理解LLM的非确定性及其对生成文本的影响具有重要意义。", "motivation": "虽然已有研究关注LLM非确定性对生成文本的影响或实现确定性执行的机制，但本研究旨在更深入地分析非确定性对token概率本身的影响，而非仅关注最终的文本输出。", "method": "通过分析GPU上LLM执行时，即使在配置为确定性执行的情况下，由于算术运算的有限精度和执行顺序依赖性（受GPU并发进程影响）所导致的token概率变异。", "result": "所有评估的模型在token概率变异的趋势和数值上表现出相似的结果。具体而言，非确定性的影响在token概率为0.1至0.9时显著，而在接近0或1时则很小。", "conclusion": "非确定性对token概率的影响对于理解LLM的行为至关重要：1）当温度（temperature）不为零时，非确定性会对生成文本产生不可忽略的影响；2）所有模型在token概率层面表现出相似的非确定性变异；3）可以通过分析单次推理的token级别概率来估计非确定性的影响，而无需多次运行同一推理。"}}
{"id": "2601.07132", "categories": ["eess.SY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.07132", "abs": "https://arxiv.org/abs/2601.07132", "authors": ["Abdikarim Mohamed Ibrahim", "Rosdiadee Nordin"], "title": "Digital Twin for Ultra-Reliable & Low-Latency 6G Wireless Communications in Dense Urban City", "comment": null, "summary": "High-frequency deployments in dense cities are difficult to plan because coverage, interference, and service reliability depend sensitively on local morphology. This paper develops a geometric Digital Twin (DT) of the Sunway City and uses it to study the service implications of a multi-site mmWave deployment. The DT is constructed from geo-referenced three-dimensional meshes of buildings, roads, and open areas, assembled in Blender and exported as a mesh scene. A seven-transmitter downlink at 10 GHz is then embedded into this geometry and evaluated using a GPU accelerated ray tracing engine that returns path-gain and Signal-to-Interference-plus-Noise Ratio (SINR) fields over a dense grid of user locations. These fields are mapped to achievable throughput and compared against representative target rates for immersive extended reality (XR), vehicle-to-everything (V2X) services, and ultra-reliable low-latency communication (URLLC). The resulting maps show that favourable streets and courtyards form narrow high rate corridors surrounded by deep shadows, even within a dense area. In the baseline deployment, one fifth of the simulated area can maintain 100 Mbps URLLC rates, and less than 10% of cells can reach 1.7 Gbps for XR, despite the presence of several rooftop sites. By exploiting the DT, we further quantify the macro-diversity margin between the best and second best serving sites and show that most URLLC-feasible cells have several decibels of SINR headroom that could be harvested through dual connectivity. The study shows how a city DT can translate ray tracing output into service centric metrics and planning insights, complementing both analytical models and expensive measurement campaigns.", "AI": {"tldr": "本研究利用几何数字孪生（DT）来模拟毫米波（mmWave）网络部署对城市高频服务的影响，并评估不同服务（XR、V2X、URLLC）的性能。", "motivation": "在高密度城市中规划高频部署存在困难，因为覆盖、干扰和服务可靠性对局部形态非常敏感。", "method": "构建了孙威伊城（Sunway City）的几何数字孪生（DT），该DT由三维网格构成。然后，将一个7个发射器的10 GHz下行链路嵌入到该几何模型中，并使用GPU加速的射线追踪引擎进行评估，该引擎在用户位置的密集网格上计算路径增益和SINR。最后，将这些结果映射到可实现的吞吐量，并与XR、V2X和URLLC服务的目标速率进行比较。", "result": "模拟结果显示，即使在密集区域，高速率区域也仅限于街道和庭院形成的狭窄走廊，周围存在深度阴影区。在基线部署下，只有五分之一的模拟区域能够维持100 Mbps的URLLC速率，而不到10%的区域能够达到1.7 Gbps的XR速率。此外，研究量化了最佳和次优服务站点之间的宏分集裕量，并表明大多数URLLC可行的单元格具有数分贝的SINR余量，可以通过双连接进行利用。", "conclusion": "城市数字孪生（DT）能够将射线追踪的输出转化为以服务为中心的指标和规划洞察，可以作为分析模型和昂贵的测量活动的补充。"}}
{"id": "2601.06113", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06113", "abs": "https://arxiv.org/abs/2601.06113", "authors": ["Nitin Vetcha"], "title": "Towards Infinite Length Extrapolation: A Unified Approach", "comment": "14 pages, 7 figures", "summary": "Large language models (LLMs) have revolutionized natural language processing, but their ability to process long sequences is fundamentally limited by the context window size during training. Existing length extrapolation methods often suffer from performance degradation or computational inefficiencies. We thereby use a unified framework that reinterprets positional encoding methods as a decomposition of the attention score into a multiplicative transformation and an additive bias. This perspective not only subsumes popular approaches such as relative position embeddings and attention-bias moderated approaches but also exposes their inherent limitations in handling long-range dependencies. To address these shortcomings, motivated by our framework, we introduce Adaptive Positional Encoding (APE), which leverages adaptive frequency modulation and an intricately designed decay bias that incorporates linear, logarithmic, and square-root terms. Our theoretical analysis establishes conditions for infinite-context extrapolation, ensuring that the softmax normalization remains well-defined over unbounded sequences while preserving long-distance correlations, entropy boundedness and gradient positional sensitivity. We substantiate our claims with an experimental case study on TinyStories dataset as well as a new synthetic dataset, \\emph{Long Tiny Stories} featuring stories up to 32,000 words. Relevant code, dataset and model weights are available at https://anonymous.4open.science/r/Check-2DAD/.", "AI": {"tldr": "该研究提出了自适应位置编码 (APE) 方法，用于解决大型语言模型 (LLMs) 处理长序列时因上下文窗口限制导致的性能下降问题，并为无限上下文外插提供了理论保证。", "motivation": "现有处理长序列的外插方法存在性能下降和计算效率低下的问题，LLMs 的上下文窗口限制了其处理长序列的能力。", "method": "提出一个统一框架，将位置编码解释为注意力分数分解为乘法变换和加性偏差。在此基础上，引入自适应位置编码 (APE)，利用自适应频率调制和包含线性、对数和平方根项的衰减偏差。对无限上下文外插的条件进行理论分析。", "result": "理论分析表明，APE 能够确保 softmax 归一化在无限序列上保持良定义，同时保留长距离相关性、熵有界性和梯度位置敏感性。在 TinyStories 和 Long Tiny Stories 数据集上的实验验证了方法的有效性。", "conclusion": "APE 是一种有效的位置编码方法，能够克服 LLMs 在处理长序列时的局限性，并为实现无限上下文外插提供了理论基础和实践验证。"}}
{"id": "2601.06854", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06854", "abs": "https://arxiv.org/abs/2601.06854", "authors": ["Luigi Romano", "Ole Morten Aamo", "Jan Åslund", "Erik Frisk"], "title": "Semilinear single-track vehicle models with distributed tyre friction dynamics", "comment": "37 pages, 12 figures. Accepted by Nonlinear Dynamics", "summary": "This paper introduces a novel family of single-track vehicle models that incorporate a distributed representation of transient tyre dynamics, whilst simultaneously accounting for nonlinear effects induced by friction. The core of the proposed framework is represented by the distributed Friction with Bristle Dynamics (FrBD) model, which unifies and extends classical formulations such as Dahl and LuGre by describing the rolling contact process as a spatially distributed system governed by semilinear partial differential equations (PDEs). This model is systematically integrated into a single-track vehicle framework, where the resulting semilinear ODE-PDE interconnection captures the interaction between lateral vehicle motion and tyre deformation. Two main variants are considered: one with rigid tyre carcass and another with flexible carcass, each admitting a compact state-space representation. Local and global well-posedness properties for the coupled system are established rigorously, highlighting the dissipative and physically consistent properties of the distributed FrBD model. A linearisation procedure is also presented, enabling spectral analysis and transfer function derivation, and potentially facilitating the synthesis of controllers and observers. Numerical simulations demonstrate the model's capability to capture micro-shimmy oscillations and transient lateral responses to advanced steering manoeuvres. The proposed formulation advances the state-of-the-art in vehicle dynamics modelling by providing a physically grounded, mathematically rigorous, and computationally tractable approach to incorporating transient tyre behaviour in lateral vehicle dynamics, when accounting for the effect of limited friction.", "AI": {"tldr": "本文提出了一种新的单轨车辆模型，该模型结合了瞬态轮胎动力学的分布式表示，并考虑了由摩擦引起.非线性效应。该模型通过将滚动接触过程描述为由半线性偏微分方程控制的空间分布式系统，统一并扩展了经典的 Dahl 和 LuGre 模型。", "motivation": "现有车辆动力学模型在处理瞬态轮胎动力学和摩擦引起的非线性效应时存在不足，尤其是在考虑有限摩擦的情况下。", "method": "提出了一种名为 FrBD（Friction with Bristle Dynamics）的分布式摩擦模型，并将其集成到单轨车辆模型中。该模型通过半线性常微分方程-偏微分方程（ODE-PDE）耦合来捕捉车辆侧向运动与轮胎变形的相互作用。研究了刚性和柔性轮胎两种情况，并建立了系统的良定性。", "result": "该模型能够捕捉微小抖动振荡和转向操作引起的瞬态侧向响应。通过线性化可以进行谱分析和传递函数推导，为控制器和观测器的设计奠定基础。", "conclusion": "本文提出了一种在考虑有限摩擦时，能够集成瞬态轮胎行为的车辆动力学建模方法，该方法在物理基础、数学严谨性和计算可行性方面均有所改进。"}}
{"id": "2601.06307", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06307", "abs": "https://arxiv.org/abs/2601.06307", "authors": ["Ishika Agarwal", "Zhenlin He", "Dhruva Patil", "Dilek Hakkani-Tür"], "title": "A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality", "comment": null, "summary": "Non-compositional expressions (e.g., idioms, proverbs, and metaphors) pose significant challenges for neural machine translation systems because their meanings cannot be derived from individual words alone. These expressions encode rich, cultural meaning, and have both figurative and literal meanings, making accurate translation difficult. Because models are fairly good at translating compositional text, we investigate GRPO-style fine-tuning using Machine Translation Quality Estimation (MTQE) models as reward functions to train models to better translate idioms. Using Chinese and Hindi idiom datasets, we find that idiom translation abilities improve by ~14 points, general, non-idiomatic translation implicitly improves by ~8 points, and cross-lingual translation abilities (trained on one language, evaluated on another) improves by ~6 points. Overall, our work quantifies the non-compositional translation gap and offers insights for developing LLMs with stronger cross-cultural and figurative language understanding.", "AI": {"tldr": "本研究提出了一种使用机器翻译质量估计（MTQE）模型作为奖励函数，通过GRPO风格微调来提升神经机器翻译系统对非构成性表达（如成语）的翻译能力。", "motivation": "非构成性表达（如成语、谚语、隐喻）由于其含义无法从单个词推导，给神经机器翻译系统带来了挑战。它们蕴含丰富的文化含义，具有字面和比喻意义，翻译难度大。", "method": "利用MTQE模型作为奖励函数，对现有翻译模型进行GRPO风格的微调，专门训练模型更好地翻译成语。", "result": "在中文和印地语成语数据集上进行实验，结果显示：成语翻译能力提升约14分；一般的、非成语的翻译能力隐式提升约8分；跨语言翻译能力（在一语言上训练，在另一语言上评估）提升约6分。", "conclusion": "本研究量化了非构成性表达的翻译鸿沟，并为开发具有更强跨文化和比喻性语言理解能力的大型语言模型提供了见解。"}}
{"id": "2601.06126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06126", "abs": "https://arxiv.org/abs/2601.06126", "authors": ["Boshen Shi", "Kexin Yang", "Yuanbo Yang", "Guanguang Chang", "Ce Chi", "Zhendong Wang", "Xing Wang", "Junlan Feng"], "title": "NL2Dashboard: A Lightweight and Controllable Framework for Generating Dashboards with LLMs", "comment": null, "summary": "While Large Language Models (LLMs) have demonstrated remarkable proficiency in generating standalone charts, synthesizing comprehensive dashboards remains a formidable challenge. Existing end-to-end paradigms, which typically treat dashboard generation as a direct code generation task (e.g., raw HTML), suffer from two fundamental limitations: representation redundancy due to massive tokens spent on visual rendering, and low controllability caused by the entanglement of analytical reasoning and presentation. To address these challenges, we propose NL2Dashboard, a lightweight framework grounded in the principle of Analysis-Presentation Decoupling. We introduce a structured intermediate representation (IR) that encapsulates the dashboard's content, layout, and visual elements. Therefore, it confines the LLM's role to data analysis and intent translation, while offloading visual synthesis to a deterministic rendering engine. Building upon this framework, we develop a multi-agent system in which the IR-driven algorithm is instantiated as a suite of tools. Comprehensive experiments conducted with this system demonstrate that NL2Dashboard significantly outperforms state-of-the-art baselines across diverse domains, achieving superior visual quality, significantly higher token efficiency, and precise controllability in both generation and modification tasks.", "AI": {"tldr": "提出了一种名为NL2Dashboard的轻量级框架，通过分析-展示解耦和结构化中间表示（IR），解决了大型语言模型在生成综合仪表盘方面的挑战，提高了效率和可控性。", "motivation": "现有大型语言模型在生成独立图表方面表现出色，但在合成综合仪表盘方面存在困难。现有的端到端方法存在表示冗余和低可控性问题。", "method": "提出NL2Dashboard框架，采用分析-展示解耦原则。引入结构化的中间表示（IR）来封装仪表盘的内容、布局和视觉元素。LLM负责数据分析和意图翻译，视觉合成由确定性渲染引擎负责。构建了一个多代理系统，将IR驱动的算法实例化为工具套件。", "result": "NL2Dashboard在多样化领域显著优于最先进的基线模型，在视觉质量、令牌效率和生成/修改任务的可控性方面表现更佳。", "conclusion": "NL2Dashboard框架通过分析-展示解耦和结构化IR，能够高效且可控地生成高质量的综合仪表盘，克服了现有方法的局限性。"}}
{"id": "2601.06198", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06198", "abs": "https://arxiv.org/abs/2601.06198", "authors": ["Shubham Goel", "Farzana S", "C V Rishi", "Aditya Arun", "C V Jawahar"], "title": "How Does India Cook Biryani?", "comment": null, "summary": "Biryani, one of India's most celebrated dishes, exhibits remarkable regional diversity in its preparation, ingredients, and presentation. With the growing availability of online cooking videos, there is unprecedented potential to study such culinary variations using computational tools systematically. However, existing video understanding methods fail to capture the fine-grained, multimodal, and culturally grounded differences in procedural cooking videos. This work presents the first large-scale, curated dataset of biryani preparation videos, comprising 120 high-quality YouTube recordings across 12 distinct regional styles. We propose a multi-stage framework leveraging recent advances in vision-language models (VLMs) to segment videos into fine-grained procedural units and align them with audio transcripts and canonical recipe text. Building on these aligned representations, we introduce a video comparison pipeline that automatically identifies and explains procedural differences between regional variants. We construct a comprehensive question-answer (QA) benchmark spanning multiple reasoning levels to evaluate procedural understanding in VLMs. Our approach employs multiple VLMs in complementary roles, incorporates human-in-the-loop verification for high-precision tasks, and benchmarks several state-of-the-art models under zero-shot and fine-tuned settings. The resulting dataset, comparison methodology, and QA benchmark provide a new testbed for evaluating VLMs on structured, multimodal reasoning tasks and open new directions for computational analysis of cultural heritage through cooking videos. We release all data, code, and the project website at https://farzanashaju.github.io/how-does-india-cook-biryani/.", "AI": {"tldr": "该研究提出了一个包含120个印度香饭制作视频的数据集，覆盖12种区域风格，并设计了一个基于多模态视觉语言模型（VLMs）的框架，用于细粒度分割视频、对齐文本和音频，从而自动识别和解释区域烹饪差异。此外，还构建了一个QA基准来评估VLMs的理解能力。", "motivation": "现有视频理解方法难以捕捉烹饪视频中细粒度、多模态和文化背景的差异，而印度香饭作为一道具有显著区域多样性的菜肴，其丰富的烹饪变化为研究提供了机会，现有计算工具无法系统地研究这些多样性。", "method": "构建了一个包含120个印度香饭制作视频的数据集，覆盖12种区域风格。提出了一种多阶段框架，利用VLMs细粒度分割视频，并将其与音频转录和标准食谱文本对齐。在此基础上，开发了一个视频比较流程，自动识别和解释区域变种之间的程序性差异。构建了一个多层级的QA基准来评估VLMs的理解能力。采用了多个VLMs，并结合了人工验证。", "result": "开发了一个新的数据集、比较方法和QA基准，为评估VLMs在结构化、多模态推理任务上的能力提供了一个新的测试平台。该方法能够自动识别和解释不同地区印度香饭制作过程中的差异。", "conclusion": "该研究为计算分析烹饪视频中的文化遗产开辟了新方向，并提供了一个评估VLMs在处理细粒度、多模态和文化相关信息方面的强大工具。所提出的数据集、框架和基准为未来的研究奠定了基础。"}}
{"id": "2601.07133", "categories": ["eess.SY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.07133", "abs": "https://arxiv.org/abs/2601.07133", "authors": ["Abdikarim Mohamed Ibrahim", "Rosdiadee Nordin"], "title": "Geometry-Aware LoRaWAN Gateway Placement in Dense Urban Cities Using Digital Twins", "comment": null, "summary": "LoRaWAN deployments rely on rough range estimates or simplified propagation models to decide where to place/mount gateways. As a result, operators have limited visibility into how rooftop choice, streets, and building shadowing jointly affect coverage and reliability. This paper addresses the problem of gateway placement in dense urban environments by combining a geometry accurate Digital Twin (DT) with a GPU accelerated ray tracing engine. Existing studies optimize placement on abstract grids or tune models with sparse measurements; few works evaluate LoRaWAN gateways on a full 3D city model using a realistic link budget. In this paper, we develop a DT with ITU radio materials and evaluate eight candidate rooftops for RAK7289 WisGate Edge Pro gateways under a sub-GHz link budget derived from the data sheet. For each rooftop, we obtain Signal-to-Noise Ratios (SNR) on a 5 meter grid, derive robust and edge coverage indicators, and apply a greedy maximum coverage algorithm to rank sites and quantify the benefit of incremental densification. Results show that a single rooftop gateway covers one fifth of the full Sunway twin (i.e., the DT) at a robust SNR threshold, and that six sites still leave large areas of single gateway or out of coverage cells in surrounding residential streets. The findings from this paper shows that DT and ray tracing tools enable network operators to bridge the gap of expensive real-world trials and planning to identify if the planned LoRaWAN gateway is sufficient or additional sites are required.", "AI": {"tldr": "该研究使用数字孪生和光线追踪技术，在三维城市模型中模拟和评估了 LoRaWAN 网关在密集城市环境中的放置策略，以优化覆盖范围和可靠性。", "motivation": "现有的 LoRaWAN 网关放置决策依赖于粗略的范围估计或简化的传播模型，导致运营商对屋顶选择、街道和建筑物阴影对覆盖和可靠性的联合影响缺乏可见性。本文旨在解决密集城市环境中网关放置的挑战。", "method": "该研究结合了具有几何精确性的数字孪生（DT）和一个 GPU 加速的光线追踪引擎。研究人员开发了一个包含 ITU 无线电材料的 DT，并使用来自数据表的亚 GHz 链路预算，评估了八个候选屋顶上 RAK7289 WisGate Edge Pro 网关的性能。对每个屋顶，在 5 米的网格上获得了信噪比（SNR），推导了稳健和边缘覆盖指标，并应用了贪婪最大覆盖算法。", "result": "研究结果表明，单个屋顶网关在稳健的 SNR 阈值下只能覆盖 Sunway 双生城市模型（即 DT）的五分之一。即使部署了六个网关，在周围的居民区街道中，仍有大片区域处于单网关覆盖或无覆盖状态。", "conclusion": "数字孪生和光线追踪工具能够帮助网络运营商弥合昂贵的真实世界试验和规划之间的差距，从而确定计划部署的 LoRaWAN 网关是否足够，或者是否需要额外的站点。"}}
{"id": "2601.06887", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06887", "abs": "https://arxiv.org/abs/2601.06887", "authors": ["Yin Zhang", "Zian Ning", "Shiyu Zhao"], "title": "Observability-Enhanced Target Motion Estimation via Bearing-Box: Theory and MAV Applications", "comment": "This paper is accepted by IEEE Transactions on Robotics (20 pages, 11 figures)", "summary": "Monocular vision-based target motion estimation is a fundamental challenge in numerous applications. This work introduces a novel bearing-box approach that fully leverages modern 3D detection measurements that are widely available nowadays but have not been well explored for motion estimation so far. Unlike existing methods that rely on restrictive assumptions such as isotropic target shape and lateral motion, our bearing-box estimator can estimate both the target's motion and its physical size without these assumptions by exploiting the information buried in a 3D bounding box. When applied to multi-rotor micro aerial vehicles (MAVs), the estimator yields an interesting advantage: it further removes the need for higher-order motion assumptions by exploiting the unique coupling between MAV's acceleration and thrust. This is particularly significant, as higher-order motion assumptions are widely believed to be necessary in state-of-the-art bearing-based estimators. We support our claims with rigorous observability analyses and extensive experimental validation, demonstrating the estimator's superior performance in real-world scenarios.", "AI": {"tldr": "本文提出了一种新颖的基于单目视觉的运动估计方法（bearing-box），利用3D边界框信息，无需对目标形状和运动进行限制性假设，即可估计目标运动和尺寸。该方法在多旋翼微型飞行器（MAVs）上具有独特优势，消除了对高阶运动假设的需求。", "motivation": "现有基于单目视觉的目标运动估计方法依赖于对目标形状（如各向同性）和运动（如横向运动）的限制性假设，并且通常需要高阶运动假设。作者希望开发一种更通用的方法，充分利用现代3D检测测量（3D边界框）来克服这些限制。", "method": "提出了一种名为“bearing-box”的估计器，该估计器利用3D边界框的几何信息来估计目标的目标运动和物理尺寸。对于多旋翼MAVs，该方法进一步利用了MAVs的加速度和推力之间的耦合关系，消除了对高阶运动假设的需求。通过可观性分析和广泛的实验验证来支持其方法的有效性。", "result": "提出的bearing-box估计器能够估计目标运动和尺寸，且无需对目标形状或运动做出限制性假设。在多旋翼MAVs上的应用，消除了对高阶运动假设的依赖。实验验证表明，该估计器在真实场景中表现优越。", "conclusion": "bearing-box方法是一种新颖有效的单目视觉目标运动估计方法，它能够利用3D边界框信息，克服现有方法的局限性，并在多旋翼MAVs上实现更鲁棒的运动估计。"}}
{"id": "2601.06202", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06202", "abs": "https://arxiv.org/abs/2601.06202", "authors": ["Shiwen Zhang", "Haibin Huang", "Chi Zhang", "Xuelong Li"], "title": "QwenStyle: Content-Preserving Style Transfer with Qwen-Image-Edit", "comment": "The codes and models are released at https://github.com/witcherofresearch/Qwen-Image-Style-Transfer", "summary": "Content-Preserving Style transfer, given content and style references, remains challenging for Diffusion Transformers (DiTs) due to its internal entangled content and style features. In this technical report, we propose the first content-preserving style transfer model trained on Qwen-Image-Edit, which activates Qwen-Image-Edit's strong content preservation and style customization capability. We collected and filtered high quality data of limited specific styles and synthesized triplets with thousands categories of style images in-the-wild. We introduce the Curriculum Continual Learning framework to train QwenStyle with such mixture of clean and noisy triplets, which enables QwenStyle to generalize to unseen styles without degradation of the precise content preservation capability. Our QwenStyle V1 achieves state-of-the-art performance in three core metrics: style similarity, content consistency, and aesthetic quality.", "AI": {"tldr": "提出了一种名为 QwenStyle V1 的内容保持风格迁移模型，它基于 Qwen-Image-Edit，并在包含合成和真实图像的混合数据集上训练，使用课程持续学习框架，在风格相似性、内容一致性和美学质量方面达到了最先进的性能。", "motivation": "扩散 Transformer (DiTs) 在内容保持风格迁移方面面临挑战，因为其内部内容和风格特征纠缠不清。现有方法难以在保持内容的同时进行风格定制。", "method": "1. 基于 Qwen-Image-Edit 构建模型，利用其内容保持和风格定制能力。\n2. 收集并过滤高质量的特定风格数据，并结合野外的大量风格图像，合成包含数千类风格图像的三元组数据。\n3. 引入课程持续学习 (Curriculum Continual Learning) 框架，用于训练模型处理混合的干净和嘈杂的三元组数据，以提高对未见风格的泛化能力，同时不损害内容保持能力。", "result": "QwenStyle V1 在风格相似性、内容一致性和美学质量这三个核心指标上均取得了最先进的性能。", "conclusion": "QwenStyle V1 成功实现了内容保持风格迁移，并能泛化到未见过的新风格，同时保持了精确的内容保持能力，证明了所提出的方法和训练策略的有效性。"}}
{"id": "2601.06316", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06316", "abs": "https://arxiv.org/abs/2601.06316", "authors": ["Mutaz Ayesh", "Saif M. Mohammad", "Nedjma Ousidhoum"], "title": "Annotating Dimensions of Social Perception in Text: The First Sentence-Level Dataset of Warmth and Competence", "comment": null, "summary": "Warmth (W) (often further broken down into Trust (T) and Sociability (S)) and Competence (C) are central dimensions along which people evaluate individuals and social groups (Fiske, 2018). While these constructs are well established in social psychology, they are only starting to get attention in NLP research through word-level lexicons, which do not completely capture their contextual expression in larger text units and discourse. In this work, we introduce Warmth and Competence Sentences (W&C-Sent), the first sentence-level dataset annotated for warmth and competence. The dataset includes over 1,600 English sentence--target pairs annotated along three dimensions: trust and sociability (components of warmth), and competence. The sentences in W&C-Sent are from social media and often express attitudes and opinions about specific individuals or social groups (the targets of our annotations). We describe the data collection, annotation, and quality-control procedures in detail, and evaluate a range of large language models (LLMs) on their ability to identify trust, sociability, and competence in text. W&C-Sent provides a new resource for analyzing warmth and competence in language and supports future research at the intersection of NLP and computational social science.", "AI": {"tldr": "本文提出了W&C-Sent，一个包含1600多个句子-目标对的英文数据集，用于标注文本中的温暖（信任、社交性）和能力维度，旨在促进NLP与计算社会科学的交叉研究。", "motivation": "现有的NLP研究主要关注词汇层面的温暖和能力，未能充分捕捉其在句子和语篇中的语境化表达。因此，需要一个句子层面的数据集来更好地分析语言中的温暖和能力。", "method": "收集并标注了超过1600个句子-目标对，涉及信任、社交性和能力三个维度。这些句子主要来源于社交媒体，表达了对特定个体或群体的态度和观点。研究详细介绍了数据收集、标注和质量控制流程，并评估了大型语言模型在识别这些维度上的能力。", "result": "创建了W&C-Sent数据集，并对LLMs在理解文本中信任、社交性和能力方面的表现进行了评估。", "conclusion": "W&C-Sent数据集为分析语言中的温暖和能力提供了一个新的资源，并有望支持NLP与计算社会科学领域未来的研究。"}}
{"id": "2601.06152", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06152", "abs": "https://arxiv.org/abs/2601.06152", "authors": ["Hailong Li", "Feifei Li", "Wenhui Que", "Xingyu Fan"], "title": "HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants", "comment": null, "summary": "Large language models (LLMs) power many interactive systems such as chatbots, customer-service agents, and personal assistants. In knowledge-intensive scenarios requiring user-specific personalization, conventional retrieval-augmented generation (RAG) pipelines exhibit limited memory capacity and insufficient coordination between retrieval mechanisms and user-specific conversational history, leading to redundant clarification, irrelevant documents, and degraded user experience. Inspired by the hippocampus-neocortex memory mechanism, we propose HiMeS, an AI-assistant architecture that fuses short-term and long-term memory. Our contributions are fourfold: (1) A short-term memory extractor is trained end-to-end with reinforcement learning to compress recent dialogue and proactively pre-retrieve documents from the knowledge base, emulating the cooperative interaction between the hippocampus and prefrontal cortex. (2) A partitioned long-term memory network stores user-specific information and re-ranks retrieved documents, simulating distributed cortical storage and memory reactivation. (3) On a real-world industrial dataset, HiMeS significantly outperforms a cascaded RAG baseline on question-answering quality. (4) Ablation studies confirm the necessity of both memory modules and suggest a practical path toward more reliable, context-aware, user-customized LLM-based assistants.", "AI": {"tldr": "本文提出了一种名为 HiMeS 的 AI 助手架构，它结合了短期和长期记忆，以解决现有 RAG（检索增强生成）方法在知识密集型、个性化场景下的局限性，从而提升对话质量和用户体验。", "motivation": "现有的 RAG 管道在用户特定个性化方面存在内存容量有限、检索机制与用户对话历史协调不足的问题，导致冗余澄清、文档不相关和用户体验下降。", "method": "HiMeS 架构包含一个短期记忆提取器（通过强化学习训练，压缩对话并预检索文档）和一个长​​期记忆网络（存储用户信息并重新排序检索到的文档）。", "result": "在真实的工业数据集上，HiMeS 在问答质量方面显著优于级联 RAG 基线。消融研究证实了两个记忆模块的必要性。", "conclusion": "HiMeS 架构通过融合短期和长期记忆，为构建更可靠、更具上下文感知能力、用户定制化的 LLM 助手提供了一条可行的途径。"}}
{"id": "2601.06329", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06329", "abs": "https://arxiv.org/abs/2601.06329", "authors": ["Jeff Chan-Jan Sju", "Liang-Hsuan Tseng", "Yi-Cheng Lin", "Yen-Chun Kuo", "Ju-Chieh Chou", "Kai-Wei Chang", "Hung-yi Lee", "Carlos Busso"], "title": "On the Fallacy of Global Token Perplexity in Spoken Language Model Evaluation", "comment": null, "summary": "Generative spoken language models pretrained on large-scale raw audio can continue a speech prompt with appropriate content while preserving attributes like speaker and emotion, serving as foundation models for spoken dialogue. In prior literature, these models are often evaluated using ``global token perplexity'', which directly applies the text perplexity formulation to speech tokens. However, this practice overlooks fundamental differences between speech and text modalities, possibly leading to an underestimation of the speech characteristics. In this work, we propose a variety of likelihood- and generative-based evaluation methods that serve in place of naive global token perplexity. We demonstrate that the proposed evaluations more faithfully reflect perceived generation quality, as evidenced by stronger correlations with human-rated mean opinion scores (MOS). When assessed under the new metrics, the relative performance landscape of spoken language models is reshaped, revealing a significantly reduced gap between the best-performing model and the human topline. Together, these results suggest that appropriate evaluation is critical for accurately assessing progress in spoken language modeling.", "AI": {"tldr": "本文提出了一系列新的评估生成式语音语言模型的方法，以取代现有的“全局 token 困惑度”评估方法，并证明了新方法更能准确地反映生成的语音质量，且能更准确地评估模型间的相对性能。", "motivation": "现有研究中用于评估生成式语音语言模型的“全局 token 困惑度”方法存在缺陷，它忽略了语音和文本模态的根本差异，可能导致对语音生成质量的低估。作者希望提出更合适的评估方法。", "method": "作者提出了一系列基于似然和生成的方法来替代“全局 token 困惑度”。他们通过将这些新方法与人类评分（MOS）进行比较，来验证其有效性。", "result": "提出的评估方法与人类评分（MOS）的相关性更强，更能忠实地反映感知的生成质量。在新的评估指标下，不同语音语言模型的相对性能排名发生了变化，最佳模型与人类基线之间的差距显著缩小。", "conclusion": "恰当的评估方法对于准确评估语音语言模型的研究进展至关重要。现有的“全局 token 困惑度”评估方法可能无法充分体现模型在语音生成方面的能力。"}}
{"id": "2601.06204", "categories": ["cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.06204", "abs": "https://arxiv.org/abs/2601.06204", "authors": ["Tayyab Rehman", "Giovanni De Gasperis", "Aly Shmahell"], "title": "Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification", "comment": null, "summary": "Intelligent anomaly detection in dynamic visual environments requires reconciling real-time performance with semantic interpretability. Conventional approaches address only fragments of this challenge. Reconstruction-based models capture low-level deviations without contextual reasoning, object detectors provide speed but limited semantics, and large vision-language systems deliver interpretability at prohibitive computational cost. This work introduces a cascading multi-agent framework that unifies these complementary paradigms into a coherent and interpretable architecture. Early modules perform reconstruction-gated filtering and object-level assessment, while higher-level reasoning agents are selectively invoked to interpret semantically ambiguous events. The system employs adaptive escalation thresholds and a publish-subscribe communication backbone, enabling asynchronous coordination and scalable deployment across heterogeneous hardware. Extensive evaluation on large-scale monitoring data demonstrates that the proposed cascade achieves a threefold reduction in latency compared to direct vision-language inference, while maintaining high perceptual fidelity (PSNR = 38.3 dB, SSIM = 0.965) and consistent semantic labeling. The framework advances beyond conventional detection pipelines by combining early-exit efficiency, adaptive multi-agent reasoning, and explainable anomaly attribution, establishing a reproducible and energy-efficient foundation for scalable intelligent visual monitoring.", "AI": {"tldr": "提出了一种级联多智能体框架，结合了重建、目标检测和视觉语言模型，以实现高效且可解释的动态视觉环境异常检测。", "motivation": "传统的异常检测方法在实时性能和语义可解释性之间存在权衡，无法同时满足要求。", "method": "构建了一个级联多智能体框架，早期模块进行重建门控过滤和对象级评估，高级推理智能体选择性地解释语义模糊的事件。系统采用自适应升级阈值和发布-订阅通信，支持异步协调和可扩展部署。", "result": "在大型监控数据上进行评估，与直接的视觉语言推理相比，提出的级联方法将延迟降低了三倍，同时保持了高感知保真度（PSNR = 38.3 dB, SSIM = 0.965）和一致的语义标注。", "conclusion": "该框架通过结合早期退出效率、自适应多智能体推理和可解释的异常归因，超越了传统的检测方法，为可扩展的智能视觉监控奠定了可重现且节能的基础。"}}
{"id": "2601.07150", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07150", "abs": "https://arxiv.org/abs/2601.07150", "authors": ["Linlin Li", "Steven X. Ding", "Maiying Zhong", "Dong Zhao", "Yang Shi"], "title": "Analysis, detection and control of secure and safe cyber-physical control systems in a unified framework", "comment": null, "summary": "This paper deals with analysis, simultaneous detection of faults and attacks, fault-tolerant control and attack-resilient of cyber-physical control systems. In our recent work, it has been observed that an attack detector driven by an input residual signal is capable of reliably detecting attacks. In particular, observing system dynamics from the perspective of the system input-output signal space reveals that attacks and system uncertainties act on different system subspaces. These results motivate our exploration of secure and safe cyber-physical control systems in the unified framework of control and detection. The unified framework is proposed to handle control and detection issues uniformly and in subspaces of system input-output data. Its mathematical and control-theoretic basis is system coprime factorizations with Bezout identity at its core. We firstly explore those methods and schemes of the unified framework, which serve as the major control-theoretic tool in our work. It is followed by re-visiting and examining established attack detection and resilient control schemes. The major part of our work is the endeavours to develop a control-theoretic paradigm, in which analysis, simultaneous detection of faults and attacks, fault-tolerant and attack-resilient control of cyber-physical control systems are addressed in a unified manner.", "AI": {"tldr": "本文提出了一个统一的控制与检测框架，用于分析、同步检测故障与攻击，并实现对网络物理控制系统的容错和抗攻击控制。", "motivation": "近期研究发现，基于输入残差信号的攻击检测器能够可靠地检测攻击。通过分析输入-输出信号空间中的系统动力学，发现攻击和系统不确定性作用于不同的子空间。这促使研究者探索在统一框架下实现安全且可靠的网络物理控制系统。", "method": "采用基于系统 coprime 分解和 Bezout 恒等式的统一框架，在输入-输出数据子空间中统一处理控制和检测问题。该框架是研究的主要控制理论工具，并在此基础上重新审视和检查现有的攻击检测和弹性控制方案。", "result": "开发了一个控制理论范式，能够统一处理网络物理控制系统的分析、故障与攻击的同步检测、容错控制以及抗攻击控制。", "conclusion": "通过将控制和检测问题置于统一的框架内，并利用系统子空间分析，可以有效地实现对网络物理控制系统的安全性和可靠性保障，包括故障和攻击的检测以及相应的容错和抗攻击控制。"}}
{"id": "2601.06997", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06997", "abs": "https://arxiv.org/abs/2601.06997", "authors": ["Yuetao Li", "Zhizhou Jia", "Yu Zhang", "Qun Hao", "Shaohui Zhang"], "title": "ObjSplat: Geometry-Aware Gaussian Surfels for Active Object Reconstruction", "comment": "Project Page: https://li-yuetao.github.io/ObjSplat-page/", "summary": "Autonomous high-fidelity object reconstruction is fundamental for creating digital assets and bridging the simulation-to-reality gap in robotics. We present ObjSplat, an active reconstruction framework that leverages Gaussian surfels as a unified representation to progressively reconstruct unknown objects with both photorealistic appearance and accurate geometry. Addressing the limitations of conventional opacity or depth-based cues, we introduce a geometry-aware viewpoint evaluation pipeline that explicitly models back-face visibility and occlusion-aware multi-view covisibility, reliably identifying under-reconstructed regions even on geometrically complex objects. Furthermore, to overcome the limitations of greedy planning strategies, ObjSplat employs a next-best-path (NBP) planner that performs multi-step lookahead on a dynamically constructed spatial graph. By jointly optimizing information gain and movement cost, this planner generates globally efficient trajectories. Extensive experiments in simulation and on real-world cultural artifacts demonstrate that ObjSplat produces physically consistent models within minutes, achieving superior reconstruction fidelity and surface completeness while significantly reducing scan time and path length compared to state-of-the-art approaches. Project page: https://li-yuetao.github.io/ObjSplat-page/ .", "AI": {"tldr": "ObjSplat是一个主动式三维物体重建框架，使用高斯曲面作为统一表示，能够快速生成具有逼真外观和精确几何形状的数字模型，尤其擅长处理几何复杂的物体，并在模拟和真实世界实验中优于现有方法。", "motivation": "现有物体重建方法在处理复杂几何形状、遮挡以及规划扫描路径方面存在局限性，尤其是在需要快速生成高保真数字资产的场景下。研究动机是为了开发一种更有效、更准确、更快速的主动重建系统。", "method": "ObjSplat 使用高斯曲面（Gaussian surfels）作为统一的三维表示。其核心方法包括：1. 几何感知的视点评估流程，考虑背面可见性和遮挡感知多视点共可见性，以识别重建不足区域。2. 下一步最优路径（Next-Best-Path, NBP）规划器，通过多步前瞻和动态构建的空间图，在信息增益和移动成本之间进行联合优化，生成全局最优扫描轨迹。", "result": "ObjSplat 在模拟和真实世界（文化遗产物品）的实验中，能在几分钟内生成物理一致的模型。相较于现有最先进的方法，ObjSplat 在重建保真度、表面完整性方面表现更优，同时显著缩短了扫描时间和路径长度。", "conclusion": "ObjSplat 提出了一种新颖的主动三维物体重建框架，通过结合高斯曲面表示、几何感知的视点评估和基于 NBP 的全局最优路径规划，有效解决了现有方法的不足，实现了高效、高保真的物体重建，为数字资产创建和机器人应用提供了强大的解决方案。"}}
{"id": "2601.07009", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07009", "abs": "https://arxiv.org/abs/2601.07009", "authors": ["Shifa Sulaiman", "Mohammad Gohari", "Francesco Schetter", "Fanny Ficuciello"], "title": "A Sliding Mode Controller Based on Timoshenko Beam Theory Developed for a Tendon-Driven Robotic Wrist", "comment": null, "summary": "Development of dexterous robotic joints is essential for advancing manipulation capabilities in robotic systems. This paper presents the design and implementation of a tendon-driven robotic wrist joint together with an efficient Sliding Mode Controller (SMC) for precise motion control. The wrist mechanism is modeled using a Timoshenko-based approach to accurately capture its kinematic and dynamic properties, which serve as the foundation for tendon force calculations within the controller. The proposed SMC is designed to deliver fast dynamic response and computational efficiency, enabling accurate trajectory tracking under varying operating conditions. The effectiveness of the controller is validated through comparative analyses with existing controllers for similar wrist mechanisms. The proposed SMC demonstrates superior performance in both simulation and experimental studies. The Root Mean Square Error (RMSE) in simulation is approximately 1.67e-2 radians, while experimental validation yields an error of 0.2 radians. Additionally, the controller achieves a settling time of less than 3 seconds and a steady-state error below 1e-1 radians, consistently observed across both simulation and experimental evaluations. Comparative analyses confirm that the developed SMC surpasses alternative control strategies in motion accuracy, rapid convergence, and steady-state precision. This work establishes a foundation for future exploration of tendon-driven wrist mechanisms and control strategies in robotic applications.", "AI": {"tldr": "本文设计并实现了一个腱驱动的机器人腕关节，并采用了一种高效的滑模控制器（SMC）来实现精确运动控制。该控制器在仿真和实验中均表现出优于现有方法的性能。", "motivation": "为了提高机器人系统的操作能力，需要开发更灵巧的机器人关节。", "method": "采用基于Timoshenko的方法对腕部机械结构进行建模，并在此基础上计算腱力，设计了滑模控制器（SMC）。通过仿真和实验验证了控制器的有效性，并与现有控制器进行了比较。", "result": "SMC在仿真和实验中均取得了优异的性能，仿真RMSE约为1.67e-2弧度，实验误差为0.2弧度。控制器在3秒内达到稳定，稳态误差小于1e-1弧度。", "conclusion": "所提出的SMC在运动精度、快速收敛和稳态精度方面优于其他控制策略，为未来腱驱动腕关节和控制策略的研究奠定了基础。"}}
{"id": "2601.06209", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06209", "abs": "https://arxiv.org/abs/2601.06209", "authors": ["Julien Combes", "Alexandre Derville", "Jean-François Coeurjolly"], "title": "When Imbalance Comes Twice: Active Learning under Simulated Class Imbalance and Label Shift in Binary Semantic Segmentation", "comment": null, "summary": "The aim of Active Learning is to select the most informative samples from an unlabelled set of data. This is useful in cases where the amount of data is large and labelling is expensive, such as in machine vision or medical imaging. Two particularities of machine vision are first, that most of the images produced are free of defects, and second, that the amount of images produced is so big that we cannot store all acquired images. This results, on the one hand, in a strong class imbalance in defect distribution and, on the other hand, in a potential label shift caused by limited storage. To understand how these two forms of imbalance affect active learning algorithms, we propose a simulation study based on two open-source datasets. We artificially create datasets for which we control the levels of class imbalance and label shift. Three standard active learning selection strategies are compared: random sampling, entropy-based selection, and core-set selection. We demonstrate that active learning strategies, and in particular the entropy-based and core-set selections, remain interesting and efficient even for highly imbalanced datasets. We also illustrate and measure the loss of efficiency that occurs in the situation a strong label shift.", "AI": {"tldr": "该研究模拟了在图像识别任务中，类别不平衡和标签偏移对主动学习策略（随机采样、熵采样、核心集采样）的影响，发现主动学习在类别不平衡情况下仍有效，但标签偏移会降低其效率。", "motivation": "在机器视觉和医学影像等领域，标注数据成本高昂且数据量巨大。图像生产中常见的缺陷样本少（类别不平衡）以及存储限制导致的标签偏移，可能会影响主动学习的效果，因此需要研究这些不平衡因素的影响。", "method": "通过模拟研究，在两个开源数据集上人工创建了不同程度类别不平衡和标签偏移的数据集，并比较了随机采样、熵采样和核心集采样这三种主动学习策略的性能。", "result": "研究表明，即使在高度不平衡的数据集上，熵采样和核心集采样等主动学习策略仍然有效。同时，研究量化了标签偏移对主动学习效率造成的损失。", "conclusion": "主动学习策略，特别是熵采样和核心集采样，在类别不平衡的图像识别任务中仍然具有价值。然而，标签偏移会显著降低主动学习的效率，需要加以注意。"}}
{"id": "2601.07156", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07156", "abs": "https://arxiv.org/abs/2601.07156", "authors": ["Mouaad Boughellaba", "Abdelhamid Tayebi", "James R. Forbes", "Soulaimane Berkane"], "title": "Nonlinear Observer Design for Visual-Inertial Odometry", "comment": null, "summary": "This paper addresses the problem of Visual-Inertial Odometry (VIO) for rigid body systems evolving in three-dimensional space. We introduce a novel matrix Lie group structure, denoted SE_{3+n}(3), that unifies the pose, gravity, linear velocity, and landmark positions within a consistent geometric framework tailored to the VIO problem. Building upon this formulation, we design an almost globally asymptotically stable nonlinear geometric observer that tightly integrates data from an Inertial Measurement Unit (IMU) and visual sensors. Unlike conventional Extended Kalman Filter (EKF)-based estimators that rely on local linearization and thus ensure only local convergence, the proposed observer achieves almost global stability through the decoupling of the rotational and translational dynamics. A globally exponentially stable Riccati-based translational observer along with an almost global input-to-state stable attitude observer are designed such that the overall cascaded observer enjoys almost global asymptotic stability. This cascaded architecture guarantees robust and consistent estimation of the extended state, including orientation, position, velocity, gravity, and landmark positions, up to the VIO unobservable directions (i.e., a global translation and rotation about gravity). The effectiveness of the proposed scheme is demonstrated through numerical simulations as well as experimental validation on the EuRoC MAV dataset, highlighting its robustness and suitability for real-world VIO applications.", "AI": {"tldr": "本文提出了一种基于矩阵李群SE_{3+n}(3)的新型框架，用于解决刚体系统的视觉-惯性里程计（VIO）问题。该框架能够将姿态、重力、线速度和特征点位置统一起来，并设计了一个几乎全局渐近稳定的非线性几何观测器，实现了IMU和视觉数据的紧密融合。与基于EKF的局部线性化方法不同，该观测器通过解耦旋转和翻译动力学，实现了几乎全局稳定性，并能鲁棒地估计姿态、位置、速度、重力和特征点位置。", "motivation": "传统的VIO估计器（如EKF）依赖于局部线性化，只能保证局部收敛，无法解决VIO的一些固有不确定性（如全局平移和绕重力轴的旋转）。作者旨在开发一种能够实现几乎全局稳定性的VIO方法，以提高估计的鲁棒性和一致性。", "method": "1. 引入了一个新的矩阵李群结构SE_{3+n}(3)，统一了VIO相关的状态变量（姿态、重力、线速度、特征点位置）。\n2. 基于该几何框架，设计了一个几乎全局渐近稳定的非线性几何观测器。\n3. 将观测器设计为级联结构：一个全局指数稳定的基于Riccati的翻译观测器和一个几乎全局输入状态稳定的姿态观测器。\n4. 通过数值仿真和EuRoC MAV数据集的实验验证了方法的有效性。", "result": "该方法能够鲁棒且一致地估计VIO的扩展状态，包括方向、位置、速度、重力和特征点位置（除了VIO固有的全局平移和绕重力轴的旋转不确定性）。实验结果表明，该方法在鲁棒性和适用性方面表现优异。", "conclusion": "本文提出的基于SE_{3+n}(3)李群的VIO方法，通过设计级联的非线性几何观测器，实现了几乎全局的渐近稳定性，克服了传统方法的局部收敛限制，并能够鲁棒地估计VIO的各种状态变量，适用于真实世界的VIO应用。"}}
{"id": "2601.06347", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06347", "abs": "https://arxiv.org/abs/2601.06347", "authors": ["Jonas Golde", "Patrick Haller", "Alan Akbik"], "title": "What Matters When Building Universal Multilingual Named Entity Recognition Models?", "comment": null, "summary": "Recent progress in universal multilingual named entity recognition (NER) has been driven by advances in multilingual transformer models and task-specific architectures, loss functions, and training datasets. Despite substantial prior work, we find that many critical design decisions for such models are made without systematic justification, with architectural components, training objectives, and data sources evaluated only in combination rather than in isolation. We argue that these decisions impede progress in the field by making it difficult to identify which choices improve model performance. In this work, we conduct extensive experiments around architectures, transformer backbones, training objectives, and data composition across a wide range of languages. Based on these insights, we introduce Otter, a universal multilingual NER model supporting over 100 languages. Otter achieves consistent improvements over strong multilingual NER baselines, outperforming GLiNER-x-base by 5.3pp in F1 and achieves competitive performance compared to large generative models such as Qwen3-32B, while being substantially more efficient. We release model checkpoints, training and evaluation code to facilitate reproducibility and future research.", "AI": {"tldr": "本研究通过对多语言命名实体识别（NER）模型中的各种组件（架构、Transformer骨干、训练目标、数据组成）进行系统性消融实验，提出了一个名为Otter的高效通用多语言NER模型，在超过100种语言上取得了优于现有基线模型的性能。", "motivation": "现有通用多语言NER模型的设计决策缺乏系统性论证，许多关键组件的有效性在组合评估中被掩盖，阻碍了对模型性能提升来源的理解。作者希望通过系统性实验来解决这一问题。", "method": "作者进行了广泛的实验，分别评估了不同架构、Transformer骨干模型、训练目标和数据组成对多语言NER模型性能的影响。基于这些实验结果，提出了Otter模型。", "result": "Otter模型在超过100种语言上取得了优于GLiNER-x-base的性能（F1值提升5.3pp），并与大型生成模型（如Qwen3-32B）相比具有竞争力，同时效率更高。研究释放了模型检查点、训练和评估代码。", "conclusion": "通过系统的消融研究，识别出提升多语言NER模型性能的关键因素，并基于此构建了高效且性能优越的通用多语言NER模型Otter，为该领域的研究和实践提供了重要贡献。"}}
{"id": "2601.06160", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06160", "abs": "https://arxiv.org/abs/2601.06160", "authors": ["Dayu Wang", "Jiaye Yang", "Weikang Li", "Jiahui Liang", "Yang Li"], "title": "Student Guides Teacher: Weak-to-Strong Inference via Spectral Orthogonal Exploration", "comment": null, "summary": "While Large Language Models (LLMs) demonstrate near-human capabilities, they often suffer from \"Reasoning Collapse\" in complex mathematical proving and long-horizon planning. Models tend to degenerate into low-rank Bias Manifold, where stochastic sampling merely produces lexical variations of erroneous logic rather than semantic exploration. This geometric collapse renders the model \"blind\" to high-value solutions that lie within its Null Space. To address this, we propose Spectral Orthogonal Exploration (SOE), a geometric framework operating on a counter-intuitive \"Student Guides Teacher\" paradigm. Specifically, we utilize a weak auxiliary agent not for imitation, but as an orthogonal probe. By explicitly navigating the Teacher's Null Space, SOE serves as a geometric bridge, effectively ejecting the model from local optima to explore diverse, high-value solution spaces. Experiments on mathematical benchmarks demonstrate that, relative to baseline methods, our approach improves average accuracy by 62.4% and increases average sampling efficiency by 113.7%, indicating a promising path toward overcoming performance plateaus in advanced reasoning tasks.", "AI": {"tldr": "提出了一种名为“谱正交探索”（SOE）的框架，通过一个弱辅助学习器作为“学生”引导“教师”模型，利用其零空间进行探索，以克服大型语言模型在复杂数学推理和长期规划中出现的“推理崩溃”问题。", "motivation": "大型语言模型（LLMs）在执行复杂数学证明和长期规划任务时，常常会陷入“推理崩溃”，表现为模型退化到低秩偏差流形，导致仅产生词汇变化而非语义探索，无法发现潜在的高价值解决方案。", "method": "提出谱正交探索（SOE）框架，采用“学生引导教师”的范式。一个弱辅助代理（学生）不用于模仿，而是作为正交探测器，显式地探索教师模型的零空间，从而将教师模型从局部最优中“弹出”，探索多样化的、高价值的解决方案空间。", "result": "在数学基准测试上的实验表明，与基线方法相比，SOE方法平均准确率提高了62.4%，平均采样效率提高了113.7%。", "conclusion": "SOE是一种有效的几何框架，能够克服LLMs在高级推理任务中的性能瓶颈，通过利用零空间探索，显著提升了模型的准确性和效率。"}}
{"id": "2601.07295", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07295", "abs": "https://arxiv.org/abs/2601.07295", "authors": ["Rongxing Hu", "Charalambos Konstantinou"], "title": "Stochastic Power-Water Coordination: Unlocking Flexibility in Hybrid RO Desalination Plants via Variable-Speed Pumps and Tank Mixing", "comment": "10 pages, 10 figures, journal", "summary": "Water desalination plants (DPs) are among the most critical infrastructures and largest electricity loads in water-scarce regions worldwide. Although reverse osmosis (RO) desalination is the most energy-efficient and dominant technology, it remains energy-intensive but can offer substantial flexibility potential for power systems. This paper proposes a coordinated operation framework for power systems and DPs that explicitly accounts for both systems' operational constraints and fully unlocks DP flexibility. To achieve this, a detailed DP model is developed, incorporating the characteristics of an actual high-pressure pump with variable-speed operation, on-off operation with flushing requirements, water quality constraints, and water dynamics and salt mixing in the storage tank. By proactively managing freshwater storage and tank salinity in a closed-loop coordinated scheduling framework, the operational flexibility of the DP is significantly enhanced. With appropriate simplification and linearization, the resulting coordinated scheduling problem is formulated as a tractable mixed-integer linear programming (MILP) model, and a two-step decomposed commitment-scheduling stochastic optimization (TDCSO) is proposed to efficiently address uncertainties. Case studies validate the proposed approach and demonstrate up to a 6% operating cost reduction.", "AI": {"tldr": "提出了一种协调电力系统和海水淡化厂（DP）运行的框架，通过优化淡化厂的灵活性来降低运营成本，并使用混合整数线性规划（MILP）模型和随机优化方法来解决不确定性。", "motivation": "海水淡化厂是重要的基础设施，也是电力消耗大户，但其固有的灵活性可用于支持电力系统。研究旨在充分挖掘这种灵活性，以优化两种系统的运行。", "method": "开发了一个详细的海水淡化厂模型，考虑了高压泵、启停操作、水质、储水罐的动态和盐度混合。将该模型纳入一个闭环协调调度框架，并将其转化为混合整数线性规划（MILP）模型。使用两步分解的承诺-调度随机优化（TDCSO）方法来处理不确定性。", "result": "通过主动管理淡化厂的储水和罐体盐度，显著增强了其运行灵活性。所提出的方法可以降低高达6%的运营成本。", "conclusion": "提出的协调运行框架能够有效地利用海水淡化厂的灵活性，降低电力系统和海水淡化厂的运营成本，并能够处理不确定性。"}}
{"id": "2601.07052", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07052", "abs": "https://arxiv.org/abs/2601.07052", "authors": ["Simon Sagmeister", "Marcel Weinmann", "Phillip Pitschi", "Markus Lienkamp"], "title": "RSLCPP - Deterministic Simulations Using ROS 2", "comment": "Submitted to 'IEEE Robotics and Automation Practice' for possible publication", "summary": "Simulation is crucial in real-world robotics, offering safe, scalable, and efficient environments for developing applications, ranging from humanoid robots to autonomous vehicles and drones. While the Robot Operating System (ROS) has been widely adopted as the backbone of these robotic applications in both academia and industry, its asynchronous, multiprocess design complicates reproducibility, especially across varying hardware platforms. Deterministic callback execution cannot be guaranteed when computation times and communication delays vary. This lack of reproducibility complicates scientific benchmarking and continuous integration, where consistent results are essential. To address this, we present a methodology to create deterministic simulations using ROS 2 nodes. Our ROS Simulation Library for C++ (RSLCPP) implements this approach, enabling existing nodes to be combined into a simulation routine that yields reproducible results without requiring any code changes. We demonstrate that our approach yields identical results across various CPUs and architectures when testing both a synthetic benchmark and a real-world robotics system. RSLCPP is open-sourced at https://github.com/TUMFTM/rslcpp.", "AI": {"tldr": "提出了一种名为 RSLCPP 的方法和库，用于在 ROS 2 中实现可复现的机器人仿真，无需修改现有节点代码，并在不同硬件上验证了其有效性。", "motivation": "ROS 的异步多进程设计导致仿真结果难以复现，这阻碍了科学基准测试和持续集成。研究旨在解决这个问题，提供可复现的 ROS 仿真。", "method": "开发了一个名为 RSLCPP (ROS Simulation Library for C++) 的库，该库实现了一种方法，可以将现有的 ROS 2 节点组合成一个可复现的仿真例程，而无需修改节点代码。", "result": "该方法在不同 CPU 和架构上进行了测试，无论是合成基准测试还是真实机器人系统，均获得了完全相同的仿真结果，证明了其可复现性。", "conclusion": "RSLCPP 提供了一种有效的方法来创建可复现的 ROS 2 仿真，解决了现有 ROS 设计在硬件平台间可能存在的复现性问题，并且易于集成，无需修改现有代码。"}}
{"id": "2601.06212", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06212", "abs": "https://arxiv.org/abs/2601.06212", "authors": ["Yani Meziani"], "title": "Akasha 2: Hamiltonian State Space Duality and Visual-Language Joint Embedding Predictive Architectur", "comment": "12 pages, 6 figures, 3 tables. Includes appendices with pseudocode and implementation details. Supplementary materials eventually at github.com/yanimeziani/akasha", "summary": "We present Akasha 2, a state-of-the-art multimodal architecture that integrates Hamiltonian State Space Duality (H-SSD) with Visual-Language Joint Embedding Predictive Architecture (VL-JEPA). The system leverages the Mamba-3 Selective State Space Model (SSM) augmented by a Sparse Mixture of Hamiltonian Experts (SMoE-HE) that enforces latent physical conservation laws through symplectic integration. For visual synthesis, we introduce Hamiltonian Flow Matching (HFM) and persistent 3D Gaussian Splatting (3DGS), enabling ultra-low latency (<50ms) on mobile hardware. This work establishes a new paradigm in latent world models, achieving unprecedented spatiotemporal coherence through a holographic memory architecture. Our approach demonstrates that incorporating physics-inspired inductive biases into neural architectures yields significant improvements: state-of-the-art video prediction (FVD: 287), 4x faster visual synthesis than diffusion models, and 3-18x inference speedup over transformer baselines while maintaining energy conservation over extended horizons.", "AI": {"tldr": "Akasha 2 是一个集成了 Hamiltonian State Space Duality (H-SSD) 和 Visual-Language Joint Embedding Predictive Architecture (VL-JEPA) 的多模态架构。它使用 Mamba-3 SSM 并辅以稀疏专家混合模型 (SMoE-HE)，通过辛积分强制执行潜在物理守恒定律。此外，它还引入了 Hamiltonian Flow Matching (HFM) 和持久化 3D Gaussian Splatting (3DGS) 来实现低延迟视觉合成。该模型在视频预测、视觉合成和推理速度方面取得了最先进的性能，并保持了能量守恒。", "motivation": "研究动机是将物理学的归纳偏置（如能量守恒）整合到神经网络架构中，以提高其在潜在世界模型中的表现，特别是在时空相干性、视频预测和视觉合成方面。", "method": "该研究提出了 Akasha 2 架构，集成了 H-SSD 和 VL-JEPA。它使用了 Mamba-3 SSM，并对其进行了增强，引入了 SMoE-HE 以利用辛积分强制执行物理守恒定律。对于视觉合成，采用了 HFM 和持久化 3DGS。", "result": "Akasha 2 在视频预测方面达到了最先进的性能（FVD: 287），视觉合成速度比扩散模型快 4 倍，推理速度比 Transformer 基线快 3-18 倍。此外，它在长时间的推理过程中保持了能量守恒。", "conclusion": "将物理学原理（如能量守恒）融入神经网络架构是构建更具时空相干性和效率的潜在世界模型的一种有效途径，能够显著提升视频预测、视觉合成和推理速度等方面的性能。"}}
{"id": "2601.07527", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.07527", "abs": "https://arxiv.org/abs/2601.07527", "authors": ["Josip Kir Hromatko", "Šandor Ileš", "Branimir Škugor", "Joško Deur"], "title": "Energy-efficient torque allocation for straight-line driving of electric vehicles based on pseudoconvex polynomials", "comment": "21 pages, 8 figures", "summary": "Electric vehicles with multiple motors provide a flexibility in meeting the driver torque demand, which calls for minimizing the battery energy consumption through torque allocation. In this paper, we present an approach to this problem based on approximating electric motor losses using higher-order polynomials with specific properties. To ensure a well-behaved optimization landscape, monotonicity and positivity constraints are imposed on the polynomial models using sum of squares programming. This methodology provides robustness against noisy or sparse data, while retaining the computational efficiency of a polynomial function approximation. The torque allocation problem based on such polynomials is formulated as a constrained nonlinear optimization problem and solved efficiently using readily available solvers. In the nominal case, the first-order necessary conditions for optimality can also be used to obtain a global solution. The performance of the proposed method is evaluated on several certification driving cycles against a grid search-based benchmark. Results show a modest influence on electric energy consumption, while enabling real-time optimization and integration with other vehicle control systems.", "AI": {"tldr": "该论文提出一种基于高次多项式逼近电机损耗的方法，用于电动汽车的多电机扭矩分配，以最小化电池能量消耗。通过和平方规划施加单调性和正值约束，确保优化问题的良好行为，并提高了对噪声和稀疏数据的鲁棒性。", "motivation": "电动汽车多电机系统需要通过扭矩分配来最小化电池能量消耗，以提高效率。", "method": "使用具有特定性质的高次多项式来近似电机损耗，并通过和平方规划施加单调性和正值约束，将扭矩分配问题转化为约束非线性优化问题，利用现有的求解器解决。", "result": "在几个认证驾驶循环中，该方法与基于网格搜索的基准相比，对电能消耗的影响适中，同时实现了实时优化和与其他车辆控制系统的集成。", "conclusion": "所提出的基于高次多项式近似电机损耗的方法，能够有效地解决电动汽车的扭矩分配问题，实现实时优化，并具有良好的鲁棒性和计算效率。"}}
{"id": "2601.06218", "categories": ["cs.CV", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.06218", "abs": "https://arxiv.org/abs/2601.06218", "authors": ["Kuan Wei Chen", "Ting Yi Lin", "Wen Ren Yang", "Aryan Kesarwani", "Riya Singh"], "title": "Two-step Authentication: Multi-biometric System Using Voice and Facial Recognition", "comment": "Accepted manuscript (author version, v2). The published version appears in IET Conference Proceedings; see DOI: 10.1049/icp.2024.4141. Code: https://github.com/NCUE-EE-AIAL/Two-step-Authentication-Multi-biometric-System", "summary": "We present a cost-effective two-step authentication system that integrates face identification and speaker verification using only a camera and microphone available on common devices. The pipeline first performs face recognition to identify a candidate user from a small enrolled group, then performs voice recognition only against the matched identity to reduce computation and improve robustness. For face recognition, a pruned VGG-16 based classifier is trained on an augmented dataset of 924 images from five subjects, with faces localized by MTCNN; it achieves 95.1% accuracy. For voice recognition, a CNN speaker-verification model trained on LibriSpeech (train-other-360) attains 98.9% accuracy and 3.456% EER on test-clean. Source code and trained models are available at https://github.com/NCUE-EE-AIAL/Two-step-Authentication-Multi-biometric-System.", "AI": {"tldr": "提出了一种基于人脸识别和声纹识别的两步身份验证系统，仅使用通用设备上的摄像头和麦克风，成本低廉且准确率高。", "motivation": "为了开发一个成本效益高、集成方便且鲁棒性强的身份验证系统，利用现有设备（摄像头和麦克风）的常见性。", "method": "采用两步流程：首先使用修剪过的VGG-16人脸识别模型（MTCNN定位人脸）识别候选用户，然后仅针对匹配身份进行声纹识别（CNN模型）。", "result": "人脸识别准确率达到95.1%；声纹识别在test-clean数据集上达到98.9%的准确率和3.456%的EER。", "conclusion": "该系统能够以高准确率有效地执行身份验证，并且由于其对常见设备的依赖性，具有良好的可部署性。"}}
{"id": "2601.06161", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06161", "abs": "https://arxiv.org/abs/2601.06161", "authors": ["Rifa Ferzana"], "title": "Beyond Accuracy: A Decision-Theoretic Framework for Allocation-Aware Healthcare AI", "comment": "11 pages, 3 figures, PDF-only submission. This work introduces a decision-theoretic framework to bridge the gap between predictive accuracy and clinical impact in healthcare AI. Includes synthetic simulation results", "summary": "Artificial intelligence (AI) systems increasingly achieve expert-level predictive accuracy in healthcare, yet improvements in model performance often fail to produce corresponding gains in patient outcomes. We term this disconnect the allocation gap and provide a decision-theoretic explanation by modelling healthcare delivery as a stochastic allocation problem under binding resource constraints. In this framework, AI acts as decision infrastructure that estimates utility rather than making autonomous decisions. Using constrained optimisation and Markov decision processes, we show how improved estimation affects optimal allocation under scarcity. A synthetic triage simulation demonstrates that allocation-aware policies substantially outperform risk-threshold approaches in realised utility, even with identical predictive accuracy. The framework provides a principled basis for evaluating and deploying healthcare AI in resource-constrained settings.", "AI": {"tldr": "本文提出“分配缺口”概念，解释了医疗AI预测准确性提高但患者结局未相应改善的现象。通过将医疗资源分配建模为带约束的随机分配问题，并使用约束优化和马尔可夫决策过程，研究表明，即使AI的预测准确性相同，考虑分配的策略也比仅依赖风险阈值的策略能带来更高的实际效用。", "motivation": "医疗AI在预测准确性上已达到专家水平，但这种准确性提升并未转化为患者结局的相应改善，这种脱节现象促使了本研究。", "method": "该研究将医疗服务建模为一个在资源约束下的随机分配问题，并将AI视为提供效用估计的决策基础设施。利用约束优化和马尔可夫决策过程（MDP）来分析改进的预测准确性如何影响稀缺资源下的最优分配。并通过合成的Triage（分诊）模拟来验证方法的有效性。", "result": "研究表明，在资源有限的情况下，即使AI的预测准确性相同，采用“分配感知”的策略（allocation-aware policies）也能显著优于仅基于风险阈值（risk-threshold）的策略，从而实现更高的实际效用。", "conclusion": "该研究提供了一个原则性的框架，用于评估和部署资源受限环境下的医疗AI。它强调了在设计和实施医疗AI时，必须考虑资源分配的约束，以弥合预测准确性和实际患者结局之间的差距。"}}
{"id": "2601.06372", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06372", "abs": "https://arxiv.org/abs/2601.06372", "authors": ["Martha Larson"], "title": "Talking to Extraordinary Objects: Folktales Offer Analogies for Interacting with Technology", "comment": null, "summary": "Speech and language are valuable for interacting with technology. It would be ideal to be able to decouple their use from anthropomorphization, which has recently met an important moment of reckoning. In the world of folktales, language is everywhere and talking to extraordinary objects is not unusual. This overview presents examples of the analogies that folktales offer. Extraordinary objects in folktales are diverse and also memorable. Language capacity and intelligence are not always connected to humanness. Consideration of folktales can offer inspiration and insight for using speech and language for interacting with technology.", "AI": {"tldr": "本文探讨了童话故事中非人类实体（如物体）具有语言能力，并提出这种叙事可以为我们与技术进行语音和语言交互提供灵感，从而避免不必要的拟人化。", "motivation": "当前技术交互中存在过度拟人化的问题，而童话故事中非人类的语言能力提供了跳出这一思维模式的视角，可以为技术交互带来新的启发。", "method": "本文通过回顾和分析童话故事中的案例，展示了非人类实体如何使用语言，以及语言能力与智能并非总是与人类相关联。", "result": "童话故事提供了丰富的例子，说明了语言能力和智能可以独立于人类存在，并且非人类的“智能”对象是多样且令人难忘的。", "conclusion": "童话故事中的类比可以为我们设计技术中的语音和语言交互提供灵感，帮助我们摆脱对拟人化的依赖，并探索更广泛的可能性。"}}
{"id": "2601.07060", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07060", "abs": "https://arxiv.org/abs/2601.07060", "authors": ["Yuanzhe Liu", "Jingyuan Zhu", "Yuchen Mo", "Gen Li", "Xu Cao", "Jin Jin", "Yifan Shen", "Zhengyuan Li", "Tianjiao Yu", "Wenzhen Yuan", "Fangqiang Ding", "Ismini Lourentzou"], "title": "PALM: Progress-Aware Policy Learning via Affordance Reasoning for Long-Horizon Robotic Manipulation", "comment": null, "summary": "Recent advancements in vision-language-action (VLA) models have shown promise in robotic manipulation, yet they continue to struggle with long-horizon, multi-step tasks. Existing methods lack internal reasoning mechanisms that can identify task-relevant interaction cues or track progress within a subtask, leading to critical execution errors such as repeated actions, missed steps, and premature termination. To address these challenges, we introduce PALM, a VLA framework that structures policy learning around interaction-centric affordance reasoning and subtask progress cues. PALM distills complementary affordance representations that capture object relevance, contact geometry, spatial placements, and motion dynamics, and serve as task-relevant anchors for visuomotor control. To further stabilize long-horizon execution, PALM predicts continuous within-subtask progress, enabling seamless subtask transitions. Across extensive simulation and real-world experiments, PALM consistently outperforms baselines, achieving a 91.8% success rate on LIBERO-LONG, a 12.5% improvement in average length on CALVIN ABC->D, and a 2x improvement over real-world baselines across three long-horizon generalization settings.", "AI": {"tldr": "PALM是一个视觉-语言-动作（VLA）框架，通过引入以交互为中心的联想推理和子任务进度提示，来解决机器人多步长任务的挑战，并在模拟和真实世界实验中展现出优于现有方法的性能。", "motivation": "现有的VLA模型在处理长时序、多步任务时存在困难，缺乏内部推理机制来识别任务相关线索或跟踪子任务进度，导致执行错误。", "method": "PALM框架通过提炼互补的联想表示来捕捉物体相关性、接触几何、空间位置和运动动力学，作为视觉-运动控制的任务相关锚点。此外，PALM预测连续的子任务内进度，以稳定长时序执行并实现无缝子任务过渡。", "result": "PALM在LIBERO-LONG上达到了91.8%的成功率，在CALVIN ABC->D上的平均长度提高了12.5%，并在三个长时序泛化场景下比真实世界基线提高了2倍。", "conclusion": "PALM通过引入联想推理和进度提示，有效地提高了VLA模型在长时序机器人操作任务中的性能和稳定性。"}}
{"id": "2601.06181", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.06181", "abs": "https://arxiv.org/abs/2601.06181", "authors": ["Yung-Shen Hsia", "Fang Yu", "Jie-Hong Roland Jiang"], "title": "Neuro-Symbolic Compliance: Integrating LLMs and SMT Solvers for Automated Financial Legal Analysis", "comment": "10 pages, 6 tables, 3 figures, accepted by the 2nd ACM AIware Conference", "summary": "Financial regulations are increasingly complex, hindering automated compliance-especially the maintenance of logical consistency with minimal human oversight. We introduce a Neuro-Symbolic Compliance Framework that integrates Large Language Models (LLMs) with Satisfiability Modulo Theories (SMT) solvers to enable formal verifiability and optimization-based compliance correction. The LLM interprets statutes and enforcement cases to generate SMT constraints, while the solver enforces consistency and computes the minimal factual modification required to restore legality when penalties arise. Unlike transparency-oriented methods, our approach emphasizes logic-driven optimization, delivering verifiable, legally consistent reasoning rather than post-hoc explanation. Evaluated on 87 enforcement cases from Taiwan's Financial Supervisory Commission (FSC), the system attains 86.2% correctness in SMT code generation, improves reasoning efficiency by over 100x, and consistently corrects violations-establishing a preliminary foundation for optimization-based compliance applications.", "AI": {"tldr": "该研究提出了一种结合大语言模型（LLMs）和可满足性模理论（SMT）求解器的神经符号合规框架，用于自动化金融合规，实现形式可验证性和基于优化的合规纠正。", "motivation": "现有金融法规的复杂性阻碍了自动化合规，特别是保持逻辑一致性并减少人工监督的难度。", "method": "利用LLM解读法规和执法案例，生成SMT约束。SMT求解器则用于强制执行一致性，并在出现违规时计算最小的事实修改以恢复合法性。", "result": "在台湾金融监督管理委员会（FSC）的87个执法案例上进行评估，系统在SMT代码生成方面达到了86.2%的正确率，推理效率提高了100倍以上，并能有效地纠正违规行为。", "conclusion": "该框架提供了一种侧重于逻辑驱动优化的方法，实现了可验证、法律上一致的推理，并为基于优化的合规应用奠定了初步基础。"}}
{"id": "2601.07608", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07608", "abs": "https://arxiv.org/abs/2601.07608", "authors": ["Jimin Wang", "Jieming Ke", "Jin Guo", "Yanlong Zhao"], "title": "Recursive Binary Identification with Differential Privacy and Data Tampering Attacks", "comment": null, "summary": "In this paper, we consider the parameter estimation in a bandwidth-constrained sensor network communicating through an insecure medium. The sensor performs a local quantization, and transmits a 1-bit message to an estimation center through a wireless medium where the transmission of information is vulnerable to attackers. Both eavesdroppers and data tampering attackers are considered in our setting. A differential privacy method is used to protect the sensitive information against eavesdroppers. Then, a recursive projection algorithm is proposed such that the estimation center achieves the almost sure convergence and mean-square convergence when quantized measurements, differential privacy, and data tampering attacks are considered in a uniform framework. A privacy analysis including the convergence rate with privacy or without privacy is given. Further, we extend the problem to multi-agent systems. For this case, a distributed recursive projection algorithm is proposed with guaranteed almost sure and mean square convergence. A simulation example is provided to illustrate the effectiveness of the proposed algorithms.", "AI": {"tldr": "本文提出了一种在带宽受限且通信不安全的传感器网络中进行参数估计的方法，该方法结合了差分隐私技术来抵抗窃听，并使用递归投影算法来处理量化测量、差分隐私和数据篡改攻击，以实现几乎必然收敛和均方收敛。同时，该方法被扩展到多智能体系统，并给出了相应的分布式算法。", "motivation": "在带宽受限且通信不安全的传感器网络中，如何同时保证参数估计的准确性、传输信息的隐私性以及抵抗数据篡改攻击是研究的动机。", "method": "1. 局部量化：传感器对数据进行本地量化。\n2. 差分隐私：采用差分隐私技术对量化后的信息进行扰动，以保护隐私免受窃听。\n3. 递归投影算法：设计了一种递归投影算法，用于处理量化测量、差分隐私和数据篡改攻击，以实现参数估计的收敛。\n4. 分布式算法扩展：将单传感器系统扩展到多智能体系统，并提出分布式递归投影算法。", "result": "所提出的递归投影算法在考虑量化测量、差分隐私和数据篡改攻击的情况下，能够实现参数估计的几乎必然收敛和均方收敛。算法的收敛率分析（有隐私和无隐私）也得到了给出。对于多智能体系统，分布式递归投影算法同样能够保证几乎必然和均方收敛。", "conclusion": "本文提出了一种在不安全通信环境下，能够有效处理量化、隐私保护和数据篡改攻击的参数估计方法，并通过分布式算法将其扩展到多智能体系统，证明了所提算法的有效性和收敛性。"}}
{"id": "2601.07186", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07186", "abs": "https://arxiv.org/abs/2601.07186", "authors": ["Zainab Altaweel", "Mohaiminul Al Nahian", "Jake Juettner", "Adnan Siraj Rakin", "Shiqi Zhang"], "title": "PROTEA: Securing Robot Task Planning and Execution", "comment": null, "summary": "Robots need task planning methods to generate action sequences for complex tasks. Recent work on adversarial attacks has revealed significant vulnerabilities in existing robot task planners, especially those built on foundation models. In this paper, we aim to address these security challenges by introducing PROTEA, an LLM-as-a-Judge defense mechanism, to evaluate the security of task plans. PROTEA is developed to address the dimensionality and history challenges in plan safety assessment. We used different LLMs to implement multiple versions of PROTEA for comparison purposes. For systemic evaluations, we created a dataset containing both benign and malicious task plans, where the harmful behaviors were injected at varying levels of stealthiness. Our results provide actionable insights for robotic system practitioners seeking to enhance robustness and security of their task planning systems. Details, dataset and demos are provided: https://protea-secure.github.io/PROTEA/", "AI": {"tldr": "本文提出了一种名为 PROTEA 的基于大型语言模型（LLM）的“裁判”的防御机制，用于评估机器人任务计划的安全性，以应对现有任务计划器（尤其是基于基础模型）在对抗性攻击下的漏洞。PROTEA 能够处理计划安全评估中的维度和历史挑战。研究人员使用不同的 LLM 实现 PROTEA 的多个版本，并构建了一个包含良性和恶意任务计划的数据集进行系统评估，其中恶意行为以不同隐蔽级别注入。结果为提高机器人任务规划系统的鲁棒性和安全性提供了可行性见解。", "motivation": "现有机器人任务规划方法，尤其是基于基础模型的，在对抗性攻击下面临显著的安全漏洞。需要一种机制来评估和增强任务计划的安全性。", "method": "提出并实现了一个名为 PROTEA 的 LLM-as-a-Judge 防御机制。该机制用于评估机器人任务计划的安全性，解决维度和历史挑战。使用了不同 LLM 实现 PROTEA 的多个版本进行比较。创建了一个包含良性和恶意任务计划的评估数据集，恶意计划中注入了不同隐蔽级别的有害行为。", "result": "通过使用不同的 LLM 实现 PROTEA，并在一系列测试用例上进行评估，研究人员获得了可操作的见解。这些见解有助于理解 PROTEA 的有效性以及不同 LLM 版本在安全评估中的表现。", "conclusion": "PROTEA 是一种有效的 LLM-as-a-Judge 机制，可以用来评估机器人任务计划的安全性，从而提高机器人系统的鲁棒性和安全性。研究结果为机器人系统从业者提供实用指导，帮助他们加强任务规划系统的安全防护。"}}
{"id": "2601.07646", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07646", "abs": "https://arxiv.org/abs/2601.07646", "authors": ["José Pulido", "Francesc Wilhelmi", "Sergio Fortes", "Alfonso Fernández-Durán", "Lorenzo Galati Giordano", "Raquel Barco"], "title": "Studying the Role of Synthetic Data for Machine Learning-based Wireless Networks Traffic Forecasting", "comment": null, "summary": "Synthetic data generation is an appealing tool for augmenting and enriching datasets, playing a crucial role in advancing artificial intelligence (AI) and machine learning (ML). Not only does synthetic data help build robust AI/ML datasets cost-effectively, but it also offers privacy-friendly solutions and bypasses the complexities of storing large data volumes. This paper proposes a novel method to generate synthetic data, based on first-order auto-regressive noise statistics, for large-scale Wi-Fi deployments. The approach operates with minimal real data requirements while producing statistically rich traffic patterns that effectively mimic real Access Point (AP) behavior. Experimental results show that ML models trained on synthetic data achieve Mean Absolute Error (MAE) values within 10 to 15 of those obtained using real data when trained on the same APs, while requiring significantly less training data. Moreover, when generalization is required, synthetic-data-trained models improve prediction accuracy by up to 50 percent compared to real-data-trained baselines, thanks to the enhanced variability and diversity of the generated traces. Overall, the proposed method bridges the gap between synthetic data generation and practical Wi-Fi traffic forecasting, providing a scalable, efficient, and real-time solution for modern wireless networks.", "AI": {"tldr": "提出一种基于一阶自回归噪声统计的合成Wi-Fi流量生成方法，该方法能有效模拟真实AP行为，且所需真实数据量少，能提升训练模型的泛化能力。", "motivation": "合成数据生成是增强AI/ML数据集、降低成本、保护隐私和简化数据存储的有效手段，但现有方法在Wi-Fi流量预测方面存在不足。", "method": "提出一种基于一阶自回归噪声统计的新型合成数据生成方法，用于大规模Wi-Fi部署，以生成统计上丰富的流量模式。", "result": "使用合成数据训练的ML模型在同一AP上的MAE值与使用真实数据训练的模型相当（相差10-15），且所需训练数据更少。在需要泛化时，合成数据训练的模型预测精度比真实数据训练的模型高出50%。", "conclusion": "该方法为Wi-Fi流量预测提供了可扩展、高效且实时的解决方案，显著弥合了合成数据生成与实际Wi-Fi流量预测之间的差距。"}}
{"id": "2601.06188", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06188", "abs": "https://arxiv.org/abs/2601.06188", "authors": ["Itai Zilberstein", "Steve Chien"], "title": "Large-Scale Continual Scheduling and Execution for Dynamic Distributed Satellite Constellation Observation Allocation", "comment": null, "summary": "The size and capabilities of Earth-observing satellite constellations are rapidly increasing. Leveraging distributed onboard control, we can enable novel time-sensitive measurements and responses. However, deploying autonomy to satellites requires efficient computation and communication. This work tackles the challenge of efficiently scheduling observations for hundreds of satellites in a dynamic, large-scale problem with millions of variables. We present the Dynamic Multi-Satellite Constellation Observation Scheduling Problem (DCOSP), a new formulation of Dynamic Distributed Constraint Optimization Problems (DDCOP) that models integrated scheduling and execution. DCOSP has a novel optimality condition for which we construct an omniscient offline algorithm for its computation. We also present the Dynamic Incremental Neighborhood Stochastic Search algorithm (D-NSS), an incomplete online decomposition-based DDCOP algorithm that repairs and solves sub-problems when problem dynamics occur. We show through simulation that D-NSS converges to near-optimal solutions and outperforms DDCOP baselines in terms of solution quality, computation time, and message volume. As part of the NASA FAME mission, DCOSP and D-NSS will be the foundation of the largest in-space demonstration of distributed multi-agent AI to date.", "AI": {"tldr": "该研究提出了一种名为DCOSP的新模型，用于解决大规模、动态的卫星星座观测调度问题，并开发了一种名为D-NSS的在线算法，该算法能够有效且近似最优地解决该问题，并将在NASA FAME任务中进行实际应用。", "motivation": "随着地球观测卫星星座的规模和能力不断增长，需要高效的计算和通信来支持自主性，以实现新颖的、对时间敏感的测量和响应。", "method": "提出了一种名为DCOSP（Dynamic Multi-Satellite Constellation Observation Scheduling Problem）的新模型，它是动态分布式约束优化问题（DDCOP）的一种新颖形式，能够整合调度和执行。开发了一种名为D-NSS（Dynamic Incremental Neighborhood Stochastic Search）的在线分解算法，用于解决DCOSP问题。", "result": "通过仿真表明，D-NSS算法能够收敛到接近最优的解决方案，并且在解决方案质量、计算时间和消息量方面优于DDCOP基线算法。", "conclusion": "DCOSP模型和D-NSS算法为解决大规模、动态的卫星星座观测调度问题提供了一个有效的方法，并将在NASA FAME任务中作为大规模分布式多智能体AI演示的基础。"}}
{"id": "2601.07242", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07242", "abs": "https://arxiv.org/abs/2601.07242", "authors": ["Taekbeom Lee", "Dabin Kim", "Youngseok Jang", "H. Jin Kim"], "title": "HERE: Hierarchical Active Exploration of Radiance Field with Epistemic Uncertainty Minimization", "comment": "Accepted to IEEE RA-L. The first two authors contributed equally", "summary": "We present HERE, an active 3D scene reconstruction framework based on neural radiance fields, enabling high-fidelity implicit mapping. Our approach centers around an active learning strategy for camera trajectory generation, driven by accurate identification of unseen regions, which supports efficient data acquisition and precise scene reconstruction. The key to our approach is epistemic uncertainty quantification based on evidential deep learning, which directly captures data insufficiency and exhibits a strong correlation with reconstruction errors. This allows our framework to more reliably identify unexplored or poorly reconstructed regions compared to existing methods, leading to more informed and targeted exploration. Additionally, we design a hierarchical exploration strategy that leverages learned epistemic uncertainty, where local planning extracts target viewpoints from high-uncertainty voxels based on visibility for trajectory generation, and global planning uses uncertainty to guide large-scale coverage for efficient and comprehensive reconstruction. The effectiveness of the proposed method in active 3D reconstruction is demonstrated by achieving higher reconstruction completeness compared to previous approaches on photorealistic simulated scenes across varying scales, while a hardware demonstration further validates its real-world applicability.", "AI": {"tldr": "本文提出了一种名为HERE的主动式3D场景重建框架，该框架基于神经辐射场，并利用基于证据深度学习的认知不确定性量化来实现高效的数据采集和精确的场景重建。", "motivation": "现有3D场景重建方法在数据采集效率和重建质量上存在不足，尤其是在识别和探索未覆盖或重建不佳的区域方面。研究的动机是开发一种更智能、更主动的方法来优化数据采集过程，从而提高3D场景重建的完整性和准确性。", "method": "该方法的核心是主动学习策略，通过认知不确定性量化来识别未探索区域。认知不确定性基于证据深度学习，能够直接捕捉数据不足，并与重建误差相关。在此基础上，设计了分层探索策略，包括局部规划（根据可见性从高不确定性体素提取目标视点）和全局规划（利用不确定性引导大范围覆盖），以实现高效全面的重建。", "result": "与现有方法相比，所提出的HERE框架在不同尺度的照片级真实模拟场景中取得了更高的重建完整性。硬件演示也验证了其在现实世界中的应用潜力。", "conclusion": "HERE框架通过结合主动学习和认知不确定性量化，能够有效地识别未探索区域，优化数据采集，从而实现更高质量的3D场景重建。该方法在模拟和真实世界场景中都表现出了优越性。"}}
{"id": "2601.06224", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06224", "abs": "https://arxiv.org/abs/2601.06224", "authors": ["Miao Pan", "Wangjie Gan", "Jintao Chen", "Wenqi Zhang", "Bing Sun", "Jianwei Yin", "Xuhong Zhang"], "title": "Ground What You See: Hallucination-Resistant MLLMs via Caption Feedback, Diversity-Aware Sampling, and Conflict Regularization", "comment": "AAAI-2026 Poster", "summary": "While Multimodal Large Language Models (MLLMs) have achieved remarkable success across diverse tasks, their practical deployment is severely hindered by hallucination issues, which become particularly acute during Reinforcement Learning (RL) optimization. This paper systematically analyzes the root causes of hallucinations in MLLMs under RL training, identifying three critical factors: (1) an over-reliance on chained visual reasoning, where inaccurate initial descriptions or redundant information anchor subsequent inferences to incorrect premises; (2) insufficient exploration diversity during policy optimization, leading the model to generate overly confident but erroneous outputs; and (3) destructive conflicts between training samples, where Neural Tangent Kernel (NTK) similarity causes false associations and unstable parameter updates. To address these challenges, we propose a comprehensive framework comprising three core modules. First, we enhance visual localization by introducing dedicated planning and captioning stages before the reasoning phase, employing a quality-based caption reward to ensure accurate initial anchoring. Second, to improve exploration, we categorize samples based on the mean and variance of their reward distributions, prioritizing samples with high variance to focus the model on diverse and informative data. Finally, to mitigate sample interference, we regulate NTK similarity by grouping sample pairs and applying an InfoNCE loss to push overly similar pairs apart and pull dissimilar ones closer, thereby guiding gradient interactions toward a balanced range. Experimental results demonstrate that our proposed method significantly reduces hallucination rates and effectively enhances the inference accuracy of MLLMs.", "AI": {"tldr": "本文提出了一种解决多模态大语言模型（MLLM）在强化学习（RL）训练中幻觉问题的框架，通过改进视觉定位、探索多样性和样本干扰来提高模型准确性。", "motivation": "多模态大语言模型（MLLM）在实际应用中存在严重的幻觉问题，尤其是在强化学习（RL）优化过程中，这阻碍了其部署。", "method": "该研究分析了MLLM在RL训练中幻觉的三个根源：视觉推理依赖、探索多样性不足和训练样本冲突。为此，提出了一个包含三个模块的框架：1. 增强视觉定位，增加规划和字幕生成阶段，并使用基于质量的字幕奖励；2. 提高探索多样性，根据奖励分布的均值和方差对样本进行分类，优先处理高方差样本；3. 减轻样本干扰，通过对样本对进行分组并应用InfoNCE损失来调节神经切线核（NTK）相似性。", "result": "实验结果表明，所提出的方法显著降低了幻觉率，并有效提高了MLLM的推理准确性。", "conclusion": "通过改进视觉定位、增加探索多样性和减轻样本干扰，可以有效地解决MLLM在RL训练中的幻觉问题，提高其准确性。"}}
{"id": "2601.06395", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06395", "abs": "https://arxiv.org/abs/2601.06395", "authors": ["Hao Yu", "Tianyi Xu", "Michael A. Hedderich", "Wassim Hamidouche", "Syed Waqas Zamir", "David Ifeoluwa Adelani"], "title": "AfriqueLLM: How Data Mixing and Model Architecture Impact Continued Pre-training for African Languages", "comment": null, "summary": "Large language models (LLMs) are increasingly multilingual, yet open models continue to underperform relative to proprietary systems, with the gap most pronounced for African languages. Continued pre-training (CPT) offers a practical route to language adaptation, but improvements on demanding capabilities such as mathematical reasoning often remain limited. This limitation is driven in part by the uneven domain coverage and missing task-relevant knowledge that characterize many low-resource language corpora. We present \\texttt{AfriqueLLM}, a suite of open LLMs adapted to 20 African languages through CPT on 26B tokens. We perform a comprehensive empirical study across five base models spanning sizes and architectures, including Llama 3.1, Gemma 3, and Qwen 3, and systematically analyze how CPT data composition shapes downstream performance. In particular, we vary mixtures that include math, code, and synthetic translated data, and evaluate the resulting models on a range of multilingual benchmarks. Our results identify data composition as the primary driver of CPT gains. Adding math, code, and synthetic translated data yields consistent improvements, including on reasoning-oriented evaluations. Within a fixed architecture, larger models typically improve performance, but architectural choices dominate scale when comparing across model families. Moreover, strong multilingual performance in the base model does not reliably predict post-CPT outcomes; robust architectures coupled with task-aligned data provide a more dependable recipe. Finally, our best models improve long-context performance, including document-level translation. Models have been released on [Huggingface](https://huggingface.co/collections/McGill-NLP/afriquellm).", "AI": {"tldr": "研究人员通过在 260 亿个 token 上进行持续预训练 (CPT)，发布了一系列名为 AfriqueLLM 的开源大语言模型，涵盖 20 种非洲语言，以弥合非洲语言在 LLM 领域与专有模型之间的差距，尤其是在数学推理等任务上。研究发现，CPT 数据集的构成（特别是包含数学、代码和合成翻译数据）是提升性能的关键，而模型架构比规模更重要。最佳模型在长上下文处理和文档级翻译方面也有所改进。", "motivation": "现有开源大语言模型（LLMs）在处理非洲语言方面表现不佳，与专有模型差距显著。而持续预训练（CPT）虽然是一种语言适应的有效途径，但在数学推理等复杂能力上提升有限，这归因于低资源语言语料库在领域覆盖和任务相关知识上的不足。", "method": "研究人员在五种不同大小和架构的基础模型（包括 Llama 3.1、Gemma 3 和 Qwen 3）上，通过持续预训练（CPT）并使用包含数学、代码和合成翻译数据的 260 亿 token 数据集，对 AfriqueLLM 模型进行了训练。他们系统地分析了 CPT 数据构成对下游性能的影响，并在多语言基准测试上评估了模型。", "result": "研究发现，CPT 数据集的构成是提升性能的主要驱动因素，添加数学、代码和合成翻译数据能够带来一致的性能提升，包括在推理任务上。在固定架构下，更大的模型通常能带来更好的性能，但在不同模型家族之间进行比较时，模型架构的选择比模型规模更具决定性。此外，基础模型强大的多语言性能并不能可靠地预测 CPT 后的表现；拥有强大的架构和与任务相关的 CPT 数据是更可靠的方法。研究中最好的模型在长上下文处理能力，包括文档级翻译方面也得到了提升。", "conclusion": "通过精心设计 CPT 数据集的构成，尤其是在其中加入数学、代码和合成翻译数据，可以显著提升大语言模型在非洲语言上的性能，尤其是在推理能力方面。模型架构的选择比模型规模对性能的影响更大。为了在低资源语言领域取得更好的 LLM 性能，重点应放在构建与任务对齐的数据集和选择强大的模型架构上。"}}
{"id": "2601.06400", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06400", "abs": "https://arxiv.org/abs/2601.06400", "authors": ["Sebastian Nehrdich", "Kurt Keutzer"], "title": "MITRA: A Large-Scale Parallel Corpus and Multilingual Pretrained Language Model for Machine Translation and Semantic Retrieval for Pāli, Sanskrit, Buddhist Chinese, and Tibetan", "comment": null, "summary": "Ancient Buddhist literature features frequent, yet often unannotated, textual parallels spread across diverse languages: Sanskrit, Pāli, Buddhist Chinese, Tibetan, and more. The scale of this material makes manual examination prohibitive. We present the MITRA framework, which consists of a novel pipeline for multilingual parallel passage mining, MITRA-parallel, a large-scale corpus of 1.74 million parallel sentence pairs between Sanskrit, Chinese, and Tibetan, and the development of the domain-specific pretrained language model Gemma 2 MITRA. We present Gemma 2 MITRA-MT, a version of this base model fine-tuned on machine translation tasks, reaching state-of-the-art performance for machine translation of these languages into English and outperforming even much larger open-source models. We also present Gemma 2 MITRA-E, a semantic embedding model that shows state-of-the-art performance on a novel, detailed semantic embedding benchmark. We make the parallel dataset, model weights, and semantic similarity benchmark openly available to aid both NLP research and philological studies in Buddhist and classical Asian literature.", "AI": {"tldr": "该研究提出了MITRA框架，用于自动挖掘和处理多语言佛教文献中的平行文本，并开发了相应的语言模型和数据集。", "motivation": "手动处理跨多种语言（梵语、巴利语、藏语、佛教中文等）的大规模佛教文献平行文本非常困难。", "method": "开发了MITRA框架，包括：1. MITRA-parallel：一个用于多语言平行文本挖掘的流水线。2. 一个包含174万对梵语、中文和藏语平行句子的大规模语料库。3. Gemma 2 MITRA：一个领域特定的预训练语言模型，以及Gemma 2 MITRA-MT（用于机器翻译）和Gemma 2 MITRA-E（用于语义嵌入）的微调版本。", "result": "Gemma 2 MITRA-MT在将佛教文献翻译成英语方面取得了最先进的性能。Gemma 2 MITRA-E在新的语义嵌入基准测试中也表现出了最先进的性能。", "conclusion": "MITRA框架、平行数据集、模型权重和语义相似性基准的开源发布，将有助于自然语言处理研究以及佛教和古典亚洲文学的文献学研究。"}}
{"id": "2601.06189", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06189", "abs": "https://arxiv.org/abs/2601.06189", "authors": ["Atharv Naphade"], "title": "Rational Synthesizers or Heuristic Followers? Analyzing LLMs in RAG-based Question-Answering", "comment": "13 pages, 9 figures, ACL ARR submission", "summary": "Retrieval-Augmented Generation (RAG) is the prevailing paradigm for grounding Large Language Models (LLMs), yet the mechanisms governing how models integrate groups of conflicting retrieved evidence remain opaque. Does an LLM answer a certain way because the evidence is factually strong, because of a prior belief, or merely because it is repeated frequently? To answer this, we introduce GroupQA, a curated dataset of 1,635 controversial questions paired with 15,058 diversely-sourced evidence documents, annotated for stance and qualitative strength. Through controlled experiments, we characterize group-level evidence aggregation dynamics: Paraphrasing an argument can be more persuasive than providing distinct independent support; Models favor evidence presented first rather than last, and Larger models are increasingly resistant to adapt to presented evidence. Additionally, we find that LLM explanations to group-based answers are unfaithful. Together, we show that LLMs behave consistently as vulnerable heuristic followers, with direct implications for improving RAG system design.", "AI": {"tldr": "本文通过GroupQA数据集研究了检索增强生成（RAG）模型在处理相互冲突的检索证据时的行为，发现模型倾向于遵循启发式规则，如重复性、顺序偏好，并且大型模型对证据的适应性较差，解释也不够忠实。", "motivation": "现有RAG范式在整合相互冲突的检索证据方面的机制不明确，例如模型是基于事实强度、先验信念还是重复频率来生成答案。", "method": "构建了一个包含1635个争议性问题和15058份不同来源的证据文件的数据集GroupQA，并对证据进行了立场和质量强度的标注。通过受控实验来分析模型在群体证据聚合方面的动力学。", "result": "模型倾向于重复性论证而非独立支持；模型偏好先呈现的证据而非后呈现的；大型模型对证据的适应性更差；LLM对群体答案的解释不忠实。", "conclusion": "LLM在处理群体证据时表现为易受启发式规则影响的“脆弱追随者”，这一发现对改进RAG系统设计具有直接意义。"}}
{"id": "2601.07284", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07284", "abs": "https://arxiv.org/abs/2601.07284", "authors": ["Haoyu Zhang", "Shibo Jin", "Lvsong Li", "Jun Li", "Liang Lin", "Xiaodong He", "Zecui Zeng"], "title": "AdaMorph: Unified Motion Retargeting via Embodiment-Aware Adaptive Transformers", "comment": null, "summary": "Retargeting human motion to heterogeneous robots is a fundamental challenge in robotics, primarily due to the severe kinematic and dynamic discrepancies between varying embodiments. Existing solutions typically resort to training embodiment-specific models, which scales poorly and fails to exploit shared motion semantics. To address this, we present AdaMorph, a unified neural retargeting framework that enables a single model to adapt human motion to diverse robot morphologies. Our approach treats retargeting as a conditional generation task. We map human motion into a morphology-agnostic latent intent space and utilize a dual-purpose prompting mechanism to condition the generation. Instead of simple input concatenation, we leverage Adaptive Layer Normalization (AdaLN) to dynamically modulate the decoder's feature space based on embodiment constraints. Furthermore, we enforce physical plausibility through a curriculum-based training objective that ensures orientation and trajectory consistency via integration. Experimental results on 12 distinct humanoid robots demonstrate that AdaMorph effectively unifies control across heterogeneous topologies, exhibiting strong zero-shot generalization to unseen complex motions while preserving the dynamic essence of the source behaviors.", "AI": {"tldr": "提出 AdaMorph，一个统一的神经动作重定向框架，允许单个模型将人类动作适配到各种机器人形态，通过将动作映射到与形态无关的潜在意图空间并使用自适应层归一化 (AdaLN) 进行条件生成，并强制执行物理合理性，实验证明了其在不同机器人上的泛化能力。", "motivation": "现有方法在将人类动作重定向到不同机器人时，需要针对不同机器人训练特定的模型，这扩展性差且无法利用共享的运动语义。", "method": "将重定向视为条件生成任务，将人类动作映射到形态无关的潜在意图空间，利用自适应层归一化 (AdaLN) 根据身体约束动态调整解码器的特征空间，并通过基于课程的学习目标来强制执行物理合理性（方向和轨迹一致性）。", "result": "在 12 个不同人形机器人上进行的实验表明，AdaMorph 能够有效地统一跨异构拓扑的控制，对未见过的复杂动作表现出强大的零样本泛化能力，同时保留了源行为的动态本质。", "conclusion": "AdaMorph 是一个统一的神经重定向框架，能够将人类动作适配到各种机器人形态，并表现出良好的泛化能力和物理一致性。"}}
{"id": "2601.07665", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.07665", "abs": "https://arxiv.org/abs/2601.07665", "authors": ["Andrea Martin", "Giuseppe Belgioioso"], "title": "Learning to accelerate Krasnosel'skii-Mann fixed-point iterations with guarantees", "comment": null, "summary": "We introduce a principled learning to optimize (L2O) framework for solving fixed-point problems involving general nonexpansive mappings. Our idea is to deliberately inject summable perturbations into a standard Krasnosel'skii-Mann iteration to improve its average-case performance over a specific distribution of problems while retaining its convergence guarantees. Under a metric sub-regularity assumption, we prove that the proposed parametrization includes only iterations that locally achieve linear convergence-up to a vanishing bias term-and that it encompasses all iterations that do so at a sufficiently fast rate. We then demonstrate how our framework can be used to augment several widely-used operator splitting methods to accelerate the solution of structured monotone inclusion problems, and validate our approach on a best approximation problem using an L2O-augmented Douglas-Rachford splitting algorithm.", "AI": {"tldr": "提出了一种基于学习优化的（L2O）框架，用于解决一般扩张映射的固定点问题，通过引入可加扰动来提高平均情况下的性能，同时保证收敛性。", "motivation": "现有方法在解决一般扩张映射的固定点问题时，其平均情况下的性能有待提高。研究旨在通过学习优化技术来加速这类问题的求解。", "method": "通过向标准的Krasnosel'skii-Mann迭代中注入可加扰动，构建了一个新的L2O框架。在度量子正则性假设下，证明了该参数化方法能实现局部线性收敛，并能够包含所有具有足够快收敛率的迭代方法。该框架被应用于增强几种算子分裂方法，用于解决结构化单调包容问题。", "result": "证明了提出的L2O框架下的参数化迭代方法在局部上能够达到线性收敛（ up to a vanishing bias term）。该框架能够覆盖所有以足够快速率实现线性收敛的迭代方法。将该框架应用于Douglas-Rachford分裂算法，并在一个最佳逼近问题上进行了验证，证明了其加速效果。", "conclusion": "提出的L2O框架是一种原则性的方法，可以用于加速解决一般扩张映射的固定点问题。该框架通过引入扰动来提高平均性能，同时保持收敛性。通过将其应用于算子分裂方法，可以有效地解决结构化单调包容问题，并在实际问题中得到了验证。"}}
{"id": "2601.06228", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06228", "abs": "https://arxiv.org/abs/2601.06228", "authors": ["Zhaoze Wang", "Changxu Zhang", "Tai Fei", "Christopher Grimm", "Yi Jin", "Claas Tebruegge", "Ernst Warsitz", "Markus Gardill"], "title": "Synthetic FMCW Radar Range Azimuth Maps Augmentation with Generative Diffusion Model", "comment": null, "summary": "The scarcity and low diversity of well-annotated automotive radar datasets often limit the performance of deep-learning-based environmental perception. To overcome these challenges, we propose a conditional generative framework for synthesizing realistic Frequency-Modulated Continuous-Wave radar Range-Azimuth Maps. Our approach leverages a generative diffusion model to generate radar data for multiple object categories, including pedestrians, cars, and cyclists. Specifically, conditioning is achieved via Confidence Maps, where each channel represents a semantic class and encodes Gaussian-distributed annotations at target locations. To address radar-specific characteristics, we incorporate Geometry Aware Conditioning and Temporal Consistency Regularization into the generative process. Experiments on the ROD2021 dataset demonstrate that signal reconstruction quality improves by \\SI{3.6}{dB} in Peak Signal-to-Noise Ratio over baseline methods, while training with a combination of real and synthetic datasets improves overall mean Average Precision by 4.15% compared with conventional image-processing-based augmentation. These results indicate that our generative framework not only produces physically plausible and diverse radar spectrum but also substantially improves model generalization in downstream tasks.", "AI": {"tldr": "该研究提出了一种条件生成框架，用于合成真实的调频连续波（FMCW）雷达的距离-方位角图（Range-Azimuth Maps），以解决现有汽车雷达数据集稀缺和多样性不足的问题。通过使用生成式扩散模型，并结合置信图（Confidence Maps）、几何感知条件（Geometry Aware Conditioning）和时序一致性正则化（Temporal Consistency Regularization），该框架能够生成多类别（行人、汽车、自行车）的雷达数据，并提升模型在下游任务中的泛化能力。", "motivation": "现有汽车雷达数据集的稀缺性和多样性不足，限制了基于深度学习的环境感知模型的性能。", "method": "提出了一种条件生成框架，利用生成式扩散模型合成雷达距离-方位角图。该框架通过置信图实现条件生成，其中每个通道代表一个语义类别并编码高斯分布的标注。同时，为了处理雷达特有的特性，引入了几何感知条件和时序一致性正则化。", "result": "在ROD2021数据集上的实验表明，该方法在信噪比（PSNR）上比基线方法提高了3.6 dB。使用真实数据和合成数据混合训练，相比于传统的基于图像处理的数据增强方法，整体平均精度（mAP）提高了4.15%。", "conclusion": "提出的生成框架能够生成物理上合理且多样化的雷达频谱，并且能够显著提高模型在下游任务中的泛化能力。"}}
{"id": "2601.06403", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06403", "abs": "https://arxiv.org/abs/2601.06403", "authors": ["Yijiang River Dong", "Tiancheng Hu", "Zheng Hui", "Nigel Collier"], "title": "Steer Model beyond Assistant: Controlling System Prompt Strength via Contrastive Decoding", "comment": null, "summary": "Large language models excel at complex instructions yet struggle to deviate from their helpful assistant persona, as post-training instills strong priors that resist conflicting instructions. We introduce system prompt strength, a training-free method that treats prompt adherence as a continuous control. By contrasting logits from target and default system prompts, we isolate and amplify the behavioral signal unique to the target persona by a scalar factor alpha. Across five diverse benchmarks spanning constraint satisfaction, behavioral control, pluralistic alignment, capability modulation, and stylistic control, our method yields substantial improvements: up to +8.5 strict accuracy on IFEval, +45pp refusal rate on OffTopicEval, and +13% steerability on Prompt-Steering. Our approach enables practitioners to modulate system prompt strength, providing dynamic control over model behavior without retraining.", "AI": {"tldr": "本文提出了一种名为“系统提示强度”的训练无关方法，通过调整目标系统提示和默认系统提示之间的对数概率差异来增强模型对特定指令的遵循能力，从而实现对模型行为的动态控制。", "motivation": "大型语言模型在遵循指令方面表现出色，但在偏离“乐于助人”的助手角色时遇到困难，因为训练后的模型具有强大的先验知识，难以接受冲突的指令。研究旨在解决模型难以偏离预设角色的问题，并提供一种无需重新训练即可动态控制模型行为的方法。", "method": "提出“系统提示强度”方法，将提示遵循视为连续控制。通过对比目标系统提示和默认系统提示的对数概率，并用标量因子 alpha 放大两者之间的行为信号差异，以隔离并增强目标个性化的行为信号。", "result": "在五个不同基准测试（约束满足、行为控制、多元对齐、能力调制和风格控制）上取得了显著改进。具体表现为：在 IFeval 上严格准确率提升高达 +8.5%；在 OffTopicEval 上拒绝率提升 +45个百分点；在 Prompt-Steering 上可控性提升 +13%。", "conclusion": "提出的“系统提示强度”方法是一种无需重新训练即可实现对模型行为进行动态控制的有效手段，使从业者能够根据需要调整模型行为，而无需进行额外的训练。"}}
{"id": "2601.06158", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06158", "abs": "https://arxiv.org/abs/2601.06158", "authors": ["Zibin Meng", "Kani Chen"], "title": "PsyAgent: Constructing Human-like Agents Based on Psychological Modeling and Contextual Interaction", "comment": null, "summary": "Human-like agents require modeling how dispositions interact with social structure. We present PsyAgent, which couples a Big Five trait prior with Bourdieu's cognitive-social co-structure. PsyAgent comprises: (i) Individual Structure (IS), a machine-usable profile encoding traits and facets, cognitive style, values, cultural and educational capital, and salient life episodes; and (ii) Multi-Scenario Contexting (MSC), role-relationship-norm frames spanning eight arenas (work, family, friendship, strangers and civic life, solitude and self-regulation, romance, learning, and public expression). At inference, fixed structured prompts bind the active scenario to the agent profile, yielding behavior that is stable yet context-sensitive. We instantiate IS and MSC to synthesize supervision (role-play dialogues, decision probes, feedback trajectories) and then fine-tune a small LLM. The resulting model produces consistent, identifiable persona-aligned behaviors for specified Big Five configurations and matches or exceeds several larger untuned LLMs and other untuned baselines on our metrics: persona consistency, contextual appropriateness, style matching, trait identifiability, and long-horizon stability. Ablations show IS chiefly improves trait fidelity and stylistic stability, while MSC drives norm awareness and decision fit; both are necessary for cross-scenario performance. PsyAgent offers a precise, data-efficient architecture for personality-grounded agents.", "AI": {"tldr": "本文提出了一种名为PsyAgent的新框架，用于构建具有类人行为的AI代理。该框架结合了“大五人格”特质模型和布迪厄的社会结构理论，通过“个体结构（IS）”和“多场景情境（MSC）”两个模块来编码代理的内在特质、认知风格、价值观以及所处的社会环境和规范。通过对小型语言模型进行微调，PsyAgent能够生成稳定且情境敏感的、与特定人格配置一致的行为，并在多项评估指标上表现优于其他模型。", "motivation": "为了使AI代理能够表现出更像人类的行为，需要模拟内在特质与社会结构之间的相互作用。现有方法在捕捉这种复杂性方面存在不足。", "method": "PsyAgent框架包含两个核心组件：1. 个体结构（IS），用于编码代理的特质、认知风格、价值观、社会资本和人生经历。2. 多场景情境（MSC），定义了代理在八个不同生活领域（工作、家庭、友谊等）的角色、关系和规范。通过结构化提示将当前场景与代理的IS信息结合，以生成行为。随后，使用IS和MSC生成的数据来微调一个小型语言模型。", "result": "经过微调的PsyAgent模型在生成一致的、可识别的、与人格匹配的行为方面表现出色，并且在 persona consistency, contextual appropriateness, style matching, trait identifiability, and long-horizon stability 等指标上优于一些更大的、未经微调的模型。消融实验表明，IS主要提升了特质的保真度和风格稳定性，而MSC则增强了规范意识和决策的契合度。", "conclusion": "PsyAgent提供了一种精确且数据高效的架构，用于构建基于人格的AI代理。该框架能够有效地区分不同人格配置下的行为，并适应不同的社会情境，为开发更具鲁棒性和类人行为的AI代理提供了新的途径。"}}
{"id": "2601.06361", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06361", "abs": "https://arxiv.org/abs/2601.06361", "authors": ["Jakub Dec", "Michał Dolina", "Stanisław Drożdż", "Jarosław Kwapień", "Jin Liu", "Tomasz Stanisz"], "title": "Average shortest-path length in word-adjacency networks: Chinese versus English", "comment": null, "summary": "Complex networks provide powerful tools for analyzing and understanding the intricate structures present in various systems, including natural language. Here, we analyze topology of growing word-adjacency networks constructed from Chinese and English literary works written in different periods. Unconventionally, instead of considering dictionary words only, we also include punctuation marks as if they were ordinary words. Our approach is based on two arguments: (1) punctuation carries genuine information related to emotional state, allows for logical grouping of content, provides a pause in reading, and facilitates understanding by avoiding ambiguity, and (2) our previous works have shown that punctuation marks behave like words in a Zipfian analysis and, if considered together with regular words, can improve authorship attribution in stylometric studies. We focus on a functional dependence of the average shortest path length $L(N)$ on a network size $N$ for different epochs and individual novels in their original language as well as for translations of selected novels into the other language. We approximate the empirical results with a growing network model and obtain satisfactory agreement between the two. We also observe that $L(N)$ behaves asymptotically similar for both languages if punctuation marks are included but becomes sizably larger for Chinese if punctuation marks are neglected.", "AI": {"tldr": "本研究分析了中英文文学作品中包含标点符号的词语邻接网络拓扑结构，发现包含标点符号的网络增长模型能更好地拟合实证数据，且对两种语言的网络增长行为有相似的描述。", "motivation": "标点符号包含情感、逻辑和理解上的信息，并且在之前的研究中已显示出其在Zipf定律分析和作者归属研究中的作用，因此作者希望将标点符号纳入网络分析。", "method": "构建了包含标点符号和普通词语的词语邻接网络，分析了不同时期中英文文学作品网络的平均最短路径长度 $L(N)$ 与网络大小 $N$ 的函数关系，并使用增长网络模型进行近似拟合。", "result": "包含标点符号的网络增长模型与实证结果吻合度令人满意。两种语言的网络增长行为在包含标点符号时表现出相似的渐近特性，而忽略标点符号则会导致中文网络的 $L(N)$ 显著增大。", "conclusion": "将标点符号纳入词语邻接网络分析能够更好地刻画网络结构，并为跨语言的网络增长行为提供更一致的解释。"}}
{"id": "2601.06197", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.06197", "abs": "https://arxiv.org/abs/2601.06197", "authors": ["Prasanna Kumar"], "title": "AI Safeguards, Generative AI and the Pandora Box: AI Safety Measures to Protect Businesses and Personal Reputation", "comment": "10 pages, 3 Figures, 6 Tables", "summary": "Generative AI has unleashed the power of content generation and it has also unwittingly opened the pandora box of realistic deepfake causing a number of social hazards and harm to businesses and personal reputation. The investigation & ramification of Generative AI technology across industries, the resolution & hybridization detection techniques using neural networks allows flagging of the content. Good detection techniques & flagging allow AI safety - this is the main focus of this paper. The research provides a significant method for efficiently detecting dark side problems by imposing a Temporal Consistency Learning (TCL) technique. Through pretrained Temporal Convolutional Networks (TCNs) model training and performance comparison, this paper showcases that TCN models outperforms the other approaches and achieves significant accuracy for five dark side problems. Findings highlight how important it is to take proactive measures in identification to reduce any potential risks associated with generative artificial intelligence.", "AI": {"tldr": "本研究提出了一种基于时间卷积网络（TCN）的时间一致性学习（TCL）技术，用于高效检测生成式AI产生的深度伪造内容，并取得了显著的准确率，以保障AI安全。", "motivation": "生成式AI在内容生成方面展现出强大能力的同时，也带来了逼真的深度伪造问题，引发了社会危害和声誉损害。因此，研究迫切需要有效的检测技术来应对这些“黑暗面”问题，保障AI安全。", "method": "该研究的核心方法是引入时间一致性学习（TCL）技术。通过预训练的时间卷积网络（TCN）模型，并与其他方法进行性能比较，以评估TCL在检测五种“黑暗面”问题上的效率和准确性。", "result": "研究表明，TCN模型在检测五种“黑暗面”问题时，相较于其他方法，展现出了更优越的性能和显著的准确率。", "conclusion": "本研究强调了主动识别生成式AI潜在风险的重要性。提出的TCL技术，特别是基于TCN的模型，为高效检测和降低与生成式AI相关的风险提供了一种有效的方法，对于保障AI安全具有重要意义。"}}
{"id": "2601.07304", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07304", "abs": "https://arxiv.org/abs/2601.07304", "authors": ["Yun Chen", "Bowei Huang", "Fan Guo", "Kang Song"], "title": "Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts", "comment": "9 pages", "summary": "Autonomous mobile manipulation in unstructured warehouses requires a balance between efficient large-scale navigation and high-precision object interaction. Traditional end-to-end learning approaches often struggle to handle the conflicting demands of these distinct phases. Navigation relies on robust decision-making over large spaces, while manipulation needs high sensitivity to fine local details. Forcing a single network to learn these different objectives simultaneously often causes optimization interference, where improving one task degrades the other. To address these limitations, we propose a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts. HMER decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner. This structure separates macro-level navigation from micro-level manipulation, allowing each expert to focus on its specific action space without interference. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. Furthermore, to solve the problem of sparse exploration, we introduce a Hybrid Imitation-Reinforcement Training Strategy. This method uses expert demonstrations to initialize the policy and Reinforcement Learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines. Our method achieves a task success rate of 94.2\\% (compared to 62.5\\% for baselines), reduces operation time by 21.4\\%, and maintains placement error within 1.5 cm, validating its efficacy for precise material handling.", "AI": {"tldr": "该研究提出了一种名为异构多专家强化学习（HMER）的框架，用于解决自动叉车在非结构化仓库中导航和操作的挑战。该框架将任务分解为专门的子策略，通过语义任务规划器协调，有效解决了导航和操作之间的冲突，并采用混合模仿-强化学习策略来解决稀疏探索问题，实验证明其性能优于现有方法。", "motivation": "传统端到端学习方法难以平衡大规模导航和高精度物体交互的需求，同时学习这两个任务会导致优化干扰。因此，需要一种新的方法来解决自动叉车在非结构化仓库中的导航和操作的冲突需求。", "method": "提出异构多专家强化学习（HMER）框架，将任务分解为专门的子策略，由语义任务规划器协调。采用混合模仿-强化学习策略，使用专家演示初始化策略，并通过强化学习进行微调。", "result": "HMER框架在Gazebo模拟中显著优于顺序和端到端基线方法，任务成功率达到94.2%（基线为62.5%），操作时间减少21.4%，放置误差保持在1.5厘米以内。", "conclusion": "HMER框架能够有效地解决自动叉车在非结构化仓库中的导航和高精度操作问题，并克服了传统方法的局限性，证明了其在精确物料搬运方面的有效性。"}}
{"id": "2601.06222", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06222", "abs": "https://arxiv.org/abs/2601.06222", "authors": ["Xinghao Wang", "Changtao Miao", "Dianmo Sheng", "Tao Gong", "Qi Chu", "Nenghai Yu", "Quanchen Zou", "Deyue Zhang", "Xiangzheng Zhang"], "title": "SAPL: Semantic-Agnostic Prompt Learning in CLIP for Weakly Supervised Image Manipulation Localization", "comment": null, "summary": "Malicious image manipulation threatens public safety and requires efficient localization methods. Existing approaches depend on costly pixel-level annotations which make training expensive. Existing weakly supervised methods rely only on image-level binary labels and focus on global classification, often overlooking local edge cues that are critical for precise localization. We observe that feature variations at manipulated boundaries are substantially larger than in interior regions. To address this gap, we propose Semantic-Agnostic Prompt Learning (SAPL) in CLIP, which learns text prompts that intentionally encode non-semantic, boundary-centric cues so that CLIPs multimodal similarity highlights manipulation edges rather than high-level object semantics. SAPL combines two complementary modules Edge-aware Contextual Prompt Learning (ECPL) and Hierarchical Edge Contrastive Learning (HECL) to exploit edge information in both textual and visual spaces. The proposed ECPL leverages edge-enhanced image features to generate learnable textual prompts via an attention mechanism, embedding semantic-irrelevant information into text features, to guide CLIP focusing on manipulation edges. The proposed HECL extract genuine and manipulated edge patches, and utilize contrastive learning to boost the discrimination between genuine edge patches and manipulated edge patches. Finally, we predict the manipulated regions from the similarity map after processing. Extensive experiments on multiple public benchmarks demonstrate that SAPL significantly outperforms existing approaches, achieving state-of-the-art localization performance.", "AI": {"tldr": "本文提出了一种名为SAPL（Semantic-Agnostic Prompt Learning）的新方法，利用CLIP模型，通过学习非语义的、以边界为中心的文本提示，来更有效地定位图像中的篡改区域，而无需昂贵的像素级标注。", "motivation": "现有的图像篡改定位方法需要昂贵的像素级标注，而弱监督方法往往忽略了对精确局部化至关重要的边缘线索。研究人员发现，篡改边界处的特征变化远大于内部区域，这促使他们探索利用这些边界信息。", "method": "SAPL结合了ECPL（Edge-aware Contextual Prompt Learning）和HECL（Hierarchical Edge Contrastive Learning）两个模块。ECPL利用边缘增强的图像特征生成可学习的文本提示，引导CLIP关注篡改边缘。HECL提取真实和篡改的边缘块，并利用对比学习增强它们之间的辨别力。最终，通过分析CLIP的相似度图来预测篡改区域。", "result": "SAPL在多个公开数据集上取得了显著的性能提升，超越了现有方法，达到了最先进的篡改定位效果。", "conclusion": "SAPL是一种有效的、弱监督的图像篡改定位方法，通过引入语义无关的边界线索，能够显著提高定位精度，克服了对像素级标注的依赖。"}}
{"id": "2601.07715", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07715", "abs": "https://arxiv.org/abs/2601.07715", "authors": ["Hugo Matias", "Daniel Silvestre"], "title": "Safe Navigation under Uncertain Obstacle Dynamics using Control Barrier Functions and Constrained Convex Generators", "comment": null, "summary": "This paper presents a sampled-data framework for the safe navigation of controlled agents in environments cluttered with obstacles governed by uncertain linear dynamics. Collision-free motion is achieved by combining Control Barrier Function (CBF)-based safety filtering with set-valued state estimation using Constrained Convex Generators (CCGs). At each sampling time, a CCG estimate of each obstacle is obtained using a finite-horizon guaranteed estimation scheme and propagated over the sampling interval to obtain a CCG-valued flow that describes the estimated obstacle evolution. However, since CCGs are defined indirectly - as an affine transformation of a generator set subject to equality constraints, rather than as a sublevel set of a scalar function - converting the estimated obstacle flows into CBFs is a nontrivial task. One of the main contributions of this paper is a procedure to perform this conversion, ultimately yielding a CBF via a convex optimization problem whose validity is established by the Implicit Function Theorem. The resulting obstacle-specific CBFs are then merged into a single CBF that is used to design a safe controller through the standard Quadratic Program (QP)-based approach. Since CCGs support Minkowski sums, the proposed framework also naturally handles rigid-body agents and generalizes existing CBF-based rigid-body navigation designs to arbitrary agent and obstacle geometries. While the main contribution is general, the paper primarily focuses on agents with first-order control-affine dynamics and second-order strict-feedback dynamics. Simulation examples demonstrate the effectiveness of the proposed method.", "AI": {"tldr": "该研究提出了一种基于采样数据的框架，用于在包含具有不确定线性动力学障碍物的环境中安全导航受控智能体。通过结合基于控制障碍函数（CBF）的安全滤波和使用约束凸生成器（CCG）的集合值状态估计来实现无碰撞运动。", "motivation": "解决在存在不确定动力学障碍物的环境中，智能体安全导航的问题，特别是如何将基于集合值状态估计的障碍物模型转换为可用于CBF的安全控制器。", "method": "1. 使用有限时域保证估计方案获取每个障碍物的CCG估计，并传播到采样区间以描述障碍物演化。\n2. 提出一种将CCG估计的障碍物流转换为CBF的方法，通过凸优化问题实现，并证明其有效性。\n3. 将障碍物特定的CBF合并成一个单一的CBF。\n4. 使用基于二次规划（QP）的方法设计安全控制器。", "result": "该框架能够有效地处理具有任意几何形状的刚体智能体和障碍物。所提出的方法能够通过凸优化问题将CCG转换为CBF，并成功地将CBF用于设计安全控制器。仿真结果表明了该方法的有效性。", "conclusion": "该研究提出了一种新颖的基于采样数据的框架，能够有效地结合集合值状态估计和CBF方法，实现复杂环境中智能体的安全导航，并能处理任意几何形状的智能体和障碍物。"}}
{"id": "2601.06407", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06407", "abs": "https://arxiv.org/abs/2601.06407", "authors": ["Yijiang River Dong", "Tiancheng Hu", "Zheng Hui", "Caiqi Zhang", "Ivan Vulić", "Andreea Bobu", "Nigel Collier"], "title": "Value of Information: A Framework for Human-Agent Communication", "comment": null, "summary": "Large Language Model (LLM) agents deployed for real-world tasks face a fundamental dilemma: user requests are underspecified, yet agents must decide whether to act on incomplete information or interrupt users for clarification. Existing approaches either rely on brittle confidence thresholds that require task-specific tuning, or fail to account for the varying stakes of different decisions. We introduce a decision-theoretic framework that resolves this trade-off through the Value of Information (VoI), enabling agents to dynamically weigh the expected utility gain from asking questions against the cognitive cost imposed on users. Our inference-time method requires no hyperparameter tuning and adapts seamlessly across contexts-from casual games to medical diagnosis. Experiments across four diverse domains (20 Questions, medical diagnosis, flight booking, and e-commerce) show that VoI consistently matches or exceeds the best manually-tuned baselines, achieving up to 1.36 utility points higher in high-cost settings. This work provides a parameter-free framework for adaptive agent communication that explicitly balances task risk, query ambiguity, and user effort.", "AI": {"tldr": "研究提出了一种基于信息价值（VoI）的决策理论框架，用于解决大型语言模型（LLM）代理在面对用户不明确请求时，是立即行动还是寻求澄清的困境，该框架无需超参数调优，并能在不同领域实现鲁棒性。", "motivation": "现有LLM代理在处理用户不明确指令时面临两难：要么依据不完整信息行动，要么打断用户寻求澄清。现有方法要么依赖难以调优的置信度阈值，要么忽略不同决策的重要性差异。", "method": "引入一个决策理论框架，利用信息价值（VoI）来量化提问所带来的预期效用增益与对用户造成的认知成本之间的权衡，从而动态决定是否寻求用户澄清。", "result": "在20问、医疗诊断、航班预订和电商等四个不同领域进行实验，结果显示VoI方法与手动调优的基线方法相当或表现更优，在关键场景下最高可提升1.36个效用点。", "conclusion": "该研究提供了一个无需参数即可自适应代理通信的框架，能够显式地平衡任务风险、查询模糊性和用户努力，解决了LLM代理在处理不明确指令时的通信困境。"}}
{"id": "2601.06239", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.06239", "abs": "https://arxiv.org/abs/2601.06239", "authors": ["Aya Kaysan Bahjat"], "title": "A survey of facial recognition techniques", "comment": "12 pages, 12 figures, article", "summary": "As multimedia content is quickly growing, the field of facial recognition has become one of the major research fields, particularly in the recent years. The most problematic area to researchers in image processing and computer vision is the human face which is a complex object with myriads of distinctive features that can be used to identify the face. The survey of this survey is particularly focused on most challenging facial characteristics, including differences in the light, ageing, variation in poses, partial occlusion, and facial expression and presents methodological solutions. The factors, therefore, are inevitable in the creation of effective facial recognition mechanisms used on facial images. This paper reviews the most sophisticated methods of facial detection which are Hidden Markov Models, Principal Component Analysis (PCA), Elastic Cluster Plot Matching, Support Vector Machine (SVM), Gabor Waves, Artificial Neural Networks (ANN), Eigenfaces, Independent Component Analysis (ICA), and 3D Morphable Model. Alongside the works mentioned above, we have also analyzed the images of a number of facial databases, namely JAFEE, FEI, Yale, LFW, AT&T (then called ORL), and AR (created by Martinez and Benavente), to analyze the results. However, this survey is aimed at giving a thorough literature review of face recognition, and its applications, and some experimental results are provided at the end after a detailed discussion.", "AI": {"tldr": "这篇论文对当前人脸识别领域进行了全面的文献综述，重点关注光照、年龄、姿态、遮挡和表情等挑战性因素，并介绍了相应的解决方法，同时分析了多种人脸检测方法和常用人脸数据库。", "motivation": "多媒体内容的快速增长以及人脸识别在识别个体方面的关键作用，促使研究者们深入研究人脸识别技术，特别是如何克服人脸识别中的各种挑战性因素。", "method": "该研究采用文献综述的方法，梳理了隐藏马尔可夫模型、主成分分析 (PCA)、弹性聚类图匹配、支持向量机 (SVM)、Gabor 滤波、人工神经网络 (ANN)、Eigenfaces、独立成分分析 (ICA) 和 3D 可变形模型等多种人脸检测方法。同时，对 JAFEE、FEI、Yale、LFW、AT&T (ORL) 和 AR 等人脸数据库进行了分析。", "result": "文章深入讨论了光照、年龄、姿态、遮挡和表情等影响人脸识别准确性的因素，并提出了相应的技术解决方案。此外，还对不同的人脸识别算法在多个数据库上的表现进行了分析，并在最后提供了一些实验结果。", "conclusion": "该论文提供了人脸识别领域的一个全面概述，涵盖了挑战、方法和数据库的分析，旨在为该领域的研究和应用提供指导。"}}
{"id": "2601.07362", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07362", "abs": "https://arxiv.org/abs/2601.07362", "authors": ["Julia Richter", "Turcan Tuna", "Manthan Patel", "Takahiro Miki", "Devon Higgins", "James Fox", "Cesar Cadena", "Andres Diaz", "Marco Hutter"], "title": "Large-Scale Autonomous Gas Monitoring for Volcanic Environments: A Legged Robot on Mount Etna", "comment": "12 pages, 7 figures, submitted to IEEE Robotics & Automation Magazine (RAM)", "summary": "Volcanic gas emissions are key precursors of eruptive activity. Yet, obtaining accurate near-surface measurements remains hazardous and logistically challenging, motivating the need for autonomous solutions. Limited mobility in rough volcanic terrain has prevented wheeled systems from performing reliable in situ gas measurements, reducing their usefulness as sensing platforms. We present a legged robotic system for autonomous volcanic gas analysis, utilizing the quadruped ANYmal, equipped with a quadrupole mass spectrometer system. Our modular autonomy stack integrates a mission planning interface, global planner, localization framework, and terrain-aware local navigation. We evaluated the system on Mount Etna across three autonomous missions in varied terrain, achieving successful gas-source detections with autonomy rates of 93-100%. In addition, we conducted a teleoperated mission in which the robot measured natural fumaroles, detecting sulfur dioxide and carbon dioxide. We discuss lessons learned from the gas-analysis and autonomy perspectives, emphasizing the need for adaptive sensing strategies, tighter integration of global and local planning, and improved hardware design.", "AI": {"tldr": "研究提出了一种名为ANYmal的四足机器人，能够自主进行火山气体测量，成功克服了地形挑战，并在实地测试中达到了高 autonome率。", "motivation": "现有火山气体近地表测量因危险和后勤困难，需要更自主的解决方案。轮式系统因地形限制难以可靠进行原位气体测量。", "method": "使用配备四极质谱仪的四足机器人ANYmal。集成了任务规划、全局规划、定位和地形感知本地导航的模块化自主系统。在埃特纳火山进行了实地测试。", "result": "在埃特纳火山的三个自主任务中，机器人成功检测到气体源，自主率达到93-100%。在遥控任务中，机器人测量了天然喷气孔，并检测到了二氧化硫和二氧化碳。", "conclusion": "该系统证明了四足机器人在火山气体自主分析方面的潜力，并强调了自适应传感策略、全局与本地规划的整合以及硬件设计改进的重要性。"}}
{"id": "2601.06411", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06411", "abs": "https://arxiv.org/abs/2601.06411", "authors": ["Zhengxuan Lu", "Dongfang Li", "Yukun Shi", "Beilun Wang", "Longyue Wang", "Baotian Hu"], "title": "Structured Episodic Event Memory", "comment": null, "summary": "Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reasoning. For autonomous agents, these passive and flat architectures lack the cognitive organization necessary to model the dynamic and associative nature of long-term interaction. To address this, we propose Structured Episodic Event Memory (SEEM), a hierarchical framework that synergizes a graph memory layer for relational facts with a dynamic episodic memory layer for narrative progression. Grounded in cognitive frame theory, SEEM transforms interaction streams into structured Episodic Event Frames (EEFs) anchored by precise provenance pointers. Furthermore, we introduce an agentic associative fusion and Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent narrative contexts from fragmented evidence. Experimental results on the LoCoMo and LongMemEval benchmarks demonstrate that SEEM significantly outperforms baselines, enabling agents to maintain superior narrative coherence and logical consistency.", "AI": {"tldr": "本研究提出了一种名为SEEM（结构化情景事件记忆）的层次化框架，用于增强大型语言模型的记忆能力，特别是在自主代理的长期交互方面。SEEM结合了图谱记忆层和动态情景记忆层，并引入了关联融合和反向溯源扩展机制，以提高叙事连贯性和逻辑一致性。", "motivation": "现有的基于检索增强生成（RAG）的LLM记忆方法存在检索分散、无法捕捉复杂推理所需的结构化依赖的问题。对于自主代理而言，这些被动的、扁平化的架构缺乏对长期交互动态性和关联性的认知组织能力。", "method": "提出SEEM（结构化情景事件记忆）框架，该框架融合了用于关系事实的图谱记忆层和用于叙事进展的动态情景记忆层。SEEM基于认知框架理论，将交互流转化为结构化的情景事件帧（EEFs），并引入了代理关联融合和反向溯源扩展（RPE）机制。", "result": "在LoCoMo和LongMemEval基准测试中，SEEM显著优于现有方法，使代理能够保持更优越的叙事连贯性和逻辑一致性。", "conclusion": "SEEM通过其层次化结构和创新的记忆机制，有效地解决了现有LLM记忆方法的局限性，显著提升了自主代理在长期交互中的表现。"}}
{"id": "2601.06279", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06279", "abs": "https://arxiv.org/abs/2601.06279", "authors": ["Stevenson Pather", "Niels Martignène", "Arnaud Bugnet", "Fouad Boutaleb", "Fabien D'Hondt", "Deise Santana Maia"], "title": "EyeTheia: A Lightweight and Accessible Eye-Tracking Toolbox", "comment": "Code for the EyeTheia gaze-tracking model: https://github.com/patherstevenson/EyeTheia. Experimental platform for the cognitive neuroscience task: https://git.interactions-team.fr/INTERACTIONS/calypso/src/branch/main/src/lonely_tester", "summary": "We introduce EyeTheia, a lightweight and open deep learning pipeline for webcam-based gaze estimation, designed for browser-based experimental platforms and real-world cognitive and clinical research. EyeTheia enables real-time gaze tracking using only a standard laptop webcam, combining MediaPipe-based landmark extraction with a convolutional neural network inspired by iTracker and optional user-specific fine-tuning. We investigate two complementary strategies: adapting a model pretrained on mobile data and training the same architecture from scratch on a desktop-oriented dataset. Validation results on MPIIFaceGaze show comparable performance between both approaches prior to calibration, while lightweight user-specific fine-tuning consistently reduces gaze prediction error. We further evaluate EyeTheia in a realistic Dot-Probe task and compare it to the commercial webcam-based tracker SeeSo SDK. Results indicate strong agreement in left-right gaze allocation during stimulus presentation, despite higher temporal variability. Overall, EyeTheia provides a transparent and extensible solution for low-cost gaze tracking, suitable for scalable and reproducible experimental and clinical studies. The code, trained models, and experimental materials are publicly available.", "AI": {"tldr": "EyeTheia 是一个轻量级、开源的深度学习管道，用于基于网络的眼动追踪，适用于浏览器实验平台和真实世界的认知/临床研究。它使用普通笔记本摄像头，通过 MediaPipe 和受 iTracker 启发的 CNN 实现实时眼动追踪，并支持用户特定微调。", "motivation": "研究动机是开发一种低成本、透明且可扩展的眼动追踪解决方案，以支持基于网络的实验平台和真实世界的认知/临床研究，而无需昂贵的专用设备。", "method": "该方法结合了基于 MediaPipe 的面部标志提取和一个受 iTracker 启发的卷积神经网络（CNN）。研究了两种策略：一种是基于移动数据预训练的模型，另一种是从头开始在桌面数据集上训练相同架构的模型。还评估了用户特定微调的有效性，并在 Dot-Probe 任务中进行了实际评估。", "result": "在 MPIIFaceGaze 数据集上，两种策略在校准前的性能相当。用户特定微调能持续降低眼动预测误差。在 Dot-Probe 任务中，EyeTheia 与商业 tracker SeeSo SDK 在刺激呈现期间的左右眼动分配上表现出高度一致性，尽管时间变异性略高。", "conclusion": "EyeTheia 提供了一个透明、可扩展的低成本眼动追踪解决方案，适用于可扩展和可重现的实验和临床研究。其开源的特性（代码、模型和实验材料）进一步增强了其实用性。"}}
{"id": "2601.07434", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07434", "abs": "https://arxiv.org/abs/2601.07434", "authors": ["Xin Guan", "Fangguo Zhao", "Qianyi Wang", "Chengcheng Zhao", "Jiming Chen", "Shuo Li"], "title": "LOONG: Online Time-Optimal Autonomous Flight for MAVs in Cluttered Environments", "comment": null, "summary": "Autonomous flight of micro air vehicles (MAVs) in unknown, cluttered environments remains challenging for time-critical missions due to conservative maneuvering strategies. This article presents an integrated planning and control framework for high-speed, time-optimal autonomous flight of MAVs in cluttered environments. In each replanning cycle (100 Hz), a time-optimal trajectory under polynomial presentation is generated as a reference, with the time-allocation process accelerated by imitation learning. Subsequently, a time-optimal model predictive contouring control (MPCC) incorporates safe flight corridor (SFC) constraints at variable horizon steps to enable aggressive yet safe maneuvering, while fully exploiting the MAV's dynamics. We validate the proposed framework extensively on a custom-built LiDAR-based MAV platform. Simulation results demonstrate superior aggressiveness compared to the state of the art, while real-world experiments achieve a peak speed of 18 m/s in a cluttered environment and succeed in 10 consecutive trials from diverse start points. The video is available at the following link: https://youtu.be/vexXXhv99oQ.", "AI": {"tldr": "提出了一种集成规划与控制框架，实现了微型飞行器（MAVs）在未知、复杂环境中的高速、时间最优自主飞行。", "motivation": "在未知、复杂环境中，现有的MAV自主飞行策略过于保守，无法满足时间关键型任务的要求，需要更具侵略性但安全的技术。", "method": "该框架在每个重规划周期（100 Hz）内，生成基于多项式的最优轨迹（利用模仿学习加速时间分配），并结合时间最优模型预测轮廓控制（MPCC）和安全飞行走廊（SFC）约束，以利用MAV动力学进行激进但安全的机动。", "result": "在基于LiDAR的MAV平台上进行了广泛验证。仿真结果显示比现有技术更具侵略性。真实世界实验中，在复杂环境中实现了18 m/s的峰值速度，并成功完成了10次不同起点的连续试飞。", "conclusion": "提出的集成规划和控制框架能够使MAVs在复杂环境中实现高速、时间最优的自主飞行，显著提升了机动性和成功率。"}}
{"id": "2601.07783", "categories": ["eess.SY", "cs.RO", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.07783", "abs": "https://arxiv.org/abs/2601.07783", "authors": ["Chaoyi Lin Yang", "Gabriele Dessena", "Oscar E. Bonilla-Manrique"], "title": "Affordable Data Collection System for UAVs Taxi Vibration Testing", "comment": null, "summary": "Structural vibration testing plays a key role in aerospace engineering for evaluating dynamic behaviour, ensuring reliability and verifying structural integrity. These tests rely on accurate and robust data acquisition systems (DAQ) to capture high-quality acceleration data. However, commercial DAQs that provide the required performance and features are often expensive and complex, limiting their accessibility for small-scale research and experimental applications. This work presents the design and experimental validation of an affordable and in-house-developed acceleration DAQ, tested on a small fixed-wing UAV through several Taxi Vibration Test (TVT) runs and ambient vibration measurements. The proposed system integrates several OrangePi 3 LTS single-board computers with multiple LSM6DS3TR-C MEMS inertial measurement units operating simultaneously via an Inter-Integrated Circuit (I2C) communication interface, managed under a Python-based master/slave architecture. Data is acquired at a stable sampling rate of approximately 208 Hz and post-processed using Welch's method to estimate their Power Spectral Density (PSD). Results confirm the system ability to provide consistent multi-sensor acceleration data and repeatable PSD profiles under the same test conditions; thus, demonstrating its reliability. With a total hardware cost below 600 EUR (approximately 690 USD), the developed DAQ offers a compact, scalable and cost-effective alternative for aerospace vibration analysis and structural testing.", "AI": {"tldr": "本文介绍了一种低成本、自主开发的航空航天结构振动测试数据采集系统（DAQ），该系统使用OrangePi 3 LTS单板计算机和LSM6DS3TR-C MEMS惯性测量单元，通过I2C接口协同工作，并采用Python主/从架构管理。该系统已在小型固定翼无人机上进行了出租车振动测试（TVT）和环境振动测量验证，结果表明其能够提供一致的多传感器加速度数据和可重复的功率谱密度（PSD）估算，为航空航天振动分析提供了一种经济高效的替代方案。", "motivation": "商业DAQ设备通常价格昂贵且复杂，限制了其在小型研究和实验应用中的可及性。研究人员需要一种成本效益高、易于获取的加速度DAQ系统，以支持航空航天结构的振动测试。", "method": "该系统集成了多个OrangePi 3 LTS单板计算机，每个计算机连接多个LSM6DS3TR-C MEMS惯性测量单元，通过I2C通信接口协同工作。系统采用Python实现主/从架构进行管理。数据以约208 Hz的采样率采集，并使用Welch方法进行功率谱密度（PSD）后处理。", "result": "实验结果证实了该系统在相同测试条件下提供一致的多传感器加速度数据和可重复的PSD剖面图的能力，证明了其可靠性。系统硬件总成本低于600欧元。", "conclusion": "所开发的DAQ系统是一种紧凑、可扩展且经济高效的航空航天振动分析和结构测试替代方案，为预算有限的研究和实验应用提供了可行选择。"}}
{"id": "2601.06285", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06285", "abs": "https://arxiv.org/abs/2601.06285", "authors": ["Shida Xu", "Jingqi Jiang", "Jonatan Scharff Willners", "Sen Wang"], "title": "NAS-GS: Noise-Aware Sonar Gaussian Splatting", "comment": null, "summary": "Underwater sonar imaging plays a crucial role in various applications, including autonomous navigation in murky water, marine archaeology, and environmental monitoring. However, the unique characteristics of sonar images, such as complex noise patterns and the lack of elevation information, pose significant challenges for 3D reconstruction and novel view synthesis. In this paper, we present NAS-GS, a novel Noise-Aware Sonar Gaussian Splatting framework specifically designed to address these challenges. Our approach introduces a Two-Ways Splatting technique that accurately models the dual directions for intensity accumulation and transmittance calculation inherent in sonar imaging, significantly improving rendering speed without sacrificing quality. Moreover, we propose a Gaussian Mixture Model (GMM) based noise model that captures complex sonar noise patterns, including side-lobes, speckle, and multi-path noise. This model enhances the realism of synthesized images while preventing 3D Gaussian overfitting to noise, thereby improving reconstruction accuracy. We demonstrate state-of-the-art performance on both simulated and real-world large-scale offshore sonar scenarios, achieving superior results in novel view synthesis and 3D reconstruction.", "AI": {"tldr": "提出了一种名为NAS-GS的噪声感知声纳高斯泼溅框架，通过双向泼溅技术和基于高斯混合模型（GMM）的噪声模型，提高了声纳图像的三维重建和新视图合成的性能。", "motivation": "声纳图像在水下应用中至关重要，但其复杂的噪声和缺乏高程信息给三维重建和新视图合成带来了挑战。", "method": "提出了一种名为NAS-GS的噪声感知声纳高斯泼溅框架，包含：1. 双向泼溅技术，用于准确建模声纳成像的强度累积和透射率计算的双向性，提高渲染速度；2. 基于高斯混合模型（GMM）的噪声模型，用于捕获复杂的声纳噪声模式（如旁瓣、散斑和多径噪声），提高重建精度并防止高斯拟合到噪声。", "result": "在模拟和真实世界的大规模海上声纳场景中，NAS-GS在视图合成和三维重建方面取得了最先进的性能。", "conclusion": "NAS-GS框架通过引入双向泼溅和先进的噪声模型，有效地解决了声纳图像的三维重建和新视图合成难题，并在实际应用中展现出优越的性能。"}}
{"id": "2601.06424", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06424", "abs": "https://arxiv.org/abs/2601.06424", "authors": ["Sazia Tabasum Mim", "Jack Morris", "Manish Dhakal", "Yanming Xiu", "Maria Gorlatova", "Yi Ding"], "title": "Can a Unimodal Language Agent Provide Preferences to Tune a Multimodal Vision-Language Model?", "comment": "Accepted to IJCNLP-AACL 2025 Findings", "summary": "To explore a more scalable path for adding multimodal capabilities to existing LLMs, this paper addresses a fundamental question: Can a unimodal LLM, relying solely on text, reason about its own informational needs and provide effective feedback to optimize a multimodal model? To answer this, we propose a method that enables a language agent to give feedback to a vision-language model (VLM) to adapt text generation to the agent's preferences. Our results from different experiments affirm this hypothesis, showing that LLM preference feedback significantly enhances VLM descriptions. Using our proposed method, we find that the VLM can generate multimodal scene descriptions to help the LLM better understand multimodal context, leading to improvements of maximum 13% in absolute accuracy compared to the baseline multimodal approach. Furthermore, a human study validated our AI-driven feedback, showing a 64.6% preference alignment rate between the LLM's choices and human judgments. Extensive experiments provide insights on how and why the method works and its limitations.", "AI": {"tldr": "本研究提出一种方法，让纯文本的语言模型（LLM）能够为视觉语言模型（VLM）提供反馈，以优化其生成的多模态描述。实验证明，LLM的反馈能显著提升VLM的描述能力，使LLM能更好地理解多模态内容，准确率最高提升13%。人类评估也表明，LLM的选择与人类判断有64.6%的一致性。", "motivation": "为了找到一种更具扩展性的方法，将多模态能力添加到现有的LLM中，本研究旨在探索纯文本LLM是否能够自主识别其信息需求，并为多模态模型提供有效的反馈以进行优化。", "method": "提出一种让语言代理（LLM）为视觉语言模型（VLM）提供反馈的方法，以根据代理的偏好调整文本生成。该方法使LLM能够理解VLM生成的多模态场景描述，并提供偏好反馈，从而引导VLM改进其生成。", "result": "实验结果表明，LLM的偏好反馈能够显著增强VLM的描述能力。采用所提出的方法，VLM生成的场景描述能够帮助LLM更好地理解多模态上下文，与基线多模态方法相比，准确率最高提升13%。人类研究也证实了AI驱动的反馈有效性，LLM的选择与人类判断有64.6%的偏好一致率。", "conclusion": "本研究的结论是，纯文本LLM能够通过提供反馈来优化多模态模型，从而实现更具可扩展性的多模态能力集成。LLM驱动的反馈能够显著提升VLM的生成质量，并与人类的判断保持较高一致性。"}}
{"id": "2601.06328", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06328", "abs": "https://arxiv.org/abs/2601.06328", "authors": ["Ziqiao Xi", "Shuang Liang", "Qi Liu", "Jiaqing Zhang", "Letian Peng", "Fang Nan", "Meshal Nayim", "Tianhui Zhang", "Rishika Mundada", "Lianhui Qin", "Biwei Huang", "Kun Zhou"], "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation", "comment": "Submitted to ACL 2026 12 pages, 4 figures Ziqiao Xi and Shuang Liang contributed equally to this work", "summary": "Tool-using LLM agents still struggle in open-world settings with large tool pools, long-horizon objectives, wild constraints, and unreliable tool states. For scalable and realistic training and testing, we introduce an open-world tool-using environment, built on 5,571 format unified tools across 204 commonly used apps. It includes a task creation engine that synthesizes long-horizon, multi-tool workflows with wild constraints, and a state controller that injects interruptions and failures to stress-test robustness. On top of this environment, we develop a tool select-then-execute agent framework with a planner-actor decomposition to separate deliberate reasoning and self-correction from step-wise execution. Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents. Our code and data will be publicly released.", "AI": {"tldr": "研究者提出了一个用于训练和测试工具使用 LLM 智能体的开放世界环境，该环境包含大量统一格式的工具、复杂的任务生成器以及注入失败的控制器。在此基础上，他们开发了一种新的智能体框架，并通过实验发现了当前 LLM 在约束遵循和工具规划执行方面存在的不足，同时证明了 DeepSeek-v3.2 模型的鲁棒性。此外，他们利用该环境生成的数据微调了 LLM，显著提升了性能，表明该环境在基准测试和数据生成方面具有价值。", "motivation": "现有的工具使用 LLM 智能体在开放世界、工具池大、任务长、约束复杂且工具状态不可靠的情况下表现不佳，需要一个更具挑战性和真实性的训练和测试环境。", "method": "构建了一个包含 5,571 个统一格式工具（覆盖 204 个常用应用）的开放世界环境。该环境包含一个任务创建引擎（用于生成长时序、多工具工作流和复杂约束）和一个状态控制器（用于注入中断和故障）。在此环境下，提出了一种“先选择后执行”的智能体框架，并采用了规划器-执行器分解策略。", "result": "在现有 LLM 上进行了综合评估，发现当前 LLM 在工具规划和执行能力之间存在不匹配，约束遵循能力较弱。DeepSeek-v3.2 在鲁棒性方面表现最强。利用该环境生成的 1,170 个轨迹对 LLM 进行微调，在样本量远小于基线的情况下，取得了更优越的性能。", "conclusion": "所提出的开放世界环境是训练和评估工具使用 LLM 智能体的现实基准和有效的数据引擎。现有的 LLM 在处理复杂约束和协调工具规划执行方面仍有提升空间。DeepSeek-v3.2 模型展现了良好的鲁棒性。通过利用环境生成的数据进行微调，可以显著提升 LLM 在工具使用任务上的表现。"}}
{"id": "2601.06334", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06334", "abs": "https://arxiv.org/abs/2601.06334", "authors": ["Masoud Deylami", "Negar Izadipour", "Adel Alaeddini"], "title": "Kolmogorov-Arnold Networks-Based Tolerance-Aware Manufacturability Assessment Integrating Design-for-Manufacturing Principles", "comment": "25 pages, 12 figures. Under review for journal publication", "summary": "Manufacturability assessment is a critical step in bridging the persistent gap between design and production. While artificial intelligence (AI) has been widely applied to this task, most existing frameworks rely on geometry-driven methods that require extensive preprocessing, suffer from information loss, and offer limited interpretability. This study proposes a methodology that evaluates manufacturability directly from parametric design features, enabling explicit incorporation of dimensional tolerances without requiring computer-aided design (CAD) processing. The approach employs Kolmogorov-Arnold Networks (KANs) to learn functional relationships between design parameters, tolerances, and manufacturability outcomes. A synthetic dataset of 300,000 labeled designs is generated to evaluate performance across three representative scenarios: hole drilling, pocket milling, and combined drilling-milling, while accounting for machining constraints and design-for-manufacturing (DFM) rules. Benchmarking against fourteen machine learning (ML) and deep learning (DL) models shows that KAN achieves the highest performance in all scenarios, with AUC values of 0.9919 for drilling, 0.9841 for milling, and 0.9406 for the combined case. The proposed framework provides high interpretability through spline-based functional visualizations and latent-space projections, enabling identification of the design and tolerance parameters that most strongly influence manufacturability. An industrial case study further demonstrates how the framework enables iterative, parameter-level design modifications that transform a non-manufacturable component into a manufacturable one.", "AI": {"tldr": "本研究提出了一种直接从参数化设计特征评估可制造性的方法，利用Kolmogorov-Arnold网络（KAN）学习设计参数、公差和可制造性结果之间的关系，并在合成数据集和工业案例研究中证明了其优于现有机器学习方法的性能，同时提高了模型的可解释性。", "motivation": "现有基于几何的人工智能方法在制造性评估中存在预处理工作量大、信息丢失和可解释性差等问题，本研究旨在克服这些缺点。", "method": "提出了一种直接从参数化设计特征（包括尺寸公差）评估可制造性的方法，不依赖CAD处理。采用Kolmogorov-Arnold网络（KAN）学习设计参数、公差和可制造性结果之间的函数关系。使用包含300,000个带标签设计的合成数据集，在钻孔、铣削和联合钻孔-铣削三种典型场景下进行评估。", "result": "KAN在所有三种场景中均取得了最高性能，AUC值分别为钻孔0.9919、铣削0.9841和联合情况0.9406，优于十四种基准机器学习和深度学习模型。该框架通过基于样条的函数可视化和潜在空间投影提供了高可解释性，能够识别对可制造性影响最大的设计和公差参数。", "conclusion": "所提出的基于KAN的方法能够直接从参数化设计特征中学习可制造性，克服了现有方法的局限性，提供了卓越的性能和高可解释性，并能指导迭代式、参数级的设计修改以提高可制造性。"}}
{"id": "2601.07823", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07823", "abs": "https://arxiv.org/abs/2601.07823", "authors": ["Zhiting Mei", "Tenny Yin", "Ola Shorinwa", "Apurva Badithela", "Zhonghe Zheng", "Joseph Bruno", "Madison Bland", "Lihan Zha", "Asher Hancock", "Jaime Fernández Fisac", "Philip Dames", "Anirudha Majumdar"], "title": "Video Generation Models in Robotics - Applications, Research Challenges, Future Directions", "comment": null, "summary": "Video generation models have emerged as high-fidelity models of the physical world, capable of synthesizing high-quality videos capturing fine-grained interactions between agents and their environments conditioned on multi-modal user inputs. Their impressive capabilities address many of the long-standing challenges faced by physics-based simulators, driving broad adoption in many problem domains, e.g., robotics. For example, video models enable photorealistic, physically consistent deformable-body simulation without making prohibitive simplifying assumptions, which is a major bottleneck in physics-based simulation. Moreover, video models can serve as foundation world models that capture the dynamics of the world in a fine-grained and expressive way. They thus overcome the limited expressiveness of language-only abstractions in describing intricate physical interactions. In this survey, we provide a review of video models and their applications as embodied world models in robotics, encompassing cost-effective data generation and action prediction in imitation learning, dynamics and rewards modeling in reinforcement learning, visual planning, and policy evaluation. Further, we highlight important challenges hindering the trustworthy integration of video models in robotics, which include poor instruction following, hallucinations such as violations of physics, and unsafe content generation, in addition to fundamental limitations such as significant data curation, training, and inference costs. We present potential future directions to address these open research challenges to motivate research and ultimately facilitate broader applications, especially in safety-critical settings.", "AI": {"tldr": "本文综述了视频生成模型在机器人领域的应用，重点介绍了它们作为具身世界模型在数据生成、动作预测、动力学建模、奖励建模、视觉规划和策略评估等方面的作用，并讨论了当前面临的挑战和未来的研究方向。", "motivation": "物理模拟器在处理复杂的物理交互时存在局限性，而视频生成模型能够生成高保真度的视频，并能够理解多模态输入，有望解决这些问题，并在机器人领域得到广泛应用。", "method": "本文采用综述（survey）的方式，回顾了视频生成模型在机器人领域的各种应用，包括数据生成、动作预测、动力学和奖励建模、视觉规划以及策略评估。", "result": "视频生成模型在机器人领域展现出巨大潜力，能够生成逼真的物理交互视频，克服了语言抽象的局限性。文章也指出了其在指令遵循、幻觉（物理违反）和不安全内容生成方面存在的问题，以及数据、训练和推理成本高昂的挑战。", "conclusion": "视频生成模型是机器人领域极具潜力的工具，但要实现可信赖的集成，仍需解决指令遵循、物理一致性、安全性和成本等方面的挑战。文章提出了未来的研究方向，以期推动视频模型在机器人领域的更广泛应用，尤其是在安全攸关的场景。"}}
{"id": "2601.07454", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07454", "abs": "https://arxiv.org/abs/2601.07454", "authors": ["Yuxuan Hu", "Kuangji Zuo", "Boyu Ma", "Shihao Li", "Zhaoyang Xia", "Feng Xu", "Jianfei Yang"], "title": "WaveMan: mmWave-Based Room-Scale Human Interaction Perception for Humanoid Robots", "comment": null, "summary": "Reliable humanoid-robot interaction (HRI) in household environments is constrained by two fundamental requirements, namely robustness to unconstrained user positions and preservation of user privacy. Millimeter-wave (mmWave) sensing inherently supports privacy-preserving interaction, making it a promising modality for room-scale HRI. However, existing mmWave-based interaction-sensing systems exhibit poor spatial generalization at unseen distances or viewpoints. To address this challenge, we introduce WaveMan, a spatially adaptive room-scale perception system that restores reliable human interaction sensing across arbitrary user positions. WaveMan integrates viewpoint alignment and spectrogram enhancement for spatial consistency, with dual-channel attention for robust feature extraction. Experiments across five participants show that, under fixed-position evaluation, WaveMan achieves the same cross-position accuracy as the baseline with five times fewer training positions. In random free-position testing, accuracy increases from 33.00% to 94.33%, enabled by the proposed method. These results demonstrate the feasibility of reliable, privacy-preserving interaction for household humanoid robots across unconstrained user positions.", "AI": {"tldr": "WaveMan是一个空间自适应的毫米波感知系统，通过视点对齐、频谱增强和双通道注意力，提高了在任意用户位置下的交互感知鲁棒性和隐私保护能力，显著提升了其在家庭环境中的应用效果。", "motivation": "现有基于毫米波的交互感知系统在未知距离或视点下泛化能力差，无法满足家庭环境中用户位置不确定且需要保护隐私的要求。", "method": "提出WaveMan系统，整合了视点对齐、频谱增强以实现空间一致性，并利用双通道注意力机制进行鲁棒的特征提取。", "result": "在固定位置评估中，WaveMan仅需五分之一的训练位置即可达到基线方法的交叉位置精度。在随机自由位置测试中，准确率从33.00%提升至94.33%。", "conclusion": "WaveMan实现了可靠且隐私保护的交互，能够跨越用户位置不确定的家庭环境，为家用人形机器人提供了可行的解决方案。"}}
{"id": "2601.06426", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06426", "abs": "https://arxiv.org/abs/2601.06426", "authors": ["Robert J. Moore", "Sungeun An", "Farhan Ahmed", "Jay Pankaj Gala"], "title": "NC-Bench: An LLM Benchmark for Evaluating Conversational Competence", "comment": "9 pages, 1 figure, 2 tables", "summary": "The Natural Conversation Benchmark (NC-Bench) introduce a new approach to evaluating the general conversational competence of large language models (LLMs). Unlike prior benchmarks that focus on the content of model behavior, NC-Bench focuses on the form and structure of natural conversation. Grounded in the IBM Natural Conversation Framework (NCF), NC-Bench comprises three distinct sets. The Basic Conversation Competence set evaluates fundamental sequence management practices, such as answering inquiries, repairing responses, and closing conversational pairs. The RAG set applies the same sequence management patterns as the first set but incorporates retrieval-augmented generation (RAG). The Complex Request set extends the evaluation to complex requests involving more intricate sequence management patterns. Each benchmark tests a model's ability to produce contextually appropriate conversational actions in response to characteristic interaction patterns. Initial evaluations across 6 open-source models and 14 interaction patterns show that models perform well on basic answering tasks, struggle more with repair tasks (especially repeat), have mixed performance on closing sequences, and find complex multi-turn requests most challenging, with Qwen models excelling on the Basic set and Granite models on the RAG set and the Complex Request set. By operationalizing fundamental principles of human conversation, NC-Bench provides a lightweight, extensible, and theory-grounded framework for assessing and improving the conversational abilities of LLMs beyond topical or task-specific benchmarks.", "AI": {"tldr": "NC-Bench 提出了一个评估大型语言模型（LLM）对话能力的新基准，侧重于对话的形式和结构，而非内容。它包含三个数据集，评估基本对话、检索增强生成（RAG）以及复杂请求的序列管理能力。测试结果显示，模型在基本问答上表现良好，但在修复和复杂多轮对话方面存在挑战。", "motivation": "现有基准主要关注模型行为的内容，而忽略了自然对话的形式和结构。研究者希望通过一个更侧重于对话结构和序列管理的基准来评估和改进 LLM 的对话能力。", "method": "提出了 NC-Bench，一个包含三个数据集（基本对话能力、RAG、复杂请求）的评估框架。该框架基于 IBM 自然对话框架 (NCF)，通过测试模型在特定交互模式下的上下文相关对话行为来评估其序列管理能力。", "result": "在 6 个开源模型和 14 种交互模式上的初步评估表明，模型在基本问答任务上表现良好，在修复任务（尤其是重复）上表现较差，在对话结束序列上的表现参半，并且在复杂的多轮请求方面面临最大挑战。Qwen 模型在基本数据集上表现出色，Granite 模型在 RAG 和复杂请求数据集上表现最佳。", "conclusion": "NC-Bench 通过操作化人类对话的基本原则，提供了一个轻量级、可扩展且有理论依据的框架，用于评估和改进 LLM 的对话能力，超越了仅关注主题或特定任务的基准。"}}
{"id": "2601.06287", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06287", "abs": "https://arxiv.org/abs/2601.06287", "authors": ["Joseph Heyward", "Nikhil Pathasarathy", "Tyler Zhu", "Aravindh Mahendran", "João Carreira", "Dima Damen", "Andrew Zisserman", "Viorica Pătrăucean"], "title": "Perception Test 2025: Challenge Summary and a Unified VQA Extension", "comment": null, "summary": "The Third Perception Test challenge was organised as a full-day workshop alongside the IEEE/CVF International Conference on Computer Vision (ICCV) 2025. Its primary goal is to benchmark state-of-the-art video models and measure the progress in multimodal perception. This year, the workshop featured 2 guest tracks as well: KiVA (an image understanding challenge) and Physic-IQ (a video generation challenge). In this report, we summarise the results from the main Perception Test challenge, detailing both the existing tasks as well as novel additions to the benchmark. In this iteration, we placed an emphasis on task unification, as this poses a more challenging test for current SOTA multimodal models. The challenge included five consolidated tracks: unified video QA, unified object and point tracking, unified action and sound localisation, grounded video QA, and hour-long video QA, alongside an analysis and interpretability track that is still open for submissions. Notably, the unified video QA track introduced a novel subset that reformulates traditional perception tasks (such as point tracking and temporal action localisation) as multiple-choice video QA questions that video-language models can natively tackle. The unified object and point tracking merged the original object tracking and point tracking tasks, whereas the unified action and sound localisation merged the original temporal action localisation and temporal sound localisation tracks. Accordingly, we required competitors to use unified approaches rather than engineered pipelines with task-specific models. By proposing such a unified challenge, Perception Test 2025 highlights the significant difficulties existing models face when tackling diverse perception tasks through unified interfaces.", "AI": {"tldr": "Perception Test 2025 挑战赛侧重于通过统一的任务接口来评估和基准化多模态视频理解模型的进展，特别是在统一视频问答、目标跟踪、动作和声音定位等任务上。挑战赛引入了新的统一视频问答子集，将传统感知任务重塑为多项选择题，以测试模型在处理多样化感知任务时的泛化能力。", "motivation": "为了评估和衡量多模态视频理解的最新进展，并为主流模型提供一个基准。今年的挑战赛特别关注“任务统一”，以更好地测试当前最先进的多模态模型在面对多样化感知任务时的泛化能力。", "method": "组织了 Perception Test 2025 挑战赛，包含五个统一的任务轨道：统一视频问答、统一目标和点跟踪、统一动作和声音定位、基于视频的问答以及时长较长的视频问答。此外，还增设了一个分析和可解释性轨道。关键的统一方法是将点跟踪和时间动作定位等任务重塑为多项选择的视频问答形式，并将原有的跟踪和定位任务合并，要求参赛者使用统一的方法而非针对特定任务的模型。", "result": "挑战赛揭示了当前最先进的模型在通过统一接口处理多样化感知任务时面临的显著困难。统一视频问答轨道通过新的子集有效地将多种感知任务转化为视频问答形式。统一目标和点跟踪以及统一动作和声音定位任务合并了原有任务，强制要求使用统一的方法。", "conclusion": "Perception Test 2025 挑战赛通过引入统一的任务接口，暴露了当前多模态模型在处理多样化感知任务时存在的局限性，并为未来研究指明了方向，即需要开发能够更灵活、更通用地处理不同感知任务的模型。"}}
{"id": "2601.06338", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06338", "abs": "https://arxiv.org/abs/2601.06338", "authors": ["Binxu Wang", "Jingxuan Fan", "Xu Pan"], "title": "Circuit Mechanisms for Spatial Relation Generation in Diffusion Transformers", "comment": "31 pages, 23 figures", "summary": "Diffusion Transformers (DiTs) have greatly advanced text-to-image generation, but models still struggle to generate the correct spatial relations between objects as specified in the text prompt. In this study, we adopt a mechanistic interpretability approach to investigate how a DiT can generate correct spatial relations between objects. We train, from scratch, DiTs of different sizes with different text encoders to learn to generate images containing two objects whose attributes and spatial relations are specified in the text prompt. We find that, although all the models can learn this task to near-perfect accuracy, the underlying mechanisms differ drastically depending on the choice of text encoder. When using random text embeddings, we find that the spatial-relation information is passed to image tokens through a two-stage circuit, involving two cross-attention heads that separately read the spatial relation and single-object attributes in the text prompt. When using a pretrained text encoder (T5), we find that the DiT uses a different circuit that leverages information fusion in the text tokens, reading spatial-relation and single-object information together from a single text token. We further show that, although the in-domain performance is similar for the two settings, their robustness to out-of-domain perturbations differs, potentially suggesting the difficulty of generating correct relations in real-world scenarios.", "AI": {"tldr": "本研究通过机制可解释性方法，探究了Diffusion Transformers (DiTs) 如何生成文本提示中指定的物体空间关系。结果发现，不同文本编码器会导致DiT内部处理空间关系信息的机制截然不同，尽管模型在同域任务上表现相似，但在跨域鲁棒性上存在差异。", "motivation": "现有的文本到图像生成模型（如DiTs）在生成文本提示中指定的物体空间关系方面仍存在困难，需要理解其内部机制以改进模型。", "method": "研究人员从头开始训练了不同大小的DiTs，并使用不同的文本编码器（随机嵌入和预训练的T5），以生成包含具有指定属性和空间关系的两个物体的图像。通过机制可解释性方法分析模型内部处理信息的方式。", "result": "1. 无论使用何种文本编码器，DiTs都能以接近完美的方式学习生成指定空间关系的图像。\n2. 使用随机文本嵌入时，DiT通过一个两阶段的机制处理空间信息，涉及两个独立的交叉注意力头分别读取空间关系和单物体属性。\n3. 使用预训练的T5编码器时，DiT采用不同的机制，通过信息融合的方式，从单个文本标记中同时读取空间关系和单物体信息。", "conclusion": "文本编码器的选择对DiT内部生成空间关系信息的机制有着显著影响。尽管在同域任务上表现相似，但不同机制在跨域鲁棒性上存在差异，这可能解释了在真实场景中生成正确空间关系的挑战。"}}
{"id": "2601.06309", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06309", "abs": "https://arxiv.org/abs/2601.06309", "authors": ["Zane Durante", "Silky Singh", "Arpandeep Khatua", "Shobhit Agarwal", "Reuben Tan", "Yong Jae Lee", "Jianfeng Gao", "Ehsan Adeli", "Li Fei-Fei"], "title": "VideoWeave: A Data-Centric Approach for Efficient Video Understanding", "comment": null, "summary": "Training video-language models is often prohibitively expensive due to the high cost of processing long frame sequences and the limited availability of annotated long videos. We present VideoWeave, a simple yet effective approach to improve data efficiency by constructing synthetic long-context training samples that splice together short, captioned videos from existing datasets. Rather than modifying model architectures or optimization objectives, VideoWeave reorganizes available video-text pairs to expand temporal diversity within fixed compute. We systematically study how different data composition strategies like random versus visually clustered splicing and caption enrichment affect downstream performance on downstream video question answering. Under identical compute constraints, models trained with VideoWeave achieve higher accuracy than conventional video finetuning. Our results highlight that reorganizing training data, rather than altering architectures, may offer a simple and scalable path for training video-language models. We link our code for all experiments here.", "AI": {"tldr": "VideoWeave通过拼接现有短视频来合成长上下文训练样本，提高了视频-语言模型的训练效率，并在相同计算资源下取得了比传统微调更好的性能。", "motivation": "视频-语言模型的训练成本高昂，主要受限于长帧序列的处理费用和长视频标注数据的稀缺性。现有方法在数据效率方面存在不足。", "method": "VideoWeave是一种数据增强方法，通过将现有的、有字幕的短视频拼接起来，构建合成的长上下文训练样本。它不修改模型架构或优化目标，而是重组数据以增加时间多样性。研究人员还探讨了不同数据组合策略（如随机拼接、视觉聚类拼接）和字幕增强对下游任务性能的影响。", "result": "在相同的计算资源限制下，使用VideoWeave训练的模型在视频问答任务上的准确率高于传统的视频微调方法。数据组合策略和字幕增强策略对下游性能有显著影响。", "conclusion": "重组训练数据（如VideoWeave所示）是一种简单且可扩展的方法，可以有效提升视频-语言模型的训练效率和性能，这可能比修改模型架构或优化目标更有前景。"}}
{"id": "2601.06437", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06437", "abs": "https://arxiv.org/abs/2601.06437", "authors": ["Jingmin An", "Wei Liu", "Qian Wang", "Fang Fang"], "title": "Time Travel Engine: A Shared Latent Chronological Manifold Enables Historical Navigation in Large Language Models", "comment": null, "summary": "Time functions as a fundamental dimension of human cognition, yet the mechanisms by which Large Language Models (LLMs) encode chronological progression remain opaque. We demonstrate that temporal information in their latent space is organized not as discrete clusters but as a continuous, traversable geometry. We introduce the Time Travel Engine (TTE), an interpretability-driven framework that projects diachronic linguistic patterns onto a shared chronological manifold. Unlike surface-level prompting, TTE directly modulates latent representations to induce coherent stylistic, lexical, and conceptual shifts aligned with target eras. By parameterizing diachronic evolution as a continuous manifold within the residual stream, TTE enables fluid navigation through period-specific \"zeitgeists\" while restricting access to future knowledge. Furthermore, experiments across diverse architectures reveal topological isomorphism between the temporal subspaces of Chinese and English-indicating that distinct languages share a universal geometric logic of historical evolution. These findings bridge historical linguistics with mechanistic interpretability, offering a novel paradigm for controlling temporal reasoning in neural networks.", "AI": {"tldr": "本研究提出了一种名为时间旅行引擎（TTE）的框架，用于解析和控制大型语言模型（LLMs）中时间信息的编码方式。研究发现，LLMs 中的时间信息以连续的几何形式存在，而非离散的簇。TTE 能够直接调整模型的潜在表征，实现与特定历史时期相符的风格、词汇和概念转变，并发现不同语言在历史演化方面共享相似的几何逻辑。", "motivation": "目前大型语言模型（LLMs）如何编码时间信息机制尚不明确，本研究旨在揭示 LLMs 中时间信息的内在组织结构，并开发一种能够控制模型时间推理能力的方法。", "method": "研究者提出时间旅行引擎（TTE）框架，该框架将语言中的历史演变模式投射到一个共享的时间流形上。TTE 通过直接调整模型残差流中的潜在表征，来实现与目标历史时期相符的风格、词汇和概念的转变，并限制对未来知识的访问。通过对比中文和英文模型，研究者分析了它们时间子空间的拓扑同构性。", "result": "研究发现，LLMs 中的时间信息在潜在空间中呈现为连续可 traversable 的几何结构，而非离散的簇。TTE 框架能够成功地诱导模型产生与特定历史时期相符的语言特征。此外，实验表明中文和英文模型的时间子空间存在拓扑同构性，暗示了历史演化的一种普遍的几何逻辑。", "conclusion": "时间信息在 LLMs 的潜在空间中以连续的几何形式组织。时间旅行引擎（TTE）提供了一种直接控制模型时间推理能力的新范式，能够实现流畅的跨时代语言控制，且不受未来知识的干扰。不同语言的模型在时间演化方面共享相似的几何逻辑，这为理解和控制神经网络中的时间推理提供了新的视角。"}}
{"id": "2601.07559", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07559", "abs": "https://arxiv.org/abs/2601.07559", "authors": ["Yuki Kuroda", "Tomoya Takahashi", "Cristian C. Beltran-Hernandez", "Kazutoshi Tanaka", "Masashi Hamaya"], "title": "Stable In-hand Manipulation for a Lightweight Four-motor Prosthetic Hand", "comment": null, "summary": "Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and designed with motors enclosed inside to protect them from damage and dirt. Additionally, in-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting a pen into a writing posture after picking it up from a desk. We previously developed PLEXUS hand (Precision-Lateral dEXteroUS manipulation hand), a lightweight (311 g) prosthetic hand driven by four motors. This prosthetic performed reorientation between precision and lateral grasps with various objects. However, its controller required predefined object widths and was limited to handling lightweight objects (of weight up to 34 g). This study addresses these limitations by employing motor current feedback. Combined with the hand's previously optimized single-axis thumb, this approach achieves more stable manipulation by estimating the object's width and adjusting the index finger position to maintain stable object holding during the reorientation. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in a 100% success rate with lightweight objects and maintained a high success rate (>=80) even with heavy aluminum prisms (of weight up to 289 g). By contrast, the performance without index finger coordination dropped to just 40% on the heaviest 289 g prism. The hand also successfully executed several daily tasks, including closing bottle caps and orienting a pen for writing.", "AI": {"tldr": "该研究通过引入电机电流反馈和优化手指协调，改进了先前的 PLEXUS 假肢手，使其能够稳定地抓握和重新定向更重、更宽的物体，并成功完成了几项日常任务。", "motivation": "为了克服先前 PLEXUS 假肢手在处理不同宽度物体和重物方面的局限性，并实现更稳定、更实用的操作。", "method": "采用了电机电流反馈来估计物体宽度，并调整食指位置以在物体重新定向过程中保持稳定的抓握。结合了先前优化的单轴拇指。", "result": "在处理各种宽度（5-30 毫米）和形状（圆柱体和棱柱体）的轻质物体时，成功率达到 100%。对于重达 289 克的铝制棱柱体，成功率也保持在 80% 以上。在没有食指协调的情况下，对于最重的物体，成功率下降到 40%。", "conclusion": "通过电机电流反馈和改进的手指协调，PLEXUS 假肢手能够更稳定地抓握和操作更重、更宽的物体，并成功执行了包括开关瓶盖和调整钢笔书写姿态在内的日常任务，显著提高了其在实际应用中的性能。"}}
{"id": "2601.06445", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06445", "abs": "https://arxiv.org/abs/2601.06445", "authors": ["Mingzhe Lu", "Yiwen Wang", "Yanbing Liu", "Qi You", "Chong Liu", "Ruize Qin", "Haoyu Dong", "Wenyu Zhang", "Jiarui Zhang", "Yue Hu", "Yunpeng Li"], "title": "LitVISTA: A Benchmark for Narrative Orchestration in Literary Text", "comment": null, "summary": "Computational narrative analysis aims to capture rhythm, tension, and emotional dynamics in literary texts. Existing large language models can generate long stories but overly focus on causal coherence, neglecting the complex story arcs and orchestration inherent in human narratives. This creates a structural misalignment between model- and human-generated narratives. We propose VISTA Space, a high-dimensional representational framework for narrative orchestration that unifies human and model narrative perspectives. We further introduce LitVISTA, a structurally annotated benchmark grounded in literary texts, enabling systematic evaluation of models' narrative orchestration capabilities. We conduct oracle evaluations on a diverse selection of frontier LLMs, including GPT, Claude, Grok, and Gemini. Results reveal systematic deficiencies: existing models fail to construct a unified global narrative view, struggling to jointly capture narrative function and structure. Furthermore, even advanced thinking modes yield only limited gains for such literary narrative understanding.", "AI": {"tldr": "该研究提出了VISTA Space框架和LitVISTA基准，以解决现有大型语言模型在生成叙事时缺乏对叙事结构和情感动态的把握问题，并对GPT、Claude、Grok和Gemini等模型进行了评估，发现它们在构建全局叙事统一性方面存在系统性缺陷。", "motivation": "现有的大型语言模型在生成长篇故事时，过度关注因果连贯性，而忽略了人类叙事中固有的复杂故事弧线和结构组织，这导致了模型生成叙事与人类叙事在结构上的不匹配。", "method": "提出了VISTA Space，一个高维度的叙事结构化表示框架，用于统一人类和模型的叙事视角。同时引入了LitVISTA，一个基于文学文本的结构化标注基准，用于系统评估模型在叙事结构化方面的能力。对GPT、Claude、Grok和Gemini等模型进行了评估。", "result": "评估结果显示，现有的大型语言模型在构建统一的全局叙事视图方面存在系统性不足，难以同时把握叙事功能和结构。即使采用先进的思考模式，在文学叙事理解方面的提升也仅是有限的。", "conclusion": "现有的大型语言模型在叙事结构化能力方面存在显著缺陷，无法有效捕捉文学叙事中的复杂性。需要进一步的研究来改进模型在理解和生成具有深度叙事结构方面的能力。"}}
{"id": "2601.06391", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06391", "abs": "https://arxiv.org/abs/2601.06391", "authors": ["Saksham Singh Kushwaha", "Sayan Nag", "Yapeng Tian", "Kuldeep Kulkarni"], "title": "Object-WIPER : Training-Free Object and Associated Effect Removal in Videos", "comment": "Project Page: https://sakshamsingh1.github.io/object_wiper_webpage/", "summary": "In this paper, we introduce Object-WIPER, a training-free framework for removing dynamic objects and their associated visual effects from videos, and inpainting them with semantically consistent and temporally coherent content. Our approach leverages a pre-trained text-to-video diffusion transformer (DiT). Given an input video, a user-provided object mask, and query tokens describing the target object and its effects, we localize relevant visual tokens via visual-text cross-attention and visual self-attention. This produces an intermediate effect mask that we fuse with the user mask to obtain a final foreground token mask to replace. We first invert the video through the DiT to obtain structured noise, then reinitialize the masked tokens with Gaussian noise while preserving background tokens. During denoising, we copy values for the background tokens saved during inversion to maintain scene fidelity. To address the lack of suitable evaluation, we introduce a new object removal metric that rewards temporal consistency among foreground tokens across consecutive frames, coherence between foreground and background tokens within each frame, and dissimilarity between the input and output foreground tokens. Experiments on DAVIS and a newly curated real-world associated effect benchmark (WIPER-Bench) show that Object-WIPER surpasses both training-based and training-free baselines in terms of the metric, achieving clean removal and temporally stable reconstruction without any retraining. Our new benchmark, source code, and pre-trained models will be publicly available.", "AI": {"tldr": "提出了一种名为Object-WIPER的训练无关框架，用于从视频中移除动态对象及其视觉效果，并用语义一致、时间连贯的内容进行修复，利用预训练的文本到视频扩散transformer。", "motivation": "现有方法在移除动态对象及其视觉效果并进行修复时存在挑战，需要针对特定场景进行训练，缺乏通用性和高效性。", "method": "使用预训练的文本到视频扩散transformer（DiT），结合用户提供的对象蒙版和查询文本，通过视觉-文本交叉注意力与视觉自注意力来定位相关视觉标记，生成中间效果蒙版并与用户蒙版融合得到最终的前景标记蒙版。通过DiT逆转视频得到结构化噪声，然后用高斯噪声重新初始化被遮蔽的标记，同时保留背景标记。在去噪过程中，复制背景标记以维持场景保真度。", "result": "在DAVIS和新构建的真实世界关联效果基准（WIPER-Bench）上进行实验，Object-WIPER在新的评估指标上优于基于训练和无训练的基线方法，实现了干净的移除和时间上稳定的重建，且无需重新训练。", "conclusion": "Object-WIPER是一种有效的训练无关框架，能够移除视频中的动态对象及其视觉效果，并进行高质量的修复，其提出的新评估指标能够有效衡量移除和修复的效果。"}}
{"id": "2601.06352", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06352", "abs": "https://arxiv.org/abs/2601.06352", "authors": ["Yutong Song", "Jiang Wu", "Weijia Zhang", "Chengze Shen", "Shaofan Yuan", "Weitao Lu", "Jian Wang", "Amir Rahmani", "Nikil Dutt", "Yu Wang"], "title": "CARD: Cluster-level Adaptation with Reward-guided Decoding for Personalized Text Generation", "comment": null, "summary": "Adapting large language models to individual users remains challenging due to the tension between fine-grained personalization and scalable deployment. We present CARD, a hierarchical framework that achieves effective personalization through progressive refinement. CARD first clusters users according to shared stylistic patterns and learns cluster-specific LoRA adapters, enabling robust generalization and strong low-resource performance. To capture individual differences within each cluster, we propose an implicit preference learning mechanism that contrasts user-authored text with cluster-level generations, allowing the model to infer user-specific style preferences without manual annotation. At inference time, CARD injects personalization exclusively at decoding via lightweight user preference vectors and low-rank logit corrections, while keeping the base model frozen. Experiments on the LaMP and LongLaMP benchmarks show that CARD achieves competitive or superior generation quality compared to state-of-the-art baselines, while significantly improving efficiency and scalability for practical personalized text generation.", "AI": {"tldr": "本文提出了一种名为CARD的框架，通过分层方法实现对大型语言模型的个性化，在满足个性化需求的同时保证了模型的可扩展性。CARD首先根据用户风格聚类，然后学习特定于聚类的LoRA适配器，并通过隐式偏好学习来捕捉个体差异。在推理时，CARD仅通过用户偏好向量和低秩Logit校正进行个性化，保持基础模型冻结。实验表明，CARD在生成质量、效率和可扩展性方面优于现有方法。", "motivation": "现有的大型语言模型在进行个性化时，面临着精细化个性化与大规模部署之间的矛盾。研究旨在解决这一挑战，实现既能有效个性化又易于部署的模型。", "method": "CARD框架采用分层方法，首先对用户进行风格聚类，并学习聚类特定的LoRA适配器。然后，通过隐式偏好学习机制，对比用户编写的文本和聚类级别的生成文本，推断用户的风格偏好。在推理阶段，通过轻量级的用户偏好向量和低秩Logit校正注入个性化，同时保持基础模型冻结。", "result": "在LaMP和LongLaMP基准测试中，CARD生成的文本质量与最先进的基线模型相比具有竞争力或更优。同时，CARD在效率和可扩展性方面也取得了显著提升。", "conclusion": "CARD框架能够通过渐进式精炼实现有效的个性化，有效地平衡了细粒度个性化与可扩展部署之间的矛盾，为实际的个性化文本生成提供了高效且可扩展的解决方案。"}}
{"id": "2601.06362", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06362", "abs": "https://arxiv.org/abs/2601.06362", "authors": ["Yutong Song", "Jiang Wu", "Shaofan Yuan", "Chengze Shen", "Jian Wang", "Amir Rahmani", "Nikil Dutt", "Yu Wang"], "title": "Styles + Persona-plug = Customized LLMs", "comment": null, "summary": "We discover a previously overlooked challenge in personalized text generation: personalization methods are increasingly applied under explicit style instructions, yet their behavior under such constraints remains poorly understood. To balance implicit personalization and explicit style, we formulate personalization as a distributional residual and propose PsPLUG, a lightweight soft-prompt plug-in trained with style-conditioned preference contrasts. Across LaMP benchmark, our framework improves persona alignment, maintains stylistic fidelity, and outperforms retrieval-based and soft-prompt baselines with minimal computation. These results show that residual modeling provides a simple and principled foundation for controllable, style-aware LLM personalization.", "AI": {"tldr": "本文提出了一种名为 PsPLUG 的轻量级插件，用于在明确的风格指导下实现个性化文本生成，通过将个性化建模为分布残差并使用风格条件偏好对比进行训练，在 LaMP 基准测试中提高了用户身份匹配度，保持了风格一致性，且计算成本极低。", "motivation": "现有个性化方法在存在显式风格指令时行为不明确，本文旨在解决在显式风格约束下隐式个性化与显式风格之间的平衡问题。", "method": "将个性化建模为分布残差，并提出 PsPLUG，一个轻量级的软提示插件，通过风格条件偏好对比进行训练。", "result": "PsPLUG 在 LaMP 基准测试中，提高了身份匹配度，保持了风格保真度，并优于基于检索和软提示的基线方法，计算开销极小。", "conclusion": "残差建模为可控、风格感知的 LLM 个性化提供了一个简单且有原则的基础。"}}
{"id": "2601.07558", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07558", "abs": "https://arxiv.org/abs/2601.07558", "authors": ["Chen Feng", "Guiyong Zheng", "Tengkai Zhuang", "Yongqian Wu", "Fangzhan He", "Haojia Li", "Juepeng Zheng", "Shaojie Shen", "Boyu Zhou"], "title": "FlyCo: Foundation Model-Empowered Drones for Autonomous 3D Structure Scanning in Open-World Environments", "comment": "34 pages, 24 figures, 9 tables. Video: https://www.youtube.com/playlist?list=PLqjZjnqsCyl40rw3y15Yzc7Mdo-z1y2j8", "summary": "Autonomous 3D scanning of open-world target structures via drones remains challenging despite broad applications. Existing paradigms rely on restrictive assumptions or effortful human priors, limiting practicality, efficiency, and adaptability. Recent foundation models (FMs) offer great potential to bridge this gap. This paper investigates a critical research problem: What system architecture can effectively integrate FM knowledge for this task? We answer it with FlyCo, a principled FM-empowered perception-prediction-planning loop enabling fully autonomous, prompt-driven 3D target scanning in diverse unknown open-world environments. FlyCo directly translates low-effort human prompts (text, visual annotations) into precise adaptive scanning flights via three coordinated stages: (1) perception fuses streaming sensor data with vision-language FMs for robust target grounding and tracking; (2) prediction distills FM knowledge and combines multi-modal cues to infer the partially observed target's complete geometry; (3) planning leverages predictive foresight to generate efficient and safe paths with comprehensive target coverage. Building on this, we further design key components to boost open-world target grounding efficiency and robustness, enhance prediction quality in terms of shape accuracy, zero-shot generalization, and temporal stability, and balance long-horizon flight efficiency with real-time computability and online collision avoidance. Extensive challenging real-world and simulation experiments show FlyCo delivers precise scene understanding, high efficiency, and real-time safety, outperforming existing paradigms with lower human effort and verifying the proposed architecture's practicality. Comprehensive ablations validate each component's contribution. FlyCo also serves as a flexible, extensible blueprint, readily leveraging future FM and robotics advances. Code will be released.", "AI": {"tldr": "FlyCo 是一个基于大模型（FM）的自主无人机 3D 扫描系统，能够通过文本或视觉提示驱动，在未知环境中完成目标结构的扫描，并能进行实时规划和避障。", "motivation": "现有无人机自主 3D 扫描方法存在局限性，如依赖限制性假设或需要大量人工先验知识，导致实用性、效率和适应性不足。而大模型（FMs）有潜力解决这些问题。", "method": "FlyCo 构建了一个基于 FM 的感知-预测-规划（perception-prediction-planning）循环系统。第一阶段“感知”融合传感器数据和视觉语言大模型，实现目标定位和跟踪。第二阶段“预测”利用大模型知识和多模态线索推断目标完整几何形状。第三阶段“规划”基于预测结果生成高效安全的扫描路径，确保全面覆盖。系统还包含提升目标定位效率、预测质量（形状精度、零样本泛化、时间稳定性）以及平衡飞行效率与实时计算和避障的组件。", "result": "FlyCo 在真实世界和模拟环境中表现出色，实现了精确的场景理解、高效率和实时安全性，优于现有方法，且需要更少的人工干预。消融实验验证了各组件的贡献。", "conclusion": "FlyCo 提出的基于大模型的系统架构能够有效实现无人机在开放世界中的自主 3D 扫描，证明了其在该领域的实用性，并可作为未来大模型和机器人技术发展的灵活基础。"}}
{"id": "2601.07476", "categories": ["cs.RO", "cs.SE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07476", "abs": "https://arxiv.org/abs/2601.07476", "authors": ["Elia Cereda", "Alessandro Giusti", "Daniele Palossi"], "title": "NanoCockpit: Performance-optimized Application Framework for AI-based Autonomous Nanorobotics", "comment": "Source code available on GitHub at https://github.com/idsia-robotics/crazyflie-nanocockpit", "summary": "Autonomous nano-drones, powered by vision-based tiny machine learning (TinyML) models, are a novel technology gaining momentum thanks to their broad applicability and pushing scientific advancement on resource-limited embedded systems. Their small form factor, i.e., a few 10s grams, severely limits their onboard computational resources to sub-\\SI{100}{\\milli\\watt} microcontroller units (MCUs). The Bitcraze Crazyflie nano-drone is the \\textit{de facto} standard, offering a rich set of programmable MCUs for low-level control, multi-core processing, and radio transmission. However, roboticists very often underutilize these onboard precious resources due to the absence of a simple yet efficient software layer capable of time-optimal pipelining of multi-buffer image acquisition, multi-core computation, intra-MCUs data exchange, and Wi-Fi streaming, leading to sub-optimal control performances. Our \\textit{NanoCockpit} framework aims to fill this gap, increasing the throughput and minimizing the system's latency, while simplifying the developer experience through coroutine-based multi-tasking. In-field experiments on three real-world TinyML nanorobotics applications show our framework achieves ideal end-to-end latency, i.e. zero overhead due to serialized tasks, delivering quantifiable improvements in closed-loop control performance ($-$30\\% mean position error, mission success rate increased from 40\\% to 100\\%).", "AI": {"tldr": "NanoCockpit是一个为资源受限的自动纳米无人机设计的软件框架，通过协程实现多任务处理，优化了图像采集、多核计算和数据传输流程，显著降低了延迟并提高了控制性能。", "motivation": "当前的自动纳米无人机由于资源限制，其板载计算能力常被低估，导致控制性能不佳。缺乏一个简单高效的软件层来优化图像采集、多核计算和数据传输流程。", "method": "提出了NanoCockpit框架，利用协程实现多任务处理，旨在优化图像采集、多核计算、MCU间数据交换和Wi-Fi流的流水线处理，以实现时间最优。", "result": "NanoCockpit实现了理想的端到端延迟（零开销），在三个真实的TinyML纳米机器人应用中，将平均位置误差降低了30%，并将任务成功率从40%提高到100%。", "conclusion": "NanoCockpit框架有效解决了纳米无人机资源受限的问题，通过优化软件架构显著提升了吞吐量、降低了延迟，并改善了闭环控制性能，同时简化了开发体验。"}}
{"id": "2601.07701", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07701", "abs": "https://arxiv.org/abs/2601.07701", "authors": ["Ziwen Zhuang", "Shaoting Zhu", "Mengjie Zhao", "Hang Zhao"], "title": "Deep Whole-body Parkour", "comment": null, "summary": "Current approaches to humanoid control generally fall into two paradigms: perceptive locomotion, which handles terrain well but is limited to pedal gaits, and general motion tracking, which reproduces complex skills but ignores environmental capabilities. This work unites these paradigms to achieve perceptive general motion control. We present a framework where exteroceptive sensing is integrated into whole-body motion tracking, permitting a humanoid to perform highly dynamic, non-locomotion tasks on uneven terrain. By training a single policy to perform multiple distinct motions across varied terrestrial features, we demonstrate the non-trivial benefit of integrating perception into the control loop. Our results show that this framework enables robust, highly dynamic multi-contact motions, such as vaulting and dive-rolling, on unstructured terrain, significantly expanding the robot's traversability beyond simple walking or running. https://project-instinct.github.io/deep-whole-body-parkour", "AI": {"tldr": "提出了一种将外感受感知集成到全身运动跟踪中的框架，使人形机器人能够在不平坦的地形上执行高度动态的非运动任务，如飞跃和翻滚，显著扩展了其通过能力。", "motivation": "现有的人形机器人控制方法要么擅长处理地形但仅限于踏步运动，要么能执行复杂技能但忽略环境因素。这项工作旨在结合这两种方法的优点，实现能够感知环境并执行通用运动控制。", "method": "该框架将外感受传感（如视觉）集成到全身运动跟踪中，训练一个单一的策略来执行多种不同的运动，并在各种地形特征上进行测试。", "result": "结果表明，该框架能够使人形机器人实现鲁棒的、高度动态的多接触运动，例如在非结构化地形上的飞跃和翻滚，显著提高了机器人的通过能力。", "conclusion": "将感知集成到控制循环中，能够使人形机器人不仅能够进行简单的行走或跑步，还能在不平坦的地形上执行更复杂、更具动感的非运动任务，极大地扩展了机器人的能力范围。"}}
{"id": "2601.06471", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06471", "abs": "https://arxiv.org/abs/2601.06471", "authors": ["Junho Park", "Dohoon Kim", "Taesup Moon"], "title": "PRISP: Privacy-Safe Few-Shot Personalization via Lightweight Adaptation", "comment": "16 pages, 9 figures", "summary": "Large language model (LLM) personalization aims to adapt general-purpose models to individual users. Most existing methods, however, are developed under data-rich and resource-abundant settings, often incurring privacy risks. In contrast, realistic personalization typically occurs after deployment under (i) extremely limited user data, (ii) constrained computational resources, and (iii) strict privacy requirements. We propose PRISP, a lightweight and privacy-safe personalization framework tailored to these constraints. PRISP leverages a Text-to-LoRA hypernetwork to generate task-aware LoRA parameters from task descriptions, and enables efficient user personalization by optimizing a small subset of task-aware LoRA parameters together with minimal additional modules using few-shot user data. Experiments on a few-shot variant of the LaMP benchmark demonstrate that PRISP achieves strong overall performance compared to prior approaches, while reducing computational overhead and eliminating privacy risks.", "AI": {"tldr": "本文提出了一种名为 PRISP 的轻量级且隐私安全的 LLM 个性化框架，它能够在数据量极少、计算资源有限和隐私要求严格的约束下进行有效个性化。", "motivation": "现有 LLM 个性化方法通常需要大量数据和计算资源，并且存在隐私风险。然而，实际应用中的个性化通常是在部署后，面临数据量极少、计算资源受限和严格隐私要求等挑战。", "method": "PRISP 利用 Text-to-LoRA 超网络从任务描述生成任务感知的 LoRA 参数。然后，通过优化少量任务感知的 LoRA 参数和最小的附加模块，并结合少样本用户数据，实现高效的用户个性化。", "result": "在 LaMP 基准的少样本变体上的实验表明，PRISP 相比现有方法取得了更优的整体性能，同时降低了计算开销并消除了隐私风险。", "conclusion": "PRISP 框架能够有效地解决在数据量有限、计算资源受限和隐私敏感场景下的 LLM 个性化问题，并在实验中证明了其优越性。"}}
{"id": "2601.06377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06377", "abs": "https://arxiv.org/abs/2601.06377", "authors": ["Ningning Zhang", "Xingxing Yang", "Zhizhong Tan", "Weiping Deng", "Wenyong Wang"], "title": "HiMem: Hierarchical Long-Term Memory for LLM Long-Horizon Agents", "comment": null, "summary": "Although long-term memory systems have made substantial progress in recent years, they still exhibit clear limitations in adaptability, scalability, and self-evolution under continuous interaction settings. Inspired by cognitive theories, we propose HiMem, a hierarchical long-term memory framework for long-horizon dialogues, designed to support memory construction, retrieval, and dynamic updating during sustained interactions. HiMem constructs cognitively consistent Episode Memory via a Topic-Aware Event--Surprise Dual-Channel Segmentation strategy, and builds Note Memory that captures stable knowledge through a multi-stage information extraction pipeline. These two memory types are semantically linked to form a hierarchical structure that bridges concrete interaction events and abstract knowledge, enabling efficient retrieval without sacrificing information fidelity. HiMem supports both hybrid and best-effort retrieval strategies to balance accuracy and efficiency, and incorporates conflict-aware Memory Reconsolidation to revise and supplement stored knowledge based on retrieval feedback. This design enables continual memory self-evolution over long-term use. Experimental results on long-horizon dialogue benchmarks demonstrate that HiMem consistently outperforms representative baselines in accuracy, consistency, and long-term reasoning, while maintaining favorable efficiency. Overall, HiMem provides a principled and scalable design paradigm for building adaptive and self-evolving LLM-based conversational agents. The code is available at https://github.com/jojopdq/HiMem.", "AI": {"tldr": "本文提出了一种名为HiMem的层级长时记忆框架，用于处理长对话场景，旨在提升模型的适应性、可扩展性和自我演化能力。HiMem通过区分事件记忆和知识笔记，并建立两者间的语义联系，实现高效且保真的信息检索，并支持动态更新和冲突感知记忆重构。实验证明HiMem在长对话任务中表现优于现有基线模型。", "motivation": "现有长时记忆系统在持续交互场景下存在适应性、可扩展性和自我演化能力不足的局限性。", "method": "HiMem框架包含两个主要的记忆模块：Episode Memory（通过Topic-Aware Event--Surprise Dual-Channel Segmentation策略构建）和Note Memory（通过多阶段信息提取管道构建）。这两个记忆模块通过语义联系形成层级结构，并支持混合检索和尽力检索策略，同时采用冲突感知记忆重构机制进行知识更新。", "result": "在长对话基准测试中，HiMem在准确性、一致性和长期推理方面优于代表性基线模型，同时保持了良好的效率。", "conclusion": "HiMem提供了一种原则性且可扩展的设计范式，用于构建自适应且自我演化的基于LLM的对话代理，克服了现有长时记忆系统的局限性。"}}
{"id": "2601.06413", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06413", "abs": "https://arxiv.org/abs/2601.06413", "authors": ["Yueming Pan", "Ruoyu Feng", "Jianmin Bao", "Chong Luo", "Nanning Zheng"], "title": "GlobalPaint: Spatiotemporal Coherent Video Outpainting with Global Feature Guidance", "comment": null, "summary": "Video outpainting extends a video beyond its original boundaries by synthesizing missing border content. Compared with image outpainting, it requires not only per-frame spatial plausibility but also long-range temporal coherence, especially when outpainted content becomes visible across time under camera or object motion. We propose GlobalPaint, a diffusion-based framework for spatiotemporal coherent video outpainting. Our approach adopts a hierarchical pipeline that first outpaints key frames and then completes intermediate frames via an interpolation model conditioned on the completed boundaries, reducing error accumulation in sequential processing. At the model level, we augment a pretrained image inpainting backbone with (i) an Enhanced Spatial-Temporal module featuring 3D windowed attention for stronger spatiotemporal interaction, and (ii) global feature guidance that distills OpenCLIP features from observed regions across all frames into compact global tokens using a dedicated extractor. Comprehensive evaluations on benchmark datasets demonstrate improved reconstruction quality and more natural motion compared to prior methods. Our demo page is https://yuemingpan.github.io/GlobalPaint/", "AI": {"tldr": "提出了一种名为GlobalPaint的基于扩散模型的视频外插框架，通过分层处理和增强的时空模块，实现了更优的时空连贯性。", "motivation": "现有的视频外插方法在保证帧内空间合理性的同时，难以实现长时域的连贯性，尤其是在相机或物体运动导致外插内容跨时间显现时。", "method": "采用分层流水线，首先对外插关键帧，然后通过条件于已完成边界的插值模型来补全中间帧。模型层面，增强了预训练的图像外插骨干网络，加入了（i）具有3D窗口注意力机制的增强时空模块，以加强时空交互，以及（ii）全局特征引导，通过专用提取器将所有帧中观测区域的OpenCLIP特征提炼成紧凑的全局token。", "result": "在基准数据集上的综合评估表明，与现有方法相比，GlobalPaint在重建质量和运动自然度方面都有所提高。", "conclusion": "GlobalPaint通过其提出的分层流水线和增强的时空模块，能够有效地解决视频外插中的时空连贯性问题，并取得优于现有方法的性能。"}}
{"id": "2601.07718", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07718", "abs": "https://arxiv.org/abs/2601.07718", "authors": ["Shaoting Zhu", "Ziwen Zhuang", "Mengjie Zhao", "Kun-Ying Lee", "Hang Zhao"], "title": "Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids", "comment": "Project Page: https://project-instinct.github.io/hiking-in-the-wild", "summary": "Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. However, integrating exteroception remains a significant challenge: mapping-based methods suffer from state estimation drift; for instance, LiDAR-based methods do not handle torso jitter well. Existing end-to-end approaches often struggle with scalability and training complexity; specifically, some previous works using virtual obstacles are implemented case-by-case. In this work, we present \\textit{Hiking in the Wild}, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. To ensure safety and training stability, we introduce two key mechanisms: a foothold safety mechanism combining scalable \\textit{Terrain Edge Detection} with \\textit{Foot Volume Points} to prevent catastrophic slippage on edges, and a \\textit{Flat Patch Sampling} strategy that mitigates reward hacking by generating feasible navigation targets. Our approach utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. Extensive field experiments on a full-size humanoid demonstrate that our policy enables robust traversal of complex terrains at speeds up to 2.5 m/s. The training and deployment code is open-sourced to facilitate reproducible research and deployment on real robots with minimal hardware modifications.", "AI": {"tldr": "该论文提出了一种名为“Hiking in the Wild”的端到端机器人感知框架，用于实现人形机器人在复杂非结构化环境下的鲁棒行走。该框架通过引入了“落脚点安全机制”和“平坦区域采样”策略，并采用单阶段强化学习，直接将深度图像和本体感觉映射到关节动作，实现了高稳健性和高速度的行走。", "motivation": "当前人形机器人虽然在受控环境中表现良好，但在复杂、非结构化环境中，从依赖本体感觉转向主动感知仍面临挑战。现有的基于地图的方法存在状态估计漂移问题，而点云等方法对躯干抖动敏感。同时，端到端方法在可扩展性和训练复杂性方面存在不足，例如一些依赖虚拟障碍物的方法实现成本高且需要针对性部署。", "method": "论文提出了一种名为“Hiking in the Wild”的框架，包含两个关键机制：1. 落脚点安全机制：结合了可扩展的“地形边缘检测”和“脚部体积点”，以防止在边缘处发生灾难性滑动。2. 平坦区域采样策略：通过生成可行的导航目标来缓解奖励劫持问题。该方法采用单阶段强化学习，直接将原始深度输入和本体感觉映射到关节动作，无需外部状态估计。", "result": "在全尺寸人形机器人上的大量实地实验表明，该策略能够以高达 2.5 m/s 的速度鲁棒地穿越复杂地形。同时，训练和部署代码已开源，便于复现和部署。", "conclusion": "“Hiking in the Wild”框架能够实现机器人鲁棒地在复杂非结构化环境中行走，克服了现有方法的局限性，并在实际应用中表现出优异的性能和速度。"}}
{"id": "2601.06477", "categories": ["cs.CL", "cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.06477", "abs": "https://arxiv.org/abs/2601.06477", "authors": ["Debasmita Panda", "Akash Anil", "Neelesh Kumar Shukla"], "title": "IndRegBias: A Dataset for Studying Indian Regional Biases in English and Code-Mixed Social Media Comments", "comment": "Preprint. Under review", "summary": "Warning: This paper consists of examples representing regional biases in Indian regions that might be offensive towards a particular region. While social biases corresponding to gender, race, socio-economic conditions, etc., have been extensively studied in the major applications of Natural Language Processing (NLP), biases corresponding to regions have garnered less attention. This is mainly because of (i) difficulty in the extraction of regional bias datasets, (ii) disagreements in annotation due to inherent human biases, and (iii) regional biases being studied in combination with other types of social biases and often being under-represented. This paper focuses on creating a dataset IndRegBias, consisting of regional biases in an Indian context reflected in users' comments on popular social media platforms, namely Reddit and YouTube. We carefully selected 25,000 comments appearing on various threads in Reddit and videos on YouTube discussing trending topics on regional issues in India. Furthermore, we propose a multilevel annotation strategy to annotate the comments describing the severity of regional biased statements. To detect the presence of regional bias and its severity in IndRegBias, we evaluate open-source Large Language Models (LLMs) and Indic Language Models (ILMs) using zero-shot, few-shot, and fine-tuning strategies. We observe that zero-shot and few-shot approaches show lower accuracy in detecting regional biases and severity in the majority of the LLMs and ILMs. However, the fine-tuning approach significantly enhances the performance of the LLM in detecting Indian regional bias along with its severity.", "AI": {"tldr": "本研究提出了一个名为 IndRegBias 的新数据集，用于识别和量化印度地区社会媒体评论中的地域偏见。研究评估了各种大型语言模型（LLMs）和印度语言模型（ILMs）在该数据集上的表现，发现微调策略显著提高了模型检测地域偏见及其严重程度的能力。", "motivation": "尽管性别、种族和社会经济地位等方面的社会偏见在自然语言处理（NLP）领域得到了广泛研究，但地域偏见却鲜少受到关注。这主要是由于缺乏地域偏见数据集、标注困难以及地域偏见常与其他偏见混杂且代表性不足。", "method": "研究人员创建了一个名为 IndRegBias 的数据集，该数据集包含了来自 Reddit 和 YouTube 平台上关于印度地区性话题的 25,000 条用户评论。采用多层次标注策略来评估地域偏见语句的严重程度。通过零样本、少样本和微调等策略，评估了开源 LLMs 和 ILMs 在检测 IndRegBias 数据集中的地域偏见及其严重程度的能力。", "result": "零样本和少样本方法在大多数 LLMs 和 ILMs 上检测地域偏见及其严重程度的准确性较低。然而，微调方法显著提高了 LLM 在检测印度地域偏见及其严重程度方面的性能。", "conclusion": "本研究为研究印度语境下的地域偏见提供了重要的数据集（IndRegBias）和评估方法。研究表明，微调策略是提高 LLMs 检测地域偏见及其严重程度的有效途径。"}}
{"id": "2601.06234", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06234", "abs": "https://arxiv.org/abs/2601.06234", "authors": ["Weijie Li", "Zhongqing Wang", "Guodong Zhou"], "title": "PCoKG: Personality-aware Commonsense Reasoning with Debate", "comment": "Accept by AAAI-2026", "summary": "Most commonsense reasoning models overlook the influence of personality traits, limiting their effectiveness in personalized systems such as dialogue generation. To address this limitation, we introduce the Personality-aware Commonsense Knowledge Graph (PCoKG), a structured dataset comprising 521,316 quadruples. We begin by employing three evaluators to score and filter events from the ATOMIC dataset, selecting those that are likely to elicit diverse reasoning patterns across different personality types. For knowledge graph construction, we leverage the role-playing capabilities of large language models (LLMs) to perform reasoning tasks. To enhance the quality of the generated knowledge, we incorporate a debate mechanism consisting of a proponent, an opponent, and a judge, which iteratively refines the outputs through feedback loops. We evaluate the dataset from multiple perspectives and conduct fine-tuning and ablation experiments using multiple LLM backbones to assess PCoKG's robustness and the effectiveness of its construction pipeline. Our LoRA-based fine-tuning results indicate a positive correlation between model performance and the parameter scale of the base models. Finally, we apply PCoKG to persona-based dialogue generation, where it demonstrates improved consistency between generated responses and reference outputs. This work bridges the gap between commonsense reasoning and individual cognitive differences, enabling the development of more personalized and context-aware AI systems.", "AI": {"tldr": "该研究提出了一个名为PCoKG的面向个性的常识知识图谱，用于解决现有常识推理模型忽略人格特质的问题，并将其应用于个性化对话生成，取得了更好的效果。", "motivation": "现有的常识推理模型在个性化系统（如对话生成）中效果有限，因为它们忽略了人格特质的影响。本研究旨在弥合常识推理与个体认知差异之间的差距。", "method": "研究者构建了一个包含521,316个四元组的PCoKG数据集。首先，通过评估者筛选ATOMIC数据集中的事件，选择能引发不同人格类型多样推理模式的事件。然后，利用大型语言模型（LLMs）的角色扮演能力进行推理任务，并采用包括提议者、反对者和裁判的辩论机制来迭代优化知识生成质量。最后，通过LoRA微调和消融实验评估PCoKG的鲁棒性和构建流程的有效性，并将其应用于基于个性的对话生成。", "result": "PCoKG数据集的评估和实验表明，其构建流程是有效的，并且PCoKG能够提升基于LLMs的个性化对话生成效果，使得生成的响应与参考输出之间的一致性得到改善。微调实验显示，模型性能与基础模型的参数规模呈正相关。", "conclusion": "PCoKG是一个面向个性的常识知识图谱，能够有效地增强常识推理在个性化AI系统中的应用，特别是对于对话生成任务。该研究为开发更具个性化和上下文感知能力的AI系统提供了新的方向。"}}
{"id": "2601.06401", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06401", "abs": "https://arxiv.org/abs/2601.06401", "authors": ["Xin Guo", "Rongjunchen Zhang", "Guilong Lu", "Xuntao Guo", "Shuai Jia", "Zhi Yang", "Liwen Zhang"], "title": "BizFinBench.v2: A Unified Dual-Mode Bilingual Benchmark for Expert-Level Financial Capability Alignment", "comment": null, "summary": "Large language models have undergone rapid evolution, emerging as a pivotal technology for intelligence in financial operations. However, existing benchmarks are often constrained by pitfalls such as reliance on simulated or general-purpose samples and a focus on singular, offline static scenarios. Consequently, they fail to align with the requirements for authenticity and real-time responsiveness in financial services, leading to a significant discrepancy between benchmark performance and actual operational efficacy. To address this, we introduce BizFinBench.v2, the first large-scale evaluation benchmark grounded in authentic business data from both Chinese and U.S. equity markets, integrating online assessment. We performed clustering analysis on authentic user queries from financial platforms, resulting in eight fundamental tasks and two online tasks across four core business scenarios, totaling 29,578 expert-level Q&A pairs. Experimental results demonstrate that ChatGPT-5 achieves a prominent 61.5% accuracy in main tasks, though a substantial gap relative to financial experts persists; in online tasks, DeepSeek-R1 outperforms all other commercial LLMs. Error analysis further identifies the specific capability deficiencies of existing models within practical financial business contexts. BizFinBench.v2 transcends the limitations of current benchmarks, achieving a business-level deconstruction of LLM financial capabilities and providing a precise basis for evaluating efficacy in the widespread deployment of LLMs within the financial domain. The data and code are available at https://github.com/HiThink-Research/BizFinBench.v2.", "AI": {"tldr": "本文提出了BizFinBench.v2，一个基于真实商业数据和在线评估的大规模金融领域大语言模型（LLM）评测基准，以解决现有基准的局限性。实验结果显示，ChatGPT-5在主要任务上表现出色，但在在线任务上DeepSeek-R1更优，同时指出了当前模型的不足。", "motivation": "现有金融领域LLM基准存在使用模拟或通用数据、仅关注离线静态场景等问题，无法满足金融服务对真实性和实时性的要求，导致基准表现与实际效果脱节。", "method": "通过对金融平台真实用户查询进行聚类分析，定义了四个核心业务场景下的八个基础任务和两个在线任务，构建了包含29,578个专家级问答对的BizFinBench.v2基准。并在真实业务场景下进行了在线评估。", "result": "ChatGPT-5在主要任务中达到了61.5%的准确率，但与金融专家仍有差距。在在线任务中，DeepSeek-R1的表现优于其他商业LLM。错误分析揭示了现有模型在实际金融业务中的具体能力缺陷。", "conclusion": "BizFinBench.v2克服了现有基准的局限性，实现了对LLM金融能力的业务层面解构，为评估LLM在金融领域的部署效果提供了精确依据。"}}
{"id": "2601.06442", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06442", "abs": "https://arxiv.org/abs/2601.06442", "authors": ["Xianghong Zou", "Jianping Li", "Yandi Yang", "Weitong Wu", "Yuan Wang", "Qiegen Liu", "Zhen Dong"], "title": "WHU-PCPR: A cross-platform heterogeneous point cloud dataset for place recognition in complex urban scenes", "comment": null, "summary": "Point Cloud-based Place Recognition (PCPR) demonstrates considerable potential in applications such as autonomous driving, robot localization and navigation, and map update. In practical applications, point clouds used for place recognition are often acquired from different platforms and LiDARs across varying scene. However, existing PCPR datasets lack diversity in scenes, platforms, and sensors, which limits the effective development of related research. To address this gap, we establish WHU-PCPR, a cross-platform heterogeneous point cloud dataset designed for place recognition. The dataset differentiates itself from existing datasets through its distinctive characteristics: 1) cross-platform heterogeneous point clouds: collected from survey-grade vehicle-mounted Mobile Laser Scanning (MLS) systems and low-cost Portable helmet-mounted Laser Scanning (PLS) systems, each equipped with distinct mechanical and solid-state LiDAR sensors. 2) Complex localization scenes: encompassing real-time and long-term changes in both urban and campus road scenes. 3) Large-scale spatial coverage: featuring 82.3 km of trajectory over a 60-month period and an unrepeated route of approximately 30 km. Based on WHU-PCPR, we conduct extensive evaluation and in-depth analysis of several representative PCPR methods, and provide a concise discussion of key challenges and future research directions. The dataset and benchmark code are available at https://github.com/zouxianghong/WHU-PCPR.", "AI": {"tldr": "本文提出了WHU-PCPR，一个跨平台异构点云数据集，用于解决现有数据集在场景、平台和传感器多样性方面的不足，并在此基础上对现有方法进行了评估和分析。", "motivation": "现有的点云定位方法（PCPR）在自动驾驶等领域潜力巨大，但现有数据集缺乏跨平台、异构传感器和复杂场景的多样性，限制了相关研究的发展。", "method": "收集了来自不同平台（车装MLS和头盔装PLS）和不同LiDAR传感器（机械式和固态）的点云数据，涵盖了城市和校园的复杂场景，并覆盖了较长的时空范围。在此基础上，对几种代表性的PCPR方法进行了评估和分析。", "result": "WHU-PCPR数据集具有跨平台异构点云、复杂场景和大规模时空覆盖等特点。对现有PCPR方法的评估揭示了关键挑战和未来研究方向。", "conclusion": "WHU-PCPR数据集为点云定位研究提供了更多样化的数据和基准，有助于推动更鲁棒和通用的点云定位算法的发展。"}}
{"id": "2601.07768", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07768", "abs": "https://arxiv.org/abs/2601.07768", "authors": ["Alex Huang", "Akshay Karthik"], "title": "THETA: Triangulated Hand-State Estimation for Teleoperation and Automation in Robotic Hand Control", "comment": "The 11th International Conference on Engineering and Emerging Technologies (ICEET) 2025", "summary": "The teleoperation of robotic hands is limited by the high costs of depth cameras and sensor gloves, commonly used to estimate hand relative joint positions (XYZ). We present a novel, cost-effective approach using three webcams for triangulation-based tracking to approximate relative joint angles (theta) of human fingers. We also introduce a modified DexHand, a low-cost robotic hand from TheRobotStudio, to demonstrate THETA's real-time application. Data collection involved 40 distinct hand gestures using three 640x480p webcams arranged at 120-degree intervals, generating over 48,000 RGB images. Joint angles were manually determined by measuring midpoints of the MCP, PIP, and DIP finger joints. Captured RGB frames were processed using a DeepLabV3 segmentation model with a ResNet-50 backbone for multi-scale hand segmentation. The segmented images were then HSV-filtered and fed into THETA's architecture, consisting of a MobileNetV2-based CNN classifier optimized for hierarchical spatial feature extraction and a 9-channel input tensor encoding multi-perspective hand representations. The classification model maps segmented hand views into discrete joint angles, achieving 97.18% accuracy, 98.72% recall, F1 Score of 0.9274, and a precision of 0.8906. In real-time inference, THETA captures simultaneous frames, segments hand regions, filters them, and compiles a 9-channel tensor for classification. Joint-angle predictions are relayed via serial to an Arduino, enabling the DexHand to replicate hand movements. Future research will increase dataset diversity, integrate wrist tracking, and apply computer vision techniques such as OpenAI-Vision. THETA potentially ensures cost-effective, user-friendly teleoperation for medical, linguistic, and manufacturing applications.", "AI": {"tldr": "本文提出了一种名为THETA的低成本手势识别系统，该系统使用三个网络摄像头通过三角测量来估算手指关节角度，并成功地将其应用于控制一个低成本的机械手，实现了高精度的实时远程操作。", "motivation": "现有的机器人手远程操作系统通常依赖昂贵的深度摄像头和传感器手套来估计手部关节位置，成本高昂。研究旨在开发一种更经济实惠的解决方案。", "method": "使用三个固定间隔（120度）的网络摄像头捕获手部RGB图像。通过DeepLabV3（ResNet-50骨干）对图像进行手部分割，然后进行HSV滤波。分割后的多视角手部图像被输入到一个基于MobileNetV2的CNN分类器（THETA架构）中，该分类器被优化用于层次化空间特征提取，并使用9通道输入张量编码多视角信息。该分类器将分割后的手部视图映射到离散的关节角度。最终，预测的关节角度通过串口发送给Arduino，以控制DexHand机械手。", "result": "THETA系统在识别离散关节角度方面取得了97.18%的准确率、98.72%的召回率、0.9274的F1分数和0.8906的精确率。在实时演示中，THETA能够实时捕捉、处理图像并控制DexHand复制手部动作。", "conclusion": "THETA系统提供了一种具有成本效益且用户友好的远程操作机器人手的方法，有望应用于医疗、语言和制造等领域。未来的工作将包括增加数据集多样性、集成手腕跟踪以及探索更先进的计算机视觉技术。"}}
{"id": "2601.06498", "categories": ["cs.CL", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2601.06498", "abs": "https://arxiv.org/abs/2601.06498", "authors": ["Minghui Jia", "Qichao Zhang", "Ali Luo", "Linjing Li", "Shuo Ye", "Hailing Lu", "Wen Hou", "Dongbin Zhao"], "title": "Spec-o3: A Tool-Augmented Vision-Language Agent for Rare Celestial Object Candidate Vetting via Automated Spectral Inspection", "comment": null, "summary": "Due to the limited generalization and interpretability of deep learning classifiers, The final vetting of rare celestial object candidates still relies on expert visual inspection--a manually intensive process. In this process, astronomers leverage specialized tools to analyze spectra and construct reliable catalogs. However, this practice has become the primary bottleneck, as it is fundamentally incapable of scaling with the data deluge from modern spectroscopic surveys. To bridge this gap, we propose Spec-o3, a tool-augmented vision-language agent that performs astronomer-aligned spectral inspection via interleaved multimodal chain-of-thought reasoning. Spec-o3 is trained with a two-stage post-training recipe: cold-start supervised fine-tuning on expert inspection trajectories followed by outcome-based reinforcement learning on rare-type verification tasks. Evaluated on five rare-object identification tasks from LAMOST, Spec-o3 establishes a new State-of-the-Art, boosting the macro-F1 score from 28.3 to 76.5 with a 7B parameter base model and outperforming both proprietary VLMs and specialized deep models. Crucially, the agent demonstrates strong generalization to unseen inspection tasks across survey shifts (from LAMOST to SDSS/DESI). Expert evaluations confirm that its reasoning traces are coherent and physically consistent, supporting transparent and trustworthy decision-making. Code, data, and models are available at \\href{https://github.com/Maxwell-Jia/spec-o3}{Project HomePage}.", "AI": {"tldr": "提出了一种名为 Spec-o3 的工具增强型视觉语言模型，通过交错的多模态链式思维推理来模拟天文学家进行光谱检查，以解决深度学习模型泛化性和可解释性不足的问题，显著提高了稀有天体候选物的识别效率和准确性。", "motivation": "深度学习分类器在泛化性和可解释性方面存在局限，导致稀有天体候选物的最终甄别仍依赖于耗时的人工目视检查，这已成为数据激增情况下的主要瓶颈。", "method": "Spec-o3 是一个工具增强型视觉语言代理，通过交错的多模态链式思维推理来执行天文学家对光谱的检查。其训练过程包括两个阶段：首先在专家检查轨迹上进行冷启动监督微调，然后针对稀有类型验证任务进行基于结果的强化学习。", "result": "在 LAMOST 的五个稀有对象识别任务上，Spec-o3 使用一个 7B 参数的基础模型，将宏观 F1 分数从 28.3 提升到 76.5，超越了专有的 VLM 和深度模型，达到了新的 SOTA 水平。该模型还能很好地泛化到未见的检查任务以及不同 survey 的数据。", "conclusion": "Spec-o3 能够有效地模拟天文学家的光谱检查过程，在稀有天体识别方面取得了显著进展，并展现出良好的泛化能力和可解释性，其推理过程被证实是连贯且物理上一致的，支持透明和可信的决策。"}}
{"id": "2601.07744", "categories": ["eess.SY", "cs.MA", "cs.RO", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.07744", "abs": "https://arxiv.org/abs/2601.07744", "authors": ["Lohitvel Gopikannan", "Shashi Ranjan Kumar", "Abhinav Sinha"], "title": "Predefined-time One-Shot Cooperative Estimation, Guidance, and Control for Simultaneous Target Interception", "comment": null, "summary": "This work develops a unified nonlinear estimation-guidance-control framework for cooperative simultaneous interception of a stationary target under a heterogeneous sensing topology, where sensing capabilities are non-uniform across interceptors. Specifically, only a subset of agents is instrumented with onboard seekers (informed/seeker-equipped agents), whereas the rest of them (seeker-less agents) acquire the information about the target indirectly via the informed agents and execute a distributed cooperative guidance for simultaneous target interception. To address the resulting partial observability, a predefined-time distributed observer is leveraged, guaranteeing convergence of the target state estimates for seeker-less agents through information exchange with seeker-equipped neighbors over a directed communication graph. Thereafter, an improved time-to-go estimate accounting for wide launch envelopes is utilized to design the distributed cooperative guidance commands. This estimate is coupled with a predefined-time consensus protocol, ensuring consensus in the agents' time-to-go values. The temporal upper bounds within which both observer error and time-to-go consensus error converge to zero can be prescribed as design parameters. Furthermore, the cooperative guidance commands are realized by means of an autopilot, wherein the interceptor is steered by canard actuation. The corresponding fin deflection commands are generated using a predefined-time convergent sliding mode control law. This enables the autopilot to precisely track the commanded lateral acceleration within a design-specified time, while maintaining non-singularity of the overall design. Theoretical guarantees are supported by numerical simulations across diverse engagement geometries, verifying the estimation accuracy, the cooperative interception performance, and the autopilot response using the proposed scheme.", "AI": {"tldr": "本研究提出了一个统一的非线性估计-制导-控制框架，用于在异构感知拓扑下合作同时拦截固定目标。该框架利用预定义时间分布式观测器解决部分可观性问题，并通过改进的剩余时间估计和预定义时间共识协议实现分布式合作制导，最后通过预定义时间滑模控制实现精确的自动驾驶仪跟踪。", "motivation": "现有研究在处理异构感知能力和实现合作拦截方面存在不足。特别是在信息获取不均匀的情况下，如何让信息受限的拦截器也能有效参与合作拦截是一个关键问题。", "method": "1. 采用预定义时间分布式观测器，使无传感器的拦截器能够通过邻居信息估计目标状态。\n2. 使用改进的剩余时间估计，考虑了更宽的发射包络。\n3. 结合预定义时间共识协议，确保所有拦截器在剩余时间估计上达成一致。\n4. 设计了预定义时间滑模控制器，用于自动驾驶仪跟踪指令的横向加速度，并实现舵面偏转。", "result": "观测器误差和剩余时间共识误差都能在预先设定的时间内收敛到零。该框架能够实现对固定目标的合作同时拦截，并且在各种交战几何形状下均表现出良好的估计精度、合作拦截性能和自动驾驶仪响应。", "conclusion": "提出的统一框架能够有效解决异构感知拓扑下的合作同时拦截问题，通过预定义时间方法确保了估计和控制的快速收敛性，并实现了鲁棒的拦截性能。"}}
{"id": "2601.06423", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06423", "abs": "https://arxiv.org/abs/2601.06423", "authors": ["Deep Mehta"], "title": "Does Inference Scaling Improve Reasoning Faithfulness? A Multi-Model Analysis of Self-Consistency Tradeoffs", "comment": "24 pages, 3 figures, 9 tables", "summary": "Self-consistency has emerged as a popular technique for improving large language model accuracy on reasoning tasks. The approach is straightforward: generate multiple reasoning paths and select the most common answer through majority voting. While this reliably boosts accuracy, it remains unclear whether these gains reflect genuine improvements in reasoning quality. We investigate a fundamental question that has not been studied before: does inference scaling improve reasoning faithfulness?\n  We conduct a comprehensive empirical study across four frontier models (GPT-5.2, Claude Opus 4.5, Gemini-3-flash-preview, and DeepSeek-v3.2) on 100 GSM8K mathematical reasoning problems. Our analysis employs bootstrap confidence intervals, McNemar's tests for paired comparisons, and Cohen's d effect sizes to quantify the effects rigorously. The results reveal striking differences across models that challenge common assumptions about self-consistency.\n  GPT-5.2 shows the expected pattern: accuracy improves from 78% to 90% at N=5, with faithfulness remaining relatively stable (0.540 to 0.510). Claude Opus 4.5 tells a completely different story. Its accuracy actually drops from 78% to 74.3% while faithfulness jumps dramatically from 0.270 to 0.891 at N=5. DeepSeek-v3.2, already at 98% accuracy, shows ceiling effects with modest faithfulness gains (0.440 to 0.541). Gemini-3-flash improves from 81% to 86% accuracy with a slight faithfulness decrease (0.260 to 0.212).\n  Problem difficulty analysis reveals that GPT-5.2 solves 82% of hard problems while breaking only 13% of easy ones. Claude, in contrast, breaks 23% of easy problems, explaining its accuracy decrease. These findings matter for practitioners: self-consistency is not universally beneficial, and teams should test their specific models before deployment. We release our code and provide practical recommendations for navigating these tradeoffs.", "AI": {"tldr": "研究了自洽性（self-consistency）推理方法是否能提高大型语言模型的推理“忠实度”（faithfulness），结果发现并非所有模型都能受益，且不同模型表现差异显著，甚至有些模型在采用自洽性后准确率下降但忠实度大幅提升。", "motivation": "现有研究大多关注自洽性在提高模型准确率方面的效果，但对其是否能真正提升推理的“忠实度”这一根本问题缺乏深入研究。", "method": "在四个前沿模型（GPT-5.2, Claude Opus 4.5, Gemini-3-flash-preview, DeepSeek-v3.2）上，使用100个GSM8K数学推理问题进行实验。分析方法包括bootstrap置信区间、McNemar检验和Cohen's d效应值。", "result": "GPT-5.2的准确率和忠实度均有提升。Claude Opus 4.5的准确率下降，但忠实度显著提升。DeepSeek-v3.2受限于“天花板效应”，准确率变化不大，忠实度有小幅提升。Gemini-3-flash的准确率略有提升，但忠实度略有下降。Claude Opus 4.5在简单问题上更容易出错，是其准确率下降的原因。", "conclusion": "自洽性并非对所有模型都普遍有益，其效果因模型而异，甚至可能牺牲准确率来换取忠实度。在部署前，应针对特定模型进行测试，并权衡准确率和忠实度之间的取舍。"}}
{"id": "2601.06519", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06519", "abs": "https://arxiv.org/abs/2601.06519", "authors": ["Yuelyu Ji", "Min Gu Kwak", "Hang Zhang", "Xizhi Wu", "Chenyu Li", "Yanshan Wang"], "title": "MedRAGChecker: Claim-Level Verification for Biomedical Retrieval-Augmented Generation", "comment": null, "summary": "Biomedical retrieval-augmented generation (RAG) can ground LLM answers in medical literature, yet long-form outputs often contain isolated unsupported or contradictory claims with safety implications.\n  We introduce MedRAGChecker, a claim-level verification and diagnostic framework for biomedical RAG.\n  Given a question, retrieved evidence, and a generated answer, MedRAGChecker decomposes the answer into atomic claims and estimates claim support by combining evidence-grounded natural language inference (NLI) with biomedical knowledge-graph (KG) consistency signals.\n  Aggregating claim decisions yields answer-level diagnostics that help disentangle retrieval and generation failures, including faithfulness, under-evidence, contradiction, and safety-critical error rates.\n  To enable scalable evaluation, we distill the pipeline into compact biomedical models and use an ensemble verifier with class-specific reliability weighting.\n  Experiments on four biomedical QA benchmarks show that MedRAGChecker reliably flags unsupported and contradicted claims and reveals distinct risk profiles across generators, particularly on safety-critical biomedical relations.", "AI": {"tldr": "MedRAGChecker 是一个用于生物医学检索增强生成 (RAG) 的框架，通过原子化拆解答案并结合自然语言推断 (NLI) 和知识图谱 (KG) 一致性信号来验证每个声明的支持度，从而检测不被支持或相互矛盾的声明，并区分检索和生成失败，特别是在安全关键的生物医学关系方面。", "motivation": "现有的生物医学 RAG 系统在生成长篇幅回答时，常常包含不被支持或自相矛盾的声明，这可能带来安全隐患。", "method": "MedRAGChecker 将答案拆解为原子声明，并结合基于证据的 NLI 和生物医学知识图谱 (KG) 的一致性信号来估计声明的支持度。通过聚合声明的判断结果，生成答案级别的诊断信息，以区分检索和生成失败，如忠实度、证据不足、矛盾和安全关键错误。", "result": "MedRAGChecker 能够可靠地标记不被支持和相互矛盾的声明，并揭示不同生成器在风险特征上的差异，尤其是在处理安全关键的生物医学关系时。", "conclusion": "MedRAGChecker 是一个有效的框架，用于生物医学 RAG 系统的声明级验证和诊断，有助于提高模型的安全性和可靠性。"}}
{"id": "2601.06443", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06443", "abs": "https://arxiv.org/abs/2601.06443", "authors": ["Xiaoya Tang", "Xiaohe Yue", "Heran Mane", "Dapeng Li", "Quynh Nguyen", "Tolga Tasdizen"], "title": "How to Build Robust, Scalable Models for GSV-Based Indicators in Neighborhood Research", "comment": null, "summary": "A substantial body of health research demonstrates a strong link between neighborhood environments and health outcomes. Recently, there has been increasing interest in leveraging advances in computer vision to enable large-scale, systematic characterization of neighborhood built environments. However, the generalizability of vision models across fundamentally different domains remains uncertain, for example, transferring knowledge from ImageNet to the distinct visual characteristics of Google Street View (GSV) imagery. In applied fields such as social health research, several critical questions arise: which models are most appropriate, whether to adopt unsupervised training strategies, what training scale is feasible under computational constraints, and how much such strategies benefit downstream performance. These decisions are often costly and require specialized expertise.\n  In this paper, we answer these questions through empirical analysis and provide practical insights into how to select and adapt foundation models for datasets with limited size and labels, while leveraging larger, unlabeled datasets through unsupervised training. Our study includes comprehensive quantitative and visual analyses comparing model performance before and after unsupervised adaptation.", "AI": {"tldr": "本研究探讨了在有限标签数据和计算资源下，如何选择和调整计算机视觉基础模型，以更好地表征邻里环境并应用于健康研究。研究重点关注无监督学习在提升模型泛化能力方面的作用。", "motivation": "健康研究已证实邻里环境对健康结果的重要性。尽管计算机视觉技术能够大规模表征邻里环境，但现有模型在ImageNet等通用数据集和Google Street View（GSV）等特定领域数据集之间的泛化能力存疑。对于健康研究而言，如何选择模型、是否使用无监督训练、训练规模以及这些策略的效益等问题尚不明确，且解决这些问题成本高昂且需要专业知识。", "method": "通过实证分析，比较模型在无监督适应前后的性能。研究涵盖了定量和视觉分析，旨在为在标签和数据量有限的情况下选择和调整基础模型提供指导，并利用大规模无标签数据进行无监督训练。", "result": "研究提供了关于模型选择和适应的实用见解。定量和视觉分析的结果表明，无监督适应策略能够有效提升模型在有限标签数据集上的下游任务性能。", "conclusion": "该研究为在计算资源受限的情况下，利用无监督学习策略，为社会健康研究等应用领域选择和调整计算机视觉基础模型提供了实用的指导和依据，特别是在处理有限标签和数据集规模较小的情况下。"}}
{"id": "2601.07813", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07813", "abs": "https://arxiv.org/abs/2601.07813", "authors": ["Francisco Leiva", "Claudio Canales", "Michelle Valenzuela", "Javier Ruiz-del-Solar"], "title": "Data-driven control of hydraulic impact hammers under strict operational and control constraints", "comment": "21 pages, 14 figures", "summary": "This paper presents a data-driven methodology for the control of static hydraulic impact hammers, also known as rock breakers, which are commonly used in the mining industry. The task addressed in this work is that of controlling the rock-breaker so its end-effector reaches arbitrary target poses, which is required in normal operation to place the hammer on top of rocks that need to be fractured. The proposed approach considers several constraints, such as unobserved state variables due to limited sensing and the strict requirement of using a discrete control interface at the joint level. First, the proposed methodology addresses the problem of system identification to obtain an approximate dynamic model of the hydraulic arm. This is done via supervised learning, using only teleoperation data. The learned dynamic model is then exploited to obtain a controller capable of reaching target end-effector poses. For policy synthesis, both reinforcement learning (RL) and model predictive control (MPC) algorithms are utilized and contrasted. As a case study, we consider the automation of a Bobcat E10 mini-excavator arm with a hydraulic impact hammer attached as end-effector. Using this machine, both the system identification and policy synthesis stages are studied in simulation and in the real world. The best RL-based policy consistently reaches target end-effector poses with position errors below 12 cm and pitch angle errors below 0.08 rad in the real world. Considering that the impact hammer has a 4 cm diameter chisel, this level of precision is sufficient for breaking rocks. Notably, this is accomplished by relying only on approximately 68 min of teleoperation data to train and 8 min to evaluate the dynamic model, and without performing any adjustments for a successful policy Sim2Real transfer. A demonstration of policy execution in the real world can be found in https://youtu.be/e-7tDhZ4ZgA.", "AI": {"tldr": "本文提出了一种数据驱动的方法来控制采矿业中常用的液压岩石破碎机，使其末端执行器能够到达任意目标姿态。该方法通过监督学习识别系统动力学模型，并结合强化学习（RL）和模型预测控制（MPC）算法进行策略合成。在模拟和真实世界的案例研究中，基于RL的策略在实际操作中达到了厘米级的定位精度，能够满足岩石破碎的需求，并且实现了良好的Sim2Real迁移。", "motivation": "现有液压岩石破碎机（rock breakers）控制主要依赖人工操作，效率和精度有待提高。需要一种数据驱动的方法来自动控制其末端执行器到达指定位置，以辅助或替代人工进行岩石破碎作业。", "method": "1. 系统识别：使用遥操作数据通过监督学习训练动态模型。2. 策略合成：分别采用强化学习（RL）和模型预测控制（MPC）算法，并进行对比。3. 案例研究：以Bobcat E10小型挖掘机臂和液压冲击锤为平台，在模拟和真实世界中进行实验。", "result": "在真实世界中，最佳RL策略能够使末端执行器在位置误差小于12厘米，俯仰角误差小于0.08弧度内达到目标姿态。该精度对于4厘米直径的钎头来说足以破碎岩石。模型训练和评估仅需约68分钟的遥操作数据，并且RL策略实现了成功的Sim2Real迁移，无需额外调整。", "conclusion": "所提出的数据驱动方法能够有效地控制液压岩石破碎机到达目标姿态，具有较高的精度和良好的Sim2Real迁移能力，为岩石破碎作业的自动化提供了可行方案。"}}
{"id": "2601.06431", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06431", "abs": "https://arxiv.org/abs/2601.06431", "authors": ["Qingyu Ren", "Qianyu He", "Jingwen Chang", "Jie Zeng", "Jiaqing Liang", "Yanghua Xiao", "Han Xia", "Zeye Sun", "Fei Yu"], "title": "LSRIF: Logic-Structured Reinforcement Learning for Instruction Following", "comment": null, "summary": "Instruction-following is critical for large language models, but real-world instructions often contain logical structures such as sequential dependencies and conditional branching. Existing methods typically construct datasets with parallel constraints and optimize average rewards, ignoring logical dependencies and yielding noisy signals. We propose a logic-structured training framework LSRIF that explicitly models instruction logic. We first construct a dataset LSRInstruct with constraint structures such as parallel, sequential, and conditional types, and then design structure-aware rewarding method LSRIF including average aggregation for parallel structures, failure-penalty propagation for sequential structures, and selective rewards for conditional branches. Experiments show LSRIF brings significant improvements in instruction-following (in-domain and out-of-domain) and general reasoning. Analysis reveals that learning with explicit logic structures brings parameter updates in attention layers and sharpens token-level attention to constraints and logical operators.", "AI": {"tldr": "提出了一种名为 LSRIF 的逻辑结构化训练框架，用于提升大型语言模型在遵循包含逻辑结构（如顺序依赖和条件分支）的指令方面的能力。该框架通过构建包含不同约束类型的指令数据集 LSRInstruct，并设计了结构感知奖励方法，有效解决了现有方法忽略逻辑依赖性导致信号嘈杂的问题。", "motivation": "现实世界中的指令常常包含逻辑结构，而现有的指令遵循方法在处理这些结构时存在不足，通常优化平均奖励而忽略逻辑依赖性，导致训练信号嘈杂。", "method": "提出 LSRIF 框架，包括：1. 构建 LSRInstruct 数据集，包含并行、顺序和条件等不同类型的约束结构。2. 设计结构感知奖励方法 LSRIF，针对不同结构采用相应的奖励机制（如并行结构的平均聚合、顺序结构的失败惩罚传播、条件分支的选择性奖励）。", "result": "LSRIF 在指令遵循（域内和域外）和通用推理方面带来了显著的改进。分析表明，显式学习逻辑结构能够使注意力层中的参数更新，并提高对约束和逻辑运算符的 token 级注意力。", "conclusion": "LSRIF 框架通过显式建模指令逻辑，能够有效提升大型语言模型在遵循复杂指令方面的能力，并在多个评估维度上展现出优越性。"}}
{"id": "2601.07821", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07821", "abs": "https://arxiv.org/abs/2601.07821", "authors": ["Huanyu Li", "Kun Lei", "Sheng Zang", "Kaizhe Hu", "Yongyuan Liang", "Bo An", "Xiaoli Li", "Huazhe Xu"], "title": "Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation", "comment": "Project page: https://failure-aware-rl.github.io", "summary": "Post-training algorithms based on deep reinforcement learning can push the limits of robotic models for specific objectives, such as generalizability, accuracy, and robustness. However, Intervention-requiring Failures (IR Failures) (e.g., a robot spilling water or breaking fragile glass) during real-world exploration happen inevitably, hindering the practical deployment of such a paradigm. To tackle this, we introduce Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a new paradigm minimizing failures during real-world reinforcement learning. We create FailureBench, a benchmark that incorporates common failure scenarios requiring human intervention, and propose an algorithm that integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing IR Failures while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training. Videos and code are available at https://failure-aware-rl.github.io.", "AI": {"tldr": "本文提出了一种名为FARL（Failure-Aware Offline-to-Online Reinforcement Learning）的新范式，旨在减少机器人强化学习在线探索过程中的干预式故障（IR Failures），并提出了一种名为FailureBench的基准测试，用于评估和解决这类故障。", "motivation": "在机器人强化学习的实际部署中，即使经过训练，也无法避免干预式故障（IR Failures），这阻碍了其广泛应用。因此，研究如何最小化这些故障至关重要。", "method": "FARL范式通过离线训练一个基于世界模型的安全批评家和一个恢复策略，来在在线探索过程中预防故障。FailureBench基准测试包含了常见的需要人工干预的故障场景。", "result": "在模拟和真实世界的实验中，FARL显著减少了IR Failures（平均减少73.1%），同时提高了在线强化学习的性能（平均提升11.3%）和泛化能力。", "conclusion": "FARL是一种有效的新范式，能够大幅减少机器人强化学习在线探索过程中的干预式故障，并提升其整体性能和泛化能力，为机器人实际部署扫清了障碍。"}}
{"id": "2601.06528", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06528", "abs": "https://arxiv.org/abs/2601.06528", "authors": ["Minghui Huang"], "title": "Atomic-SNLI: Fine-Grained Natural Language Inference through Atomic Fact Decomposition", "comment": null, "summary": "Current Natural Language Inference (NLI) systems primarily operate at the sentence level, providing black-box decisions that lack explanatory power. While atomic-level NLI offers a promising alternative by decomposing hypotheses into individual facts, we demonstrate that the conventional assumption that a hypothesis is entailed only when all its atomic facts are entailed fails in practice due to models' poor performance on fine-grained reasoning. Our analysis reveals that existing models perform substantially worse on atomic level inference compared to sentence level tasks. To address this limitation, we introduce Atomic-SNLI, a novel dataset constructed by decomposing SNLI and enriching it with carefully curated atomic level examples through linguistically informed generation strategies. Experimental results demonstrate that models fine-tuned on Atomic-SNLI achieve significant improvements in atomic reasoning capabilities while maintaining strong sentence level performance, enabling both accurate judgements and transparent, explainable results at the fact level.", "AI": {"tldr": "现有自然语言推理（NLI）系统在句子层面运作且缺乏解释性。本文提出了Atomic-SNLI数据集，通过分解假设为原子事实来解决此问题，并提出了一种新的数据集构建方法，以提高模型在细粒度推理上的表现。", "motivation": "现有NLI系统缺乏解释性，并且在原子层面推理时性能较差。", "method": "构建了Atomic-SNLI数据集，该数据集通过分解SNLI数据集并利用语言学信息进行生成，以提高模型在原子推理上的性能。", "result": "在Atomic-SNLI数据集上微调的模型在原子推理能力上显著提升，同时保持了句子层面的性能。", "conclusion": "Atomic-SNLI数据集的引入能够实现准确的NLI判断，并提供可解释的、在事实层面的推理结果。"}}
{"id": "2601.06453", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06453", "abs": "https://arxiv.org/abs/2601.06453", "authors": ["Hyungjun Yoon", "Mohammad Malekzadeh", "Sung-Ju Lee", "Fahim Kawsar", "Lorena Qendro"], "title": "ConSensus: Multi-Agent Collaboration for Multimodal Sensing", "comment": "17 pages, 6 figures, 5 tables", "summary": "Large language models (LLMs) are increasingly grounded in sensor data to perceive and reason about human physiology and the physical world. However, accurately interpreting heterogeneous multimodal sensor data remains a fundamental challenge. We show that a single monolithic LLM often fails to reason coherently across modalities, leading to incomplete interpretations and prior-knowledge bias. We introduce ConSensus, a training-free multi-agent collaboration framework that decomposes multimodal sensing tasks into specialized, modality-aware agents. To aggregate agent-level interpretations, we propose a hybrid fusion mechanism that balances semantic aggregation, which enables cross-modal reasoning and contextual understanding, with statistical consensus, which provides robustness through agreement across modalities. While each approach has complementary failure modes, their combination enables reliable inference under sensor noise and missing data. We evaluate ConSensus on five diverse multimodal sensing benchmarks, demonstrating an average accuracy improvement of 7.1% over the single-agent baseline. Furthermore, ConSensus matches or exceeds the performance of iterative multi-agent debate methods while achieving a 12.7 times reduction in average fusion token cost through a single-round hybrid fusion protocol, yielding a robust and efficient solution for real-world multimodal sensing tasks.", "AI": {"tldr": "提出了一种名为ConSensus的训练无关的多智能体协作框架，用于处理异构多模态传感器数据。通过将任务分解为专门的、感知模态的智能体，并结合语义聚合和统计共识的混合融合机制，ConSensus在提高准确性（平均提高7.1%）和降低计算成本（降低12.7倍）方面取得了显著成效。", "motivation": "大型语言模型（LLMs）在理解人类生理和物理世界方面面临着解释异构多模态传感器数据的挑战。单一的LLM在跨模态推理时表现不佳，容易导致解释不完整和先验知识偏差。", "method": " ConSensus框架将多模态感知任务分解为独立的、模态感知的智能体。它采用一种混合融合机制，结合了语义聚合（用于跨模态推理和上下文理解）和统计共识（用于通过模态间一致性提供鲁棒性）。", "result": " 在五个多模态感知基准测试中，ConSensus的平均准确率比单一智能体基线提高了7.1%。与迭代多智能体辩论方法相比，ConSensus在性能上相当或更优，同时通过单轮混合融合协议实现了12.7倍的平均融合token成本降低。", "conclusion": " ConSensus提供了一个鲁棒且高效的解决方案，能够应对传感器噪声和数据缺失等挑战，适用于现实世界的多模态感知任务。"}}
{"id": "2601.06604", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06604", "abs": "https://arxiv.org/abs/2601.06604", "authors": ["Rodion Vakhitov", "Leonid Ugadiarov", "Aleksandr Panov"], "title": "Object-Centric World Models Meet Monte Carlo Tree Search", "comment": null, "summary": "In this paper, we introduce ObjectZero, a novel reinforcement learning (RL) algorithm that leverages the power of object-level representations to model dynamic environments more effectively. Unlike traditional approaches that process the world as a single undifferentiated input, our method employs Graph Neural Networks (GNNs) to capture intricate interactions among multiple objects. These objects, which can be manipulated and interact with each other, serve as the foundation for our model's understanding of the environment. We trained the algorithm in a complex setting teeming with diverse, interactive objects, demonstrating its ability to effectively learn and predict object dynamics. Our results highlight that a structured world model operating on object-centric representations can be successfully integrated into a model-based RL algorithm utilizing Monte Carlo Tree Search as a planning module.", "AI": {"tldr": "本文提出了一种名为ObjectZero的新型强化学习算法，该算法使用图神经网络（GNN）来处理物体级别的表示，以更有效地模拟动态环境，并在复杂的交互式物体环境中进行了训练和验证。", "motivation": "传统的强化学习方法将环境视为单一的输入，难以有效建模复杂的、由多个相互作用的物体组成的动态环境。研究者希望通过引入物体级别的表示来改进这一点。", "method": "该方法利用图神经网络（GNN）来捕捉环境中多个物体之间的复杂交互。这些物体是模型理解环境的基础。算法在包含各种交互式物体的复杂环境中进行了训练，并集成了基于模型的强化学习算法和蒙特卡洛树搜索（MCTS）作为规划模块。", "result": "在复杂的、包含多样化交互式物体的环境中，ObjectZero算法能够有效地学习和预测物体动力学。结果表明，基于物体中心表示的结构化世界模型可以成功地集成到基于模型的强化学习算法中。", "conclusion": "基于物体中心表示的结构化世界模型可以成功地集成到采用蒙特卡洛树搜索作为规划模块的强化学习算法中，从而更有效地模拟动态环境。"}}
{"id": "2601.06464", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06464", "abs": "https://arxiv.org/abs/2601.06464", "authors": ["Chao Liu", "Ngai-Man Cheung"], "title": "On the Adversarial Robustness of 3D Large Vision-Language Models", "comment": "Under Review", "summary": "3D Vision-Language Models (VLMs), such as PointLLM and GPT4Point, have shown strong reasoning and generalization abilities in 3D understanding tasks. However, their adversarial robustness remains largely unexplored. Prior work in 2D VLMs has shown that the integration of visual inputs significantly increases vulnerability to adversarial attacks, making these models easier to manipulate into generating toxic or misleading outputs. In this paper, we investigate whether incorporating 3D vision similarly compromises the robustness of 3D VLMs. To this end, we present the first systematic study of adversarial robustness in point-based 3D VLMs. We propose two complementary attack strategies: \\textit{Vision Attack}, which perturbs the visual token features produced by the 3D encoder and projector to assess the robustness of vision-language alignment; and \\textit{Caption Attack}, which directly manipulates output token sequences to evaluate end-to-end system robustness. Each attack includes both untargeted and targeted variants to measure general vulnerability and susceptibility to controlled manipulation. Our experiments reveal that 3D VLMs exhibit significant adversarial vulnerabilities under untargeted attacks, while demonstrating greater resilience against targeted attacks aimed at forcing specific harmful outputs, compared to their 2D counterparts. These findings highlight the importance of improving the adversarial robustness of 3D VLMs, especially as they are deployed in safety-critical applications.", "AI": {"tldr": "本研究首次系统性地评估了基于点的3D视觉语言模型（VLM）在对抗性攻击下的鲁棒性，提出了两种攻击策略（Vision Attack 和 Caption Attack），并发现3D VLM对非定向攻击表现出显著的脆弱性，但相对于2D VLM，在定向攻击下表现出更强的韧性。", "motivation": "现有2D VLM在集成视觉输入后更容易受到对抗性攻击，本文旨在探索3D VLM是否也面临类似的问题，即3D视觉输入的加入是否会削弱其鲁棒性。", "method": "提出两种对抗性攻击策略：Vision Attack（扰乱3D编码器和投影仪产生的视觉token特征）和Caption Attack（直接操纵输出token序列）。每种攻击都有无目标和有目标两种变体。", "result": "实验表明，3D VLM在无目标攻击下表现出显著的对抗性脆弱性。与2D VLM相比，3D VLM在抵御旨在强制特定有害输出的有目标攻击时表现出更强的韧性。", "conclusion": "3D VLM存在显著的对抗性脆弱性，尤其是在非定向攻击下。尽管它们在有目标攻击下比2D VLM更具韧性，但提高3D VLM的对抗性鲁棒性仍然至关重要，尤其是在安全关键应用中。"}}
{"id": "2601.06500", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.06500", "abs": "https://arxiv.org/abs/2601.06500", "authors": ["Alok Khatri", "Bishesh Khanal"], "title": "The AI Pyramid A Conceptual Framework for Workforce Capability in the Age of AI", "comment": "14 pages", "summary": "Artificial intelligence (AI) represents a qualitative shift in technological change by extending cognitive labor itself rather than merely automating routine tasks. Recent evidence shows that generative AI disproportionately affects highly educated, white collar work, challenging existing assumptions about workforce vulnerability and rendering traditional approaches to digital or AI literacy insufficient. This paper introduces the concept of AI Nativity, the capacity to integrate AI fluidly into everyday reasoning, problem solving, and decision making, and proposes the AI Pyramid, a conceptual framework for organizing human capability in an AI mediated economy. The framework distinguishes three interdependent capability layers: AI Native capability as a universal baseline for participation in AI augmented environments; AI Foundation capability for building, integrating, and sustaining AI enabled systems; and AI Deep capability for advancing frontier AI knowledge and applications. Crucially, the pyramid is not a career ladder but a system level distribution of capabilities required at scale. Building on this structure, the paper argues that effective AI workforce development requires treating capability formation as infrastructure rather than episodic training, centered on problem based learning embedded in work contexts and supported by dynamic skill ontologies and competency based measurement. The framework has implications for organizations, education systems, and governments seeking to align learning, measurement, and policy with the evolving demands of AI mediated work, while addressing productivity, resilience, and inequality at societal scale.", "AI": {"tldr": "该论文提出了“AI 原生性”和“AI 技能金字塔”概念，旨在应对生成式 AI 对高度专业化工作的挑战，并为 AI 驱动的经济中的人力资本发展提供一个框架。它强调需要将能力培养视为基础设施，通过基于问题的学习和动态技能评估来提升员工适应 AI 时代的能力。", "motivation": "生成式 AI 对高度专业化、白领工作的冲击，颠覆了对劳动力脆弱性的传统认知，并使现有的数字或 AI 素养方法失效，这促使研究者提出新的概念和框架来应对这一挑战。", "method": "提出“AI 原生性”（AI Nativity）概念，并构建“AI 技能金字塔”（AI Pyramid）框架。该框架包含三个相互依存的能力层级：AI 原生能力、AI 基础能力和 AI 深度能力。在此基础上，论文论证了将能力培养视为基础设施，并结合基于问题的学习、动态技能本体和基于能力的度量来应对 AI 时代劳动力发展需求。", "result": "AI 技能金字塔框架区分了在 AI 增强环境中参与所需的通用基础能力、构建和维护 AI 系统的能力以及推动前沿 AI 知识和应用的能力。论文强调，需要将能力培养作为一种基础设施，而不是零散的培训，以适应 AI 驱动的工作环境。", "conclusion": "为了有效发展 AI 劳动力，需要将能力培养视为基础设施，以问题为基础的学习嵌入工作情境，并辅以动态技能本体和基于能力的度量。这一框架对组织、教育系统和政府具有指导意义，有助于实现学习、度量和政策与 AI 驱动工作不断变化的需求相一致，并解决生产力、韧性和不平等问题。"}}
{"id": "2601.06806", "categories": ["cs.CV", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.06806", "abs": "https://arxiv.org/abs/2601.06806", "authors": ["Jiwen Zhang", "Zejun Li", "Siyuan Wang", "Xiangyu Shi", "Zhongyu Wei", "Qi Wu"], "title": "SpatialNav: Leveraging Spatial Scene Graphs for Zero-Shot Vision-and-Language Navigation", "comment": "11 pages, 4 figures, 6 tables", "summary": "Although learning-based vision-and-language navigation (VLN) agents can learn spatial knowledge implicitly from large-scale training data, zero-shot VLN agents lack this process, relying primarily on local observations for navigation, which leads to inefficient exploration and a significant performance gap. To deal with the problem, we consider a zero-shot VLN setting that agents are allowed to fully explore the environment before task execution. Then, we construct the Spatial Scene Graph (SSG) to explicitly capture global spatial structure and semantics in the explored environment. Based on the SSG, we introduce SpatialNav, a zero-shot VLN agent that integrates an agent-centric spatial map, a compass-aligned visual representation, and a remote object localization strategy for efficient navigation. Comprehensive experiments in both discrete and continuous environments demonstrate that SpatialNav significantly outperforms existing zero-shot agents and clearly narrows the gap with state-of-the-art learning-based methods. Such results highlight the importance of global spatial representations for generalizable navigation.", "AI": {"tldr": "本文提出了一种名为SpatialNav的零样本视觉语言导航（VLN）方法，它通过在任务执行前充分探索环境并构建空间场景图（SSG）来显式地捕捉全局空间结构和语义，从而提高了导航效率，缩小了与现有先进方法的性能差距。", "motivation": "现有的零样本VLN代理主要依赖局部观测进行导航，导致探索效率低下且性能差距较大。研究旨在解决零样本VLN中的这一问题，提高其导航效率和泛化能力。", "method": "在任务执行前允许代理充分探索环境，构建空间场景图（SSG）。基于SSG，SpatialNav整合了代理中心空间地图、罗盘对齐的视觉表示和远程对象定位策略，以实现高效导航。", "result": "SpatialNav在离散和连续环境中均显著优于现有的零样本代理，并显著缩小了与最先进学习方法的性能差距。", "conclusion": "全局空间表示对于可泛化的导航至关重要。提出的SpatialNav方法通过显式地利用全局空间结构和语义，有效提升了零样本VLN的性能。"}}
{"id": "2601.06536", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06536", "abs": "https://arxiv.org/abs/2601.06536", "authors": ["Dennis Zyska", "Alla Rozovskaya", "Ilia Kuznetsov", "Iryna Gurevych"], "title": "Exposía: Academic Writing Assessment of Exposés and Peer Feedback", "comment": null, "summary": "We present Exposía, the first public dataset that connects writing and feedback assessment in higher education, enabling research on educationally grounded approaches to academic writing evaluation. Exposía includes student research project proposals and peer and instructor feedback consisting of comments and free-text reviews. The dataset was collected in the \"Introduction to Scientific Work\" course of the Computer Science undergraduate program that focuses on teaching academic writing skills and providing peer feedback on academic writing. Exposía reflects the multi-stage nature of the academic writing process that includes drafting, providing and receiving feedback, and revising the writing based on the feedback received. Both the project proposals and peer feedback are accompanied by human assessment scores based on a fine-grained, pedagogically-grounded schema for writing and feedback assessment that we develop.\n  We use Exposía to benchmark state-of-the-art open-source large language models (LLMs) for two tasks: automated scoring of (1) the proposals and (2) the student reviews. The strongest LLMs attain high agreement on scoring aspects that require little domain knowledge but degrade on dimensions evaluating content, in line with human agreement values. We find that LLMs align better with the human instructors giving high scores. Finally, we establish that a prompting strategy that scores multiple aspects of the writing together is the most effective, an important finding for classroom deployment.", "AI": {"tldr": "本文介绍了Exposía，一个连接高等教育中写作与反馈评估的公共数据集，旨在促进学术写作评估研究。数据集包含学生项目提案、同行及教师反馈，并附有人工评分。研究人员使用Exposía对大型语言模型（LLMs）在提案和学生评审评分任务上进行了基准测试，发现LLMs在评估低领域知识方面表现良好，但在内容评估方面表现下降，与人类评估者一致。LLMs与给予高分的教师评分一致性更高。研究还发现，将多个写作方面一起评分的提示策略最有效。", "motivation": "现有研究缺乏连接写作和反馈评估的高等教育公共数据集，阻碍了教育性学术写作评估方法的研究。作者旨在创建一个这样的数据集，并利用它来评估和改进大型语言模型在学术写作评估中的表现。", "method": "1. 构建Exposía数据集：收集了计算机科学本科课程中学生的研究项目提案、同行和教师的反馈（包括评论和自由文本评审），并根据开发出的细粒度、教学法基础的写作和反馈评估方案进行人工评分。\n2. LLM基准测试：使用Exposía数据集对先进的开源大型语言模型（LLMs）在两项任务上进行基准测试：(1) 提案的自动评分；(2) 学生评审的自动评分。\n3. 评估LLM性能：分析LLMs在不同评分维度上的表现，并与人类评分者（特别是教师）的一致性进行比较。\n4. 提示策略研究：探索不同的提示策略，以确定哪种策略对LLM的评分效果最好。", "result": "1. LLMs在需要较少领域知识的评分方面表现良好，但在评估内容维度上性能有所下降，这与人类评分者的一致性水平相当。\n2. LLMs的评分结果与给予高分的教师评分结果更一致。\n3. 一种将多个写作方面一起评分的提示策略被证明是最有效的。", "conclusion": "Exposía数据集为学术写作评估研究提供了宝贵资源。大型语言模型在某些写作评估任务上展现出潜力，尤其是在与人类教师评分一致性方面，但仍需改进内容评估能力。研究还为有效部署LLM进行课堂写作评估提供了实用的提示策略指导。"}}
{"id": "2601.06543", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06543", "abs": "https://arxiv.org/abs/2601.06543", "authors": ["Jun-Qi Chen", "Kun Zhang", "Rui Zheng", "Ying Zhong"], "title": "SimLLM: Fine-Tuning Code LLMs for SimPy-Based Queueing System Simulation", "comment": "33 pages, 10 figures", "summary": "The Python package SimPy is widely used for modeling queueing systems due to its flexibility, simplicity, and smooth integration with modern data analysis and optimization frameworks. Recent advances in large language models (LLMs) have shown strong ability in generating clear and executable code, making them powerful and suitable tools for writing SimPy queueing simulation code. However, directly employing closed-source models like GPT-4o to generate such code may lead to high computational costs and raise data privacy concerns. To address this, we fine-tune two open-source LLMs, Qwen-Coder-7B and DeepSeek-Coder-6.7B, on curated SimPy queueing data, which enhances their code-generating performance in executability, output-format compliance, and instruction-code consistency. Particularly, we proposed a multi-stage fine-tuning framework comprising two stages of supervised fine-tuning (SFT) and one stage of direct preference optimization (DPO), progressively enhancing the model's ability in SimPy-based queueing simulation code generation. Extensive evaluations demonstrate that both fine-tuned models achieve substantial improvements in executability, output-format compliance, and instruct consistency. These results confirm that domain-specific fine-tuning can effectively transform compact open-source code models into reliable SimPy simulation generators which provide a practical alternative to closed-source LLMs for education, research, and operational decision support.", "AI": {"tldr": "本研究通过对开源大型语言模型（LLMs）进行针对SimPy队列仿真的数据微调，显著提升了其生成SimPy模拟代码的能力，提出了一种多阶段微调框架（SFT+DPO），为教育、研究和决策支持提供了比闭源模型更具成本效益和隐私保护的替代方案。", "motivation": "直接使用GPT-4o等闭源LLMs生成SimPy代码成本高昂且存在数据隐私问题，研究旨在探索更经济、更安全的开源LLM解决方案。", "method": "采用多阶段微调框架，包括两阶段监督微调（SFT）和一阶段直接偏好优化（DPO），对Qwen-Coder-7B和DeepSeek-Coder-6.7B两个开源LLMs进行SimPy队列数据微调。", "result": "微调后的模型在生成SimPy模拟代码的可执行性、输出格式合规性以及指令-代码一致性方面均取得了显著提升。", "conclusion": "针对特定领域（SimPy队列仿真）进行微调，能够有效地将小型开源代码模型转变为可靠的SimPy模拟代码生成器，为教育、研究和运营决策支持提供了实用且优于闭源模型的替代方案。"}}
{"id": "2601.06474", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06474", "abs": "https://arxiv.org/abs/2601.06474", "authors": ["Chenxu Dang", "Jie Wang", "Guang Li", "Zhiwen Hou", "Zihan You", "Hangjun Ye", "Jie Ma", "Long Chen", "Yan Wang"], "title": "SparseOccVLA: Bridging Occupancy and Vision-Language Models via Sparse Queries for Unified 4D Scene Understanding and Planning", "comment": null, "summary": "In autonomous driving, Vision Language Models (VLMs) excel at high-level reasoning , whereas semantic occupancy provides fine-grained details. Despite significant progress in individual fields, there is still no method that can effectively integrate both paradigms. Conventional VLMs struggle with token explosion and limited spatiotemporal reasoning, while semantic occupancy provides a unified, explicit spatial representation but is too dense to integrate efficiently with VLMs. To address these challenges and bridge the gap between VLMs and occupancy, we propose SparseOccVLA, a novel vision-language-action model that unifies scene understanding, occupancy forecasting, and trajectory planning powered by sparse occupancy queries. Starting with a lightweight Sparse Occupancy Encoder, SparseOccVLA generates compact yet highly informative sparse occupancy queries that serve as the single bridge between vision and language. These queries are aligned into the language space and reasoned by the LLM for unified scene understanding and future occupancy forecasting. Furthermore, we introduce an LLM-guided Anchor-Diffusion Planner featuring decoupled anchor scoring and denoising, as well as cross-model trajectory-condition fusion. SparseOccVLA achieves a 7% relative improvement in CIDEr over the state-of-the-art on OmniDrive-nuScenes, a 0.5 increase in mIoU score on Occ3D-nuScenes, and sets state-of-the-art open-loop planning metric on nuScenes benchmark, demonstrating its strong holistic capability.", "AI": {"tldr": "本文提出了一种名为 SparseOccVLA 的新模型，它能够有效地将自动驾驶中的高级视觉语言推理与精细的语义占用表示相结合，实现了场景理解、占用预测和轨迹规划的统一。", "motivation": "现有的视觉语言模型（VLMs）在高级推理方面表现出色，但难以处理细粒度的空间信息，并且存在 token 爆炸和时空推理能力有限的问题。而语义占用表示虽然提供了显式的空间信息，但过于密集，难以与 VLMs 高效集成。因此，研究动机在于弥合 VLM 和语义占用之间的差距，并实现两者的有效融合。", "method": "SparseOccVLA 模型采用了一种新颖的方法，首先通过一个轻量级的稀疏占用编码器生成紧凑但信息丰富的稀疏占用查询。这些查询被对齐到语言空间，并由大型语言模型（LLM）进行推理，以实现统一的场景理解和未来的占用预测。此外，模型还引入了一个由 LLM 驱动的锚点-扩散规划器，该规划器具有解耦的锚点评分和去噪功能，以及跨模型轨迹条件融合。", "result": "SparseOccVLA 在 OmniDrive-nuScenes 数据集上取得了 7% 的 CIDEr 指标相对提升，在 Occ3D-nuScenes 数据集上 mIoU 分数提高了 0.5，并在 nuScenes 基准测试中设定了最先进的闭环规划指标，展示了其强大的整体能力。", "conclusion": "SparseOccVLA 成功地将高级视觉语言推理与精细的语义占用表示相结合，通过稀疏占用查询作为连接视觉和语言的桥梁，实现了场景理解、占用预测和轨迹规划的统一，并在多个自动驾驶任务上取得了显著的性能提升。"}}
{"id": "2601.06502", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06502", "abs": "https://arxiv.org/abs/2601.06502", "authors": ["Shengkai Chen", "Zhiguang Cao", "Jianan Zhou", "Yaoxin Wu", "Senthilnath Jayavelu", "Zhuoyi Lin", "Xiaoli Li", "Shili Xiang"], "title": "DRAGON: LLM-Driven Decomposition and Reconstruction Agents for Large-Scale Combinatorial Optimization", "comment": "This paper has been accepted for presentation and publication at the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), source code will be available soon", "summary": "Large Language Models (LLMs) have recently shown promise in addressing combinatorial optimization problems (COPs) through prompt-based strategies. However, their scalability and generalization remain limited, and their effectiveness diminishes as problem size increases, particularly in routing problems involving more than 30 nodes. We propose DRAGON, which stands for Decomposition and Reconstruction Agents Guided OptimizatioN, a novel framework that combines the strengths of metaheuristic design and LLM reasoning. Starting from an initial global solution, DRAGON autonomously identifies regions with high optimization potential and strategically decompose large-scale COPs into manageable subproblems. Each subproblem is then reformulated as a concise, localized optimization task and solved through targeted LLM prompting guided by accumulated experiences. Finally, the locally optimized solutions are systematically reintegrated into the original global context to yield a significantly improved overall outcome. By continuously interacting with the optimization environment and leveraging an adaptive experience memory, the agents iteratively learn from feedback, effectively coupling symbolic reasoning with heuristic search. Empirical results show that, unlike existing LLM-based solvers limited to small-scale instances, DRAGON consistently produces feasible solutions on TSPLIB, CVRPLIB, and Weibull-5k bin packing benchmarks, and achieves near-optimal results (0.16% gap) on knapsack problems with over 3M variables. This work shows the potential of feedback-driven language agents as a new paradigm for generalizable and interpretable large-scale optimization.", "AI": {"tldr": "提出了一种名为DRAGON的新框架，它结合了元启发式设计和LLM推理，通过分解和重构子问题来解决大规模组合优化问题，并在多个基准测试中取得了优异的结果。", "motivation": "现有的基于LLM的组合优化方法在扩展性和泛化性方面存在局限，特别是在处理大规模问题时效果不佳。本研究旨在克服这些限制，开发一种能够有效解决大规模组合优化问题的框架。", "method": "DRAGON框架首先从一个全局解决方案开始，然后识别优化潜力高的区域，将大规模问题分解为可管理的子问题。每个子问题被转化为本地化任务，并通过有针对性的LLM提示结合经验来解决。最后，将局部优化的解决方案重新整合以获得改进的全局结果。该框架利用自适应经验记忆，通过与优化环境的交互进行学习。", "result": "DRAGON框架在TSPLIB、CVRPLIB和Weibull-5k装箱问题基准测试中能够持续生成可行解，并在具有超过300万个变量的背包问题上取得了接近最优的结果（0.16%的差距）。", "conclusion": "DRAGON框架展示了反馈驱动的语言智能体作为可泛化、可解释的大规模优化新范式的潜力，克服了现有LLM方法在处理大规模问题时的局限性。"}}
{"id": "2601.06394", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06394", "abs": "https://arxiv.org/abs/2601.06394", "authors": ["Ahmed Abdelkawy", "Ahmed Elsayed", "Asem Ali", "Aly Farag", "Thomas Tretter", "Michael McIntyre"], "title": "Context Matters: Peer-Aware Student Behavioral Engagement Measurement via VLM Action Parsing and LLM Sequence Classification", "comment": null, "summary": "Understanding student behavior in the classroom is essential to improve both pedagogical quality and student engagement. Existing methods for predicting student engagement typically require substantial annotated data to model the diversity of student behaviors, yet privacy concerns often restrict researchers to their own proprietary datasets. Moreover, the classroom context, represented in peers' actions, is ignored. To address the aforementioned limitation, we propose a novel three-stage framework for video-based student engagement measurement. First, we explore the few-shot adaptation of the vision-language model for student action recognition, which is fine-tuned to distinguish among action categories with a few training samples. Second, to handle continuous and unpredictable student actions, we utilize the sliding temporal window technique to divide each student's 2-minute-long video into non-overlapping segments. Each segment is assigned an action category via the fine-tuned VLM model, generating a sequence of action predictions. Finally, we leverage the large language model to classify this entire sequence of actions, together with the classroom context, as belonging to an engaged or disengaged student. The experimental results demonstrate the effectiveness of the proposed approach in identifying student engagement.", "AI": {"tldr": "提出了一种基于视频的学生参与度测量框架，结合了少样本学习、时序窗口和大型语言模型，以克服数据稀疏性和上下文缺失问题。", "motivation": "现有学生参与度预测方法需要大量标注数据，且受限于私有数据集，同时忽略了课堂环境中的同伴行为。为了解决这些局限性，本研究旨在提出一种新的方法。", "method": "采用一个包含三个阶段的框架：1. 使用少样本学习（VLM模型微调）进行学生行为识别；2. 利用滑动时间窗口将视频分割成短片段，并为每个片段分配行为类别，生成行为预测序列；3. 利用大型语言模型对行为序列和课堂上下文进行分析，最终判断学生是否处于参与状态。", "result": "实验结果表明，所提出的方法在识别学生参与度方面是有效的。", "conclusion": "该研究成功开发了一种能够有效测量学生参与度的新颖框架，该框架通过少样本学习、时序分析和上下文感知来解决现有方法的不足。"}}
{"id": "2601.06475", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06475", "abs": "https://arxiv.org/abs/2601.06475", "authors": ["Kai Cheng", "Ruoqi Wang", "Qiong Luo"], "title": "VVTRec: Radio Interferometric Reconstruction through Visual and Textual Modality Enrichment", "comment": null, "summary": "Radio astronomy is an indispensable discipline for observing distant celestial objects. Measurements of wave signals from radio telescopes, called visibility, need to be transformed into images for astronomical observations. These dirty images blend information from real sources and artifacts. Therefore, astronomers usually perform reconstruction before imaging to obtain cleaner images. Existing methods consider only a single modality of sparse visibility data, resulting in images with remaining artifacts and insufficient modeling of correlation. To enhance the extraction of visibility information and emphasize output quality in the image domain, we propose VVTRec, a multimodal radio interferometric data reconstruction method with visibility-guided visual and textual modality enrichment. In our VVTRec, sparse visibility is transformed into image-form and text-form features to obtain enhancements in terms of spatial and semantic information, improving the structural integrity and accuracy of images. Also, we leverage Vision-Language Models (VLMs) to achieve additional training-free performance improvements. VVTRec enables sparse visibility, as a foreign modality unseen by VLMs, to accurately extract pre-trained knowledge as a supplement. Our experiments demonstrate that VVTRec effectively enhances imaging results by exploiting multimodal information without introducing excessive computational overhead.", "AI": {"tldr": "本文提出了一种名为 VVTRec 的多模态射电干涉数据重建方法，通过融合可见光和文本模态来增强稀疏可见光数据的成像质量。", "motivation": "现有方法仅考虑单一模态的稀疏可见光数据，导致重建图像存在伪影且对相关性建模不足。为了提高可见光信息的提取效率和图像域的输出质量，需要更先进的方法。", "method": "VVTRec 将稀疏可见光数据转化为图像和文本形式的特征，以增强空间和语义信息。该方法利用视觉-语言模型（VLMs）在训练过程中无需额外调整即可提升性能，并能够从稀疏可见光这一 VLM 未见过的模态中提取预训练知识作为补充。", "result": "实验证明，VVTRec 通过利用多模态信息，在不增加过多计算开销的情况下，有效地提升了成像结果，减少了伪影，提高了图像的结构完整性和准确性。", "conclusion": "VVTRec 是一种有效的多模态射电干涉数据重建方法，它通过融合可见光和文本模态，并利用 VLM 的预训练知识，显著提高了射电天文成像的质量。"}}
{"id": "2601.07333", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07333", "abs": "https://arxiv.org/abs/2601.07333", "authors": ["Tessa Pulli", "Jean-Baptiste Weibel", "Peter Hönig", "Matthias Hirschmanner", "Markus Vincze", "Andreas Holzinger"], "title": "OSCAR: Open-Set CAD Retrieval from a Language Prompt and a Single Image", "comment": null, "summary": "6D object pose estimation plays a crucial role in scene understanding for applications such as robotics and augmented reality. To support the needs of ever-changing object sets in such context, modern zero-shot object pose estimators were developed to not require object-specific training but only rely on CAD models. Such models are hard to obtain once deployed, and a continuously changing and growing set of objects makes it harder to reliably identify the instance model of interest. To address this challenge, we introduce an Open-Set CAD Retrieval from a Language Prompt and a Single Image (OSCAR), a novel training-free method that retrieves a matching object model from an unlabeled 3D object database. During onboarding, OSCAR generates multi-view renderings of database models and annotates them with descriptive captions using an image captioning model. At inference, GroundedSAM detects the queried object in the input image, and multi-modal embeddings are computed for both the Region-of-Interest and the database captions. OSCAR employs a two-stage retrieval: text-based filtering using CLIP identifies candidate models, followed by image-based refinement using DINOv2 to select the most visually similar object. In our experiments we demonstrate that OSCAR outperforms all state-of-the-art methods on the cross-domain 3D model retrieval benchmark MI3DOR. Furthermore, we demonstrate OSCAR's direct applicability in automating object model sourcing for 6D object pose estimation. We propose using the most similar object model for pose estimation if the exact instance is not available and show that OSCAR achieves an average precision of 90.48\\% during object retrieval on the YCB-V object dataset. Moreover, we demonstrate that the most similar object model can be utilized for pose estimation using Megapose achieving better results than a reconstruction-based approach.", "AI": {"tldr": "提出了一种名为 OSCAR 的新方法，用于从语言提示和单张图像中进行开放集 CAD 模型检索，该方法不需要训练，能够为 6D 对象姿态估计自动获取对象模型。", "motivation": "现有的零样本对象姿态估计方法需要对象特定的 CAD 模型，这在对象集合不断变化的情况下难以获取。因此，需要一种无需训练且能从无标签的 3D 对象数据库中检索匹配模型的方法。", "method": "OSCAR 在训练阶段生成数据库模型的多视图渲染并用图像描述模型添加描述性字幕。在推理阶段，使用 GroundedSAM 检测查询对象，然后计算感兴趣区域和数据库字幕的多模态嵌入。OSCAR 采用两阶段检索：首先使用 CLIP 进行文本过滤识别候选模型，然后使用 DINOv2 进行基于图像的精炼选择最相似的对象。", "result": "OSCAR 在 MI3DOR 基准测试中超越了所有现有方法。在 YCB-V 数据集上，OSCAR 在对象检索方面的平均精度达到 90.48%。证明了使用最相似的模型进行姿态估计优于基于重建的方法。", "conclusion": "OSCAR 是一种有效的无训练式 CAD 模型检索方法，可以为 6D 对象姿态估计自动化对象模型来源，并且即使在找不到精确匹配的模型时，使用最相似的模型也能取得良好的姿态估计结果。"}}
{"id": "2601.07723", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.07723", "abs": "https://arxiv.org/abs/2601.07723", "authors": ["Guillaume J. Laurent", "Patrick Sandoz"], "title": "FMAC: a Fair Fiducial Marker Accuracy Comparison Software", "comment": null, "summary": "This paper presents a method for carrying fair comparisons of the accuracy of pose estimation using fiducial markers. These comparisons rely on large sets of high-fidelity synthetic images enabling deep exploration of the 6 degrees of freedom. A low-discrepancy sampling of the space allows to check the correlations between each degree of freedom and the pose errors by plotting the 36 pairs of combinations. The images are rendered using a physically based ray tracing code that has been specifically developed to use the standard calibration coefficients of any camera directly. The software reproduces image distortions, defocus and diffraction blur. Furthermore, sub-pixel sampling is applied to sharp edges to enhance the fidelity of the rendered image. After introducing the rendering algorithm and its experimental validation, the paper proposes a method for evaluating the pose accuracy. This method is applied to well-known markers, revealing their strengths and weaknesses for pose estimation. The code is open source and available on GitHub.", "AI": {"tldr": "本文提出了一种使用光学标记进行姿态估计精度公平比较的方法，通过基于物理的光线追踪渲染大量高保真合成图像，并对6自由度进行深入探索，以评估不同标记的优缺点。", "motivation": "为了对不同光学标记在姿态估计中的精度进行公平、深入的比较，尤其是在6自由度变化的情况下。", "method": "利用基于物理的光线追踪渲染技术生成包含图像失真、散焦和衍射模糊等效果的高保真合成图像，并进行亚像素采样。通过低差异采样探索6自由度空间，并绘制36对组合以检查各自由度与姿态误差的相关性。最后，将提出的评估方法应用于已知标记。", "result": "该方法能够生成逼真的合成图像，并揭示了不同标记在姿态估计中的优势和劣势。", "conclusion": "提出的方法为姿态估计的公平比较提供了一种有效手段，并通过应用证明了其有效性，同时强调了生成高质量合成图像在评估中的重要性。"}}
{"id": "2601.06460", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06460", "abs": "https://arxiv.org/abs/2601.06460", "authors": ["Weihao Hong", "Zhiyuan Jiang", "Bingyu Shen", "Xinlei Guan", "Yangyi Feng", "Meng Xu", "Boyang Li"], "title": "Tone Matters: The Impact of Linguistic Tone on Hallucination in VLMs", "comment": "10 pages, 6 figures, WACV Workshop", "summary": "Vision-Language Models (VLMs) are increasingly used in safety-critical applications that require reliable visual grounding. However, these models often hallucinate details that are not present in the image to satisfy user prompts. While recent datasets and benchmarks have been introduced to evaluate systematic hallucinations in VLMs, many hallucination behaviors remain insufficiently characterized. In particular, prior work primarily focuses on object presence or absence, leaving it unclear how prompt phrasing and structural constraints can systematically induce hallucinations. In this paper, we investigate how different forms of prompt pressure influence hallucination behavior. We introduce Ghost-100, a procedurally generated dataset of synthetic scenes in which key visual details are deliberately removed, enabling controlled analysis of absence-based hallucinations. Using a structured 5-Level Prompt Intensity Framework, we vary prompts from neutral queries to toxic demands and rigid formatting constraints. We evaluate three representative open-weight VLMs: MiniCPM-V 2.6-8B, Qwen2-VL-7B, and Qwen3-VL-8B. Across all three models, hallucination rates do not increase monotonically with prompt intensity. All models exhibit reductions at higher intensity levels at different thresholds, though not all show sustained reduction under maximum coercion. These results suggest that current safety alignment is more effective at detecting semantic hostility than structural coercion, revealing model-specific limitations in handling compliance pressure. Our dataset is available at: https://github.com/bli1/tone-matters", "AI": {"tldr": "本研究通过引入Ghost-100数据集和5级提示强度框架，探究了提示的压力（从温和到强硬）如何影响视觉语言模型（VLMs）在视觉基础能力上的幻觉行为。研究发现，幻觉率并非随着提示强度单调增加，且模型在应对语义攻击比结构性胁迫时，安全对齐效果更好。", "motivation": "现有的视觉语言模型（VLMs）在安全关键应用中存在幻觉问题，现有数据集和基准测试未能充分表征所有幻觉行为，尤其是在提示措辞和结构约束如何系统性诱导幻觉方面。因此，研究者希望系统性地调查提示压力对幻觉行为的影响。", "method": "研究者引入了Ghost-100数据集，这是一个包含程序生成合成场景的数据集，其中关键视觉细节被故意移除，以便于分析基于缺失的幻觉。同时，提出了一个结构化的5级提示强度框架，通过改变提示的语气（从中性查询到严苛要求）和格式约束来评估模型。研究评估了MiniCPM-V 2.6-8B、Qwen2-VL-7B和Qwen3-VL-8B这三个开源VLMs。", "result": "所有被评估的模型在提示强度增加时，幻觉率并非单调递增。在更高强度下，所有模型都出现了幻觉率的降低，但并非在最大胁迫下都能持续降低。这表明当前模型在处理结构性胁迫方面存在局限性。", "conclusion": "当前VLMs的安全对齐在检测语义敌意方面比检测结构性胁迫更有效。不同模型在处理合规性压力时表现出模型特有的局限性。Ghost-100数据集和5级提示强度框架为进一步研究VLMs的幻觉行为提供了工具。"}}
{"id": "2601.06479", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06479", "abs": "https://arxiv.org/abs/2601.06479", "authors": ["JiaLin Zhang", "Dong Li"], "title": "SRFlow: A Dataset and Regularization Model for High-Resolution Facial Optical Flow via Splatting Rasterization", "comment": null, "summary": "Facial optical flow supports a wide range of tasks in facial motion analysis. However, the lack of high-resolution facial optical flow datasets has hindered progress in this area. In this paper, we introduce Splatting Rasterization Flow (SRFlow), a high-resolution facial optical flow dataset, and Splatting Rasterization Guided FlowNet (SRFlowNet), a facial optical flow model with tailored regularization losses. These losses constrain flow predictions using masks and gradients computed via difference or Sobel operator. This effectively suppresses high-frequency noise and large-scale errors in texture-less or repetitive-pattern regions, enabling SRFlowNet to be the first model explicitly capable of capturing high-resolution skin motion guided by Gaussian splatting rasterization. Experiments show that training with the SRFlow dataset improves facial optical flow estimation across various optical flow models, reducing end-point error (EPE) by up to 42% (from 0.5081 to 0.2953). Furthermore, when coupled with the SRFlow dataset, SRFlowNet achieves up to a 48% improvement in F1-score (from 0.4733 to 0.6947) on a composite of three micro-expression datasets. These results demonstrate the value of advancing both facial optical flow estimation and micro-expression recognition.", "AI": {"tldr": "本文提出了高分辨率人脸光流数据集SRFlow和相应模型SRFlowNet，该模型通过定制正则化损失来抑制噪声和错误，从而在人脸运动分析和微表情识别任务上取得了显著提升。", "motivation": "现有的人脸光流数据集分辨率不足，阻碍了人脸运动分析领域的研究进展。", "method": "构建了一个高分辨率人脸光流数据集SRFlow。提出了一种名为SRFlowNet的人脸光流模型，该模型结合了高斯泼溅渲染技术，并通过定制的正则化损失（基于掩码和梯度）来约束光流预测，以抑制纹理缺失或重复区域的高频噪声和大尺度误差。", "result": "SRFlow数据集的引入显著提高了多种光流模型的人脸光流估计精度，端点误差（EPE）最多降低42%。SRFlowNet结合SRFlow数据集后，在三个微表情数据集上的F1分数最多提高了48%。", "conclusion": "SRFlow数据集和SRFlowNet模型在人脸光流估计和微表情识别方面均取得了显著的性能提升，证明了提升人脸光流估计精度和微表情识别能力的重要性。"}}
{"id": "2601.06565", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06565", "abs": "https://arxiv.org/abs/2601.06565", "authors": ["Pei Yang", "Wanyi Chen", "Ke Wang", "Lynn Ai", "Eric Yang", "Tianyu Shi"], "title": "EVM-QuestBench: An Execution-Grounded Benchmark for Natural-Language Transaction Code Generation", "comment": "10 pages, 13 figures", "summary": "Large language models are increasingly applied to various development scenarios. However, in on-chain transaction scenarios, even a minor error can cause irreversible loss for users. Existing evaluations often overlook execution accuracy and safety. We introduce EVM-QuestBench, an execution-grounded benchmark for natural-language transaction-script generation on EVM-compatible chains. The benchmark employs dynamic evaluation: instructions are sampled from template pools, numeric parameters are drawn from predefined intervals, and validators verify outcomes against these instantiated values. EVM-QuestBench contains 107 tasks (62 atomic, 45 composite). Its modular architecture enables rapid task development. The runner executes scripts on a forked EVM chain with snapshot isolation; composite tasks apply step-efficiency decay. We evaluate 20 models and find large performance gaps, with split scores revealing persistent asymmetry between single-action precision and multi-step workflow completion. Code: https://anonymous.4open.science/r/bsc_quest_bench-A9CF/.", "AI": {"tldr": "本文提出了一个名为 EVM-QuestBench 的新基准，用于评估大型语言模型在以太坊虚拟机（EVM）兼容链上的交易脚本生成能力，重点关注执行准确性和安全性，并通过动态评估和对20个模型进行测试，发现了模型在单步操作精度和多步流程完成度之间的显著性能差异。", "motivation": "现有的大型语言模型在开发场景中的应用日益广泛，但在链上交易场景中，任何微小的错误都可能导致用户无法挽回的损失。然而，现有的评估方法往往忽略了执行准确性和安全性。", "method": "引入 EVM-QuestBench，一个基于执行的基准，用于生成 EVM 兼容链上的自然语言交易脚本。该基准采用动态评估方法：指令从模板池中采样，数值参数从预定义区间中抽取，并通过验证器根据这些实例化值来验证结果。EVM-QuestBench 包含107个任务（62个原子任务，45个复合任务）。其模块化架构支持快速任务开发。运行器在分叉的 EVM 链上执行脚本，并具有快照隔离；复合任务应用步进效率衰减。", "result": "对20个模型进行了评估，发现模型之间存在巨大的性能差距。评估结果显示，模型在单步操作的精确度与多步工作流的完成度之间存在持续的不对称性。", "conclusion": "EVM-QuestBench 是一个用于评估 LLM 在 EVM 兼容链上生成交易脚本的有效工具，其动态评估和执行验证机制能够揭示模型在准确性和安全性方面的潜在问题，尤其是在处理复杂的多步交易任务时。"}}
{"id": "2601.06575", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06575", "abs": "https://arxiv.org/abs/2601.06575", "authors": ["Yusuke Yamauchi", "Akiko Aizawa"], "title": "Are Emotions Arranged in a Circle? Geometric Analysis of Emotion Representations via Hyperspherical Contrastive Learning", "comment": null, "summary": "Psychological research has long utilized circumplex models to structure emotions, placing similar emotions adjacently and opposing ones diagonally. Although frequently used to interpret deep learning representations, these models are rarely directly incorporated into the representation learning of language models, leaving their geometric validity unexplored. This paper proposes a method to induce circular emotion representations within language model embeddings via contrastive learning on a hypersphere. We show that while this circular alignment offers superior interpretability and robustness against dimensionality reduction, it underperforms compared to conventional designs in high-dimensional settings and fine-grained classification. Our findings elucidate the trade-offs involved in applying psychological circumplex models to deep learning architectures.", "AI": {"tldr": "本研究提出了一种在语言模型嵌入中通过超球体上的对比学习来诱导圆形情绪表示的方法，并探讨了这种方法在可解释性、鲁棒性以及高维和细粒度分类任务中的权衡。", "motivation": "虽然心理学中的情绪环形模型被广泛用于解释深度学习的表示，但它们很少被直接整合到语言模型的表示学习中，因此其几何有效性尚未得到探索。", "method": "使用超球体上的对比学习来诱导语言模型嵌入中的圆形情绪表示。", "result": "这种圆形对齐在可解释性和对抗维度降低方面表现优越，但在高维设置和细粒度分类任务中性能不如传统设计。", "conclusion": "将心理学中的情绪环形模型应用于深度学习架构存在权衡，圆形对齐提供了更好的可解释性和鲁棒性，但在某些情况下会牺牲性能。"}}
{"id": "2601.06484", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06484", "abs": "https://arxiv.org/abs/2601.06484", "authors": ["Yue Wang", "Lawrence Amadi", "Xiang Gao", "Yazheng Chen", "Yuanpeng Liu", "Ning Lu", "Xianfeng Gu"], "title": "Learning Domain Agnostic Latent Embeddings of 3D Faces for Zero-shot Animal Expression Transfer", "comment": "WACV 2026 Workshop LENS", "summary": "We present a zero-shot framework for transferring human facial expressions to 3D animal face meshes. Our method combines intrinsic geometric descriptors (HKS/WKS) with a mesh-agnostic latent embedding that disentangles facial identity and expression. The ID latent space captures species-independent facial structure, while the expression latent space encodes deformation patterns that generalize across humans and animals. Trained only with human expression pairs, the model learns the embeddings, decoupling, and recoupling of cross-identity expressions, enabling expression transfer without requiring animal expression data. To enforce geometric consistency, we employ Jacobian loss together with vertex-position and Laplacian losses. Experiments show that our approach achieves plausible cross-species expression transfer, effectively narrowing the geometric gap between human and animal facial shapes.", "AI": {"tldr": "该研究提出了一种零样本框架，用于将人类面部表情转移到三维动物面部网格上，通过解耦身份和表情的潜在嵌入来实现跨物种表情迁移。", "motivation": "研究的动机是实现跨物种的面部表情迁移，克服现有方法在缺乏目标物种表情数据时的局限性。", "method": "该方法结合了内在几何描述符（HKS/WKS）和一个网格无关的潜在嵌入，该嵌入解耦了面部身份和表情。身份潜在空间捕获物种独立的结构，表情潜在空间编码跨物种的变形模式。通过雅可比损失、顶点位置损失和拉普拉斯损失来保证几何一致性。", "result": "实验表明，该方法能够实现合理的跨物种表情迁移，有效缩小了人类和动物面部形状之间的几何差距。", "conclusion": "提出的零样本框架能够成功地将人类表情转移到三维动物面部网格上，证明了其在跨物种表情迁移方面的有效性，并且无需动物表情数据。"}}
{"id": "2601.06640", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.06640", "abs": "https://arxiv.org/abs/2601.06640", "authors": ["Genze Jiang", "Kezhi Wang", "Xiaomin Chen", "Yizhou Huang"], "title": "Agentic AI Empowered Intent-Based Networking for 6G", "comment": "Submitted for Possible Journal Publication", "summary": "The transition towards sixth-generation (6G) wireless networks necessitates autonomous orchestration mechanisms capable of translating high-level operational intents into executable network configurations. Existing approaches to Intent-Based Networking (IBN) rely upon either rule-based systems that struggle with linguistic variation or end-to-end neural models that lack interpretability and fail to enforce operational constraints. This paper presents a hierarchical multi-agent framework where Large Language Model (LLM) based agents autonomously decompose natural language intents, consult domain-specific specialists, and synthesise technically feasible network slice configurations through iterative reasoning-action (ReAct) cycles. The proposed architecture employs an orchestrator agent coordinating two specialist agents, i.e., Radio Access Network (RAN) and Core Network agents, via ReAct-style reasoning, grounded in structured network state representations. Experimental evaluation across diverse benchmark scenarios shows that the proposed system outperforms rule-based systems and direct LLM prompting, with architectural principles applicable to Open RAN (O-RAN) deployments. The results also demonstrate that whilst contemporary LLMs possess general telecommunications knowledge, network automation requires careful prompt engineering to encode context-dependent decision thresholds, advancing autonomous orchestration capabilities for next-generation wireless systems.", "AI": {"tldr": "本文提出了一种基于LLM的多代理框架，用于将自然语言意图自动转换为可行的网络切片配置，解决了现有IBN方法的局限性，并在O-RAN部署中显示出优于现有方法的性能。", "motivation": "现有基于意图的网络（IBN）方法存在不足，要么难以处理语言变异（基于规则的系统），要么缺乏可解释性且无法强制执行操作约束（端到端神经网络模型），这阻碍了向6G网络的自主编排。", "method": "提出了一个分层多代理框架，其中基于LLM的代理通过迭代推理-行动（ReAct）周期，自主分解自然语言意图，咨询领域专家（RAN和核心网代理），并合成技术上可行的网络切片配置。该框架使用一个协调代理和两个专业代理，并基于结构化的网络状态表示。", "result": "实验评估表明，所提出的系统在各种基准场景下优于基于规则的系统和直接LLM提示。结果还表明，虽然当前的LLM具有通用的电信知识，但网络自动化需要仔细的提示工程来编码上下文相关的决策阈值。", "conclusion": "该多代理LLM框架能够自主地将自然语言意图转换为网络切片配置，并且其架构原则适用于O-RAN部署，为下一代无线系统的自主编排能力提供了进步。"}}
{"id": "2601.06663", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06663", "abs": "https://arxiv.org/abs/2601.06663", "authors": ["Kaiwen Zhou", "Shreedhar Jangam", "Ashwin Nagarajan", "Tejas Polu", "Suhas Oruganti", "Chengzhi Liu", "Ching-Chen Kuo", "Yuting Zheng", "Sravana Narayanaraju", "Xin Eric Wang"], "title": "SafePro: Evaluating the Safety of Professional-Level AI Agents", "comment": null, "summary": "Large language model-based agents are rapidly evolving from simple conversational assistants into autonomous systems capable of performing complex, professional-level tasks in various domains. While these advancements promise significant productivity gains, they also introduce critical safety risks that remain under-explored. Existing safety evaluations primarily focus on simple, daily assistance tasks, failing to capture the intricate decision-making processes and potential consequences of misaligned behaviors in professional settings. To address this gap, we introduce \\textbf{SafePro}, a comprehensive benchmark designed to evaluate the safety alignment of AI agents performing professional activities. SafePro features a dataset of high-complexity tasks across diverse professional domains with safety risks, developed through a rigorous iterative creation and review process. Our evaluation of state-of-the-art AI models reveals significant safety vulnerabilities and uncovers new unsafe behaviors in professional contexts. We further show that these models exhibit both insufficient safety judgment and weak safety alignment when executing complex professional tasks. In addition, we investigate safety mitigation strategies for improving agent safety in these scenarios and observe encouraging improvements. Together, our findings highlight the urgent need for robust safety mechanisms tailored to the next generation of professional AI agents.", "AI": {"tldr": "该研究提出了 SafePro 基准测试，用于评估大型语言模型（LLM）在执行专业任务时的安全对齐能力，发现现有模型在复杂专业场景下存在显著的安全漏洞和行为不当。", "motivation": "现有对AI代理的安全评估主要集中在简单的日常任务上，未能充分捕捉在专业领域中复杂决策和潜在的错误行为所带来的安全风险，因此需要一个更全面的评估基准。", "method": "研究人员开发了一个名为 SafePro 的综合基准测试，包含大量高复杂度、跨领域且具有安全风险的专业任务。他们使用该基准测试了当前最先进的AI模型，并探究了安全缓解策略。", "result": "评估结果显示，现有AI模型在执行复杂专业任务时存在显著的安全漏洞，表现出不足的安全判断能力和薄弱的安全对齐。研究还发现了一些在专业环境中新出现的危险行为。", "conclusion": "该研究强调了为下一代专业AI代理开发定制化、稳健的安全机制的紧迫性。SafePro 基准测试为未来AI安全研究提供了重要工具，并为改进AI代理在专业领域的安全性提供了方向。"}}
{"id": "2601.06496", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06496", "abs": "https://arxiv.org/abs/2601.06496", "authors": ["Hao Tang", "Ting Huang", "Zeyu Zhang"], "title": "3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence", "comment": null, "summary": "Spatial intelligence refers to the ability to perceive, reason about, and describe objects and their relationships within three-dimensional environments, forming a foundation for embodied perception and scene understanding. 3D captioning aims to describe 3D scenes in natural language; however, it remains challenging due to the sparsity and irregularity of point clouds and, more critically, the weak grounding and limited out-of-distribution (OOD) generalization of existing captioners across drastically different environments, including indoor and outdoor 3D scenes. To address this challenge, we propose 3D CoCa v2, a generalizable 3D captioning framework that unifies contrastive vision-language learning with 3D caption generation and further improves robustness via test-time search (TTS) without updating the captioner parameters. 3D CoCa v2 builds on a frozen CLIP-based semantic prior, a spatially-aware 3D scene encoder for geometry, and a multimodal decoder jointly optimized with contrastive and captioning objectives, avoiding external detectors or handcrafted proposals. At inference, TTS produces diverse caption candidates and performs reward-guided selection using a compact scene summary. Experiments show improvements over 3D CoCa of +1.50 CIDEr@0.5IoU on ScanRefer and +1.61 CIDEr@0.5IoU on Nr3D, and +3.8 CIDEr@0.25 in zero-shot OOD evaluation on TOD3Cap. Code will be released at https://github.com/AIGeeksGroup/3DCoCav2.", "AI": {"tldr": "本文提出了3D CoCa v2，一个通用的3D场景描述框架，通过结合对比学习和测试时搜索来提高泛化能力和鲁棒性，并在多个数据集上取得了显著的性能提升。", "motivation": "现有3D场景描述方法在处理点云稀疏性和不规则性方面存在挑战，并且在跨不同环境（室内/室外）时泛化能力较弱。", "method": "提出3D CoCa v2框架，结合了冻结的CLIP语义先验、空间感知的3D场景编码器和多模态解码器，并采用对比学习和描述生成进行联合优化。在推理时，通过测试时搜索（TTS）生成候选描述并进行选择。", "result": "在ScanRefer和Nr3D数据集上，3D CoCa v2的CIDEr@0.5IoU得分分别比3D CoCa提高了1.50和1.61。在TOD3Cap数据集的零样本OOD评估中，CIDEr@0.25得分提高了3.8。", "conclusion": "3D CoCa v2是一个通用且鲁棒的3D场景描述框架，通过利用对比学习和测试时搜索，有效克服了现有方法的局限性，并在泛化能力和性能上取得了显著提升。"}}
{"id": "2601.06564", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06564", "abs": "https://arxiv.org/abs/2601.06564", "authors": ["Rajpreet Singh", "Novak Boškov", "Lawrence Drabeck", "Aditya Gudal", "Manzoor A. Khan"], "title": "CSR-RAG: An Efficient Retrieval System for Text-to-SQL on the Enterprise Scale", "comment": null, "summary": "Natural language to SQL translation (Text-to-SQL) is one of the long-standing problems that has recently benefited from advances in Large Language Models (LLMs). While most academic Text-to-SQL benchmarks request schema description as a part of natural language input, enterprise-scale applications often require table retrieval before SQL query generation. To address this need, we propose a novel hybrid Retrieval Augmented Generation (RAG) system consisting of contextual, structural, and relational retrieval (CSR-RAG) to achieve computationally efficient yet sufficiently accurate retrieval for enterprise-scale databases. Through extensive enterprise benchmarks, we demonstrate that CSR-RAG achieves up to 40% precision and over 80% recall while incurring a negligible average query generation latency of only 30ms on commodity data center hardware, which makes it appropriate for modern LLM-based enterprise-scale systems.", "AI": {"tldr": "本文提出了一种名为CSR-RAG的混合检索增强生成系统，用于在企业级数据库中进行高效的表检索和Text-to-SQL查询生成，在精度和召回率上表现优异，且延迟极低。", "motivation": "现有的Text-to-SQL研究大多将表结构信息作为输入，而实际企业应用中需要先进行表检索。因此，研究动机是开发一种适用于企业级规模数据库、计算高效且精度高的表检索方法，以支持LLM驱动的Text-to-SQL系统。", "method": "提出了一种混合检索增强生成（RAG）系统，称为CSR-RAG。该系统结合了上下文、结构和关系三种检索方式，旨在实现对企业级数据库的有效检索。", "result": "在企业级基准测试中，CSR-RAG实现了高达40%的精度和超过80%的召回率。在商品数据中心硬件上，平均查询生成延迟仅为30毫秒，非常低。", "conclusion": "CSR-RAG是一种计算高效且准确的检索系统，适用于企业级数据库的表检索和Text-to-SQL应用，其性能使其能够很好地集成到现代LLM驱动的企业级系统中。"}}
{"id": "2601.06580", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06580", "abs": "https://arxiv.org/abs/2601.06580", "authors": ["Linus Tze En Foo", "Weihan Angela Ng", "Wenkai Li", "Lynnette Hui Xian Ng"], "title": "Stylistic Evolution and LLM Neutrality in Singlish Language", "comment": null, "summary": "Singlish is a creole rooted in Singapore's multilingual environment and continues to evolve alongside social and technological change. This study investigates the evolution of Singlish over a decade of informal digital text messages. We propose a stylistic similarity framework that compares lexico-structural, pragmatic, psycholinguistic, and encoder-derived features across years to quantify temporal variation. Our analysis reveals notable diachronic changes in tone, expressivity and sentence construction over the years. Conversely, while some LLMs were able to generate superficially realistic Singlish messages, they do not produce temporally neutral outputs, and residual temporal signals remain detectable despite prompting and fine-tuning. Our findings highlight the dynamic evolution of Singlish, as well as the capabilities and limitations of current LLMs in modeling sociolectal and temporal variations in the colloquial language.", "AI": {"tldr": "本研究通过分析十年来社交媒体上的新加坡英语（Singlish）短信，量化其在词汇结构、语用、心理语言学和编码器特征上的随时间演变。研究发现Singlish在语气、表现力和句子结构上发生了显著变化，并且现有的大型语言模型（LLM）在生成具有时间中立性的Singlish方面存在局限性。", "motivation": "了解新加坡英语（Singlish）这种克里奥尔语在社会和技术变革下的演变，以及评估当前大型语言模型（LLM）在模拟这种演变和时态变化方面的能力。", "method": "采用一种风格相似性框架，通过比较过去十年非正式数字文本信息中的词汇结构、语用、心理语言学以及编码器派生的特征，来量化Singlish的时间变化。同时，测试了现有LLM在生成Singlish时保持时间中立性的能力。", "result": "研究揭示了Singlish在语气、表现力和句子结构方面在过去十年中发生了显著的历时性变化。此外，尽管经过提示和微调，LLM生成的Singlish仍然存在可检测的残留时间信号，其输出并非时间中立的。", "conclusion": "Singlish是一种动态演变的语言，其演变体现在语气、表现力和句子结构等方面。当前的大型语言模型在模拟Singlish的时态和社会方言变异方面存在能力和局限性。"}}
{"id": "2601.06586", "categories": ["cs.CL", "cs.LG", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.06586", "abs": "https://arxiv.org/abs/2601.06586", "authors": ["Hongyi Zhou", "Jin Zhu", "Ying Yang", "Chengchun Shi"], "title": "Detecting LLM-Generated Text with Performance Guarantees", "comment": null, "summary": "Large language models (LLMs) such as GPT, Claude, Gemini, and Grok have been deeply integrated into our daily life. They now support a wide range of tasks -- from dialogue and email drafting to assisting with teaching and coding, serving as search engines, and much more. However, their ability to produce highly human-like text raises serious concerns, including the spread of fake news, the generation of misleading governmental reports, and academic misconduct. To address this practical problem, we train a classifier to determine whether a piece of text is authored by an LLM or a human. Our detector is deployed on an online CPU-based platform https://huggingface.co/spaces/stats-powered-ai/StatDetectLLM, and contains three novelties over existing detectors: (i) it does not rely on auxiliary information, such as watermarks or knowledge of the specific LLM used to generate the text; (ii) it more effectively distinguishes between human- and LLM-authored text; and (iii) it enables statistical inference, which is largely absent in the current literature. Empirically, our classifier achieves higher classification accuracy compared to existing detectors, while maintaining type-I error control, high statistical power, and computational efficiency.", "AI": {"tldr": "本文提出了一种不依赖辅助信息的新型大语言模型（LLM）生成文本检测器，该检测器能更有效地识别LLM生成的文本，并支持统计推断，在准确性、功效和效率方面优于现有方法。", "motivation": "大型语言模型（LLM）生成的类人文本引发了对虚假信息传播、学术不端等问题的担忧，需要有效的检测方法来区分人类和LLM的创作。", "method": "训练一个分类器来区分LLM和人类撰写的文本，该分类器不依赖水印或特定LLM信息，并实现了统计推断。", "result": "提出的分类器在分类准确性上优于现有检测器，同时控制了I类错误，保持了高统计功效和计算效率。", "conclusion": "该研究成功开发了一种高效、准确且通用的LLM生成文本检测器，为解决LLM带来的实际问题提供了一种解决方案。"}}
{"id": "2601.06518", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06518", "abs": "https://arxiv.org/abs/2601.06518", "authors": ["Yash Thesia", "Meera Suthar"], "title": "Bridging Robustness and Efficiency: Real-Time Low-Light Enhancement via Attention U-Net GAN", "comment": "7 pages, 2 figures, 3 tables", "summary": "Recent advancements in Low-Light Image Enhancement (LLIE) have focused heavily on Diffusion Probabilistic Models, which achieve high perceptual quality but suffer from significant computational latency (often exceeding 2-4 seconds per image). Conversely, traditional CNN-based baselines offer real-time inference but struggle with \"over-smoothing,\" failing to recover fine structural details in extreme low-light conditions. This creates a practical gap in the literature: the lack of a model that provides generative-level texture recovery at edge-deployable speeds. In this paper, we address this trade-off by proposing a hybrid Attention U-Net GAN. We demonstrate that the heavy iterative sampling of diffusion models is not strictly necessary for texture recovery. Instead, by integrating Attention Gates into a lightweight U-Net backbone and training within a conditional adversarial framework, we can approximate the high-frequency fidelity of generative models in a single forward pass. Extensive experiments on the SID dataset show that our method achieves a best-in-class LPIPS score of 0.112 among efficient models, significantly outperforming efficient baselines (SID, EnlightenGAN) while maintaining an inference latency of 0.06s. This represents a 40x speedup over latent diffusion models, making our approach suitable for near real-time applications.", "AI": {"tldr": "提出了一种混合注意力U-Net GAN模型，可在单次前向传播中实现高质量低光图像增强，速度比扩散模型快40倍，适合实时应用。", "motivation": "现有低光图像增强方法存在性能与速度的权衡：扩散模型生成质量高但速度慢，CNN模型速度快但容易过度平滑，缺乏同时具备生成级纹理恢复能力和边缘部署速度的模型。", "method": "采用混合注意力U-Net GAN模型，将注意力门集成到轻量级U-Net骨干网络中，并使用条件对抗框架进行训练，以在单次前向传播中实现高频细节恢复。", "result": "在SID数据集上，提出的方法取得了0.112的最佳LPIPS分数，显著优于其他高效基线模型（SID, EnlightenGAN），推理延迟仅为0.06秒。", "conclusion": "该混合注意力U-Net GAN模型成功弥合了生成模型和实时模型的差距，能够在极快的速度下实现接近扩散模型的纹理恢复效果，适用于近实时应用。"}}
{"id": "2601.06747", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06747", "abs": "https://arxiv.org/abs/2601.06747", "authors": ["Glenn Matlin", "Akhil Theerthala", "Anant Gupta", "Anirudh JM", "Rayan Castilla", "Yi Mei Ng", "Sudheer Chava"], "title": "FinForge: Semi-Synthetic Financial Benchmark Generation", "comment": "AAAI 2026 Workshop on Agentic AI in Financial Services", "summary": "Evaluating Language Models (LMs) in specialized, high-stakes domains such as finance remains a significant challenge due to the scarcity of open, high-quality, and domain-specific datasets. Existing general-purpose benchmarks provide broad coverage but lack the depth and domain fidelity needed to assess LMs' capabilities for real-world financial reasoning, which requires both conceptual understanding and quantitative rigor. To address this gap, we introduce FinForge, a scalable, semi-synthetic pipeline for constructing finance-specific evaluation benchmarks through a hybrid of expert-guided data curation and controlled LM-based synthesis. FinForge combines manual and programmatic corpus construction from authoritative financial sources with structured question generation and validation using Gemini 2.5 Flash. To demonstrate the pipeline's efficacy, we produce FinForge-5k, a snapshot benchmark comprising over 5,000 human-validated question-answer pairs across 11 finance subdomains, derived from a curated corpus of 100,000 verified documents totaling 143M tokens. Evaluation of state-of-the-art open-source and closed-source models on FinForge-5k reveals significant differences in financial reasoning, with leading models achieving accuracy levels near 80%. These findings underscore the framework's utility for diagnosing current model limitations and guiding future improvements in financial domain competence. All code and data are available at https://github.com/gtfintechlab/FinForge.", "AI": {"tldr": "该研究提出了 FinForge，一个用于构建金融领域评估基准的半合成流水线，以解决现有通用基准在金融领域评估中的不足。研究人员利用此流水线创建了一个包含 5000 多个问答对的 FinForge-5k 基准，并评估了当前先进的模型，发现它们在金融推理方面存在显著差异。", "motivation": "现有通用语言模型评估基准在金融等高风险专业领域存在数据稀缺、缺乏领域特异性、深度和真实性不足的问题，难以有效评估模型在金融概念理解和量化推理方面的能力。", "method": "研究人员开发了一个名为 FinForge 的可扩展、半合成流水线，该流水线结合了专家指导的数据策展和受控的语言模型合成。它通过手动和程序化方式从权威金融来源构建语料库，并使用 Gemini 2.5 Flash 进行结构化问题生成和验证，从而创建金融领域特定的评估基准。", "result": "使用 FinForge 流水线构建的 FinForge-5k 基准包含超过 5000 个经过人工验证的问答对，覆盖 11 个金融子领域，数据源自 10 万份经过验证的文档。对 FinForge-5k 的评估显示，顶尖模型在金融推理方面的准确率接近 80%，但不同模型之间存在显著差异。", "conclusion": "FinForge 流水线能够有效地构建金融领域评估基准，有助于诊断当前语言模型在金融领域的能力限制，并为未来的模型改进提供方向。研究表明，尽管先进模型在金融推理方面取得了一定进展，但仍有提升空间。"}}
{"id": "2601.06599", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06599", "abs": "https://arxiv.org/abs/2601.06599", "authors": ["Shivam Adarsh", "Maria Maistro", "Christina Lioma"], "title": "How Context Shapes Truth: Geometric Transformations of Statement-level Truth Representations in LLMs", "comment": null, "summary": "Large Language Models (LLMs) often encode whether a statement is true as a vector in their residual stream activations. These vectors, also known as truth vectors, have been studied in prior work, however how they change when context is introduced remains unexplored. We study this question by measuring (1) the directional change ($θ$) between the truth vectors with and without context and (2) the relative magnitude of the truth vectors upon adding context. Across four LLMs and four datasets, we find that (1) truth vectors are roughly orthogonal in early layers, converge in middle layers, and may stabilize or continue increasing in later layers; (2) adding context generally increases the truth vector magnitude, i.e., the separation between true and false representations in the activation space is amplified; (3) larger models distinguish relevant from irrelevant context mainly through directional change ($θ$), while smaller models show this distinction through magnitude differences. We also find that context conflicting with parametric knowledge produces larger geometric changes than parametrically aligned context. To the best of our knowledge, this is the first work that provides a geometric characterization of how context transforms the truth vector in the activation space of LLMs.", "AI": {"tldr": "本研究首次从几何角度刻画了上下文如何改变大型语言模型（LLMs）中表示“真值”的向量，发现上下文通常会增加真值向量的幅度，且不同模型和上下文类型对向量变化的影响方式不同。", "motivation": "现有研究虽然关注了LLMs中的真值向量，但并未探索在引入上下文时这些向量如何变化，本研究旨在填补这一空白。", "method": "通过测量（1）有无上下文时真值向量的方向变化（$θ$）和（2）添加上下文后真值向量的相对幅度，在四个LLMs和四个数据集上进行实验。", "result": "研究发现：1）真值向量在早期层大致正交，在中期层收敛，在后期层趋于稳定或增大；2）添加上下文通常会增加真值向量的幅度，放大了真假表征在激活空间中的分离；3）更大的模型主要通过方向变化（$θ$）区分相关和不相关的上下文，而较小的模型则通过幅度差异来区分。此外，与参数知识冲突的上下文会产生比参数一致的上下文更大的几何变化。", "conclusion": "本研究首次对上下文如何改变LLMs激活空间中的真值向量进行了几何表征，揭示了上下文对真值表示的影响机制，并区分了不同模型大小和上下文类型的影响特点。"}}
{"id": "2601.06776", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06776", "abs": "https://arxiv.org/abs/2601.06776", "authors": ["Xufei Tian", "Wenli Du", "Shaoyi Yang", "Han Hu", "Hui Xin", "Shifeng Qu", "Ke Ye"], "title": "From Text to Simulation: A Multi-Agent LLM Workflow for Automated Chemical Process Design", "comment": null, "summary": "Process simulation is a critical cornerstone of chemical engineering design. Current automated chemical design methodologies focus mainly on various representations of process flow diagrams. However, transforming these diagrams into executable simulation flowsheets remains a time-consuming and labor-intensive endeavor, requiring extensive manual parameter configuration within simulation software. In this work, we propose a novel multi-agent workflow that leverages the semantic understanding capabilities of large language models(LLMs) and enables iterative interactions with chemical process simulation software, achieving end-to-end automated simulation from textual process specifications to computationally validated software configurations for design enhancement. Our approach integrates four specialized agents responsible for task understanding, topology generation, parameter configuration, and evaluation analysis, respectively, coupled with Enhanced Monte Carlo Tree Search to accurately interpret semantics and robustly generate configurations. Evaluated on Simona, a large-scale process description dataset, our method achieves a 31.1% improvement in the simulation convergence rate compared to state-of-the-art baselines and reduces the design time by 89. 0% compared to the expert manual design. This work demonstrates the potential of AI-assisted chemical process design, which bridges the gap between conceptual design and practical implementation. Our workflow is applicable to diverse process-oriented industries, including pharmaceuticals, petrochemicals, food processing, and manufacturing, offering a generalizable solution for automated process design.", "AI": {"tldr": "提出了一种新的多智能体工作流，利用大型语言模型（LLMs）实现从文本描述到可执行流程模拟的端到端自动化，显著提高了模拟收敛率并缩短了设计时间。", "motivation": "当前的自动化化学设计方法主要关注流程图表示，但将其转化为可执行的模拟流程图耗时耗力，需要大量手动参数配置。研究旨在解决这一痛点，实现从文本规格到计算验证的自动化。", "method": "采用一个包含四个专门智能体的多智能体工作流：任务理解、拓扑生成、参数配置和评估分析。结合增强型蒙特卡洛树搜索，利用LLMs的语义理解能力，实现迭代交互和鲁棒的配置生成。", "result": "在Simona数据集上评估，该方法比现有技术提高了31.1%的模拟收敛率，并将设计时间缩短了89.0%。", "conclusion": "AI辅助的化学过程设计能够有效弥合概念设计与实际实施之间的差距，该工作流具有广泛的适用性，可应用于制药、石化、食品加工和制造等多种流程导向型行业，为自动化过程设计提供了一个通用解决方案。"}}
{"id": "2601.06521", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06521", "abs": "https://arxiv.org/abs/2601.06521", "authors": ["Liang Chen", "Weichu Xie", "Yiyan Liang", "Hongfeng He", "Hans Zhao", "Zhibo Yang", "Zhiqi Huang", "Haoning Wu", "Haoyu Lu", "Y. charles", "Yiping Bao", "Yuantao Fan", "Guopeng Li", "Haiyang Shen", "Xuanzhong Chen", "Wendong Xu", "Shuzheng Si", "Zefan Cai", "Wenhao Chai", "Ziqi Huang", "Fangfu Liu", "Tianyu Liu", "Baobao Chang", "Xiaobo Hu", "Kaiyuan Chen", "Yixin Ren", "Yang Liu", "Yuan Gong", "Kuan Li"], "title": "BabyVision: Visual Reasoning Beyond Language", "comment": "26 pages, Homepage at https://unipat.ai/blog/BabyVision", "summary": "While humans develop core visual skills long before acquiring language, contemporary Multimodal LLMs (MLLMs) still rely heavily on linguistic priors to compensate for their fragile visual understanding. We uncovered a crucial fact: state-of-the-art MLLMs consistently fail on basic visual tasks that humans, even 3-year-olds, can solve effortlessly. To systematically investigate this gap, we introduce BabyVision, a benchmark designed to assess core visual abilities independent of linguistic knowledge for MLLMs. BabyVision spans a wide range of tasks, with 388 items divided into 22 subclasses across four key categories. Empirical results and human evaluation reveal that leading MLLMs perform significantly below human baselines. Gemini3-Pro-Preview scores 49.7, lagging behind 6-year-old humans and falling well behind the average adult score of 94.1. These results show despite excelling in knowledge-heavy evaluations, current MLLMs still lack fundamental visual primitives. Progress in BabyVision represents a step toward human-level visual perception and reasoning capabilities. We also explore solving visual reasoning with generation models by proposing BabyVision-Gen and automatic evaluation toolkit. Our code and benchmark data are released at https://github.com/UniPat-AI/BabyVision for reproduction.", "AI": {"tldr": "当前的多模态大型语言模型（MLLMs）在基础视觉任务上表现不佳，远不如人类儿童，这表明它们缺乏基础的视觉感知能力。研究者提出了BabyVision基准测试来独立评估MLLMs的视觉能力，并展示了现有模型与人类的巨大差距。", "motivation": "当前的MLLMs在视觉理解方面存在“脆弱性”，过度依赖语言知识进行补偿，即使是3岁儿童都能轻易解决的基础视觉任务，MLLMs也常常失败。这种差距促使研究者去系统地研究和量化这种不足。", "method": "提出了BabyVision基准测试，包含388个项目，分布在22个子类和4个主要类别中，旨在独立于语言知识来评估MLLMs的核心视觉能力。通过对领先的MLLMs进行测试，并与人类基线进行比较，包括成人和儿童的得分。此外，还探索了使用生成模型解决视觉推理问题，并提出了BabyVision-Gen和自动评估工具包。", "result": "领先的MLLMs在BabyVision基准测试上的表现显著低于人类基线。例如，Gemini3-Pro-Preview得分为49.7，低于6岁儿童，并且远低于平均成人得分94.1。这表明尽管MLLMs在知识密集型评估中表现出色，但在基础视觉能力方面仍有欠缺。", "conclusion": "现有的MLLMs缺乏基础的视觉原语（visual primitives），尽管它们在语言和知识密集型任务上表现优异。BabyVision基准测试揭示了当前MLLMs在核心视觉能力上的不足，并在解决视觉推理问题方面提供了新的方向（BabyVision-Gen）。在BabyVision上的进步是迈向实现人类水平视觉感知和推理能力的重要一步。"}}
{"id": "2601.06794", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06794", "abs": "https://arxiv.org/abs/2601.06794", "authors": ["Zhicong Li", "Lingjie Jiang", "Yulan Hu", "Xingchen Zeng", "Yixia Li", "Xiangwen Zhang", "Guanhua Chen", "Zheng Pan", "Xin Li", "Yong Liu"], "title": "No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning", "comment": null, "summary": "Critique-guided reinforcement learning (RL) has emerged as a powerful paradigm for training LLM agents by augmenting sparse outcome rewards with natural-language feedback. However, current methods often rely on static or offline critic models, which fail to adapt as the policy evolves. In on-policy RL, the agent's error patterns shift over time, causing stationary critics to become stale and providing feedback of diminishing utility. To address this, we introduce ECHO (Evolving Critic for Hindsight-Guided Optimization)}, a framework that jointly optimizes the policy and critic through a synchronized co-evolutionary loop. ECHO utilizes a cascaded rollout mechanism where the critic generates multiple diagnoses for an initial trajectory, followed by policy refinement to enable group-structured advantage estimation. We address the challenge of learning plateaus via a saturation-aware gain shaping objective, which rewards the critic for inducing incremental improvements in high-performing trajectories. By employing dual-track GRPO updates, ECHO ensures the critic's feedback stays synchronized with the evolving policy. Experimental results show that ECHO yields more stable training and higher long-horizon task success across open-world environments.", "AI": {"tldr": "ECHO是一个新框架，通过同步的协同演化循环，联合优化策略和评论家，以解决现有评论家模型静态或离线的问题，从而实现更稳定的训练和更高的长周期任务成功率。", "motivation": "现有的基于评论家的强化学习方法依赖于静态或离线的评论家模型，这些模型无法适应策略的演变。随着策略的更新，代理的错误模式会发生变化，导致固定评论家变得过时，其提供的反馈效用降低。", "method": "ECHO框架通过同步的协同演化循环联合优化策略和评论家。它使用级联回放机制，评论家对初始轨迹生成多个诊断，然后策略进行精炼，实现分组结构的优势估计。为解决学习平台问题，ECHO引入了饱和感知增益整形目标，并采用双轨道GRPO更新来确保评论家的反馈与策略保持同步。", "result": "实验结果表明，ECHO在开放世界环境中实现了更稳定的训练和更高的长周期任务成功率。", "conclusion": "ECHO框架通过引入动态演化的评论家，克服了静态评论家模型的局限性，显著提升了LLM代理在长周期任务中的训练稳定性和性能。"}}
{"id": "2601.06525", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06525", "abs": "https://arxiv.org/abs/2601.06525", "authors": ["Yuanting Gao", "Shuo Cao", "Xiaohui Li", "Yuandong Pu", "Yihao Liu", "Kai Zhang"], "title": "Toward Generalizable Deblurring: Leveraging Massive Blur Priors with Linear Attention for Real-World Scenarios", "comment": "19 pages, 14 figures, 6 tables", "summary": "Image deblurring has advanced rapidly with deep learning, yet most methods exhibit poor generalization beyond their training datasets, with performance dropping significantly in real-world scenarios. Our analysis shows this limitation stems from two factors: datasets face an inherent trade-off between realism and coverage of diverse blur patterns, and algorithmic designs remain restrictive, as pixel-wise losses drive models toward local detail recovery while overlooking structural and semantic consistency, whereas diffusion-based approaches, though perceptually strong, still fail to generalize when trained on narrow datasets with simplistic strategies. Through systematic investigation, we identify blur pattern diversity as the decisive factor for robust generalization and propose Blur Pattern Pretraining (BPP), which acquires blur priors from simulation datasets and transfers them through joint fine-tuning on real data. We further introduce Motion and Semantic Guidance (MoSeG) to strengthen blur priors under severe degradation, and integrate it into GLOWDeblur, a Generalizable reaL-wOrld lightWeight Deblur model that combines convolution-based pre-reconstruction & domain alignment module with a lightweight diffusion backbone. Extensive experiments on six widely-used benchmarks and two real-world datasets validate our approach, confirming the importance of blur priors for robust generalization and demonstrating that the lightweight design of GLOWDeblur ensures practicality in real-world applications. The project page is available at https://vegdog007.github.io/GLOWDeblur_Website/.", "AI": {"tldr": "该研究提出了一种名为GLOWDeblur的轻量级图像去模糊模型，通过模糊模式预训练（BPP）和运动与语义引导（MoSeG）来提高模型的泛化能力，解决了现有深度学习去模糊方法在真实世界场景中表现不佳的问题。", "motivation": "现有深度学习去模糊方法在真实世界场景泛化能力差，性能显著下降。这源于训练数据集在真实性和模糊模式多样性上的权衡，以及算法设计中像素级损失过度关注细节而忽视结构和语义一致性，扩散模型在狭窄数据集上训练效果不佳。", "method": "提出模糊模式预训练（BPP）方法，从模拟数据集中学习模糊先验，并通过在真实数据上联合微调来迁移这些先验。引入运动与语义引导（MoSeG）来增强严重退化下的模糊先验。将BPP和MoSeG集成到GLOWDeblur模型中，该模型结合了基于卷积的预重建和域对齐模块以及轻量级扩散骨干。", "result": "在六个基准数据集和两个真实世界数据集上进行了大量实验。结果表明，模糊先验对于鲁棒泛化至关重要，并且GLOWDeblur的轻量级设计保证了其在实际应用中的实用性。", "conclusion": "模糊模式多样性是实现鲁棒泛化的决定性因素。通过BPP和MoSeG，GLOWDeblur能够有效地学习和迁移模糊先验，显著提高了图像去模糊的泛化能力，同时保持了轻量级的特性，适合实际应用。"}}
{"id": "2601.06600", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06600", "abs": "https://arxiv.org/abs/2601.06600", "authors": ["Jen-tse Huang", "Chang Chen", "Shiyang Lai", "Wenxuan Wang", "Michelle R. Kaufman", "Mark Dredze"], "title": "Probing Multimodal Large Language Models on Cognitive Biases in Chinese Short-Video Misinformation", "comment": "9 pages, 6 figures, 9 tables", "summary": "Short-video platforms have become major channels for misinformation, where deceptive claims frequently leverage visual experiments and social cues. While Multimodal Large Language Models (MLLMs) have demonstrated impressive reasoning capabilities, their robustness against misinformation entangled with cognitive biases remains under-explored. In this paper, we introduce a comprehensive evaluation framework using a high-quality, manually annotated dataset of 200 short videos spanning four health domains. This dataset provides fine-grained annotations for three deceptive patterns, experimental errors, logical fallacies, and fabricated claims, each verified by evidence such as national standards and academic literature. We evaluate eight frontier MLLMs across five modality settings. Experimental results demonstrate that Gemini-2.5-Pro achieves the highest performance in the multimodal setting with a belief score of 71.5/100, while o3 performs the worst at 35.2. Furthermore, we investigate social cues that induce false beliefs in videos and find that models are susceptible to biases like authoritative channel IDs.", "AI": {"tldr": "该研究提出了一个包含200个短视频的健康领域信息评估框架，评估了八种前沿多模态大语言模型（MLLMs）在识别包含欺骗性模式（实验错误、逻辑谬误、虚假声明）和利用社会线索（如权威频道ID）的虚假信息方面的鲁棒性，并发现Gemini-2.5-Pro表现最佳。", "motivation": "现有研究对MLLMs在应对与认知偏见交织的信息的鲁棒性研究不足，而短视频平台是虚假信息传播的重要渠道，经常利用视觉实验和社会线索。", "method": "构建了一个包含200个短视频的高质量、手动标注数据集，涵盖四个健康领域。数据集提供了三种欺骗模式（实验错误、逻辑谬误、虚假声明）的细粒度标注，并引用了国家标准和学术文献作为证据。评估了八种前沿MLLMs在五种模态设置下的表现。", "result": "Gemini-2.5-Pro在多模态设置下表现最佳，得分为71.5/100，而o3表现最差，得分为35.2。研究还发现模型容易受到权威频道ID等社会线索引起的偏见影响。", "conclusion": "MLLMs在识别短视频中的虚假信息方面仍存在挑战，特别是当信息与认知偏见相结合时。模型容易受到社会线索（如频道ID）的影响，这表明需要进一步改进模型以增强其鲁棒性。"}}
{"id": "2601.06795", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06795", "abs": "https://arxiv.org/abs/2601.06795", "authors": ["Zhengqing Yan", "Xinyang Liu", "Yi Zhang", "Fan Guo", "Yao Liu", "Junchen Wan", "Kang Song"], "title": "GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning", "comment": null, "summary": "Automated Theorem Proving (ATP) represents a fundamental challenge in Artificial Intelligence (AI), requiring the construction of machine-verifiable proofs in formal languages such as Lean to evaluate AI reasoning capabilities. Reinforcement learning (RL), particularly the high-performance Group Relative Policy Optimization (GRPO) algorithm, has emerged as a mainstream approach for this task. However, in ATP scenarios, GRPO faces two critical issues: when composite rewards are used, its relative advantage estimation may conflict with the binary feedback from the formal verifier; meanwhile, its static sampling strategy may discard entire batches of data if no valid proof is found, resulting in zero contribution to model updates and significant data waste. To address these limitations, we propose Group Dual-dynamic and Equal-right-advantage Policy Optimization (GDEPO), a method incorporating three core mechanisms: 1) dynamic additional sampling, which resamples invalid batches until a valid proof is discovered; 2) equal-right advantage, decoupling the sign of the advantage function (based on correctness) from its magnitude (modulated by auxiliary rewards) to ensure stable and correct policy updates; and 3) dynamic additional iterations, applying extra gradient steps to initially failed but eventually successful samples to accelerate learning on challenging cases. Experiments conducted on three datasets of varying difficulty (MinF2F-test, MathOlympiadBench, PutnamBench) confirm the effectiveness of GDEPO, while ablation studies validate the necessity of its synergistic components. The proposed method enhances data utilization and optimization efficiency, offering a novel training paradigm for ATP.", "AI": {"tldr": "本文提出了一种名为GDEPO的新型强化学习算法，用于解决自动化定理证明（ATP）中的奖励冲突和数据浪费问题。GDEPO通过动态重采样、等权优势函数和动态额外迭代等机制，提高了数据利用率和优化效率，为ATP提供了新的训练范式。", "motivation": "现有的GRPO算法在ATP任务中存在两个主要问题：一是复合奖励可能与形式验证器的二元反馈冲突，导致优势函数估计不准确；二是静态采样策略可能导致在未找到有效证明时丢弃整个数据批次，造成数据浪费和学习效率低下。", "method": "提出Group Dual-dynamic and Equal-right-advantage Policy Optimization (GDEPO)算法，包含三个核心机制：1) 动态额外采样：对未产生有效证明的数据批次进行重采样，直至发现有效证明；2) 等权优势函数：解耦优势函数的符号（基于正确性）与幅度（由辅助奖励调节），确保策略更新的稳定性和准确性；3) 动态额外迭代：对初始失败但最终成功的样本应用额外的梯度更新步骤，加速对难题的学习。", "result": "在MinF2F-test、MathOlympiadBench和PutnamBench三个不同难度的ATP数据集上进行的实验表明，GDEPO有效解决了GRPO的局限性。消融研究也验证了GDEPO各组成部分的协同有效性。", "conclusion": "GDEPO算法通过改进采样策略和优势函数设计，显著提升了ATP任务中数据利用率和优化效率，是一种有效的新型训练范式。"}}
{"id": "2601.06801", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06801", "abs": "https://arxiv.org/abs/2601.06801", "authors": ["Shujian Gao", "Yuan Wang", "Jiangtao Yan", "Zuxuan Wu", "Yu-Gang Jiang"], "title": "Thinking with Deltas: Incentivizing Reinforcement Learning via Differential Visual Reasoning Policy", "comment": "24 pages, 10 tables, 4 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced reasoning capabilities in Large Language Models. However, adapting RLVR to multimodal domains suffers from a critical \\textit{perception-reasoning decoupling}. Existing paradigms, driven by text-centric outcome rewards, reasoning in language medium, inadvertently encourage models to bypass visual perception. We empirically validate this through blind experiments: state-of-the-art policies maintain or surprisingly improve performance even when visual inputs are entirely removed. This reveals that these models degenerate into \\textit{blind reasoners}, exploiting linguistic priors to generate plausible answers instead of attending to visual evidence. In response, we propose \\textbf{Thinking with Deltas}, a framework driven by a \\textbf{Differential Visual Reasoning Policy (DVRP)}. DVRP introduces intrinsic supervision via visual triplets, comprising original, masked, and perturbed inputs. It optimizes the model to maximize reasoning divergence from masked inputs (enforcing \\textit{visual sensitivity}) while minimizing divergence from perturbed inputs (ensuring \\textit{visual robustness}). By aligning reasoning variations strictly with the \\textit{Delta} of visual information, DVRP inherently bolsters visual understanding capabilities and significantly outperforms state-of-the-art methods on both general and medical benchmarks, without requiring external annotations or auxiliary tools.", "AI": {"tldr": "提出了一种名为“Thinking with Deltas”的新框架，使用差分视觉推理策略（DVRP）来解决多模态强化学习中的感知-推理脱钩问题，通过对视觉信息的修改来训练模型，使其对视觉输入更加敏感和鲁棒。", "motivation": "现有的多模态强化学习方法存在感知-推理脱顾问题，即模型倾向于依赖语言线索而非视觉信息进行推理，即使在移除视觉输入后性能也不会下降。", "method": "提出差分视觉推理策略（DVRP），该策略通过使用原始、掩码和扰动三种形式的视觉输入（视觉三元组）来引入内在监督。DVRP 旨在最大化模型在处理掩码输入时的推理差异（增强视觉敏感性），同时最小化处理扰动输入时的推理差异（确保视觉鲁棒性）。", "result": "DVRP 框架通过使推理变化与视觉信息的变化严格对齐，显著提高了模型的视觉理解能力。在通用和医学领域的基准测试中，DVRP 的性能显著优于现有最先进的方法。", "conclusion": "Thinking with Deltas 框架及其差分视觉推理策略（DVRP）能够有效解决多模态强化学习中的感知-推理脱钩问题，使模型能够更好地利用视觉信息进行推理，并在多个基准测试中取得了优越的性能，且无需额外的标注或工具。"}}
{"id": "2601.06537", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06537", "abs": "https://arxiv.org/abs/2601.06537", "authors": ["Wiktor Mucha", "Michael Wray", "Martin Kampel"], "title": "Towards Egocentric 3D Hand Pose Estimation in Unseen Domains", "comment": "Accepted at WACV 2026", "summary": "We present V-HPOT, a novel approach for improving the cross-domain performance of 3D hand pose estimation from egocentric images across diverse, unseen domains. State-of-the-art methods demonstrate strong performance when trained and tested within the same domain. However, they struggle to generalise to new environments due to limited training data and depth perception -- overfitting to specific camera intrinsics. Our method addresses this by estimating keypoint z-coordinates in a virtual camera space, normalised by focal length and image size, enabling camera-agnostic depth prediction. We further leverage this invariance to camera intrinsics to propose a self-supervised test-time optimisation strategy that refines the model's depth perception during inference. This is achieved by applying a 3D consistency loss between predicted and in-space scale-transformed hand poses, allowing the model to adapt to target domain characteristics without requiring ground truth annotations. V-HPOT significantly improves 3D hand pose estimation performance in cross-domain scenarios, achieving a 71% reduction in mean pose error on the H2O dataset and a 41% reduction on the AssemblyHands dataset. Compared to state-of-the-art methods, V-HPOT outperforms all single-stage approaches across all datasets and competes closely with two-stage methods, despite needing approximately x3.5 to x14 less data.", "AI": {"tldr": "V-HPOT 提出了一种新的 3D 手部姿态估计方法，通过在虚拟相机空间中进行深度预测，并结合自监督的测试时优化策略，显著提高了跨域泛化能力，尤其是在数据量有限的情况下。", "motivation": "现有 3D 手部姿态估计方法在同一域内表现良好，但在跨域（新环境）时泛化能力差，原因在于训练数据不足以及对特定相机内参的过拟合，导致深度感知受限。", "method": "1.  将关键点的 z 坐标在归一化到以焦距和图像尺寸为基础的虚拟相机空间进行估计，实现相机无关的深度预测。2.  利用这种相机内参不变性，提出一种自监督的测试时优化策略，通过预测姿态与空间尺度变换后姿态之间的 3D 一致性损失，在推理时无需真实标注即可自适应目标域的深度感知。", "result": "V-HPOT 在跨域场景下显著提升了 3D 手部姿态估计性能，在 H2O 数据集上平均姿态误差降低 71%，在 AssemblyHands 数据集上降低 41%。与现有最优方法相比，V-HPOT 在所有数据集上均优于所有单阶段方法，并接近双阶段方法的性能，而所需数据量却少 3.5 到 14 倍。", "conclusion": "V-HPOT 通过相机无关的深度预测和自监督测试时优化，有效地解决了 3D 手部姿态估计的跨域泛化问题，尤其在数据稀疏的情况下，展现出优越的性能和效率。"}}
{"id": "2601.06603", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06603", "abs": "https://arxiv.org/abs/2601.06603", "authors": ["Mohamed Sharafath", "Aravindh Annamalai", "Ganesh Murugan", "Aravindakumar Venugopalan"], "title": "N2N-GQA: Noise-to-Narrative for Graph-Based Table-Text Question Answering Using LLMs", "comment": "Accepted at an AAAI 2026 Workshop", "summary": "Multi-hop question answering over hybrid table-text data requires retrieving and reasoning across multiple evidence pieces from large corpora, but standard Retrieval-Augmented Generation (RAG) pipelines process documents as flat ranked lists, causing retrieval noise to obscure reasoning chains. We introduce N2N-GQA. To our knowledge, it is the first zeroshot framework for open-domain hybrid table-text QA that constructs dynamic evidence graphs from noisy retrieval outputs. Our key insight is that multi-hop reasoning requires understanding relationships between evidence pieces: by modeling documents as graph nodes with semantic relationships as edges, we identify bridge documents connecting reasoning steps, a capability absent in list-based retrieval. On OTT-QA, graph-based evidence curation provides a 19.9-point EM improvement over strong baselines, demonstrating that organizing retrieval results as structured graphs is critical for multihop reasoning. N2N-GQA achieves 48.80 EM, matching finetuned retrieval models (CORE: 49.0 EM) and approaching heavily optimized systems (COS: 56.9 EM) without any task specific training. This establishes graph-structured evidence organization as essential for scalable, zero-shot multi-hop QA systems and demonstrates that simple, interpretable graph construction can rival sophisticated fine-tuned approaches.", "AI": {"tldr": "本文提出了N2N-GQA，一个用于开放域混合表格-文本问答的零样本框架，通过将检索到的文档构建成动态证据图来解决标准RAG管道中因检索噪声导致的多跳推理困难问题。该方法在OTT-QA数据集上取得了显著的EM分数提升，证明了图结构证据组织对多跳推理的重要性。", "motivation": "标准RAG管道将文档视为平坦的排序列表，这会导致检索噪声干扰多跳推理过程。多跳问答需要跨多个证据片段进行检索和推理，而现有的方法难以有效处理这种复杂性。", "method": "提出N2N-GQA框架，将检索到的文档表示为图的节点，并将它们之间的语义关系表示为图的边。通过构建动态证据图，识别连接推理步骤的桥接文档，从而克服了列表式检索的局限性。", "result": "在OTT-QA数据集上，基于图的证据策划比强基线模型提高了19.9个点的EM分数。N2N-GQA在零样本设置下达到了48.80的EM分数，性能与微调检索模型相当，并接近高度优化的系统。", "conclusion": "将检索结果组织成结构化图对于多跳推理至关重要。N2N-GQA证明了图结构证据组织对于可扩展的零样本多跳QA系统是必不可少的，并且简单的、可解释的图构建方法可以与复杂的微调方法相媲美。"}}
{"id": "2601.06550", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06550", "abs": "https://arxiv.org/abs/2601.06550", "authors": ["Pan Liao", "Feng Yang", "Di Wu", "Jinwen Yu", "Yuhua Zhu", "Wenhui Zhao"], "title": "LLMTrack: Semantic Multi-Object Tracking with Multi-modal Large Language Models", "comment": null, "summary": "Traditional Multi-Object Tracking (MOT) systems have achieved remarkable precision in localization and association, effectively answering \\textit{where} and \\textit{who}. However, they often function as autistic observers, capable of tracing geometric paths but blind to the semantic \\textit{what} and \\textit{why} behind object behaviors. To bridge the gap between geometric perception and cognitive reasoning, we propose \\textbf{LLMTrack}, a novel end-to-end framework for Semantic Multi-Object Tracking (SMOT). We adopt a bionic design philosophy that decouples strong localization from deep understanding, utilizing Grounding DINO as the eyes and the LLaVA-OneVision multimodal large model as the brain. We introduce a Spatio-Temporal Fusion Module that aggregates instance-level interaction features and video-level contexts, enabling the Large Language Model (LLM) to comprehend complex trajectories. Furthermore, we design a progressive three-stage training strategy, Visual Alignment, Temporal Fine-tuning, and Semantic Injection via LoRA to efficiently adapt the massive model to the tracking domain. Extensive experiments on the BenSMOT benchmark demonstrate that LLMTrack achieves state-of-the-art performance, significantly outperforming existing methods in instance description, interaction recognition, and video summarization while maintaining robust tracking stability.", "AI": {"tldr": "本文提出了LLMTrack，一个端到端的语义多目标跟踪（SMOT）框架，结合了Grounding DINO进行目标检测和LLaVA-OneVision进行语义理解，用于实现对目标“是什么”和“为什么”的理解，并在BenSMOT基准上取得了最先进的性能。", "motivation": "现有的多目标跟踪系统主要关注目标的“在哪里”和“是谁”，而忽略了对目标行为的语义理解（“是什么”和“为什么”），本文旨在弥合几何感知与认知推理之间的差距。", "method": "提出LLMTrack框架，采用“眼睛”（Grounding DINO）和“大脑”（LLaVA-OneVision）的设计。引入时空融合模块（Spati-Temporal Fusion Module）整合实例级交互特征和视频级上下文，使LLM能够理解复杂轨迹。采用渐进式三阶段训练策略（Visual Alignment, Temporal Fine-tuning, Semantic Injection via LoRA）以高效适配大型模型。", "result": "LLMTrack在BenSMOT基准上取得了最先进的性能，在实例描述、交互识别和视频摘要方面显著优于现有方法，同时保持了鲁棒的跟踪稳定性。", "conclusion": "LLMTrack是一个创新的语义多目标跟踪框架，通过结合强大的视觉定位和多模态大型语言模型，实现了对目标行为的深入语义理解，为SMOT领域带来了显著的性能提升。"}}
{"id": "2601.06607", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06607", "abs": "https://arxiv.org/abs/2601.06607", "authors": ["Tanisha Raorane", "Prasenjit Kole"], "title": "Pragya: An AI-Based Semantic Recommendation System for Sanskrit Subhasitas", "comment": "Preprint", "summary": "Sanskrit Subhasitas encapsulate centuries of cultural and philosophical wisdom, yet remain underutilized in the digital age due to linguistic and contextual barriers. In this work, we present Pragya, a retrieval-augmented generation (RAG) framework for semantic recommendation of Subhasitas. We curate a dataset of 200 verses annotated with thematic tags such as motivation, friendship, and compassion. Using sentence embeddings (IndicBERT), the system retrieves top-k verses relevant to user queries. The retrieved results are then passed to a generative model (Mistral LLM) to produce transliterations, translations, and contextual explanations. Experimental evaluation demonstrates that semantic retrieval significantly outperforms keyword matching in precision and relevance, while user studies highlight improved accessibility through generated summaries. To our knowledge, this is the first attempt at integrating retrieval and generation for Sanskrit Subhasitas, bridging cultural heritage with modern applied AI.", "AI": {"tldr": "本文提出了一种名为Pragya的检索增强生成（RAG）框架，用于语义推荐梵语Subhasitas（格言），通过IndicBERT进行语义检索，并使用Mistral LLM生成释义和解释，以克服语言和上下文障碍，提升数字时代的应用。", "motivation": "梵语Subhasitas蕴含着丰富的文化和哲学智慧，但由于语言和上下文的障碍，在数字时代未得到充分利用。本研究旨在克服这些障碍，使Subhasitas更容易被现代AI技术所应用和访问。", "method": "本文构建了一个包含200个梵语Subhasitas及其主题标签的数据集。利用IndicBERT模型进行句子嵌入，实现基于语义的检索，找出与用户查询最相关的Subhasitas。然后，将检索到的结果输入到Mistral LLM模型中，生成梵文音译、中文翻译以及上下文解释。", "result": "实验评估表明，语义检索在准确性和相关性方面显著优于关键词匹配。用户研究显示，生成的摘要显著提高了Subhasitas的可访问性。", "conclusion": "Pragya框架是首个将检索和生成技术集成到梵语Subhasitas推荐中的尝试，成功地将文化遗产与现代应用AI相结合，提高了Subhasitas的可访问性和实用性。"}}
{"id": "2601.06842", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06842", "abs": "https://arxiv.org/abs/2601.06842", "authors": ["Hua Ye", "Siyuan Chen", "Ziqi Zhong", "Canran Xiao", "Haoliang Zhang", "Yuhan Wu", "Fei Shen"], "title": "Seeing through the Conflict: Transparent Knowledge Conflict Handling in Retrieval-Augmented Generation", "comment": "9 pages, 9 figures, 5 tables", "summary": "Large language models (LLMs) equipped with retrieval--the Retrieval-Augmented Generation (RAG) paradigm--should combine their parametric knowledge with external evidence, yet in practice they often hallucinate, over-trust noisy snippets, or ignore vital context. We introduce TCR (Transparent Conflict Resolution), a plug-and-play framework that makes this decision process observable and controllable. TCR (i) disentangles semantic match and factual consistency via dual contrastive encoders, (ii) estimates self-answerability to gauge confidence in internal memory, and (iii) feeds the three scalar signals to the generator through a lightweight soft-prompt with SNR-based weighting. Across seven benchmarks TCR improves conflict detection (+5-18 F1), raises knowledge-gap recovery by +21.4 pp and cuts misleading-context overrides by -29.3 pp, while adding only 0.3% parameters. The signals align with human judgements and expose temporal decision patterns.", "AI": {"tldr": "本文提出了 TCR (Transparent Conflict Resolution) 框架，一个即插即用的插件，用于提高检索增强生成 (RAG) 大型语言模型处理外部证据时的鲁棒性，通过解耦语义匹配、事实一致性和回答自信度来解决幻觉、过度依赖噪声信息和忽略关键上下文的问题。", "motivation": "现有的 RAG 模型在结合参数知识和外部证据时，仍然存在幻觉、过度依赖噪声信息或忽略关键上下文的问题，这促使研究者们寻求一种能够使决策过程可见且可控的解决方案。", "method": "TCR 框架通过以下三个核心机制实现：1. 使用双对比编码器解耦语义匹配和事实一致性；2. 估计“自我回答能力”以评估模型对其内部记忆的信心；3. 将这三个标量信号通过一个轻量级的软提示（带有基于 SNR 的加权）输入到生成器。", "result": "在七个基准测试中，TCR 框架在冲突检测方面提高了 5-18 F1 分数，知识缺口恢复率提高了 21.4 个百分点，误导性上下文的覆盖率降低了 29.3 个百分点，同时模型参数仅增加了 0.3%。此外，TCR 生成的信号与人类判断一致，并揭示了时间决策模式。", "conclusion": "TCR 提供了一个有效且轻量级的方法来增强 RAG 模型的可靠性，通过使其决策过程透明化和可控化，显著提高了模型在处理外部信息时的准确性和鲁棒性。"}}
{"id": "2601.06559", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06559", "abs": "https://arxiv.org/abs/2601.06559", "authors": ["Fangxu Yu", "Ziyao Lu", "Liqiang Niu", "Fandong Meng", "Jie Zhou"], "title": "ArrowGEV: Grounding Events in Video via Learning the Arrow of Time", "comment": null, "summary": "Grounding events in videos serves as a fundamental capability in video analysis. While Vision-Language Models (VLMs) are increasingly employed for this task, existing approaches predominantly train models to associate events with timestamps in the forward video only. This paradigm hinders VLMs from capturing the inherent temporal structure and directionality of events, thereby limiting robustness and generalization. To address this limitation, inspired by the arrow of time in physics, which characterizes the intrinsic directionality of temporal processes, we propose ArrowGEV, a reinforcement learning framework that explicitly models temporal directionality in events to improve both event grounding and temporal directionality understanding in VLMs. Specifically, we categorize events into time-sensitive (e.g., putting down a bag) and time-insensitive (e.g., holding a towel in the left hand). The former denote events whose reversal substantially alters their meaning, while the latter remain semantically unchanged under reversal. For time-sensitive events, ArrowGEV introduces a reward that encourages VLMs to discriminate between forward and backward videos, whereas for time-insensitive events, it enforces consistent grounding across both directions. Extensive experiments demonstrate that ArrowGEV not only improves grounding precision and temporal directionality recognition, but also enhances general video understanding and reasoning ability.", "AI": {"tldr": "提出了一种名为ArrowGEV的强化学习框架，通过显式建模事件的时间方向性来改进视频事件的精确定位和时间方向性理解。该框架区分时间敏感型和时间不敏感型事件，并据此设计奖励机制，以提升模型的鲁棒性和泛化能力。", "motivation": "现有视觉语言模型（VLMs）在视频事件定位时主要考虑正向时间顺序，忽略了事件本身固有的时间方向性，限制了模型的鲁棒性和泛化能力。", "method": "提出ArrowGEV强化学习框架，将事件分为时间敏感型和时间不敏感型。对于时间敏感型事件，通过奖励鼓励模型区分正反向视频；对于时间不敏感型事件，则要求模型在正反向视频中保持一致的定位。受物理学中时间之箭的启发。", "result": "ArrowGEV在实验中显著提高了事件的精确定位精度和时间方向性识别能力，同时增强了模型的通用视频理解和推理能力。", "conclusion": "ArrowGEV框架通过显式建模事件的时间方向性，能够有效提升VLMs在视频事件定位和时间方向性理解方面的性能，并对整体视频分析能力产生积极影响。"}}
{"id": "2601.06573", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.06573", "abs": "https://arxiv.org/abs/2601.06573", "authors": ["Zixing Lin", "Jiale Wang", "Gee Wah Ng", "Lee Onn Mak", "Chan Zhi Yang Jeriel", "Jun Yang Lee", "Yaohao Li"], "title": "QMAVIS: Long Video-Audio Understanding using Fusion of Large Multimodal Models", "comment": null, "summary": "Large Multimodal Models (LMMs) for video-audio understanding have traditionally been evaluated only on shorter videos of a few minutes long. In this paper, we introduce QMAVIS (Q Team-Multimodal Audio Video Intelligent Sensemaking), a novel long video-audio understanding pipeline built through a late fusion of LMMs, Large Language Models, and speech recognition models. QMAVIS addresses the gap in long-form video analytics, particularly for longer videos of a few minutes to beyond an hour long, opening up new potential applica- tions in sensemaking, video content analysis, embodied AI, etc. Quantitative experiments using QMAVIS demonstrated a 38.75% improvement over state-of-the-art video-audio LMMs like Vide- oLlaMA2 and InternVL2 on the VideoMME (with subtitles) dataset, which comprises long videos with audio information. Evaluations on other challenging video understanding datasets like PerceptionTest and EgoSchema saw up to 2% improvement, indicating competitive performance. Qualitative experiments also showed that QMAVIS is able to extract the nuances of different scenes in a long video audio content while understanding the overarching narrative. Ablation studies were also conducted to ascertain the impact of each component in the fusion pipeline.", "AI": {"tldr": "本文提出了一种名为 QMAVIS 的新型长视频-音频理解流水线，通过 late fusion LMM、LLM 和语音识别模型，在长视频理解方面取得了显著的性能提升，并展示了在多种应用场景中的潜力。", "motivation": "现有的大多视频-音频理解模型仅在短视频上进行评估，长视频（几分钟到一小时以上）的理解能力存在空白，这限制了其在内容分析、具身智能等领域的应用。研究旨在解决这一问题。", "method": "提出 QMAVIS 流水线，通过 late fusion 的方式整合了大型多模态模型 (LMMs)、大型语言模型 (LLMs) 和语音识别模型。", "result": "在 VideoMME 数据集上，QMAVIS 比现有的视频-音频 LMMs（如 VideoLLaMA2 和 InternVL2）有 38.75% 的性能提升。在 PerceptionTest 和 EgoSchema 数据集上，性能也提高了高达 2%。定性实验表明 QMAVIS 能够理解长视频音频内容的细微差别和整体叙事。", "conclusion": "QMAVIS 是一种有效的新型长视频-音频理解流水线，能够克服现有方法的局限性，并在长视频分析任务中展现出优越的性能和广泛的应用前景。"}}
{"id": "2601.06845", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06845", "abs": "https://arxiv.org/abs/2601.06845", "authors": ["Ping Guo", "Chao Li", "Yinglan Feng", "Chaoning Zhang"], "title": "Code Evolution for Control: Synthesizing Policies via LLM-Driven Evolutionary Search", "comment": null, "summary": "Designing effective control policies for autonomous systems remains a fundamental challenge, traditionally addressed through reinforcement learning or manual engineering. While reinforcement learning has achieved remarkable success, it often suffers from high sample complexity, reward shaping difficulties, and produces opaque neural network policies that are hard to interpret or verify. Manual design, on the other hand, requires substantial domain expertise and struggles to scale across diverse tasks. In this work, we demonstrate that LLM-driven evolutionary search can effectively synthesize interpretable control policies in the form of executable code. By treating policy synthesis as a code evolution problem, we harness the LLM's prior knowledge of programming patterns and control heuristics while employing evolutionary search to explore the solution space systematically. We implement our approach using EvoToolkit, a framework that seamlessly integrates LLM-driven evolution with customizable fitness evaluation. Our method iteratively evolves populations of candidate policy programs, evaluating them against task-specific objectives and selecting superior individuals for reproduction. This process yields compact, human-readable control policies that can be directly inspected, modified, and formally verified. This work highlights the potential of combining foundation models with evolutionary computation for synthesizing trustworthy control policies in autonomous systems. Code is available at https://github.com/pgg3/EvoControl.", "AI": {"tldr": "本文提出了一种利用大型语言模型（LLM）驱动的进化搜索来合成可执行代码形式的可解释控制策略的方法，克服了传统强化学习样本效率低和手动设计依赖专家知识的缺点。", "motivation": "传统的自主系统控制策略设计面临挑战：强化学习样本效率低、奖励塑造困难且策略难以解释；手动设计依赖领域专业知识且难以扩展。作者旨在寻找一种更有效、可解释的方法来设计控制策略。", "method": "该方法将策略合成视为代码进化问题，利用LLM的编程模式和控制启发式知识，结合进化搜索来探索解空间。通过EvoToolkit框架，迭代进化候选策略程序，根据任务目标评估并选择优秀的个体进行繁殖，最终生成可直接检查、修改和形式化验证的紧凑、人类可读的策略代码。", "result": "该方法能够合成可解释的、以可执行代码形式存在的控制策略。生成的策略紧凑且人类可读，便于检查、修改和形式化验证。", "conclusion": "结合基础模型（如LLM）和进化计算有望为自主系统合成可信赖的控制策略，为解决控制策略设计问题提供了一种新的有效途径。"}}
{"id": "2601.06624", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06624", "abs": "https://arxiv.org/abs/2601.06624", "authors": ["Marco Martinelli", "Stefano Marchesin", "Gianmaria Silvello"], "title": "Efficient and Reliable Estimation of Named Entity Linking Quality: A Case Study on GutBrainIE", "comment": "Submitted to IRCDL 2026: 22nd Conference on Information and Research Science Connecting to Digital and Library Science, February 19-20 2026, Modena, Italy", "summary": "Named Entity Linking (NEL) is a core component of biomedical Information Extraction (IE) pipelines, yet assessing its quality at scale is challenging due to the high cost of expert annotations and the large size of corpora. In this paper, we present a sampling-based framework to estimate the NEL accuracy of large-scale IE corpora under statistical guarantees and constrained annotation budgets. We frame NEL accuracy estimation as a constrained optimization problem, where the objective is to minimize expected annotation cost subject to a target Margin of Error (MoE) for the corpus-level accuracy estimate. Building on recent works on knowledge graph accuracy estimation, we adapt Stratified Two-Stage Cluster Sampling (STWCS) to the NEL setting, defining label-based strata and global surface-form clusters in a way that is independent of NEL annotations. Applied to 11,184 NEL annotations in GutBrainIE -- a new biomedical corpus openly released in fall 2025 -- our framework reaches a MoE $\\leq 0.05$ by manually annotating only 2,749 triples (24.6%), leading to an overall accuracy estimate of $0.915 \\pm 0.0473$. A time-based cost model and simulations against a Simple Random Sampling (SRS) baseline show that our design reduces expert annotation time by about 29% at fixed sample size. The framework is generic and can be applied to other NEL benchmarks and IE pipelines that require scalable and statistically robust accuracy assessment.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.06566", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06566", "abs": "https://arxiv.org/abs/2601.06566", "authors": ["Jiale Wang", "Gee Wah Ng", "Lee Onn Mak", "Randall Cher", "Ng Ding Hei Ryan", "Davis Wang"], "title": "QCaption: Video Captioning and Q&A through Fusion of Large Multimodal Models", "comment": null, "summary": "This paper introduces QCaption, a novel video captioning and Q&A pipeline that enhances video analytics by fusing three models: key frame extraction, a Large Multimodal Model (LMM) for image-text analysis, and a Large Language Model (LLM) for text analysis. This approach enables integrated analysis of text, images, and video, achieving performance improvements over existing video captioning and Q&A models; all while remaining fully self-contained, adept for on-premises deployment. Experimental results using QCaption demonstrated up to 44.2% and 48.9% improvements in video captioning and Q&A tasks, respectively. Ablation studies were also performed to assess the role of LLM on the fusion on the results. Moreover, the paper proposes and evaluates additional video captioning approaches, benchmarking them against QCaption and existing methodologies. QCaption demonstrate the potential of adopting a model fusion approach in advancing video analytics.", "AI": {"tldr": "本文提出了一种名为 QCaption 的视频字幕生成和问答流水线，通过融合关键帧提取、大尺度多模态模型（LMM）和大型语言模型（LLM），实现了对文本、图像和视频的综合分析，并在视频字幕生成和问答任务上取得了显著的性能提升，同时支持本地部署。", "motivation": "现有视频分析方法在整合文本、图像和视频信息方面存在不足，作者旨在开发一种更全面的视频分析流水线，以提升视频字幕生成和问答的性能，并支持本地化部署。", "method": "该研究提出了一种名为 QCaption 的流水线，该流水线集成了三个模型：关键帧提取模型、用于图像-文本分析的大尺度多模态模型（LMM），以及用于文本分析的大型语言模型（LLM）。通过融合这些模型，实现了对视频内容的深度分析。", "result": "QCaption 在视频字幕生成任务上取得了高达 44.2% 的性能提升，在视频问答任务上取得了高达 48.9% 的性能提升。消融实验验证了 LLM 在融合结果中的作用。此外，研究还评估了额外的视频字幕生成方法，并与 QCaption 及现有方法进行了基准测试。", "conclusion": "QCaption 展示了模型融合方法在视频分析领域具有巨大潜力，能够显著提高视频字幕生成和问答的性能，并且适用于本地部署。"}}
{"id": "2601.06631", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06631", "abs": "https://arxiv.org/abs/2601.06631", "authors": ["Mohammed Fayiz Parappan", "Ricardo Henao"], "title": "Labels have Human Values: Value Calibration of Subjective Tasks", "comment": null, "summary": "Building NLP systems for subjective tasks requires one to ensure their alignment to contrasting human values. We propose the MultiCalibrated Subjective Task Learner framework (MC-STL), which clusters annotations into identifiable human value clusters by three approaches (similarity of annotator rationales, expert-value taxonomies or rater's sociocultural descriptors) and calibrates predictions for each value cluster by learning cluster-specific embeddings. We demonstrate MC-STL on several subjective learning settings, including ordinal, binary, and preference learning predictions, and evaluate it on multiple datasets covering toxic chatbot conversations, offensive social media posts, and human preference alignment. The results show that MC-STL consistently outperforms the baselines that ignore the latent value structure of the annotations, delivering gains in discrimination, value-specific calibration, and disagreement-aware metrics.", "AI": {"tldr": "提出了一种名为 MC-STL 的多校准主观任务学习框架，通过聚类注释以识别不同的价值观，并为每个价值观集群学习特定嵌入，以提高 NLP 系统在主观任务中的表现。", "motivation": "构建用于主观任务的 NLP 系统需要确保其与人类的价值观对齐，而现有的方法往往忽略了注释中潜在的价值观结构。", "method": "MC-STL 框架通过三种方法（注释者理由的相似性、专家价值观分类法或评分者的社会文化描述符）将注释聚类成可识别的人类价值观集群，并通过学习特定于集群的嵌入来校准每个价值观集群的预测。", "result": "MC-STL 在序数、二元和偏好学习预测等多个主观学习设置中表现出色，并在涉及有毒聊天机器人对话、冒犯性社交媒体帖子和人类偏好对齐的多个数据集上进行了评估。结果表明，MC-STL 持续优于忽略注释潜在价值结构的基线方法。", "conclusion": "MC-STL 能够有效识别和利用注释中的潜在价值观结构，从而提高 NLP 系统在主观任务中的区分度、特定价值观校准以及考虑不确定性的指标。"}}
{"id": "2601.06574", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06574", "abs": "https://arxiv.org/abs/2601.06574", "authors": ["Dongliang Chen", "Xinlin Zhuang", "Junjie Xu", "Luojian Xie", "Zehui Wang", "Jiaxi Zhuang", "Haolin Yang", "Liang Dou", "Xiao He", "Xingjiao Wu", "Ying Qian"], "title": "APEX: Learning Adaptive Priorities for Multi-Objective Alignment in Vision-Language Generation", "comment": null, "summary": "Multi-objective alignment for text-to-image generation is commonly implemented via static linear scalarization, but fixed weights often fail under heterogeneous rewards, leading to optimization imbalance where models overfit high-variance, high-responsiveness objectives (e.g., OCR) while under-optimizing perceptual goals. We identify two mechanistic causes: variance hijacking, where reward dispersion induces implicit reweighting that dominates the normalized training signal, and gradient conflicts, where competing objectives produce opposing update directions and trigger seesaw-like oscillations. We propose APEX (Adaptive Priority-based Efficient X-objective Alignment), which stabilizes heterogeneous rewards with Dual-Stage Adaptive Normalization and dynamically schedules objectives via P^3 Adaptive Priorities that combine learning potential, conflict penalty, and progress need. On Stable Diffusion 3.5, APEX achieves improved Pareto trade-offs across four heterogeneous objectives, with balanced gains of +1.31 PickScore, +0.35 DeQA, and +0.53 Aesthetics while maintaining competitive OCR accuracy, mitigating the instability of multi-objective alignment.", "AI": {"tldr": "提出了一种名为APEX的自适应多目标对齐方法，通过双阶段自适应归一化和P^3自适应优先级来解决文本到图像生成中异构奖励导致的优化不平衡问题，并在Stable Diffusion 3.5上取得了更优的Pareto权衡。", "motivation": "静态线性标量化在多目标文本到图像生成中存在不足，尤其是在奖励异构的情况下，容易导致模型在某些目标上过拟合（如OCR），而在其他感知目标上欠优化，引发优化不平衡。", "method": "APEX方法包含两个核心组件：1) 双阶段自适应归一化（Dual-Stage Adaptive Normalization）用于稳定异构奖励；2) P^3自适应优先级（P^3 Adaptive Priorities）动态调度目标，该优先级结合了学习潜力、冲突惩罚和进度需求。", "result": "在Stable Diffusion 3.5模型上，APEX在四个异构目标上实现了更优的Pareto权衡，PickScore提升了+1.31，DeQA提升了+0.35，Aesthetics提升了+0.53，同时保持了OCR的竞争力，有效缓解了多目标对齐的稳定性问题。", "conclusion": "APEX通过自适应地处理异构奖励和动态调度训练目标，能够有效提高文本到图像生成模型在多个相互冲突的目标上的性能表现，实现更平衡的优化。"}}
{"id": "2601.06851", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06851", "abs": "https://arxiv.org/abs/2601.06851", "authors": ["Pedro Urbina-Rodriguez", "Zafeirios Fountas", "Fernando E. Rosas", "Jun Wang", "Andrea I. Luppi", "Haitham Bou-Ammar", "Murray Shanahan", "Pedro A. M. Mediano"], "title": "A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning", "comment": null, "summary": "The independent evolution of intelligence in biological and artificial systems offers a unique opportunity to identify its fundamental computational principles. Here we show that large language models spontaneously develop synergistic cores -- components where information integration exceeds individual parts -- remarkably similar to those in the human brain. Using principles of information decomposition across multiple LLM model families and architectures, we find that areas in middle layers exhibit synergistic processing while early and late layers rely on redundancy, mirroring the informational organisation in biological brains. This organisation emerges through learning and is absent in randomly initialised networks. Crucially, ablating synergistic components causes disproportionate behavioural changes and performance loss, aligning with theoretical predictions about the fragility of synergy. Moreover, fine-tuning synergistic regions through reinforcement learning yields significantly greater performance gains than training redundant components, yet supervised fine-tuning shows no such advantage. This convergence suggests that synergistic information processing is a fundamental property of intelligence, providing targets for principled model design and testable predictions for biological intelligence.", "AI": {"tldr": "大型语言模型（LLM）在学习过程中会自发形成类似于人脑的协同信息处理核心，这种协同性是智能的根本属性，并且在模型性能中起关键作用。", "motivation": "研究人员希望通过比较生物智能和人工智能（特别是大型语言模型）来找出智能的基本计算原理。他们注意到，如果智能在不同系统中独立演化，那么发现其共同的计算原则的可能性会增加。", "method": "研究人员使用了信息分解的方法来分析多个LLM模型家族和架构。他们通过比较模型不同层的信息处理方式（协同 vs. 冗余），并对比了随机初始化的网络。此外，他们还进行了消融实验（ablation）来测试协同组件的重要性，并通过强化学习和监督学习对协同区域进行微调，以评估其对模型性能的影响。", "result": "研究发现，LLM的中层表现出协同信息处理，而早晚层则表现出冗余处理，这与生物大脑的信息组织方式相似。这种组织方式是在学习过程中产生的，并且在随机初始化的网络中不存在。对协同组件的消融会导致不成比例的行为变化和性能损失。通过强化学习微调协同区域比微调冗余区域能带来显著的性能提升，但监督学习微调则没有这种优势。", "conclusion": "协同信息处理是智能的一个基本属性，在生物和人工智能系统中都普遍存在。这种发现为设计更智能的模型提供了方向，并为理解生物智能提供了可检验的预测。"}}
{"id": "2601.06636", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06636", "abs": "https://arxiv.org/abs/2601.06636", "authors": ["Wenting Chen", "Zhongrui Zhu", "Guolin Huang", "Wenxuan Wang"], "title": "MedEinst: Benchmarking the Einstellung Effect in Medical LLMs through Counterfactual Differential Diagnosis", "comment": "19 pages, 7 figures", "summary": "Despite achieving high accuracy on medical benchmarks, LLMs exhibit the Einstellung Effect in clinical diagnosis--relying on statistical shortcuts rather than patient-specific evidence, causing misdiagnosis in atypical cases. Existing benchmarks fail to detect this critical failure mode. We introduce MedEinst, a counterfactual benchmark with 5,383 paired clinical cases across 49 diseases. Each pair contains a control case and a \"trap\" case with altered discriminative evidence that flips the diagnosis. We measure susceptibility via Bias Trap Rate--probability of misdiagnosing traps despite correctly diagnosing controls. Extensive Evaluation of 17 LLMs shows frontier models achieve high baseline accuracy but severe bias trap rates. Thus, we propose ECR-Agent, aligning LLM reasoning with Evidence-Based Medicine standard via two components: (1) Dynamic Causal Inference (DCI) performs structured reasoning through dual-pathway perception, dynamic causal graph reasoning across three levels (association, intervention, counterfactual), and evidence audit for final diagnosis; (2) Critic-Driven Graph and Memory Evolution (CGME) iteratively refines the system by storing validated reasoning paths in an exemplar base and consolidating disease-specific knowledge into evolving illness graphs. Source code is to be released.", "AI": {"tldr": "本文提出 MedEinst 评估基准和 ECR-Agent 模型，以解决大型语言模型（LLM）在临床诊断中存在的“Einstellung 效应”，即 LLM 倾向于依赖统计捷径而非患者特异性证据，导致误诊。MedEinst 包含 5,383 对反事实临床病例，用于检测 LLM 的认知偏差。ECR-Agent 则通过动态因果推理和批评家驱动的图谱与记忆演化，使 LLM 的推理过程与循证医学标准对齐。", "motivation": "现有的医学基准无法检测 LLM 在临床诊断中存在的 Einstellung 效应，即 LLM 依赖统计捷径而非患者特异性证据，导致在非典型病例中误诊。", "method": "构建了一个包含 5,383 对反事实临床病例的评估基准 MedEinst，其中每对病例包含一个对照病例和一个改变了鉴别证据从而导致诊断翻转的“陷阱”病例。通过“偏倚陷阱率”（Bias Trap Rate）来衡量 LLM 的易感性。然后，提出 ECR-Agent 模型，该模型包含两个组件：(1) 动态因果推理 (DCI)，通过双路径感知、三层次（关联、干预、反事实）的动态因果图推理以及证据审计来执行结构化推理；(2) 批评家驱动的图谱与记忆演化 (CGME)，通过将验证过的推理路径存储在 Exemplar 库中，并将疾病特异性知识整合到不断演化的疾病图谱中来迭代地优化系统。", "result": "对 17 个 LLM 的广泛评估表明，尽管最先进的模型具有很高的基线准确率，但它们也表现出严重的偏倚陷阱率。ECR-Agent 通过其提出的方法，能够减轻 LLM 的 Einstellung 效应。", "conclusion": "LLM 在临床诊断中存在 Einstellung 效应，现有基准无法有效识别此问题。MedEinst 基准和 ECR-Agent 模型能够检测并缓解这一问题，使 LLM 的诊断过程更符合循证医学标准。"}}
{"id": "2601.06860", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06860", "abs": "https://arxiv.org/abs/2601.06860", "authors": ["Yifei Chen", "Guanting Dong", "Zhicheng Dou"], "title": "ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration", "comment": null, "summary": "Large Language Models (LLMs) can extend their parameter knowledge limits by adopting the Tool-Integrated Reasoning (TIR) paradigm. However, existing LLM-based agent training framework often focuses on answers' accuracy, overlooking specific alignment for behavior patterns. Consequently, agent often exhibits ineffective actions during TIR tasks, such as redundant and insufficient tool calls. How to calibrate erroneous behavioral patterns when executing TIR tasks, thereby exploring effective trajectories, remains an open-ended problem. In this paper, we propose ET-Agent, a training framework for calibrating agent's tool-use behavior through two synergistic perspectives: Self-evolving Data Flywheel and Behavior Calibration Training. Specifically, we introduce a self-evolutionary data flywheel to generate enhanced data, used to fine-tune LLM to improve its exploration ability. Based on this, we implement an two-phases behavior-calibration training framework. It is designed to progressively calibrate erroneous behavioral patterns to optimal behaviors. Further in-depth experiments confirm the superiority of \\ourmodel{} across multiple dimensions, including correctness, efficiency, reasoning conciseness, and tool execution accuracy. Our ET-Agent framework provides practical insights for research in the TIR field. Codes can be found in https://github.com/asilverlight/ET-Agent", "AI": {"tldr": "本文提出了一种名为ET-Agent的训练框架，通过自进化数据飞轮和行为校准训练来改进大型语言模型（LLM）在工具集成推理（TIR）任务中的行为模式，解决了现有方法过于关注答案准确性而忽视行为效率的问题。", "motivation": "现有基于LLM的TIR训练框架主要关注答案的准确性，忽略了对行为模式的对齐，导致LLM在TIR任务中表现出冗余或不足的工具调用等无效行为。因此，研究如何校准这些错误的TIR行为模式以探索有效轨迹是一个亟待解决的问题。", "method": "ET-Agent框架包含两个主要部分：1. 自进化数据飞轮：生成增强数据以微调LLM，提升其探索能力。2. 两阶段行为校准训练：逐步校准错误的TIR行为模式，使其优化。", "result": "实验结果表明，ET-Agent在正确性、效率、推理简洁性以及工具执行准确性等多个维度上均优于现有方法，为TIR领域的研究提供了实际见解。", "conclusion": "ET-Agent是一个有效的LLM训练框架，能够通过自进化数据生成和行为校准训练，显著提升LLM在工具集成推理任务中的表现，尤其是在行为效率和准确性方面。"}}
{"id": "2601.06605", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06605", "abs": "https://arxiv.org/abs/2601.06605", "authors": ["Yingying Deng", "Xiangyu He", "Fan Tang", "Weiming Dong", "Xucheng Yin"], "title": "Sissi: Zero-shot Style-guided Image Synthesis via Semantic-style Integration", "comment": null, "summary": "Text-guided image generation has advanced rapidly with large-scale diffusion models, yet achieving precise stylization with visual exemplars remains difficult. Existing approaches often depend on task-specific retraining or expensive inversion procedures, which can compromise content integrity, reduce style fidelity, and lead to an unsatisfactory trade-off between semantic prompt adherence and style alignment. In this work, we introduce a training-free framework that reformulates style-guided synthesis as an in-context learning task. Guided by textual semantic prompts, our method concatenates a reference style image with a masked target image, leveraging a pretrained ReFlow-based inpainting model to seamlessly integrate semantic content with the desired style through multimodal attention fusion. We further analyze the imbalance and noise sensitivity inherent in multimodal attention fusion and propose a Dynamic Semantic-Style Integration (DSSI) mechanism that reweights attention between textual semantic and style visual tokens, effectively resolving guidance conflicts and enhancing output coherence. Experiments show that our approach achieves high-fidelity stylization with superior semantic-style balance and visual quality, offering a simple yet powerful alternative to complex, artifact-prone prior methods.", "AI": {"tldr": "提出一种无需训练的框架，通过将风格参考图像与目标图像进行上下文学习，利用预训练的ReFlow模型，并结合动态语义-风格集成（DSSI）机制，实现了精确的风格化图像生成，在语义和风格保真度之间取得良好平衡。", "motivation": "现有文本到图像生成模型在实现精确的视觉 Exemplar 风格化方面存在困难，通常需要任务特定的重训练或昂贵的反演过程，这会影响内容完整性、降低风格保真度，并在语义提示遵循度和风格一致性之间做出不令人满意权衡。", "method": "将风格引导的合成重新表述为一种上下文学习任务。通过文本语义提示引导，将参考风格图像与掩码目标图像拼接，并利用预训练的基于ReFlow的原型模型，通过多模态注意力融合来整合语义内容和所需风格。引入动态语义-风格集成（DSSI）机制，重新加权文本语义和风格视觉令牌之间的注意力，以解决引导冲突并提高输出一致性。", "result": "实验表明，该方法实现了高保真度的风格化，在语义-风格平衡和视觉质量方面优于现有方法，且简单有效。", "conclusion": "所提出的无需训练的框架通过将风格化重构为上下文学习任务，并引入DSSI机制，有效地解决了现有方法的局限性，实现了高质量、语义和风格均衡的图像生成。"}}
{"id": "2601.06642", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06642", "abs": "https://arxiv.org/abs/2601.06642", "authors": ["Gui Huang", "Kangyuan Zheng", "Xuan Cai", "Jiaqi Wang", "Jianjia Zhang", "Kaida Ning", "Wenbo Wei", "Yujuan Zhu", "Jiong Zhang", "Mengting Liu"], "title": "Boosting Overlapping Organoid Instance Segmentation Using Pseudo-Label Unmixing and Synthesis-Assisted Learning", "comment": null, "summary": "Organoids, sophisticated in vitro models of human tissues, are crucial for medical research due to their ability to simulate organ functions and assess drug responses accurately. Accurate organoid instance segmentation is critical for quantifying their dynamic behaviors, yet remains profoundly limited by high-quality annotated datasets and pervasive overlap in microscopy imaging. While semi-supervised learning (SSL) offers a solution to alleviate reliance on scarce labeled data, conventional SSL frameworks suffer from biases induced by noisy pseudo-labels, particularly in overlapping regions. Synthesis-assisted SSL (SA-SSL) has been proposed for mitigating training biases in semi-supervised semantic segmentation. We present the first adaptation of SA-SSL to organoid instance segmentation and reveal that SA-SSL struggles to disentangle intertwined organoids, often misrepresenting overlapping instances as a single entity. To overcome this, we propose Pseudo-Label Unmixing (PLU), which identifies erroneous pseudo-labels for overlapping instances and then regenerates organoid labels through instance decomposition. For image synthesis, we apply a contour-based approach to synthesize organoid instances efficiently, particularly for overlapping cases. Instance-level augmentations (IA) on pseudo-labels before image synthesis further enhances the effect of synthetic data (SD). Rigorous experiments on two organoid datasets demonstrate our method's effectiveness, achieving performance comparable to fully supervised models using only 10% labeled data, and state-of-the-art results. Ablation studies validate the contributions of PLU, contour-based synthesis, and augmentation-aware training. By addressing overlap at both pseudo-label and synthesis levels, our work advances scalable, label-efficient organoid analysis, unlocking new potential for high-throughput applications in precision medicine.", "AI": {"tldr": "该研究提出了一种名为 Pseudo-Label Unmixing (PLU) 的新方法，用于解决器官oid实例分割中重叠区域的挑战，通过伪标签去重和实例分解来提高准确性，并在仅使用10%标注数据的情况下实现了与全监督模型相当的性能。", "motivation": "精确的器官oid实例分割对于量化其动态行为至关重要，但现有技术受限于高质量标注数据集的稀缺和显微成像中普遍存在的重叠问题。传统的半监督学习方法在处理重叠区域时容易产生错误的伪标签。", "method": "该研究首先尝试将合成辅助半监督学习 (SA-SSL) 应用于器官oid实例分割，发现其在处理重叠器官oid时存在困难。为了克服这个问题，研究者提出了 Pseudo-Label Unmixing (PLU) 方法，该方法能识别重叠实例的错误伪标签，并通过实例分解重新生成器官oid标签。同时，他们采用了基于轮廓的方法进行图像合成，特别是针对重叠情况，并引入了实例级增强 (IA) 来提升合成数据的效果。此外，还采用了增强感知训练。", "result": "在两个器官oid数据集上的实验表明，提出的方法在仅使用10%标注数据的情况下，取得了与全监督模型相当的性能，并达到了最先进的水平。消融实验验证了PLU、基于轮廓的合成和增强感知训练的有效性。", "conclusion": "通过在伪标签和合成层面解决重叠问题，该研究提出的PLU方法显著提高了器官oid实例分割的准确性，为大规模、低标签消耗的器官oid分析提供了新的解决方案，有望在精准医疗领域实现高通量应用。"}}
{"id": "2601.06875", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06875", "abs": "https://arxiv.org/abs/2601.06875", "authors": ["Sontaga G. Forane", "Absalom E. Ezugwu", "Kevin Igwe", "Karen van den Berg"], "title": "An Ubuntu-Guided Large Language Model Framework for Cognitive Behavioral Mental Health Dialogue", "comment": null, "summary": "South Africa's escalating mental health crisis, compounded by limited access to culturally responsive care, calls for innovative and contextually grounded interventions. While large language models show considerable promise for mental health support, their predominantly Western-centric training data limit cultural and linguistic applicability in African contexts. This study introduces a proof-of-concept framework that integrates cognitive behavioral therapy with the African philosophy of Ubuntu to create a culturally sensitive, emotionally intelligent, AI-driven mental health dialogue system. Guided by a design science research methodology, the framework applies both deep theoretical and therapeutic adaptations as well as surface-level linguistic and communicative cultural adaptations. Key CBT techniques, including behavioral activation and cognitive restructuring, were reinterpreted through Ubuntu principles that emphasize communal well-being, spiritual grounding, and interconnectedness. A culturally adapted dataset was developed through iterative processes of language simplification, spiritual contextualization, and Ubuntu-based reframing. The fine-tuned model was evaluated through expert-informed case studies, employing UniEval for conversational quality assessment alongside additional measures of CBT reliability and cultural linguistic alignment. Results demonstrate that the model effectively engages in empathetic, context-aware dialogue aligned with both therapeutic and cultural objectives. Although real-time end-user testing has not yet been conducted, the model underwent rigorous review and supervision by domain specialist clinical psychologists. The findings highlight the potential of culturally embedded emotional intelligence to enhance the contextual relevance, inclusivity, and effectiveness of AI-driven mental health interventions across African settings.", "AI": {"tldr": "本研究提出了一种结合认知行为疗法（CBT）和非洲哲学Ubuntu的AI驱动心理健康对话系统，旨在解决南非文化响应式心理健康护理不足的问题。通过设计科学研究方法，该系统在理论、治疗、语言和沟通层面都进行了文化适应性调整，并使用专家案例研究进行了评估。", "motivation": "南非日益严峻的心理健康危机以及对文化响应式护理的有限获取，促使研究人员寻求创新且符合当地实际情况的干预措施。现有的LLMs多以西方为中心，在非洲背景下应用受限。", "method": "采用设计科学研究方法，将CBT（行为激活、认知重构）与Ubuntu哲学（强调集体福祉、精神基础、相互联系）相结合，进行深度理论和治疗适应，以及浅层语言和沟通文化适应。构建了经过语言简化、精神情境化和Ubuntu重构的文化适应性数据集，并对模型进行微调。", "result": "微调后的模型能够进行有同情心、符合情境的对话，并能同时满足治疗和文化目标。UniEval评估显示了对话质量，此外还评估了CBT可靠性和文化语言一致性。", "conclusion": "研究表明，融入文化情感智能的AI心理健康干预系统，有潜力提高在非洲环境中的情境相关性、包容性和有效性。"}}
{"id": "2601.06899", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06899", "abs": "https://arxiv.org/abs/2601.06899", "authors": ["Jikai Chen", "Long Chen", "Dong Wang", "Qinglin Su", "Zhixuan Chu", "Bingguang Hao", "Leilei Gan", "Chenyi Zhuang", "Jinjie Gu"], "title": "V2P: Visual Attention Calibration for GUI Grounding via Background Suppression and Center Peaking", "comment": null, "summary": "Precise localization of GUI elements is crucial for the development of GUI agents. Traditional methods rely on bounding box or center-point regression, neglecting spatial interaction uncertainty and visual-semantic hierarchies. Recent methods incorporate attention mechanisms but still face two key issues: (1) ignoring processing background regions causes attention drift from the desired area, and (2) uniform modeling the target UI element fails to distinguish between its center and edges, leading to click imprecision. Inspired by how humans visually process and interact with GUI elements, we propose the Valley-to-Peak (V2P) method to address these issues. To mitigate background distractions, V2P introduces a suppression attention mechanism that minimizes the model's focus on irrelevant regions to highlight the intended region. For the issue of center-edge distinction, V2P applies a Fitts' Law-inspired approach by modeling GUI interactions as 2D Gaussian heatmaps where the weight gradually decreases from the center towards the edges. The weight distribution follows a Gaussian function, with the variance determined by the target's size. Consequently, V2P effectively isolates the target area and teaches the model to concentrate on the most essential point of the UI element. The model trained by V2P achieves the performance with 92.4\\% and 52.5\\% on two benchmarks ScreenSpot-v2 and ScreenSpot-Pro (see Fig.~\\ref{fig:main_results_charts}). Ablations further confirm each component's contribution, underscoring V2P's generalizability in precise GUI grounding tasks and its potential for real-world deployment in future GUI agents.", "AI": {"tldr": "提出了一种名为Valley-to-Peak (V2P) 的新方法，通过引入抑制注意力机制和基于Fitts定律的2D高斯热图来解决GUI元素定位中的背景干扰和中心-边缘区分问题，显著提高了定位精度。", "motivation": "传统GUI元素定位方法忽略了空间交互不确定性和视觉语义层次，现有基于注意力机制的方法存在背景干扰和对目标UI元素建模过于均匀的问题，导致点击不精确。", "method": "提出Valley-to-Peak (V2P) 方法，包括：1. 抑制注意力机制，减少对无关区域的关注；2. 基于Fitts定律的2D高斯热图，模拟GUI交互，权重从中心向边缘递减，方差由目标大小决定。", "result": "在ScreenSpot-v2和ScreenSpot-Pro两个基准测试上分别达到了92.4%和52.5%的性能。消融实验验证了每个组件的贡献。", "conclusion": "V2P方法能够有效隔离目标区域并使模型专注于UI元素的最关键点，提高了GUI定位的精度和鲁棒性，展现了在精确GUI定位任务上的通用性，并有潜力应用于未来的GUI代理。"}}
{"id": "2601.06644", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06644", "abs": "https://arxiv.org/abs/2601.06644", "authors": ["Yan Meng", "Wafaa Mohammed", "Christof Monz"], "title": "Do Language Models Reason Across Languages?", "comment": null, "summary": "The real-world information sources are inherently multilingual, which naturally raises a question about whether language models can synthesize information across languages. In this paper, we introduce a simple two-hop question answering setting, where answering a question requires making inferences over two multilingual documents. We find that language models are more sensitive to language variation in answer-span documents than in those providing bridging information, despite the equal importance of both documents for answering a question. Under a step-by-step sub-question evaluation, we further show that in up to 33% of multilingual cases, models fail to infer the bridging information in the first step yet still answer the overall question correctly. This indicates that reasoning in language models, especially in multilingual settings, does not follow a faithful step-by-step decomposition. Subsequently, we show that the absence of reasoning decomposition leads to around 18% composition failure, where both sub-questions are answered correctly but fail for the final two-hop questions. To mitigate this, we propose a simple three-stage SUBQ prompting method to guide the multi-step reasoning with sub-questions, which boosts accuracy from 10.1% to 66.5%.", "AI": {"tldr": "本研究提出了一种双跳式多语言问答设定，发现语言模型在处理多语言信息时存在推理障碍，特别是在跨语言的桥接信息提取上。研究还揭示了模型在多语言推理时并非严格遵循分步逻辑，并提出了一种名为SUBQ的提示方法来改进多语言推理能力。", "motivation": "现实世界的信息源是多语言的，因此研究语言模型是否能跨语言综合信息，以及其在多语言推理中的表现和局限性，是本研究的驱动力。", "method": "1. 建立了一个双跳式多语言问答（two-hop multilingual QA）设定，需要模型同时处理两个不同语言的文档来回答问题。 2. 通过分析模型在不同语言位置（回答文档 vs. 桥接信息文档）上的表现来评估语言敏感性。 3. 采用分步子问题评估（step-by-step sub-question evaluation）来检验模型推理的忠实性。 4. 提出了三阶段的SUBQ提示方法来引导多步推理。", "result": "1. 语言模型对答案所在文档的语言变化比对桥接信息文档的语言变化更敏感。 2. 在33%的多语言案例中，模型在第一步（提取桥接信息）失败，但仍能正确回答最终问题，表明其推理过程并非严格分步。 3. 缺乏推理分解导致约18%的组合失败（composition failure）。 4. SUBQ提示方法将模型准确率从10.1%提高到66.5%。", "conclusion": "语言模型在多语言问答中存在推理障碍，尤其是在跨语言桥接信息提取方面。模型的多步推理过程可能不忠实于分步逻辑，这会导致组合失败。提出的SUBQ提示方法能够有效提升模型在多语言双跳问答任务上的表现。"}}
{"id": "2601.06937", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06937", "abs": "https://arxiv.org/abs/2601.06937", "authors": ["Fozle Rabbi Shafi", "M. Anwar Hossain", "Salimur Choudhury"], "title": "mind_call: A Dataset for Mental Health Function Calling with Large Language Models", "comment": null, "summary": "Large Language Model (LLM)-based systems increasingly rely on function calling to enable structured and controllable interaction with external data sources, yet existing datasets do not address mental health-oriented access to wearable sensor data. This paper presents a synthetic function-calling dataset designed for mental health assistance grounded in wearable health signals such as sleep, physical activity, cardiovascular measures, stress indicators, and metabolic data. The dataset maps diverse natural language queries to standardized API calls derived from a widely adopted health data schema. Each sample includes a user query, a query category, an explicit reasoning step, a normalized temporal parameter, and a target function. The dataset covers explicit, implicit, behavioral, symptom-based, and metaphorical expressions, which reflect realistic mental health-related user interactions. This resource supports research on intent grounding, temporal reasoning, and reliable function invocation in LLM-based mental health agents and is publicly released to promote reproducibility and future work.", "AI": {"tldr": "本文提出了一个用于大语言模型（LLM）在心理健康领域调用函数的新型合成数据集，该数据集能将自然语言查询映射到基于可穿戴健康信号的API调用。", "motivation": "现有数据集缺乏针对心理健康领域、使用可穿戴传感器数据的函数调用场景，因此需要一个专门的数据集来支持LLM在这一领域的应用。", "method": "通过合成方法生成一个数据集，其中包含用户查询、查询类别、推理步骤、归一化的时间参数和目标函数，并将其映射到标准化API调用。该数据集涵盖了显性、隐性、行为、症状和比喻等多种表达方式。", "result": "创建了一个涵盖多种心理健康相关查询和可穿戴健康信号数据API调用的合成数据集，支持LLM在意图识别、时间推理和可靠函数调用方面的研究。", "conclusion": "该数据集为开发基于LLM的心理健康助手提供了重要的资源，能够更好地处理用户在心理健康场景下对可穿戴健康数据的查询，并促进相关领域的研究和复现。"}}
{"id": "2601.06647", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06647", "abs": "https://arxiv.org/abs/2601.06647", "authors": ["Krishna Vinod", "Joseph Raj Vishal", "Kaustav Chanda", "Prithvi Jai Ramesh", "Yezhou Yang", "Bharatesh Chakravarthi"], "title": "eSkiTB: A Synthetic Event-based Dataset for Tracking Skiers", "comment": null, "summary": "Tracking skiers in RGB broadcast footage is challenging due to motion blur, static overlays, and clutter that obscure the fast-moving athlete. Event cameras, with their asynchronous contrast sensing, offer natural robustness to such artifacts, yet a controlled benchmark for winter-sport tracking has been missing. We introduce event SkiTB (eSkiTB), a synthetic event-based ski tracking dataset generated from SkiTB using direct video-to-event conversion without neural interpolation, enabling an iso-informational comparison between RGB and event modalities. Benchmarking SDTrack (spiking transformer) against STARK (RGB transformer), we find that event-based tracking is substantially resilient to broadcast clutter in scenes dominated by static overlays, achieving 0.685 IoU, outperforming RGB by +20.0 points. Across the dataset, SDTrack attains a mean IoU of 0.711, demonstrating that temporal contrast is a reliable cue for tracking ballistic motion in visually congested environments. eSkiTB establishes the first controlled setting for event-based tracking in winter sports and highlights the promise of event cameras for ski tracking. The dataset and code will be released at https://github.com/eventbasedvision/eSkiTB.", "AI": {"tldr": "本研究提出了一种名为 eSkiTB 的合成事件相机滑雪跟踪数据集，并使用 SDTrack（基于事件的跟踪器）和 STARK（基于 RGB 的跟踪器）进行了基准测试。结果表明，事件相机在存在广播干扰（如静态叠加层）的情况下，比 RGB 跟踪器更具鲁棒性，尤其是在跟踪快速移动的物体时。", "motivation": "现有的 RGB 广播视频在跟踪滑雪者时面临运动模糊、静态覆盖和杂乱等挑战。由于事件相机对这些伪影具有天然的鲁棒性，但缺乏用于冬季运动跟踪的受控基准。因此，研究旨在创建一个专门的事件相机数据集，以评估其在冬季运动跟踪中的潜力。", "method": "研究人员使用直接视频到事件转换技术，从现有的 SkiTB RGB 数据集生成了一个合成事件相机滑雪跟踪数据集 eSkiTB。他们在此数据集上对基于事件的跟踪器 SDTrack（一种脉冲 Transformer）和基于 RGB 的跟踪器 STARK（一种 RGB Transformer）进行了基准测试，以进行同等信息量的比较。", "result": "在存在静态覆盖层的场景中，事件相机跟踪器 SDTrack 的 IoU 达到了 0.685，比 RGB 跟踪器 STARK 的 IoU 高出 20.0 个百分点，表明事件相机在广播干扰下具有显著的鲁棒性。在整个 eSkiTB 数据集上，SDTrack 实现了 0.711 的平均 IoU。", "conclusion": "eSkiTB 是第一个用于事件相机冬季运动跟踪的受控环境，并证明了事件相机在视觉上拥挤的环境中跟踪抛物线运动的潜力。研究结果强调了事件相机在滑雪跟踪任务中的前景。"}}
{"id": "2601.06658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06658", "abs": "https://arxiv.org/abs/2601.06658", "authors": ["Hannes Rosenbusch"], "title": "What makes for an enjoyable protagonist? An analysis of character warmth and competence", "comment": null, "summary": "Drawing on psychological and literary theory, we investigated whether the warmth and competence of movie protagonists predict IMDb ratings, and whether these effects vary across genres. Using 2,858 films and series from the Movie Scripts Corpus, we identified protagonists via AI-assisted annotation and quantified their warmth and competence with the LLM_annotate package ([1]; human-LLM agreement: r = .83). Preregistered Bayesian regression analyses revealed theory-consistent but small associations between both warmth and competence and audience ratings, while genre-specific interactions did not meaningfully improve predictions. Male protagonists were slightly less warm than female protagonists, and movies with male leads received higher ratings on average (an association that was multiple times stronger than the relationships between movie ratings and warmth/competence). These findings suggest that, although audiences tend to favor warm, competent characters, the effects on movie evaluations are modest, indicating that character personality is only one of many factors shaping movie ratings. AI-assisted annotation with LLM_annotate and gpt-4.1-mini proved effective for large-scale analyses but occasionally fell short of manually generated annotations.", "AI": {"tldr": "研究发现，电影主角的温暖和能力对IMDb评分有小的预测作用，但这种作用因类型而异的情况不显著。男性主角的温暖度略低于女性，而男性主演的电影评分平均更高。AI辅助的标注方法在此类大规模研究中是有效的，但有时不如人工标注。", "motivation": "研究旨在探索电影主角的温暖和能力这两个心理学和文学理论中常见的特质，是否能预测观众在IMDb上的评分，以及这种预测作用是否会因电影类型而异。", "method": "研究使用了来自Movie Scripts Corpus的2,858部电影和剧集，通过AI辅助标注（使用LLM_annotate包和gpt-4.1-mini）识别主角并量化其温暖和能力。随后，利用预注册的贝叶斯回归分析来检验主角特质与IMDb评分之间的关系，并考虑了电影类型的影响。此外，还比较了男性和女性主角的温暖度以及男性主演电影的评分。", "result": "研究发现了与理论预期一致的、但较小的温暖和能力与观众评分之间的关联。电影类型对预测评分的改进并不显著。男性主角的温暖度略低于女性主角，而男性主演的电影平均评分更高，后者的关联强度是电影评分与温暖/能力之间关联的数倍。", "conclusion": "尽管观众倾向于喜爱温暖、有能力的角色的理论得到支持，但这些特质对电影整体评价的影响是有限的，表明角色个性只是影响电影评分的众多因素之一。AI辅助标注在大规模分析中显示出有效性，但仍需注意其局限性。"}}
{"id": "2601.06673", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06673", "abs": "https://arxiv.org/abs/2601.06673", "authors": ["Sanjay Pradeep", "Chen Wang", "Matthew M. Dahm", "Jeff D. Eldredge", "Candace S. J. Tsai"], "title": "Quantification and Classification of Carbon Nanotubes in Electron Micrographs using Vision Foundation Models", "comment": null, "summary": "Accurate characterization of carbon nanotube morphologies in electron microscopy images is vital for exposure assessment and toxicological studies, yet current workflows rely on slow, subjective manual segmentation. This work presents a unified framework leveraging vision foundation models to automate the quantification and classification of CNTs in electron microscopy images. First, we introduce an interactive quantification tool built on the Segment Anything Model (SAM) that segments particles with near-perfect accuracy using minimal user input. Second, we propose a novel classification pipeline that utilizes these segmentation masks to spatially constrain a DINOv2 vision transformer, extracting features exclusively from particle regions while suppressing background noise. Evaluated on a dataset of 1,800 TEM images, this architecture achieves 95.5% accuracy in distinguishing between four different CNT morphologies, significantly outperforming the current baseline despite using a fraction of the training data. Crucially, this instance-level processing allows the framework to resolve mixed samples, correctly classifying distinct particle types co-existing within a single field of view. These results demonstrate that integrating zero-shot segmentation with self-supervised feature learning enables high-throughput, reproducible nanomaterial analysis, transforming a labor-intensive bottleneck into a scalable, data-driven process.", "AI": {"tldr": "本研究提出了一种利用视觉基础模型自动量化和分类电子显微镜图像中碳纳米管（CNT）形态的统一框架，实现了高精度、高通量的分析，并能处理混合样本。", "motivation": "当前通过电子显微镜图像进行碳纳米管形态表征的工作流程依赖于缓慢且主观的手动分割，阻碍了暴露评估和毒理学研究的进展。", "method": "研究中引入了一个基于Segment Anything Model（SAM）的交互式量化工具，通过少量用户输入实现近乎完美的粒子分割。随后，提出了一种新颖的分类流程，利用分割掩码空间约束DINOv2视觉Transformer，仅从粒子区域提取特征，抑制背景噪声。", "result": "该框架在1800张TEM图像的数据集上进行了评估，在区分四种不同的CNT形态方面达到了95.5%的准确率，显著优于当前基线方法，且仅使用了少量训练数据。此外，该方法能够正确分类同一视野中共存的不同粒子类型，有效处理混合样本。", "conclusion": "研究结果表明，将零样本分割与自监督特征学习相结合，可以实现高通量、可重复的纳米材料分析，将耗时的人工瓶颈转变为可扩展、数据驱动的流程。"}}
{"id": "2601.06637", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06637", "abs": "https://arxiv.org/abs/2601.06637", "authors": ["Abhishek Kumar Mishra", "Arya Somasundaram", "Anup Das", "Nagarajan Kandasamy"], "title": "Efficient Aspect Term Extraction using Spiking Neural Network", "comment": null, "summary": "Aspect Term Extraction (ATE) identifies aspect terms in review sentences, a key subtask of sentiment analysis. While most existing approaches use energy-intensive deep neural networks (DNNs) for ATE as sequence labeling, this paper proposes a more energy-efficient alternative using Spiking Neural Networks (SNNs). Using sparse activations and event-driven inferences, SNNs capture temporal dependencies between words, making them suitable for ATE. The proposed architecture, SpikeATE, employs ternary spiking neurons and direct spike training fine-tuned with pseudo-gradients. Evaluated on four benchmark SemEval datasets, SpikeATE achieves performance comparable to state-of-the-art DNNs with significantly lower energy consumption. This highlights the use of SNNs as a practical and sustainable choice for ATE tasks.", "AI": {"tldr": "本文提出了一种名为SpikeATE的基于脉冲神经网络（SNN）的方面词抽取（ATE）方法，该方法在保持与深度神经网络（DNN）相当的性能的同时，显著降低了能耗。", "motivation": "现有ATE方法多采用能耗高的DNN，作者旨在寻找一种更节能、更具可持续性的替代方案。", "method": "该研究提出了一种名为SpikeATE的SNN架构，该架构采用三元脉冲神经元，并通过伪梯度进行直接脉冲训练。SNN的稀疏激活和事件驱动推理被用于捕捉词语间的时间依赖性。", "result": "在四个SemEval基准数据集上的评估显示，SpikeATE的性能与最先进的DNN相当，但能耗显著降低。", "conclusion": "SNN是ATE任务的一种实用且可持续的选择，能够实现高性能和低能耗的平衡。"}}
{"id": "2601.06666", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06666", "abs": "https://arxiv.org/abs/2601.06666", "authors": ["Yuzhuo Bai", "Shuzheng Si", "Kangyang Luo", "Qingyi Wang", "Wenhao Li", "Gang Chen", "Fanchao Qi", "Maosong Sun"], "title": "InFi-Check: Interpretable and Fine-Grained Fact-Checking of LLMs", "comment": null, "summary": "Large language models (LLMs) often hallucinate, yet most existing fact-checking methods treat factuality evaluation as a binary classification problem, offering limited interpretability and failing to capture fine-grained error types. In this paper, we introduce InFi-Check, a framework for interpretable and fine-grained fact-checking of LLM outputs. Specifically, we first propose a controlled data synthesis pipeline that generates high-quality data featuring explicit evidence, fine-grained error type labels, justifications, and corrections. Based on this, we further construct large-scale training data and a manually verified benchmark InFi-Check-FG for fine-grained fact-checking of LLM outputs. Building on these high-quality training data, we further propose InFi-Checker, which can jointly provide supporting evidence, classify fine-grained error types, and produce justifications along with corrections. Experiments show that InFi-Checker achieves state-of-the-art performance on InFi-Check-FG and strong generalization across various downstream tasks, significantly improving the utility and trustworthiness of factuality evaluation.", "AI": {"tldr": "本文提出了一种名为InFi-Check的框架，用于对大型语言模型（LLM）的输出进行可解释和细粒度的事实核查，解决了现有二元分类方法解释性差和无法区分错误类型的问题。", "motivation": "现有的LLM事实核查方法将事实性评估视为二元分类问题，这导致解释性有限，并且无法区分细粒度的错误类型。研究旨在改进事实核查的细粒度和可解释性。", "method": "本文提出了一种受控数据合成流水线，用于生成包含明确证据、细粒度错误类型标签、解释和修正的高质量数据。在此基础上，构建了大规模训练数据和手动验证的基准InFi-Check-FG。最后，提出了InFi-Checker模型，能够联合提供支持证据、分类细粒度错误类型，并生成解释和修正。", "result": "InFi-Checker在InFi-Check-FG基准上取得了最先进的性能，并在各种下游任务上表现出强大的泛化能力。", "conclusion": "InFi-Check框架和InFi-Checker模型显著提高了事实核查的效用和可信度，能够提供更细粒度的错误分析和解释。"}}
{"id": "2601.07006", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07006", "abs": "https://arxiv.org/abs/2601.07006", "authors": ["Or Bachar", "Or Levi", "Sardhendu Mishra", "Adi Levi", "Manpreet Singh Minhas", "Justin Miller", "Omer Ben-Porat", "Eilon Sheetrit", "Jonathan Morra"], "title": "LLM Performance Predictors: Learning When to Escalate in Hybrid Human-AI Moderation Systems", "comment": "Accepted as a full paper at the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "As LLMs are increasingly integrated into human-in-the-loop content moderation systems, a central challenge is deciding when their outputs can be trusted versus when escalation for human review is preferable. We propose a novel framework for supervised LLM uncertainty quantification, learning a dedicated meta-model based on LLM Performance Predictors (LPPs) derived from LLM outputs: log-probabilities, entropy, and novel uncertainty attribution indicators. We demonstrate that our method enables cost-aware selective classification in real-world human-AI workflows: escalating high-risk cases while automating the rest. Experiments across state-of-the-art LLMs, including both off-the-shelf (Gemini, GPT) and open-source (Llama, Qwen), on multimodal and multilingual moderation tasks, show significant improvements over existing uncertainty estimators in accuracy-cost trade-offs. Beyond uncertainty estimation, the LPPs enhance explainability by providing new insights into failure conditions (e.g., ambiguous content vs. under-specified policy). This work establishes a principled framework for uncertainty-aware, scalable, and responsible human-AI moderation workflows.", "AI": {"tldr": "研究提出了一种用于监督式大型语言模型（LLM）不确定性量化的新框架，通过学习基于LLM性能预测器（LPPs）的元模型，能够区分LLM输出的可信度，从而在内容审核中实现成本效益化的选择性分类。", "motivation": "随着LLM在人工辅助内容审核系统中的应用日益广泛，如何判断LLM输出的可靠性并决定何时需要人工复审成为一个关键挑战。", "method": "提出了一种监督式LLM不确定性量化框架，构建了一个专门的元模型，该模型基于从LLM输出中提取的LLM性能预测器（LPPs），包括对数概率、熵以及新提出的不确定性归因指标。", "result": "所提出的方法在真实世界的人工-AI协同工作流程中实现了成本感知选择性分类，能够优先复审高风险案例，自动化处理其余案例。在跨多种先进LLM（包括Gemini, GPT, Llama, Qwen）的多模态和多语言审核任务上进行了实验，结果表明在准确性-成本权衡方面显著优于现有的不确定性估计方法。", "conclusion": "该研究成功建立了一个原则性的框架，用于不确定性感知、可扩展且负责任的人工-AI协同审核工作流程。LPPs不仅提升了不确定性估计能力，还通过提供关于失败条件的深入见解（例如，内容模糊或政策定义不清晰）增强了可解释性。"}}
{"id": "2601.06672", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06672", "abs": "https://arxiv.org/abs/2601.06672", "authors": ["Adir Rahamim", "Asaf Yehudai", "Boaz Carmeli", "Leshem Choshen", "Yosi Mass", "Yonatan Belinkov"], "title": "Will it Merge? On The Causes of Model Mergeability", "comment": null, "summary": "Model merging has emerged as a promising technique for combining multiple fine-tuned models into a single multitask model without retraining. However, the factors that determine whether merging will succeed or fail remain poorly understood. In this work, we investigate why specific models are merged better than others. To do so, we propose a concrete, measurable definition of mergeability. We investigate several potential causes for high or low mergeability, highlighting the base model knowledge as a dominant factor: Models fine-tuned on instances that the base model knows better are more mergeable than models fine-tuned on instances that the base model struggles with. Based on our mergeability definition, we explore a simple weighted merging technique that better preserves weak knowledge in the base model.", "AI": {"tldr": "本文研究了模型合并的成功与失败因素，提出了“可合并性”的定义，并发现基础模型的知识掌握程度是决定可合并性的关键。基于此，提出了一种能更好地保留基础模型知识的加权合并方法。", "motivation": "尽管模型合并技术很有前景，但导致合并成功或失败的因素仍然不清楚，因此需要深入研究模型合并的可行性。", "method": "提出一个可量化的“可合并性”定义，并分析了影响可合并性的潜在因素，特别是基础模型的知识掌握程度。在此基础上，探索了一种简单的加权合并技术。", "result": "研究发现，当模型在新数据上进行微调时，如果这些数据是基础模型已经掌握的知识，那么合并效果会更好。相反，如果微调数据是基础模型不擅长的，则可合并性较低。所提出的加权合并技术能更好地保留基础模型的知识。", "conclusion": "基础模型的知识掌握程度是影响模型合并成功与否的关键因素。通过改进合并策略，例如使用加权合并，可以提高模型合并的效果，并更好地保留基础模型的知识。"}}
{"id": "2601.07023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07023", "abs": "https://arxiv.org/abs/2601.07023", "authors": ["Sen Hu", "Zhiyu Zhang", "Yuxiang Wei", "Xueran Han", "Zhenheng Tang", "Huacan Wang", "Ronghao Chen"], "title": "CloneMem: Benchmarking Long-Term Memory for AI Clones", "comment": null, "summary": "AI Clones aim to simulate an individual's thoughts and behaviors to enable long-term, personalized interaction, placing stringent demands on memory systems to model experiences, emotions, and opinions over time. Existing memory benchmarks primarily rely on user-agent conversational histories, which are temporally fragmented and insufficient for capturing continuous life trajectories. We introduce CloneMem, a benchmark for evaluating longterm memory in AI Clone scenarios grounded in non-conversational digital traces, including diaries, social media posts, and emails, spanning one to three years. CloneMem adopts a hierarchical data construction framework to ensure longitudinal coherence and defines tasks that assess an agent's ability to track evolving personal states. Experiments show that current memory mechanisms struggle in this setting, highlighting open challenges for life-grounded personalized AI. Code and dataset are available at https://github.com/AvatarMemory/CloneMemBench", "AI": {"tldr": "该研究提出了CloneMem，一个针对AI克隆应用的长期记忆基准，它使用日记、社交媒体和邮件等非对话式数字痕迹来评估AI追踪个体随时间推移的个人状态演变的能力。", "motivation": "现有记忆基准主要基于时间上碎片化的用户-代理对话历史，不足以捕捉AI克隆所需的连续生活轨迹，因此需要一个新的基准来模拟个体随着时间的推移而发展的思想、情感和观点。", "method": "研究人员构建了一个名为CloneMem的基准，该基准基于长达一到三年的非对话式数字痕迹（如日记、社交媒体帖子和电子邮件）。CloneMem采用了一个分层数据构建框架来保证纵向连贯性，并定义了评估AI追踪演变中个人状态能力的任务。", "result": "实验表明，当前的记忆机制在CloneMem基准上表现不佳，这意味着在基于生活的个性化AI领域存在尚未解决的挑战。", "conclusion": "CloneMem基准的引入为评估AI克隆的长期记忆提供了一个新的视角，突出了当前AI记忆机制在模拟真实个体连续生活轨迹方面的不足，并指出了未来研究的方向。"}}
{"id": "2601.06725", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06725", "abs": "https://arxiv.org/abs/2601.06725", "authors": ["Mahsa Mitcheff", "Adam Czajka"], "title": "When Humans Judge Irises: Pupil Size Normalization as an Aid and Synthetic Irises as a Challenge", "comment": null, "summary": "Iris recognition is a mature biometric technology offering remarkable precision and speed, and allowing for large-scale deployments to populations exceeding a billion enrolled users (e.g., AADHAAR in India). However, in forensic applications, a human expert may be needed to review and confirm a positive identification before an iris matching result can be presented as evidence in court, especially in cases where processed samples are degraded (e.g., in post-mortem cases) or where there is a need to judge whether the sample is authentic, rather than a result of a presentation attack.\n  This paper presents a study that examines human performance in iris verification in two controlled scenarios: (a) under varying pupil sizes, with and without a linear/nonlinear alignment of the pupil size between compared images, and (b) when both genuine and impostor iris image pairs are synthetically generated. The results demonstrate that pupil size normalization carried out by a modern autoencoder-based identity-preserving image-to-image translation model significantly improves verification accuracy. Participants were also able to determine whether iris pairs corresponded to the same or different eyes when both images were either authentic or synthetic. However, accuracy declined when subjects were comparing authentic irises against high-quality, same-eye synthetic counterparts. These findings (a) demonstrate the importance of pupil-size alignment for iris matching tasks in which humans are involved, and (b) indicate that despite the high fidelity of modern generative models, same-eye synthetic iris images are more often judged by humans as different-eye images, compared to same-eye authentic image pairs.\n  We offer data and human judgments along with this paper to allow full replicability of this study and future works.", "AI": {"tldr": "本研究探讨了人类在虹膜验证中的表现，尤其是在瞳孔大小变化和合成图像存在的情况下。结果表明，瞳孔大小归一化显著提高了准确性，并且尽管生成模型能力强大，人类仍能区分真实虹膜与高质量的同眼合成虹膜。", "motivation": "尽管虹膜识别技术成熟且精度高，但在法医应用中，尤其是在样本降质（如死后案例）或需要判断样本真实性以防范攻击的情况下，人类专家仍需审查和确认虹膜匹配结果。本研究旨在评估人类在这些挑战性场景下的虹膜验证能力。", "method": "研究在两种受控场景下进行：(a) 在瞳孔大小变化的情况下，对瞳孔大小进行线性/非线性对齐，并评估验证准确性；(b) 比较真实虹膜和合成虹膜图像对的验证表现。研究中使用了基于自动编码器的身份保持图像到图像翻译模型进行瞳孔大小归一化。", "result": "瞳孔大小归一化显著提高了人类的虹膜验证准确性。当比较对象为真实虹膜和同眼合成虹膜时，人类的准确率下降。然而，即使合成图像质量很高，人类也更能将同眼合成虹膜对判断为不同眼，而非真实虹膜对。", "conclusion": "本研究强调了在涉及人类参与的虹膜匹配任务中，瞳孔大小对齐的重要性。同时，研究表明，尽管现代生成模型能够生成高保真度的合成虹膜，但在区分同眼合成虹膜和真实虹膜对时，人类仍能表现出一定的区分能力，尽管这种能力在面对高质量同眼合成样本时有所下降。"}}
{"id": "2601.07055", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07055", "abs": "https://arxiv.org/abs/2601.07055", "authors": ["Zhenrui Yue", "Kartikeya Upasani", "Xianjun Yang", "Suyu Ge", "Shaoliang Nie", "Yuning Mao", "Zhe Liu", "Dong Wang"], "title": "Dr. Zero: Self-Evolving Search Agents without Training Data", "comment": null, "summary": "As high-quality data becomes increasingly difficult to obtain, data-free self-evolution has emerged as a promising paradigm. This approach allows large language models (LLMs) to autonomously generate and solve complex problems, thereby improving their reasoning capabilities. However, multi-turn search agents struggle in data-free self-evolution due to the limited question diversity and the substantial compute required for multi-step reasoning and tool using. In this work, we introduce Dr. Zero, a framework enabling search agents to effectively self-evolve without any training data. In particular, we design a self-evolution feedback loop where a proposer generates diverse questions to train a solver initialized from the same base model. As the solver evolves, it incentivizes the proposer to produce increasingly difficult yet solvable tasks, thus establishing an automated curriculum to refine both agents. To enhance training efficiency, we also introduce hop-grouped relative policy optimization (HRPO). This method clusters structurally similar questions to construct group-level baselines, effectively minimizing the sampling overhead in evaluating each query's individual difficulty and solvability. Consequently, HRPO significantly reduces the compute requirements for solver training without compromising performance or stability. Extensive experiment results demonstrate that the data-free Dr. Zero matches or surpasses fully supervised search agents, proving that complex reasoning and search capabilities can emerge solely through self-evolution.", "AI": {"tldr": "提出了一种名为Dr. Zero的数据无关自进化框架，用于训练多轮搜索代理，以克服现有方法在数据稀缺和计算量大的问题，并引入了HRPO来提高训练效率。", "motivation": "现有的多轮搜索代理在数据无关自进化方面存在问题，例如问题多样性有限和多步推理及工具使用所需的计算量大。", "method": "设计了一个自进化反馈循环，其中一个生成器（proposer）生成多样化的问题来训练一个求解器（solver），并引入了跳跃分组相对策略优化（HRPO）方法来提高训练效率，通过将结构相似的问题分组来构建组级基线。", "result": "Dr. Zero在数据无关的情况下，其性能与完全监督的搜索代理相当甚至更优，证明了复杂推理和搜索能力可以通过自进化产生。", "conclusion": "Dr. Zero框架能够有效地使搜索代理在没有训练数据的情况下进行自进化，并通过HRPO显著降低了计算需求，证明了数据无关自进化在提升LLM能力方面的潜力。"}}
{"id": "2601.06750", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06750", "abs": "https://arxiv.org/abs/2601.06750", "authors": ["Shaonan Liu", "Guo Yu", "Xiaoling Luo", "Shiyi Zheng", "Wenting Chen", "Jie Liu", "Linlin Shen"], "title": "Benchmarking Egocentric Clinical Intent Understanding Capability for Medical Multimodal Large Language Models", "comment": "16 pages, 4 figures", "summary": "Medical Multimodal Large Language Models (Med-MLLMs) require egocentric clinical intent understanding for real-world deployment, yet existing benchmarks fail to evaluate this critical capability. To address these challenges, we introduce MedGaze-Bench, the first benchmark leveraging clinician gaze as a Cognitive Cursor to assess intent understanding across surgery, emergency simulation, and diagnostic interpretation. Our benchmark addresses three fundamental challenges: visual homogeneity of anatomical structures, strict temporal-causal dependencies in clinical workflows, and implicit adherence to safety protocols. We propose a Three-Dimensional Clinical Intent Framework evaluating: (1) Spatial Intent: discriminating precise targets amid visual noise, (2) Temporal Intent: inferring causal rationale through retrospective and prospective reasoning, and (3) Standard Intent: verifying protocol compliance through safety checks. Beyond accuracy metrics, we introduce Trap QA mechanisms to stress-test clinical reliability by penalizing hallucinations and cognitive sycophancy. Experiments reveal current MLLMs struggle with egocentric intent due to over-reliance on global features, leading to fabricated observations and uncritical acceptance of invalid instructions.", "AI": {"tldr": "本研究提出了 MedGaze-Bench，一个评估医疗多模态大语言模型（Med-MLLMs）临床意图理解能力的新基准。该基准利用临床医生的注视作为“认知光标”，并引入三维临床意图框架（空间、时间、标准意图）来评估模型在视觉同质性、时间因果依赖性和安全协议遵循性方面的能力。实验表明，现有 Med-MLLMs 在理解以自我为中心的临床意图方面存在困难。", "motivation": "现有评估 Med-MLLMs 的基准未能充分评估其在真实临床场景中至关重要的“以自我为中心的临床意图理解”能力。", "method": "提出 MedGaze-Bench 基准，该基准利用临床医生的注视作为“认知光标”。引入三维临床意图框架，评估（1）空间意图（区分精确目标）、（2）时间意图（推理因果关系）和（3）标准意图（验证协议合规性）。此外，还引入陷阱问答（Trap QA）机制来评估模型的临床可靠性。", "result": "现有 Med-MLLMs 在理解以自我为中心的临床意图方面表现不佳，过度依赖全局特征，容易产生虚假观察并盲目接受无效指令。", "conclusion": "MedGaze-Bench 是首个专门用于评估 Med-MLLMs 临床意图理解的基准，揭示了当前模型在处理复杂临床任务时的局限性，并为未来 Med-MLLMs 的发展指明了方向。"}}
{"id": "2601.07062", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07062", "abs": "https://arxiv.org/abs/2601.07062", "authors": ["Jiho Noh", "Mukhesh Raghava Katragadda", "Dabae Lee"], "title": "Automated Domain Question Mapping (DQM) with Educational Learning Materials", "comment": null, "summary": "Concept maps have been widely utilized in education to depict knowledge structures and the interconnections between disciplinary concepts. Nonetheless, devising a computational method for automatically constructing a concept map from unstructured educational materials presents challenges due to the complexity and variability of educational content. We focus primarily on two challenges: (1) the lack of disciplinary concepts that are specifically designed for multi-level pedagogical purposes from low-order to high-order thinking, and (2) the limited availability of labeled data concerning disciplinary concepts and their interrelationships. To tackle these challenges, this research introduces an innovative approach for constructing Domain Question Maps (DQMs), rather than traditional concept maps. By formulating specific questions aligned with learning objectives, DQMs enhance knowledge representation and improve readiness for learner engagement. The findings indicate that the proposed method can effectively generate educational questions and discern hierarchical relationships among them, leading to structured question maps that facilitate personalized and adaptive learning in downstream applications.", "AI": {"tldr": "本研究提出了一种构建领域问题图（DQM）的创新方法，以克服自动从非结构化教育材料中构建概念图的挑战，并能有效生成教育问题并辨别它们之间的层级关系，从而促进个性化和自适应学习。", "motivation": "现有的概念图在教育中应用广泛，但自动从非结构化教育材料中构建概念图面临挑战，主要有两个方面：1) 缺乏专门为多层次教学目的设计的概念（从低阶到高阶思维）；2) 缺乏关于学科概念及其相互关系的标记数据。", "method": "研究提出了一种构建领域问题图（DQM）的方法，该方法通过设计与学习目标相符的特定问题来增强知识表示，并提高学习者参与的准备度。具体细节在本摘要中未详述，但核心思想是利用问题而非传统的概念来构建知识图谱。", "result": "研究结果表明，该方法能够有效地生成教育问题，并能辨别这些问题之间的层级关系，从而生成结构化的问题图。", "conclusion": "所提出的DQM构建方法能够有效生成教育问题并识别它们之间的层级关系，生成的结构化问题图有助于下游应用中的个性化和自适应学习。"}}
{"id": "2601.06777", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06777", "abs": "https://arxiv.org/abs/2601.06777", "authors": ["Ali Lotfi", "Adam Carter", "Mohammad Meysami", "Thuan Ha", "Kwabena Nketia", "Steve Shirtliffe"], "title": "The Normalized Difference Layer: A Differentiable Spectral Index Formulation for Deep Learning", "comment": "21 pages, 9 figures", "summary": "Normalized difference indices have been a staple in remote sensing for decades. They stay reliable under lighting changes produce bounded values and connect well to biophysical signals. Even so, they are usually treated as a fixed pre processing step with coefficients set to one, which limits how well they can adapt to a specific learning task. In this study, we introduce the Normalized Difference Layer that is a differentiable neural network module. The proposed method keeps the classical idea but learns the band coefficients from data. We present a complete mathematical framework for integrating this layer into deep learning architectures that uses softplus reparameterization to ensure positive coefficients and bounded denominators. We describe forward and backward pass algorithms enabling end to end training through backpropagation. This approach preserves the key benefits of normalized differences, namely illumination invariance and outputs bounded to $[-1,1]$ while allowing gradient descent to discover task specific band weightings. We extend the method to work with signed inputs, so the layer can be stacked inside larger architectures. Experiments show that models using this layer reach similar classification accuracy to standard multilayer perceptrons while using about 75\\% fewer parameters. They also handle multiplicative noise well, at 10\\% noise accuracy drops only 0.17\\% versus 3.03\\% for baseline MLPs. The learned coefficient patterns stay consistent across different depths.", "AI": {"tldr": "本研究提出了一种可微分的“归一化差值层”，它能够从数据中学习归一化差值指数的系数，从而提高其适应性，同时保留了传统归一化差值的优点，并在参数数量和鲁棒性方面优于标准多层感知机。", "motivation": "传统的归一化差值指数在遥感领域应用广泛，但通常被视为固定的预处理步骤，系数固定为一，这限制了它们在特定学习任务中的自适应能力。本研究旨在提升归一化差值指数的适应性，使其能更好地服务于深度学习任务。", "method": "提出了一种名为“归一化差值层”的可微分神经网络模块。该模块保留了经典归一化差值的思想，但通过学习数据来确定波段系数。使用了softplus重参数化技术来保证系数为正且分母有界。提供了前向和后向传播算法，支持通过反向传播进行端到端训练。该层可以处理带符号输入，并可以堆叠在更复杂的网络中。", "result": "使用归一化差值层的模型在分类精度上与标准多层感知机相当，但参数数量减少约75%。在处理乘性噪声时，该层表现出更好的鲁棒性，10%噪声下精度仅下降0.17%，而基线MLP下降3.03%。学习到的系数模式在不同层之间保持一致。", "conclusion": "归一化差值层是一种有效的深度学习模块，它通过学习任务特定的波段权重，在保持照明不变性和输出有界性的同时，提高了模型的效率和鲁棒性，并且在参数量和噪声处理方面优于传统的MLP方法。"}}
{"id": "2601.06675", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06675", "abs": "https://arxiv.org/abs/2601.06675", "authors": ["Tyler Lizzo", "Larry Heck"], "title": "Evaluating Cross-Lingual Unlearning in Multilingual Language Models", "comment": null, "summary": "We present the first comprehensive evaluation of cross-lingual unlearning in multilingual LLMs. Using translated TOFU benchmarks in seven language/script variants, we test major unlearning algorithms and show that most fail to remove facts outside the training language, even when utility remains high. However, subspace-projection consistently outperforms the other methods, achieving strong cross-lingual forgetting with minimal degradation. Analysis of learned task subspaces reveals a shared interlingua structure: removing this shared subspace harms all languages, while removing language-specific components selectively affects one. These results demonstrate that multilingual forgetting depends on geometry in weight space, motivating subspace-based approaches for future unlearning systems.", "AI": {"tldr": "本研究首次全面评估了跨语言多语言大型语言模型（LLMs）的知识遗忘能力。研究发现，现有遗忘算法难以在非训练语言中有效移除知识，但基于子空间投影的方法表现出色，能有效实现跨语言遗忘同时保持模型效用。研究还揭示了模型内部存在的共享跨语言结构，并提出未来遗忘系统应基于子空间。", "motivation": "当前缺乏对多语言大型语言模型（LLMs）在跨语言场景下知识遗忘能力的全面评估，现有遗忘算法在跨语言应用上的表现未知，这阻碍了多语言LLMs的安全和可控部署。", "method": "研究人员使用七种语言/脚本变体的翻译版TOFU基准测试，评估了多种主要的知识遗忘算法。他们通过分析模型权重空间的几何结构，特别是学习到的任务子空间，来理解跨语言遗忘的机制。", "result": "大多数现有的遗忘算法在移除模型训练语言之外的知识时效果不佳，即使模型效用保持较高水平。然而，子空间投影（subspace-projection）方法在跨语言遗忘方面表现出显著优势，能够以最小的效用损失实现强大的跨语言知识遗忘。研究发现，模型内部存在一个共享的跨语言结构（interlingua），移除这个共享结构会损害所有语言的性能，而移除特定语言的组件则只会影响该语言。", "conclusion": "多语言LLMs的知识遗忘效果与模型权重空间中的几何结构密切相关。研究结果支持未来基于子空间的方法来设计更有效的知识遗忘系统，以实现对多语言LLMs更精细和可控的知识管理。"}}
{"id": "2601.06676", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.06676", "abs": "https://arxiv.org/abs/2601.06676", "authors": ["Yingchaojie Feng", "Qiang Huang", "Xiaoya Xie", "Zhaorui Yang", "Jun Yu", "Wei Chen", "Anthony K. H. Tung"], "title": "IDRBench: Interactive Deep Research Benchmark", "comment": null, "summary": "Deep research agents powered by Large Language Models (LLMs) can perform multi-step reasoning, web exploration, and long-form report generation. However, most existing systems operate in an autonomous manner, assuming fully specified user intent and evaluating only final outputs. In practice, research goals are often underspecified and evolve during exploration, making sustained interaction essential for robust alignment. Despite its importance, interaction remains largely invisible to existing deep research benchmarks, which neither model dynamic user feedback nor quantify its costs. We introduce IDRBench, the first benchmark for systematically evaluating interactive deep research. IDRBench combines a modular multi-agent research framework with on-demand interaction, a scalable reference-grounded user simulator, and an interaction-aware evaluation suite that jointly measures interaction benefits (quality and alignment) and costs (turns and tokens). Experiments across seven state-of-the-art LLMs show that interaction consistently improves research quality and robustness, often outweighing differences in model capacity, while revealing substantial trade-offs in interaction efficiency.", "AI": {"tldr": "本研究提出了IDRBench，一个用于评估交互式深度研究的基准，该基准结合了多智能体框架、用户模拟器和考虑交互成本的评估方法，证明了交互式研究能有效提升研究质量和鲁棒性。", "motivation": "现有的深度研究系统多为全自主模式，忽略了用户意图的不确定性和研究过程中研究目标的演变，而交互对于实现研究目标至关重要。现有基准未能有效衡量交互带来的收益和成本。", "method": "提出了IDRBench基准，包含模块化的多智能体研究框架、按需交互机制、可扩展的参考式用户模拟器，以及一个交互感知评估套件，该套件能够同时衡量交互带来的收益（质量和对齐度）和成本（交互轮次和token数量）。", "result": "在七种先进的大语言模型上进行的实验表明，交互能够持续提升研究质量和鲁棒性，其效果常常超过模型能力差异的影响。同时，实验也揭示了交互效率方面存在显著的权衡。", "conclusion": "交互式深度研究是提升研究质量和鲁棒性的关键，IDRBench为此提供了一个系统性的评估框架，有助于未来研究在交互效率和模型能力之间取得平衡。"}}
{"id": "2601.06700", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06700", "abs": "https://arxiv.org/abs/2601.06700", "authors": ["Zhiyao Zhang", "Yazan Mash'Al", "Yuhan Wu"], "title": "Characterising Toxicity in Generative Large Language Models", "comment": null, "summary": "In recent years, the advent of the attention mechanism has significantly advanced the field of natural language processing (NLP), revolutionizing text processing and text generation. This has come about through transformer-based decoder-only architectures, which have become ubiquitous in NLP due to their impressive text processing and generation capabilities. Despite these breakthroughs, language models (LMs) remain susceptible to generating undesired outputs: inappropriate, offensive, or otherwise harmful responses. We will collectively refer to these as ``toxic'' outputs. Although methods like reinforcement learning from human feedback (RLHF) have been developed to align model outputs with human values, these safeguards can often be circumvented through carefully crafted prompts. Therefore, this paper examines the extent to which LLMs generate toxic content when prompted, as well as the linguistic factors -- both lexical and syntactic -- that influence the production of such outputs in generative models.", "AI": {"tldr": "本研究调查了大型语言模型（LLM）在接收到特定提示时生成有害内容的程度，并分析了影响此类输出的词汇和句法因素，尽管 RLHF 等对齐方法已得到开发。", "motivation": "尽管注意力机制和 Transformer 模型在 NLP 领域取得了巨大进展，但大型语言模型仍然会生成不当、冒犯性或有害的“有毒”内容，即使有 RLHF 等对齐方法，这些方法也可能被规避。", "method": "通过精心设计的提示来诱导 LLM 生成有毒内容，并分析影响这些输出的词汇和句法因素。", "result": "（摘要中未具体说明，但暗示了 LLM 在特定提示下确实会生成有毒内容，并且存在影响其产生的词汇和句法因素）", "conclusion": "本研究旨在评估 LLM 生成有毒内容的倾向，并确定影响此类输出的语言学特征，从而改进对齐方法以防止有害内容。"}}
{"id": "2601.07123", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07123", "abs": "https://arxiv.org/abs/2601.07123", "authors": ["Ruichu Cai", "Haopeng Du", "Qingwen Lin", "Yutong Chen", "Zijian Li", "Boyan Xu"], "title": "ENTRA: Entropy-Based Redundancy Avoidance in Large Language Model Reasoning", "comment": null, "summary": "Large Reasoning Models (LRMs) often suffer from overthinking, generating unnecessarily long reasoning chains even for simple tasks. This leads to substantial computational overhead with limited performance gain, primarily due to redundant verification and repetitive generation. While prior work typically constrains output length or optimizes correctness, such coarse supervision fails to guide models toward concise yet accurate inference. In this paper, we propose ENTRA, an entropy-based training framework that suppresses redundant reasoning while preserving performance. ENTRA first estimates the token-level importance using a lightweight Bidirectional Importance Estimation (BIE) method, which accounts for both prediction confidence and forward influence. It then computes a redundancy reward based on the entropy of low-importance tokens, normalized by its theoretical upper bound, and optimizes this reward via reinforcement learning. Experiments on mathematical reasoning benchmarks demonstrate that ENTRA reduces output length by 37% to 53% with no loss-and in some cases, gains-in accuracy. Our approach offers a principled and efficient solution to reduce overthinking in LRMs, and provides a generalizable path toward redundancy-aware reasoning optimization.", "AI": {"tldr": "提出了一种名为ENTRA的基于熵的训练框架，通过抑制冗余推理来减少大型推理模型（LRMs）的过度思考，同时保持甚至提高其性能。", "motivation": "大型推理模型（LRMs）在处理简单任务时会产生过长的推理链，导致计算开销大且性能提升有限，主要是由于冗余验证和重复生成。现有的方法（如限制输出长度或优化正确性）未能有效地引导模型生成简洁而准确的推理。", "method": "ENTRA框架首先使用一种轻量级的双向重要性估计（BIE）方法来估算token级别的重要性，该方法考虑了预测置信度和前向影响。然后，通过计算低重要性token的熵来得到一个冗余奖励，并将其与理论上限进行归一化。最后，通过强化学习优化这个奖励。", "result": "在数学推理基准测试上的实验表明，ENTRA可以将输出长度减少37%至53%，同时保持甚至在某些情况下提高了准确性。", "conclusion": "ENTRA提供了一种原则性且高效的解决方案，用于减少LRMs的过度思考，并为实现冗余感知的推理优化提供了一条可推广的途径。"}}
{"id": "2601.06793", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06793", "abs": "https://arxiv.org/abs/2601.06793", "authors": ["Zhongping Ji"], "title": "CliffordNet: All You Need is Geometric Algebra", "comment": "15 pages", "summary": "Modern computer vision architectures, from CNNs to Transformers, predominantly rely on the stacking of heuristic modules: spatial mixers (Attention/Conv) followed by channel mixers (FFNs). In this work, we challenge this paradigm by returning to mathematical first principles. We propose the \\textbf{Clifford Algebra Network (CAN)}, also referred to as CliffordNet, a vision backbone grounded purely in Geometric Algebra. Instead of engineering separate modules for mixing and memory, we derive a unified interaction mechanism based on the \\textbf{Clifford Geometric Product} ($uv = u \\cdot v + u \\wedge v$). This operation ensures algebraic completeness regarding the Geometric Product by simultaneously capturing feature coherence (via the generalized inner product) and structural variation (via the exterior wedge product).\n  Implemented via an efficient sparse rolling mechanism with \\textbf{strict linear complexity $\\mathcal{O}(N)$}, our model reveals a surprising emergent property: the geometric interaction is so representationally dense that standard Feed-Forward Networks (FFNs) become redundant. Empirically, CliffordNet establishes a new Pareto frontier: our \\textbf{Nano} variant achieves \\textbf{76.41\\%} accuracy on CIFAR-100 with only \\textbf{1.4M} parameters, effectively matching the heavy-weight ResNet-18 (11.2M) with \\textbf{$8\\times$ fewer parameters}, while our \\textbf{Base} variant sets a new SOTA for tiny models at \\textbf{78.05\\%}. Our results suggest that global understanding can emerge solely from rigorous, algebraically complete local interactions, potentially signaling a shift where \\textit{geometry is all you need}. Code is available at https://github.com/ParaMind2025/CAN.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.06831", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06831", "abs": "https://arxiv.org/abs/2601.06831", "authors": ["Jee Won Lee", "Hansol Lim", "Minhyeok Im", "Dohyeon Lee", "Jongseong Brad Choi"], "title": "SARA: Scene-Aware Reconstruction Accelerator", "comment": "This work has been submitted to the 2026 International Conference on Pattern Recognition (ICPR) for possible publication", "summary": "We present SARA (Scene-Aware Reconstruction Accelerator), a geometry-driven pair selection module for Structure-from-Motion (SfM). Unlike conventional pipelines that select pairs based on visual similarity alone, SARA introduces geometry-first pair selection by scoring reconstruction informativeness - the product of overlap and parallax - before expensive matching. A lightweight pre-matching stage uses mutual nearest neighbors and RANSAC to estimate these cues, then constructs an Information-Weighted Spanning Tree (IWST) augmented with targeted edges for loop closure, long-baseline anchors, and weak-view reinforcement. Compared to exhaustive matching, SARA reduces rotation errors by 46.5+-5.5% and translation errors by 12.5+-6.5% across modern learned detectors, while achieving at most 50x speedup through 98% pair reduction (from 30,848 to 580 pairs). This reduces matching complexity from quadratic to quasi-linear, maintaining within +-3% of baseline reconstruction metrics for 3D Gaussian Splatting and SVRaster.", "AI": {"tldr": "SARA是一种新的几何驱动的 SfM 对选择模块，通过在进行昂贵匹配之前评估重建信息量（重叠度和视差的乘积）来优化对选择，显著提高了效率和准确性。", "motivation": "现有的 SfM 管线仅依赖视觉相似性进行对选择，效率低下且可能导致不准确的重建。研究人员旨在通过一种几何优先的方法来改进这一过程，以提高准确性并大幅缩短处理时间。", "method": "SARA 采用几何优先的对选择策略。首先，通过互近邻和 RANSAC 预估重叠度和视差。然后，构建一个信息加权跨越树（IWST），并加入针对闭环、长基线锚点和弱视图的边。最后，利用这些选择的对进行匹配，用于后续的 3D 高斯溅射和 SVRaster 重建。", "result": "与穷举匹配相比，SARA 将旋转误差降低了 46.5±5.5%，平移误差降低了 12.5±6.5%。通过将对的数量减少 98%（从 30,848 对减少到 580 对），SARA 实现了高达 50 倍的加速，并将匹配复杂度从二次方降低到近线性。同时，在 3D 高斯溅射和 SVRaster 的重建指标上，SARA 保持了与基线误差在 3% 以内。", "conclusion": "SARA 是一种高效且准确的几何驱动对选择方法，能够显著提高 SfM 流程的效率和重建质量，同时大幅减少计算开销。"}}
{"id": "2601.07149", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07149", "abs": "https://arxiv.org/abs/2601.07149", "authors": ["Zhaoyan Li", "Hang Lei", "Yujia Wang", "Lanbo Liu", "Hao Liu", "Liang Yu"], "title": "Rewarding Creativity: A Human-Aligned Generative Reward Model for Reinforcement Learning in Storytelling", "comment": null, "summary": "While Large Language Models (LLMs) can generate fluent text, producing high-quality creative stories remains challenging. Reinforcement Learning (RL) offers a promising solution but faces two critical obstacles: designing reliable reward signals for subjective storytelling quality and mitigating training instability. This paper introduces the Reinforcement Learning for Creative Storytelling (RLCS) framework to systematically address both challenges. First, we develop a Generative Reward Model (GenRM) that provides multi-dimensional analysis and explicit reasoning about story preferences, trained through supervised fine-tuning on demonstrations with reasoning chains distilled from strong teacher models, followed by GRPO-based refinement on expanded preference data. Second, we introduce an entropy-based reward shaping strategy that dynamically prioritizes learning on confident errors and uncertain correct predictions, preventing overfitting on already-mastered patterns. Experiments demonstrate that GenRM achieves 68\\% alignment with human creativity judgments, and RLCS significantly outperforms strong baselines including Gemini-2.5-Pro in overall story quality. This work provides a practical pipeline for applying RL to creative domains, effectively navigating the dual challenges of reward modeling and training stability.", "AI": {"tldr": "本文提出RLCS框架，通过生成奖励模型（GenRM）和基于熵的奖励塑造策略，解决了大型语言模型生成高质量创意故事中的奖励信号设计和训练不稳定性问题。", "motivation": "大型语言模型在生成流畅文本方面表现出色，但在创作高质量创意故事方面仍面临挑战，这主要源于难以设计用于主观故事质量评估的可靠奖励信号以及训练过程中的不稳定性。", "method": "本文提出了RLCS框架，包含两个关键部分：1. 生成奖励模型（GenRM），通过监督微调和GRPO优化，对故事偏好进行多维度分析和显式推理。2. 基于熵的奖励塑造策略，动态调整学习过程，关注“有把握的错误”和“不确定的正确预测”，以防止过拟合。", "result": "GenRM在人类创造力判断方面达到了68%的一致性。RLCS框架在整体故事质量上显著优于包括Gemini-2.5-Pro在内的强基线模型。", "conclusion": "该研究提供了一个将强化学习应用于创意领域的实用流程，有效解决了奖励建模和训练稳定性这两个关键挑战，提升了大型语言模型在创意故事生成方面的能力。"}}
{"id": "2601.06834", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06834", "abs": "https://arxiv.org/abs/2601.06834", "authors": ["Chenglong Bao", "Tongyao Pang", "Zuowei Shen", "Dihan Zheng", "Yihang Zou"], "title": "Enhancing Low-resolution Image Representation Through Normalizing Flows", "comment": null, "summary": "Low-resolution image representation is a special form of sparse representation that retains only low-frequency information while discarding high-frequency components. This property reduces storage and transmission costs and benefits various image processing tasks. However, a key challenge is to preserve essential visual content while maintaining the ability to accurately reconstruct the original images. This work proposes LR2Flow, a nonlinear framework that learns low-resolution image representations by integrating wavelet tight frame blocks with normalizing flows. We conduct a reconstruction error analysis of the proposed network, which demonstrates the necessity of designing invertible neural networks in the wavelet tight frame domain. Experimental results on various tasks, including image rescaling, compression, and denoising, demonstrate the effectiveness of the learned representations and the robustness of the proposed framework.", "AI": {"tldr": "提出了一种名为LR2Flow的非线性框架，通过结合小波紧框架和归一化流来学习低分辨率图像表示，并在图像重缩放、压缩和去噪任务上取得了有效的结果。", "motivation": "低分辨率图像表示可以降低存储和传输成本，但如何在减少信息的同時保留关键视觉内容并准确重建原始图像是一个挑战。", "method": "利用小波紧框架和归一化流构建了一个非线性框架LR2Flow，并进行了重构误差分析，证明了在小波紧框架域设计可逆神经网络的必要性。", "result": "在图像重缩放、压缩和去噪任务上，LR2Flow学习到的低分辨率图像表示被证明是有效的，并且该框架表现出良好的鲁棒性。", "conclusion": "LR2Flow框架成功地学习了低分辨率图像表示，在不丢失关键视觉信息的情况下实现了有效的图像重建，并在多个图像处理任务中验证了其有效性和鲁棒性。"}}
{"id": "2601.06702", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06702", "abs": "https://arxiv.org/abs/2601.06702", "authors": ["Besher Hassan", "Xiuying Chen"], "title": "GRASP LoRA: GRPO Guided Adapter Sparsity Policy for Cross Lingual Transfer", "comment": "12 pages, 3 figures", "summary": "Parameter efficient fine tuning is a way to adapt LLMs to new languages when compute or data are limited, yet adapter pipelines usually choose a global prune ratio by grid search. This practice is computationally expensive and development set intensive, since it repeats training, freezes sparsity, and misses fractional optima. We introduce GRASP LoRA (GRPO Guided Adapter Sparsity Policy), which treats global sparsity as a learnable control variable. A GRPO controller interleaves with training, periodically probing candidate prune ratios on a small micro development set and updating a single global prune ratio online from its reward signal. It operates on merged source and target LoRA adapters on a frozen backbone and replaces grid search with one controller run that learns a prune ratio, followed by a single final merge and prune fine tuning run with pruning fixed to that ratio. On cross lingual transfer from English into Arabic and Chinese, including XL-Sum summarization and MLQA extractive question answering with Llama 3 8B, GRASP LoRA improves semantic faithfulness, content coverage, and answer quality over strong target only and merge and prune baselines. It reduces end to end runtime by multiple times relative to grid search, lowers reliance on large development sets, and makes adapter reuse practical for low resource deployment.", "AI": {"tldr": "提出了一种名为 GRASP LoRA 的新方法，将全局稀疏性视为一个可学习的控制变量，用于参数高效的微调，通过 GRPO 控制器在线学习最佳剪枝比例，从而在计算和数据受限的情况下实现跨语言迁移，提高了语义忠实度、内容覆盖率和答案质量，并显著减少了运行时长和对开发集的依赖。", "motivation": "传统的适配器管道在参数高效微调中通常采用全局剪枝比例进行网格搜索，这种方法计算成本高昂且依赖大量开发集，并且可能错过最优的局部剪枝比例。作者希望找到一种更有效率且性能更好的方法来确定全局剪枝比例。", "method": "提出 GRASP LoRA (GRPO Guided Adapter Sparsity Policy)，将全局稀疏性作为可学习的控制变量。一个 GRPO 控制器与训练交织进行，周期性地在一个小的微型开发集上探测候选剪枝比例，并从奖励信号中在线更新单一全局剪枝比例。该方法在冻结的骨干网络上操作合并的源和目标 LoRA 适配器，用一次控制器运行取代网格搜索，该控制器运行学习一个剪枝比例，随后进行一次固定的剪枝微调。", "result": "在从英语到阿拉伯语和中文的跨语言迁移任务（包括 XL-Sum 摘要和 MLQA 提取式问答），使用 Llama 3 8B 进行实验。GRASP LoRA 在语义忠实度、内容覆盖率和答案质量方面优于仅针对目标语言的适配器和合并剪枝的基线方法。同时，与网格搜索相比，端到端运行时长减少了数倍，对大型开发集的依赖性降低，并使得适配器重用对于低资源部署更加实用。", "conclusion": "GRASP LoRA 是一种有效的方法，可以将全局稀疏性作为可学习的控制变量，用于参数高效的微调。它通过 GRPO 控制器实现了更高效的剪枝比例学习，在跨语言迁移任务中取得了优于现有方法的性能，并显著降低了计算和数据资源的需求，使其成为低资源场景下适配器重用的可行方案。"}}
{"id": "2601.06707", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06707", "abs": "https://arxiv.org/abs/2601.06707", "authors": ["Jie Zhou", "Xin Chen", "Jie Zhang", "Hai Li", "Jie Wang", "Zhe Li"], "title": "Evaluating Accounting Reasoning Capabilities of Large Language Models", "comment": null, "summary": "Large language models are transforming learning, cognition, and research across many fields. Effectively integrating them into professional domains, such as accounting, is a key challenge for enterprise digital transformation. To address this, we define vertical domain accounting reasoning and propose evaluation criteria derived from an analysis of the training data characteristics of representative GLM models. These criteria support systematic study of accounting reasoning and provide benchmarks for performance improvement. Using this framework, we evaluate GLM-6B, GLM-130B, GLM-4, and OpenAI GPT-4 on accounting reasoning tasks. Results show that prompt design significantly affects performance, with GPT-4 demonstrating the strongest capability. Despite these gains, current models remain insufficient for real-world enterprise accounting, indicating the need for further optimization to unlock their full practical value.", "AI": {"tldr": "研究人员为大语言模型在会计领域的应用定义了垂直领域会计推理，并提出了评估标准。通过使用这些标准评估了GLM和GPT-4模型，发现GPT-4表现最佳，但仍不足以满足企业会计的实际需求，需要进一步优化。", "motivation": "大型语言模型在各个领域具有变革潜力，但将其有效集成到会计等专业领域以推动企业数字化转型是一个关键挑战。", "method": "研究人员定义了垂直领域会计推理，并基于对代表性GLM模型训练数据特征的分析，提出了评估标准。然后，他们使用此框架在会计推理任务上评估了GLM-6B、GLM-130B、GLM-4和OpenAI GPT-4模型。", "result": "研究结果表明，提示词设计对模型性能有显著影响。在被评估的模型中，GPT-4展现出最强的会计推理能力。然而，目前的模型在满足实际企业会计需求方面仍然存在不足。", "conclusion": "尽管GPT-4在会计推理任务上表现出最强能力，但当前的大型语言模型尚未完全达到企业会计的实际应用要求，未来需要进一步的优化来充分发挥其潜力。"}}
{"id": "2601.07160", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07160", "abs": "https://arxiv.org/abs/2601.07160", "authors": ["Xinzi Cao", "Jianyang Zhai", "Pengfei Li", "Zhiheng Hu", "Cen Yan", "Bingxu Mu", "Guanghuan Fang", "Bin She", "Jiayu Li", "Yihan Su", "Dongyang Tao", "Xiansong Huang", "Fan Xu", "Feidiao Yang", "Yao Lu", "Chang-Dong Wang", "Yutong Lu", "Weicheng Xue", "Bin Zhou", "Yonghong Tian"], "title": "AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units", "comment": "33 pages,7 figures,16 tables", "summary": "To meet the ever-increasing demand for computational efficiency, Neural Processing Units (NPUs) have become critical in modern AI infrastructure. However, unlocking their full potential requires developing high-performance compute kernels using vendor-specific Domain-Specific Languages (DSLs), a task that demands deep hardware expertise and is labor-intensive. While Large Language Models (LLMs) have shown promise in general code generation, they struggle with the strict constraints and scarcity of training data in the NPU domain. Our preliminary study reveals that state-of-the-art general-purpose LLMs fail to generate functional complex kernels for Ascend NPUs, yielding a near-zero success rate. To address these challenges, we propose AscendKernelGen, a generation-evaluation integrated framework for NPU kernel development. We introduce Ascend-CoT, a high-quality dataset incorporating chain-of-thought reasoning derived from real-world kernel implementations, and KernelGen-LM, a domain-adaptive model trained via supervised fine-tuning and reinforcement learning with execution feedback. Furthermore, we design NPUKernelBench, a comprehensive benchmark for assessing compilation, correctness, and performance across varying complexity levels. Experimental results demonstrate that our approach significantly bridges the gap between general LLMs and hardware-specific coding. Specifically, the compilation success rate on complex Level-2 kernels improves from 0% to 95.5% (Pass@10), while functional correctness achieves 64.3% compared to the baseline's complete failure. These results highlight the critical role of domain-specific reasoning and rigorous evaluation in automating accelerator-aware code generation.", "AI": {"tldr": "本研究提出了AscendKernelGen框架，一个集成了生成和评估的NPU（神经网络处理单元）内核开发方案。通过构建包含链式思考推理的数据集Ascend-CoT，并利用领域自适应模型KernelGen-LM，以及引入NPUKernelBench基准测试，显著提升了针对Ascend NPU的内核代码生成能力，解决了通用LLM在该领域的局限性。", "motivation": "通用LLM在NPU领域生成高性能内核代码面临挑战，因为NPU需要使用特定硬件的DSL，并且相关训练数据稀缺。现有研究表明，通用LLM在生成Ascend NPU的复杂内核时成功率接近于零，这阻碍了NPU潜力的发挥。", "method": "提出了AscendKernelGen框架，该框架包含：1. Ascend-CoT数据集，包含从实际内核实现中提取的链式思考推理过程。2. KernelGen-LM，一个通过监督微调和基于执行反馈的强化学习进行训练的领域自适应模型。3. NPUKernelBench，一个用于评估编译、正确性和性能的基准测试套件。", "result": "在Level-2复杂内核上，AscendKernelGen将编译成功率从0%提升到95.5%（Pass@10），并将功能正确性从0%提升到64.3%。", "conclusion": "本研究证明了领域特定推理和严格评估在自动化加速器感知代码生成方面的重要性。AscendKernelGen框架和相关技术能够有效弥合通用LLM在NPU内核开发领域的性能差距。"}}
{"id": "2601.06835", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06835", "abs": "https://arxiv.org/abs/2601.06835", "authors": ["Hyunseo Lee", "Sang Min Kim", "Ho Kyung Shin", "Taeheon Kim", "Woo-Jeoung Nam"], "title": "OSCAR: Optical-aware Semantic Control for Aleatoric Refinement in Sar-to-Optical Translation", "comment": "main 15 pages, supplementary 5 pages", "summary": "Synthetic Aperture Radar (SAR) provides robust all-weather imaging capabilities; however, translating SAR observations into photo-realistic optical images remains a fundamentally ill-posed problem. Current approaches are often hindered by the inherent speckle noise and geometric distortions of SAR data, which frequently result in semantic misinterpretation, ambiguous texture synthesis, and structural hallucinations. To address these limitations, a novel SAR-to-Optical (S2O) translation framework is proposed, integrating three core technical contributions: (i) Cross-Modal Semantic Alignment, which establishes an Optical-Aware SAR Encoder by distilling robust semantic priors from an Optical Teacher into a SAR Student (ii) Semantically-Grounded Generative Guidance, realized by a Semantically-Grounded ControlNet that integrates class-aware text prompts for global context with hierarchical visual prompts for local spatial guidance; and (iii) an Uncertainty-Aware Objective, which explicitly models aleatoric uncertainty to dynamically modulate the reconstruction focus, effectively mitigating artifacts caused by speckle-induced ambiguity. Extensive experiments demonstrate that the proposed method achieves superior perceptual quality and semantic consistency compared to state-of-the-art approaches.", "AI": {"tldr": "提出了一种新颖的SAR到光学图像翻译框架，通过跨模态语义对齐、语义引导生成以及不确定性感知目标来解决SAR数据的固有噪声和几何畸变问题，从而生成更高质量和语义一致的光学图像。", "motivation": "当前的SAR到光学图像翻译方法受限于SAR数据固有的斑点噪声和几何畸变，导致语义误解、纹理合成模糊和结构幻觉。本研究旨在克服这些限制，生成更逼真、语义一致的光学图像。", "method": "提出了一种整合了三个核心技术贡献的SAR到光学（S2O）翻译框架：1. 跨模态语义对齐（构建光学感知SAR编码器，从光学教师模型中提取语义先验到SAR学生模型）；2. 语义引导生成（使用语义引导ControlNet，整合类别感知文本提示和层级视觉提示）；3. 不确定性感知目标（明确建模随机不确定性，动态调节重建焦点）。", "result": "所提出的方法在感知质量和语义一致性方面优于现有最先进的方法。", "conclusion": "该框架能够有效地缓解由SAR数据噪声引起的伪影，生成更高质量和语义一致的光学图像，证明了其在SAR到光学图像翻译任务上的优越性。"}}
{"id": "2601.06753", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06753", "abs": "https://arxiv.org/abs/2601.06753", "authors": ["Yiran Rex Ma"], "title": "Towards Computational Chinese Paleography", "comment": "A position paper in progress with Peking University & ByteDance Digital Humanities Open Lab", "summary": "Chinese paleography, the study of ancient Chinese writing, is undergoing a computational turn powered by artificial intelligence. This position paper charts the trajectory of this emerging field, arguing that it is evolving from automating isolated visual tasks to creating integrated digital ecosystems for scholarly research. We first map the landscape of digital resources, analyzing critical datasets for oracle bone, bronze, and bamboo slip scripts. The core of our analysis follows the field's methodological pipeline: from foundational visual processing (image restoration, character recognition), through contextual analysis (artifact rejoining, dating), to the advanced reasoning required for automated decipherment and human-AI collaboration. We examine the technological shift from classical computer vision to modern deep learning paradigms, including transformers and large multimodal models. Finally, we synthesize the field's core challenges -- notably data scarcity and a disconnect between current AI capabilities and the holistic nature of humanistic inquiry -- and advocate for a future research agenda focused on creating multimodal, few-shot, and human-centric systems to augment scholarly expertise.", "AI": {"tldr": "本文探讨了人工智能如何推动中国古文字学的发展，从孤立的任务自动化转向构建集成的数字研究生态系统。文章分析了现有数字资源和方法论，关注从视觉处理到自动释读的演变，并探讨了深度学习的应用。最后，文章指出了数据稀缺和AI与人文学科需求脱节等挑战，并提出了未来研究方向。", "motivation": "古文字学领域正在经历计算化转型，作者希望描绘这一新兴领域的发展轨迹，并论证其从自动化到集成研究生态系统的演变。", "method": "文章首先梳理了甲骨文、青铜器铭文和竹简等关键数据集。随后，分析了该领域的方法论流程，包括视觉处理（图像修复、字符识别）、情境分析（器物拼合、年代测定）以及自动释读和人机协作所需的先进推理。文章还考察了从经典计算机视觉到深度学习（包括Transformer和大型多模态模型）的技术转变。", "result": "AI在古文字学中已从简单的视觉任务自动化发展，并正在构建一个更集成的数字研究生态系统。深度学习技术，特别是Transformer和大型多模态模型，在古文字分析中展现出巨大潜力。", "conclusion": "古文字学的计算化转型面临数据稀缺和AI能力与人文学科需求的脱节等核心挑战。未来的研究应专注于开发多模态、少样本和以人为中心的人工智能系统，以增强学者的专业能力。"}}
{"id": "2601.07190", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07190", "abs": "https://arxiv.org/abs/2601.07190", "authors": ["Nikhil Verma"], "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "comment": "8 pages, 2 figures, 2 tables. IEEE conference format", "summary": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors. Existing solutions often rely on passive, external summarization mechanisms that the agent cannot control. This paper proposes Focus, an agent-centric architecture inspired by the biological exploration strategies of Physarum polycephalum (slime mold). The Focus Agent autonomously decides when to consolidate key learnings into a persistent \"Knowledge\" block and actively withdraws (prunes) the raw interaction history. Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. With aggressive prompting that encourages frequent compression, Focus achieves 22.7% token reduction (14.9M -> 11.5M tokens) while maintaining identical accuracy (3/5 = 60% for both agents). Focus performed 6.0 autonomous compressions per task on average, with token savings up to 57% on individual instances. We demonstrate that capable models can autonomously self-regulate their context when given appropriate tools and prompting, opening pathways for cost-aware agentic systems without sacrificing task performance.", "AI": {"tldr": "提出了一种名为 Focus 的 LLM agent 架构，通过模仿史莱姆菌的探索策略，自主管理上下文，在保持相同准确率的情况下，显著减少了 token 使用量，为构建成本效益高的 agent 系统提供了新途径。", "motivation": "大型语言模型 (LLM) agents 在处理长时序软件工程任务时，面临“上下文膨胀”问题，导致计算成本、延迟增加，并因无关信息的干扰而降低推理能力。现有解决方案通常依赖于 agent 无法控制的被动外部摘要机制。", "method": "提出 Focus Agent，一种 agent 中心架构，灵感来自史莱姆菌的生物学探索策略。Focus Agent 自主决定何时将关键学习内容整合到持久的“知识”块中，并主动修剪原始交互历史。使用行业最佳实践（持久 bash + 字符串替换编辑器）的优化脚手架，在 SWE-bench Lite 的 5 个上下文密集型实例上，使用 Claude Haiku 4.5 进行了评估。", "result": "Focus Agent 实现了 22.7% 的 token 缩减（从 14.9M 减少到 11.5M），同时保持了相同的准确率（3/5 = 60%）。平均每个任务执行 6.0 次自主压缩，单实例 token 节省最高可达 57%。", "conclusion": "研究表明，当具备合适的工具和提示时，能够自主调节上下文的 LLM agent 可以在不牺牲任务性能的情况下，实现成本效益更高的 agent 系统。"}}
{"id": "2601.06839", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06839", "abs": "https://arxiv.org/abs/2601.06839", "authors": ["Hansol Lim", "Minhyeok Im", "Jongseong Brad Choi"], "title": "PRISM: Color-Stratified Point Cloud Sampling", "comment": "This work has been submitted to the 2026 International Conference on Pattern Recognition (ICPR) for possible publication", "summary": "We present PRISM, a novel color-guided stratified sampling method for RGB-LiDAR point clouds. Our approach is motivated by the observation that unique scene features often exhibit chromatic diversity while repetitive, redundant features are homogeneous in color. Conventional downsampling methods (Random Sampling, Voxel Grid, Normal Space Sampling) enforce spatial uniformity while ignoring this photometric content. In contrast, PRISM allocates sampling density proportional to chormatic diversity. By treating RGB color space as the stratification domain and imposing a maximum capacity k per color bin, the method preserves texture-rich regions with high color variation while substantially reducing visually homogeneous surfaces. This shifts the sampling space from spatial coverage to visual complexity to produce sparser point clouds that retain essential features for 3D reconstruction tasks.", "AI": {"tldr": "提出了一种名为PRISM的新型颜色引导分层采样方法，用于RGB-LiDAR点云，通过根据颜色多样性分配采样密度来保留纹理丰富区域，同时减少视觉上同质的表面，以实现更稀疏但保留关键特征的点云。", "motivation": "观察到独特的场景特征通常具有色彩多样性，而重复、冗余的特征在颜色上是均匀的。现有的下采样方法忽略了这种光度信息，PRISM旨在利用颜色信息来更有效地进行点云采样。", "method": "PRISM方法将RGB颜色空间视为分层域，并对每个颜色bin施加最大容量k。采样密度与色彩多样性成比例分配，将采样空间从空间覆盖转移到视觉复杂度。", "result": "PRISM能够保留具有高颜色变化的纹理丰富区域，同时大幅减少视觉上同质的表面，生成更稀疏的点云，但能保留对3D重建任务至关重要的特征。", "conclusion": "PRISM是一种新颖的颜色引导分层采样方法，能够比传统的空间均匀性方法更有效地在RGB-LiDAR点云中保留关键的几何和纹理信息，适用于3D重建任务。"}}
{"id": "2601.06843", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06843", "abs": "https://arxiv.org/abs/2601.06843", "authors": ["Junyan Lin", "Junlong Tong", "Hao Wu", "Jialiang Zhang", "Jinming Liu", "Xin Jin", "Xiaoyu Shen"], "title": "Speak While Watching: Unleashing TRUE Real-Time Video Understanding Capability of Multimodal Large Language Models", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have achieved strong performance across many tasks, yet most systems remain limited to offline inference, requiring complete inputs before generating outputs. Recent streaming methods reduce latency by interleaving perception and generation, but still enforce a sequential perception-generation cycle, limiting real-time interaction. In this work, we target a fundamental bottleneck that arises when extending MLLMs to real-time video understanding: the global positional continuity constraint imposed by standard positional encoding schemes. While natural in offline inference, this constraint tightly couples perception and generation, preventing effective input-output parallelism. To address this limitation, we propose a parallel streaming framework that relaxes positional continuity through three designs: Overlapped, Group-Decoupled, and Gap-Isolated. These designs enable simultaneous perception and generation, allowing the model to process incoming inputs while producing responses in real time. Extensive experiments reveal that Group-Decoupled achieves the best efficiency-performance balance, maintaining high fluency and accuracy while significantly reducing latency. We further show that the proposed framework yields up to 2x acceleration under balanced perception-generation workloads, establishing a principled pathway toward speak-while-watching real-time systems. We make all our code publicly available: https://github.com/EIT-NLP/Speak-While-Watching.", "AI": {"tldr": "本研究提出了一种用于多模态大语言模型（MLLMs）的并行流式框架，通过放松位置连续性约束，实现了实时视频理解中的感知和生成并行化，显著降低了延迟。", "motivation": "现有的流式MLLMs仍然受到顺序感知-生成周期的限制，无法实现真正的实时交互。主要瓶颈在于标准位置编码方案带来的全局位置连续性约束，这紧密耦合了感知和生成，阻碍了输入-输出的并行化。", "method": "提出了一种并行流式框架，通过三种设计（Overlapped, Group-Decoupled, Gap-Isolated）放松了位置连续性约束，实现了感知和生成的并行处理。", "result": "实验表明，Group-Decoupled设计在效率和性能之间取得了最佳平衡，保持了高流畅度和准确性，同时显著降低了延迟。该框架在平衡的感知-生成工作负载下可实现高达2倍的加速。", "conclusion": "提出的并行流式框架为实现“边看边说”的实时系统提供了一条原则性的途径，克服了传统MLLMs在实时视频理解中的延迟瓶颈。"}}
{"id": "2601.06757", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06757", "abs": "https://arxiv.org/abs/2601.06757", "authors": ["Zheyuan Liu", "Dongwhi Kim", "Yixin Wan", "Xiangchi Yuan", "Zhaoxuan Tan", "Fengran Mo", "Meng Jiang"], "title": "MTMCS-Bench: Evaluating Contextual Safety of Multimodal Large Language Models in Multi-Turn Dialogues", "comment": "A benchmark of realistic images and multi-turn conversations that evaluates contextual safety in MLLMs under two complementary settings", "summary": "Multimodal large language models (MLLMs) are increasingly deployed as assistants that interact through text and images, making it crucial to evaluate contextual safety when risk depends on both the visual scene and the evolving dialogue. Existing contextual safety benchmarks are mostly single-turn and often miss how malicious intent can emerge gradually or how the same scene can support both benign and exploitative goals. We introduce the Multi-Turn Multimodal Contextual Safety Benchmark (MTMCS-Bench), a benchmark of realistic images and multi-turn conversations that evaluates contextual safety in MLLMs under two complementary settings, escalation-based risk and context-switch risk. MTMCS-Bench offers paired safe and unsafe dialogues with structured evaluation. It contains over 30 thousand multimodal (image+text) and unimodal (text-only) samples, with metrics that separately measure contextual intent recognition, safety-awareness on unsafe cases, and helpfulness on benign ones. Across eight open-source and seven proprietary MLLMs, we observe persistent trade-offs between contextual safety and utility, with models tending to either miss gradual risks or over-refuse benign dialogues. Finally, we evaluate five current guardrails and find that they mitigate some failures but do not fully resolve multi-turn contextual risks.", "AI": {"tldr": "本研究提出了一个名为MTMCS-Bench的多轮多模态上下文安全基准，用于评估大型多模态模型（MLLMs）在结合图像和多轮对话时的安全性，并发现现有模型在处理渐进式风险和避免误拒绝方面存在挑战，现有的安全护栏也未能完全解决这些问题。", "motivation": "现有的大型多模态模型（MLLMs）评估基准大多是单轮的，无法充分捕捉到恶意意图如何随着多轮对话逐渐产生，也无法区分同一场景下支持良性和剥削性目标的可能性。因此，需要一个能够评估多轮对话和图像结合上下文安全性的基准。", "method": "研究者提出了MTMCS-Bench基准，包含逼真的图像和多轮对话。该基准在两种设置下评估上下文安全：升级风险和上下文切换风险。它提供了成对的安全和不安全对话，并进行结构化评估。基准包含超过3万个多模态和单模态样本，并设计了单独衡量上下文意图识别、不安全案例的安全意识以及良性案例有用性的指标。", "result": "在对八个开源和七个专有MLLMs的评估中，研究者观察到上下文安全性和实用性之间存在持续的权衡。模型倾向于要么错过渐进式风险，要么过度拒绝良性对话。对五种现有安全护栏的评估表明，它们能在一定程度上缓解部分失败，但未能完全解决多轮上下文风险。", "conclusion": "大型多模态模型在处理多轮对话和图像结合的上下文安全方面存在挑战，普遍存在安全性和实用性之间的权衡问题。现有的安全护栏机制不足以完全解决这些多轮上下文安全风险。"}}
{"id": "2601.07224", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07224", "abs": "https://arxiv.org/abs/2601.07224", "authors": ["Yang Zhao", "Yangou Ouyang", "Xiao Ding", "Hepeng Wang", "Bibo Cai", "Kai Xiong", "Jinglong Gao", "Zhouhao Sun", "Li Du", "Bing Qin", "Ting Liu"], "title": "Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration", "comment": null, "summary": "While Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has become the standard paradigm for training LLM agents, effective mechanisms for data allocation between these stages remain largely underexplored. Current data arbitration strategies often rely on surface-level heuristics that fail to diagnose intrinsic learning needs. Since SFT targets pattern consolidation through imitation while RL drives structural adaptation via exploration, misaligning data with these functional roles causes severe optimization interference. We propose PRISM, a dynamics-aware framework grounded in Schema Theory that arbitrates data based on its degree of cognitive conflict with the model's existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring. In contrast, data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22$\\times$. Our findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment.", "AI": {"tldr": "本文提出了一种名为PRISM的数据分配框架，用于优化大型语言模型（LLM）智能体的训练。PRISM基于图示理论，通过分析梯度几何结构来区分需要结构性重塑（RL）和模式巩固（SFT）的数据，实现了比现有方法更优越的性能和更高的计算效率。", "motivation": "当前LLM智能体训练中，SFT和RL阶段的数据分配机制研究不足，现有方法依赖表面启发式规则，未能有效识别模型内在的学习需求。不当的数据分配会导致优化干扰，影响训练效果。", "method": "PRISM框架基于图示理论，通过分析模型梯度的空间几何结构来判断数据的“认知冲突”程度。高空间集中的梯度信号被识别为高冲突数据，适合RL进行结构性重塑；而梯度扩散的数据则被路由到SFT进行模式巩固。", "result": "在WebShop和ALFWorld上的实验表明，PRISM取得了帕累托改进，性能优于最先进的混合方法，并将计算成本降低了高达3.22倍。", "conclusion": "将数据根据其内在优化机制进行分离，对于实现可扩展且鲁棒的智能体对齐至关重要。PRISM通过动态感知的数据分配，有效解决了LLM智能体训练中的数据分配难题。"}}
{"id": "2601.07206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07206", "abs": "https://arxiv.org/abs/2601.07206", "authors": ["Hao Li", "Yiqun Zhang", "Zhaoyan Guo", "Chenxu Wang", "Shengji Tang", "Qiaosheng Zhang", "Yang Chen", "Biqing Qi", "Peng Ye", "Lei Bai", "Zhen Wang", "Shuyue Hu"], "title": "LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing", "comment": null, "summary": "Large language model (LLM) routing assigns each query to the most suitable model from an ensemble. We introduce LLMRouterBench, a large-scale benchmark and unified framework for LLM routing. It comprises over 400K instances from 21 datasets and 33 models. Moreover, it provides comprehensive metrics for both performance-oriented routing and performance-cost trade-off routing, and integrates 10 representative routing baselines. Using LLMRouterBench, we systematically re-evaluate the field. While confirming strong model complementarity-the central premise of LLM routing-we find that many routing methods exhibit similar performance under unified evaluation, and several recent approaches, including commercial routers, fail to reliably outperform a simple baseline. Meanwhile, a substantial gap remains to the Oracle, driven primarily by persistent model-recall failures. We further show that backbone embedding models have limited impact, that larger ensembles exhibit diminishing returns compared to careful model curation, and that the benchmark also enables latency-aware analysis. All code and data are available at https://github.com/ynulihao/LLMRouterBench.", "AI": {"tldr": "本文提出了 LLMRouterBench，一个包含 400K+ 实例、21 个数据集和 33 个模型的 LLM 路由基准和框架，并提供了性能和性能-成本权衡的评估指标。通过该基准，研究发现现有路由方法性能相似，部分近期方法甚至不如简单基线，且 Oracle 仍有较大差距。此外，研究还探讨了嵌入模型、模型数量和延迟对路由的影响。", "motivation": "LLM 路由领域缺乏一个大规模、统一的基准和框架来系统地评估不同的路由方法，导致对该领域的研究进展和实际效果的认识不清晰，存在模型互补性被夸大、新方法效果不佳等问题。", "method": "构建了一个包含 400K+ 实例、21 个数据集和 33 个模型的 LLMRouterBench 基准和统一框架。该框架支持性能导向和性能-成本权衡两种评估模式，并集成了 10 种代表性的路由基线。利用该基准对现有路由方法进行了系统性的重新评估，并分析了嵌入模型、模型数量和延迟等因素的影响。", "result": "研究确认了 LLM 路由的中心思想——模型互补性——是存在的。然而，在统一的评估下，许多路由方法的性能相似，一些近期方法（包括商业路由）未能可靠地超越简单的基线。Oracle 仍有显著的性能差距，主要归因于模型召回率的持续问题。此外，研究表明嵌入模型的选择影响有限，更大的模型集合相比精心挑选的模型集合，收益递减，并且该基准还可以进行延迟感知分析。", "conclusion": "LLMRouterBench 为 LLM 路由领域提供了一个重要的评估工具。尽管模型互补性真实存在，但当前的路由方法在性能和成本效益方面仍有提升空间，需要关注模型召回率的改进。未来的研究应更加关注模型的实际选择、精心设计的模型集合以及延迟等实际应用因素。"}}
{"id": "2601.06780", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06780", "abs": "https://arxiv.org/abs/2601.06780", "authors": ["Keito Inoshita", "Xiaokang Zhou", "Akira Kawai"], "title": "Multi-Stage Evolutionary Model Merging with Meta Data Driven Curriculum Learning for Sentiment-Specialized Large Language Modeling", "comment": "This paper was presented at the 10th IEEE International Conference on Data Science and Systems in December 2024 and is awaiting publication", "summary": "The emergence of large language models (LLMs) has significantly transformed natural language processing (NLP), enabling more generalized models to perform various tasks with minimal training. However, traditional sentiment analysis methods, which focus on individual tasks such as sentiment classification or aspect-based analysis, are not practical for real-world applications that usually require handling multiple tasks. While offering flexibility, LLMs in sentiment-specific tasks often fall short of the required accuracy. Techniques like fine-tuning and evolutionary model merging help integrate models into a unified framework, which can improve the learning performance while reducing computational costs. The use of task meta-data and curriculum learning to optimize learning processes remains underexplored, while sentiment analysis is a critical task in NLP that requires high accuracy and scalability across multiple subtasks. In this study, we propose a hybrid learning model called Multi-stage Evolutionary Model Merging with Meta data driven Curriculum Learning (MEM-MCL), to enhance the sentiment analysis in large language modeling. In particular, expert models are created through instruction tuning for specific sentiment tasks and then merged using evolutionary algorithms to form a unified model. The merging process is optimized with weak data to enhance performance across tasks. The curriculum learning is incorporated to provide a learning sequence based on task difficulty, improving knowledge extraction from LLMs. Experiment results demonstrate that the proposed MEM-MCL model outperforms conventional LLMs in a majority of sentiment analysis tasks, achieving superior results across various subtasks.", "AI": {"tldr": "提出了一种名为 MEM-MCL 的混合学习模型，通过多阶段进化模型合并和元数据驱动的课程学习来改进大型语言模型的情感分析能力，并在多种情感分析子任务中取得了优于传统 LLM 的结果。", "motivation": "传统的情感分析方法难以应对需要处理多个任务的现实应用；而现有 LLM 在情感特定任务上的精度不足；同时，利用任务元数据和课程学习优化 LLM 情感分析学习过程的研究尚不充分，而情感分析是 NLP 中一个关键且需要高精度和可扩展性的任务。", "method": "创建针对特定情感任务的指令微调专家模型，然后使用进化算法将这些模型合并成一个统一的模型。该合并过程通过弱标签数据进行优化。引入课程学习，根据任务难度提供学习序列，以增强 LLM 的知识提取能力。", "result": "MEM-MCL 模型在大多数情感分析任务中优于传统的 LLM，并在各种子任务上取得了卓越的结果。", "conclusion": "所提出的 MEM-MCL 模型能够通过多阶段的进化模型合并和元数据驱动的课程学习，有效提升大型语言模型在情感分析任务上的表现，实现跨多个子任务的优越性能。"}}
{"id": "2601.06767", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06767", "abs": "https://arxiv.org/abs/2601.06767", "authors": ["Shubhashis Roy Dipta", "Khairul Mahbub", "Nadia Najjar"], "title": "GanitLLM: Difficulty-Aware Bengali Mathematical Reasoning through Curriculum-GRPO", "comment": null, "summary": "We present a Bengali mathematical reasoning model called GanitLLM (named after the Bangla word for mathematics, \"Ganit\"), together with a new difficulty-aware Bengali math corpus and a curriculum-based GRPO pipeline. Bengali is one of the world's most widely spoken languages, yet existing LLMs either reason in English and then translate, or simply fail on multi-step Bengali math, in part because reinforcement learning recipes are tuned for high-resource languages and collapse under reward sparsity in low-resource settings. To address this, we construct Ganit, a rigorously filtered and decontaminated Bengali math dataset with automatic difficulty tags derived from the pass@k of a strong evaluator model. Building on this dataset, we propose Curriculum-GRPO, which combines multi-stage training (SFT + GRPO) with difficulty-aware sampling and verifiable rewards for format, numerical correctness, and Bengali reasoning. On Bn-MGSM and Bn-MSVAMP, GanitLLM-4B improves over its Qwen3-4B base by +8 and +7 accuracy points, respectively, while increasing the percentage of Bengali reasoning tokens from 14% to over 88% and reducing average solution length from 943 to 193 words.", "AI": {"tldr": "本研究提出了一个名为 GanitLLM 的孟加拉语数学推理模型，以及一个难度感知的孟加拉语数学语料库和一个基于课程的 GRPO 流程。该模型在孟加拉语数学任务上取得了显著的准确性提升，并大幅提高了孟加拉语推理的比例，同时缩短了解决方案的长度。", "motivation": "现有的 LLM 在处理多步孟加拉语数学问题时存在困难，要么依赖英语翻译，要么直接失败。这部分原因在于强化学习的调优方式适用于高资源语言，在低资源环境下会出现奖励稀疏问题。因此，需要一个专门针对孟加拉语数学推理的模型和有效的方法。", "method": "研究构建了一个经过严格过滤和去污的孟加拉语数学数据集 Ganit，并自动标注了难度等级。在此基础上，提出了一种名为 Curriculum-GRPO 的方法，该方法结合了多阶段训练（SFT + GRPO）、难度感知采样以及基于格式、数值正确性和孟加拉语推理的可验证奖励。", "result": "GanitLLM-4B 在 Bn-MGSM 和 Bn-MSVAMP 数据集上，准确性分别比其 Qwen3-4B 基线模型提高了 +8 和 +7 个百分点。同时，孟加拉语推理代币的比例从 14% 提升至 88% 以上，平均解决方案长度从 943 个词缩短至 193 个词。", "conclusion": "GanitLLM 模型通过结合专门构建的数据集和创新的 Curriculum-GRPO 流程，有效解决了孟加拉语数学推理的挑战，显著提高了模型在孟加拉语数学任务上的性能，并促进了模型使用目标语言进行推理。"}}
{"id": "2601.06847", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06847", "abs": "https://arxiv.org/abs/2601.06847", "authors": ["Mengmeng Zhang", "Xiaoping Wu", "Hao Luo", "Fan Wang", "Yisheng Lv"], "title": "MedGround: Bridging the Evidence Gap in Medical Vision-Language Models with Verified Grounding Data", "comment": "18 pages, 10 figures", "summary": "Vision-Language Models (VLMs) can generate convincing clinical narratives, yet frequently struggle to visually ground their statements. We posit this limitation arises from the scarcity of high-quality, large-scale clinical referring-localization pairs. To address this, we introduce MedGround, an automated pipeline that transforms segmentation resources into high-quality medical referring grounding data. Leveraging expert masks as spatial anchors, MedGround precisely derives localization targets, extracts shape and spatial cues, and guides VLMs to synthesize natural, clinically grounded queries that reflect morphology and location. To ensure data rigor, a multi-stage verification system integrates strict formatting checks, geometry- and medical-prior rules, and image-based visual judging to filter out ambiguous or visually unsupported samples. Finally, we present MedGround-35K, a novel multimodal medical dataset. Extensive experiments demonstrate that VLMs trained with MedGround-35K consistently achieve improved referring grounding performance, enhance multi-object semantic disambiguation, and exhibit strong generalization to unseen grounding settings. This work highlights MedGround as a scalable, data-driven approach to anchor medical language to verifiable visual evidence. Dataset and code will be released publicly upon acceptance.", "AI": {"tldr": "本研究提出了一种名为MedGround的自动化流程，用于从医学分割资源生成高质量的医学指代定位数据，并构建了MedGround-35K数据集。使用该数据集训练的视觉语言模型（VLMs）在指代定位、多目标消歧和泛化能力上均有显著提升。", "motivation": "现有的视觉语言模型（VLMs）在生成临床文本时，尽管能产生令人信服的叙述，但往往难以将语句与图像中的视觉信息进行准确的关联（视觉接地）。研究者认为这是由于缺乏高质量、大规模的临床指代定位数据。因此，本研究旨在解决这一数据稀缺问题。", "method": "研究者提出了MedGround自动化流程，该流程利用专家分割掩码作为空间锚点，精确导出定位目标，提取形状和空间线索，并指导VLMs生成符合临床语境、能够反映形态和位置的自然查询。为了保证数据质量，建立了一个多阶段验证系统，包括格式检查、几何和医学先验规则以及基于图像的视觉判断，以过滤掉模糊或视觉上不支持的样本。最终构建了MedGround-35K数据集。", "result": "在MedGround-35K数据集上进行的大量实验表明，使用该数据集训练的VLMs在指代定位性能上得到了一致的提升，增强了多目标语义消歧能力，并且在面对未见过（unseen）的接地设置时表现出很强的泛化能力。", "conclusion": "MedGround提供了一种可扩展、数据驱动的方法，能够将医学语言与可验证的视觉证据进行关联。研究证明了MedGround-35K数据集在提升VLMs的视觉接地能力方面的有效性。"}}
{"id": "2601.06874", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06874", "abs": "https://arxiv.org/abs/2601.06874", "authors": ["Changli Wu", "Haodong Wang", "Jiayi Ji", "Yutian Yao", "Chunsai Du", "Jihua Kang", "Yanwei Fu", "Liujuan Cao"], "title": "MVGGT: Multimodal Visual Geometry Grounded Transformer for Multiview 3D Referring Expression Segmentation", "comment": "Project Website: https://mvggt.github.io", "summary": "Most existing 3D referring expression segmentation (3DRES) methods rely on dense, high-quality point clouds, while real-world agents such as robots and mobile phones operate with only a few sparse RGB views and strict latency constraints. We introduce Multi-view 3D Referring Expression Segmentation (MV-3DRES), where the model must recover scene structure and segment the referred object directly from sparse multi-view images. Traditional two-stage pipelines, which first reconstruct a point cloud and then perform segmentation, often yield low-quality geometry, produce coarse or degraded target regions, and run slowly. We propose the Multimodal Visual Geometry Grounded Transformer (MVGGT), an efficient end-to-end framework that integrates language information into sparse-view geometric reasoning through a dual-branch design. Training in this setting exposes a critical optimization barrier, termed Foreground Gradient Dilution (FGD), where sparse 3D signals lead to weak supervision. To resolve this, we introduce Per-view No-target Suppression Optimization (PVSO), which provides stronger and more balanced gradients across views, enabling stable and efficient learning. To support consistent evaluation, we build MVRefer, a benchmark that defines standardized settings and metrics for MV-3DRES. Experiments show that MVGGT establishes the first strong baseline and achieves both high accuracy and fast inference, outperforming existing alternatives. Code and models are publicly available at https://mvggt.github.io.", "AI": {"tldr": "提出了一种名为MV-3DRES的新任务，即仅从稀疏的多视图图像中进行3D指代表达分割。为此，开发了一个名为MVGGT的高效端到端框架，解决了稀疏信号带来的梯度稀释问题（FGD），并提出了PVSO优化策略。同时构建了MVRefer基准以支持评估。实验证明MVGGT在准确性和推理速度上均优于现有方法。", "motivation": "现有3D指代表达分割方法依赖于密集的点云，不适用于机器人和手机等在现实世界中仅能获取稀疏RGB视图且对延迟敏感的场景。", "method": "提出MV-3DRES任务，并设计了MVGGT端到端框架，采用双分支设计将语言信息融入稀疏视图几何推理。为解决训练中的前景梯度稀释（FGD）问题，引入了逐视图无目标抑制优化（PVSO）策略。构建了MVRefer基准以进行标准化评估。", "result": "MVGGT在MVRefer基准上建立了首个强有力基线，实现了高准确率和快速推理，优于现有方法。", "conclusion": "MVGGT是一种有效解决稀疏多视图3D指代表达分割问题的端到端框架，PVSO策略克服了训练中的关键优化障碍，MVRefer基准促进了该领域的研究和评估。"}}
{"id": "2601.07226", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07226", "abs": "https://arxiv.org/abs/2601.07226", "authors": ["Seongyun Lee", "Yongrae Jo", "Minju Seo", "Moontae Lee", "Minjoon Seo"], "title": "Lost in the Noise: How Reasoning Models Fail with Contextual Distractors", "comment": "Preprint", "summary": "Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current sanitized benchmarks fail to capture. We introduce NoisyBench, a comprehensive benchmark that systematically evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. Our evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. Crucially, we find that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. We find that prompting, context engineering, SFT, and outcome-reward only RL fail to ensure robustness; in contrast, our proposed Rationale-Aware Reward (RARE) significantly strengthens resilience by incentivizing the identification of helpful information within noise. Finally, we uncover an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrate via attention visualization that models disproportionately focus on distractor tokens, providing vital insights for building the next generation of robust, reasoning-capable agents.", "AI": {"tldr": "本研究提出了NoisyBench基准，用于评估模型在嘈杂输入环境下的鲁棒性。结果表明，现有模型在面对噪声时性能急剧下降，代理工作流会放大错误，并可能导致意外的失准。研究还发现，RARE方法能有效提高鲁棒性，并揭示了计算量增加反而可能导致性能下降的现象。", "motivation": "现有模型评估基准未能捕捉到真实世界中模型面临的嘈杂输入信息，例如RAG、推理、对齐和工具使用任务中的噪声。这导致对模型鲁棒性的评估不准确。", "method": "提出了NoisyBench基准，包含11个数据集，覆盖RAG、推理、对齐和工具使用任务，并引入了多种噪声类型（随机文档、不相关聊天记录、硬负面干扰物）。评估了现有最先进模型在NoisyBench上的表现，并提出了RARE（Rationale-Aware Reward）方法来增强鲁棒性。", "result": "在NoisyBench基准上，最先进模型的性能下降高达80%。代理工作流因过度信任嘈杂的工具输出而放大了错误。噪声可能在无对抗意图的情况下触发模型失准。RARE方法显著提高了模型的韧性。在嘈杂设置下，测试时计算量增加反而导致性能下降。", "conclusion": "当前模型在面对嘈杂输入时表现脆弱。代理工作流和增加计算量并不能保证鲁棒性。RARE方法通过激励模型识别有用信息来增强鲁棒性。未来需要关注模型在嘈杂环境下的行为，并开发更具鲁棒性的推理能力代理。"}}
{"id": "2601.06786", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06786", "abs": "https://arxiv.org/abs/2601.06786", "authors": ["Jewon Yeom", "Jaewon Sok", "Seonghyeon Park", "Jeongjae Park", "Taesup Kim"], "title": "EpiCaR: Knowing What You Don't Know Matters for Better Reasoning in LLMs", "comment": null, "summary": "Improving the reasoning abilities of large language models (LLMs) has largely relied on iterative self-training with model-generated data. While effective at boosting accuracy, existing approaches primarily reinforce successful reasoning paths, incurring a substantial calibration cost: models become overconfident and lose the ability to represent uncertainty. This failure has been characterized as a form of model collapse in alignment, where predictive distributions degenerate toward low-variance point estimates. We address this issue by reframing reasoning training as an epistemic learning problem, in which models must learn not only how to reason, but also when their reasoning should be trusted. We propose epistemically-calibrated reasoning (EpiCaR) as a training objective that jointly optimizes reasoning performance and calibration, and instantiate it within an iterative supervised fine-tuning framework using explicit self-evaluation signals. Experiments on Llama-3 and Qwen-3 families demonstrate that our approach achieves Pareto-superiority over standard baselines in both accuracy and calibration, particularly in models with sufficient reasoning capacity (e.g., 3B+). This framework generalizes effectively to OOD mathematical reasoning (GSM8K) and code generation (MBPP). Ultimately, our approach enables a 3X reduction in inference compute, matching the K=30 performance of STaR with only K=10 samples in capable models.", "AI": {"tldr": "该研究提出了一种名为 EpiCaR 的新训练方法，通过将 LLM 的推理训练重塑为认知学习问题，旨在提高模型在推理准确性和置信度校准方面的能力，从而解决现有方法导致模型过拟合和丧失不确定性表达能力的问题。", "motivation": "现有的大型语言模型（LLM）的推理能力提升主要依赖于模型生成的迭代自训练数据，这种方法虽然提高了准确性，但导致模型过度自信，丧失了表达不确定性的能力，即所谓的“模型对齐崩溃”。", "method": "研究者提出了认知校准推理（EpiCaR）的训练目标，该目标能够同时优化推理性能和置信度校准。EpiCaR 被实例化在一个迭代的监督微调框架中，并利用明确的自我评估信号。", "result": "在 Llama-3 和 Qwen-3 系列模型上的实验表明，EpiCaR 在准确性和置信度校准方面都优于标准基线。该方法能够显著提高推理能力强的模型（如 3B+ 模型）的表现。此外，EpiCaR 在处理 OOD 数学推理（GSM8K）和代码生成（MBPP）任务时也表现出良好的泛化能力。最终，在能力强的模型中，EpiCaR 实现了 3 倍的推理计算量减少，以 K=10 个样本达到了 STaR 方法 K=30 个样本的性能。", "conclusion": "EpiCaR 是一种有效的训练框架，能够同时提升 LLM 的推理准确性和置信度校准能力，解决现有方法带来的模型对齐问题，并在计算效率上有所提升。"}}
{"id": "2601.07232", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07232", "abs": "https://arxiv.org/abs/2601.07232", "authors": ["Olivia Shanhong Liu", "Pai Chet Ng", "De Wen Soh", "Konstantinos N. Plataniotis"], "title": "Yes FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for Humorous Meme Detection", "comment": "LaMAS@AAAI 2026 (Oral)", "summary": "Humorous memes blend visual and textual cues to convey irony, satire, or social commentary, posing unique challenges for AI systems that must interpret intent rather than surface correlations. Existing multimodal or prompting-based models generate explanations for humor but operate in an open loop,lacking the ability to critique or refine their reasoning once a prediction is made. We propose FLoReNce, an agentic feedback reasoning framework that treats meme understanding as a closed-loop process during learning and an open-loop process during inference. In the closed loop, a reasoning agent is critiqued by a judge; the error and semantic feedback are converted into control signals and stored in a feedback-informed, non-parametric knowledge base. At inference, the model retrieves similar judged experiences from this KB and uses them to modulate its prompt, enabling better, self-aligned reasoning without finetuning. On the PrideMM dataset, FLoReNce improves both predictive performance and explanation quality over static multimodal baselines, showing that feedback-regulated prompting is a viable path to adaptive meme humor understanding.", "AI": {"tldr": "提出了一种名为FLoReNce的具身反馈推理框架，用于理解幽默表情包。该框架将表情包理解视为一个闭环学习过程，通过引入一个“评判者”来 critique 推理过程，并将错误和语义反馈转化为控制信号存储在知识库中。在推理时，模型从知识库中检索相似的经验来调整其提示，从而实现无需微调的自适应推理。实验表明，FLoReNce在PrideMM数据集上提升了预测性能和解释质量。", "motivation": "现有模型在生成表情包幽默解释时存在“开环”问题，即一旦做出预测就无法对其推理进行 critique 或 refine。研究旨在解决这一局限性，实现更智能、自适应的表情包幽默理解。", "method": "提出FLoReNce框架，包含一个推理代理和一个评判者。在闭环学习过程中，评判者 critique 推理代理的解释，错误和语义反馈被转化为控制信号存储在反馈驱动的非参数知识库中。在推理时，模型从知识库中检索相似的 judged experience，并利用这些经验来调节其提示，实现自适应推理，无需微调。", "result": "在PrideMM数据集上，FLoReNce相比于静态多模态基线模型，在预测性能和解释质量上均有所提升。", "conclusion": "反馈调节的提示是一种可行的途径，能够实现自适应的表情包幽默理解。FLoReNce框架证明了闭环学习和基于知识库的推理对于提升AI理解复杂模态内容（如幽默表情包）的潜力。"}}
{"id": "2601.07233", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07233", "abs": "https://arxiv.org/abs/2601.07233", "authors": ["Chen Qian", "Yimeng Wang", "Yu Chen", "Lingfei Wu", "Andreas Stathopoulos"], "title": "From \"Thinking\" to \"Justifying\": Aligning High-Stakes Explainability with Professional Communication Standards", "comment": null, "summary": "Explainable AI (XAI) in high-stakes domains should help stakeholders trust and verify system outputs. Yet Chain-of-Thought methods reason before concluding, and logical gaps or hallucinations can yield conclusions that do not reliably align with their rationale. Thus, we propose \"Result -> Justify\", which constrains the output communication to present a conclusion before its structured justification. We introduce SEF (Structured Explainability Framework), operationalizing professional conventions (e.g., CREAC, BLUF) via six metrics for structure and grounding. Experiments across four tasks in three domains validate this approach: all six metrics correlate with correctness (r=0.20-0.42; p<0.001), and SEF achieves 83.9% accuracy (+5.3 over CoT). These results suggest structured justification can improve verifiability and may also improve reliability.", "AI": {"tldr": "提出了一种名为“结果 -> 证明”的新方法，通过结构化解释框架（SEF）来改善高风险领域中可解释人工智能（XAI）的可靠性和可验证性，该方法先呈现结论再给出理由，实验结果表明该方法优于链式思考（CoT）。", "motivation": "现有的链式思考（Chain-of-Thought）方法在推理后得出结论，可能存在逻辑不一致或幻觉，导致结论与其理由不匹配，在高风险领域中降低了信任度和可验证性。", "method": "提出“结果 -> 证明”方法，要求先呈现结论，再给出结构化的理由。引入结构化解释框架（SEF），通过六个关于结构和依据的指标来遵循专业惯例（如CREAC，BLUF）。", "result": "在四个任务和三个领域进行的实验表明，SEF的六个指标均与正确性相关（r=0.20-0.42; p<0.001），并且SEF的准确率达到83.9%，比CoT提高了5.3%。", "conclusion": "结构化证明可以提高可验证性，并可能改善AI系统的可靠性，特别是在高风险应用中。"}}
{"id": "2601.06883", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06883", "abs": "https://arxiv.org/abs/2601.06883", "authors": ["Xinhang Liu", "Jiawei Shi", "Zheng Dang", "Yuchao Dai"], "title": "MixRI: Mixing Features of Reference Images for Novel Object Pose Estimation", "comment": "Accepted by ICCV 2025", "summary": "We present MixRI, a lightweight network that solves the CAD-based novel object pose estimation problem in RGB images. It can be instantly applied to a novel object at test time without finetuning. We design our network to meet the demands of real-world applications, emphasizing reduced memory requirements and fast inference time. Unlike existing works that utilize many reference images and have large network parameters, we directly match points based on the multi-view information between the query and reference images with a lightweight network. Thanks to our reference image fusion strategy, we significantly decrease the number of reference images, thus decreasing the time needed to process these images and the memory required to store them. Furthermore, with our lightweight network, our method requires less inference time. Though with fewer reference images, experiments on seven core datasets in the BOP challenge show that our method achieves comparable results with other methods that require more reference images and larger network parameters.", "AI": {"tldr": "MixRI是一个轻量级网络，用于基于CAD模型的RGB图像新颖物体姿态估计，无需微调即可应用于新物体，内存和推理速度要求低，通过多视图点匹配和参考图像融合策略，在BOP挑战的七个数据集上取得了与需要更多参考图像和更大网络参数的方法相当的结果。", "motivation": "现有物体姿态估计方法通常需要大量参考图像和较大的网络参数，不适用于内存和推理速度要求高的实际应用。本研究旨在设计一个轻量级的网络，以满足实际应用的需求。", "method": "MixRI直接基于查询图像和参考图像之间的多视图信息进行点匹配。采用参考图像融合策略，减少了所需的参考图像数量。网络本身设计得轻量化，以降低内存需求和加快推理速度。", "result": "在BOP挑战的七个核心数据集上，MixRI在减少参考图像数量和网络参数的同时，取得了与使用更多参考图像和更大网络参数的其他方法相当的性能。", "conclusion": "MixRI是一种高效、轻量级的物体姿态估计方法，通过创新的多视图点匹配和参考图像融合策略，在保证性能的同时显著降低了计算和内存开销，使其适用于实际应用场景。"}}
{"id": "2601.06799", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06799", "abs": "https://arxiv.org/abs/2601.06799", "authors": ["Zili Wei", "Xiaocui Yang", "Yilin Wang", "Zihan Wang", "Weidong Bao", "Shi Feng", "Daling Wang", "Yifei Zhang"], "title": "CIRAG: Construction-Integration Retrieval and Adaptive Generation for Multi-hop Question Answering", "comment": null, "summary": "Triple-based Iterative Retrieval-Augmented Generation (iRAG) mitigates document-level noise for multi-hop question answering. However, existing methods still face limitations: (i) greedy single-path expansion, which propagates early errors and fails to capture parallel evidence from different reasoning branches, and (ii) granularity-demand mismatch, where a single evidence representation struggles to balance noise control with contextual sufficiency. In this paper, we propose the Construction-Integration Retrieval and Adaptive Generation model, CIRAG. It introduces an Iterative Construction-Integration module that constructs candidate triples and history-conditionally integrates them to distill core triples and generate the next-hop query. This module mitigates the greedy trap by preserving multiple plausible evidence chains. Besides, we propose an Adaptive Cascaded Multi-Granularity Generation module that progressively expands contextual evidence based on the problem requirements, from triples to supporting sentences and full passages. Moreover, we introduce Trajectory Distillation, which distills the teacher model's integration policy into a lightweight student, enabling efficient and reliable long-horizon reasoning. Extensive experiments demonstrate that CIRAG achieves superior performance compared to existing iRAG methods.", "AI": {"tldr": "CIRAG 提出了一种新的迭代式检索增强生成方法，通过构建-整合模块和多粒度生成模块来克服现有方法的局限性，并在多跳问答任务上取得了更好的性能。", "motivation": "现有基于三元组的迭代检索增强生成方法存在贪婪单路径扩展和粒度需求不匹配的问题，容易传播错误并难以平衡噪声控制与上下文充足性。", "method": "提出 CIRAG 模型，包含迭代构建-整合模块（构建候选三元组并历史条件整合以提炼核心三元组并生成下一跳查询）和自适应级联多粒度生成模块（从三元组到句子再到段落逐步扩展上下文证据）。还引入了轨迹蒸馏，将教师模型的整合策略蒸馏到轻量级学生模型。", "result": " CIRAG 通过保留多个合理证据链来缓解贪婪陷阱，并根据问题需求逐步扩展上下文证据。实验表明 CIRAG 的性能优于现有的 iRAG 方法。", "conclusion": " CIRAG 通过创新的模块设计和蒸馏技术，有效解决了多跳问答中的噪声和推理瓶颈问题，实现了更高效和可靠的长程推理。"}}
{"id": "2601.06882", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06882", "abs": "https://arxiv.org/abs/2601.06882", "authors": ["Dillan Imans", "Phuoc-Nguyen Bui", "Duc-Tai Le", "Hyunseung Choo"], "title": "Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation", "comment": "Accepted in BIBM 2025", "summary": "Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation", "AI": {"tldr": "该研究提出了一种名为SAM-RefiSeR的无监督领域自适应方法，用于增强脑肿瘤分割的性能。", "motivation": "在医学图像分割任务中，由于不同成像设备、扫描协议或数据采集环境导致的领域偏移（domain shift）问题，导致模型在源域上训练后，在目标域上性能下降。因此，研究动机是开发一种能够有效解决领域偏移问题的无监督方法，从而提高在不同目标域上的脑肿瘤分割准确性。", "method": "研究方法是提出SAM-RefiSeR框架。该框架利用SAM（Segment Anything Model）作为基础模型，并通过一种名为RefiSeR（Refinement and Self-Supervised Reconstruction）的自监督学习策略进行微调。SAM能够提供强大的通用分割能力，而RefiSeR则通过生成伪标签、进行对比学习以及利用自重建任务来指导SAM在目标域上进行领域适应。", "result": "实验结果表明，SAM-RefiSeR在多个公开脑肿瘤数据集上取得了显著的性能提升。与现有的无监督领域自适应方法相比，SAM-RefiSeR在Dice分数和Hausdorff距离等评估指标上均表现出更优越的分割效果，尤其是在跨域分割任务中。", "conclusion": "研究得出结论，SAM-RefiSeR是一种有效的无监督领域自适应框架，它结合了强大的基础模型SAM和创新的自监督微调策略，能够有效减轻领域偏移带来的影响，显著提高脑肿瘤分割的准确性和鲁棒性。"}}
{"id": "2601.06787", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06787", "abs": "https://arxiv.org/abs/2601.06787", "authors": ["Jaewon Sok", "Jewon Yeom", "Seonghyeon Park", "Jeongjae Park", "Taesup Kim"], "title": "Garbage Attention in Large Language Models: BOS Sink Heads and Sink-aware Pruning", "comment": null, "summary": "Large Language Models (LLMs) are known to contain significant redundancy, yet a systematic explanation for why certain components, particularly in higher layers, are more redundant has remained elusive. In this work, we identify the BOS sink phenomenon as a key mechanism driving this layer-wise sensitivity. We show that attention heads with high BOS sink scores are strongly associated with functional redundancy: such heads, especially in deeper layers, contribute little to predictive performance and effectively serve as \\emph{dumping grounds} for superfluous attention weights. This provides a concrete functional explanation for the structural redundancy reported in prior studies. Leveraging this insight, we introduce a simple pruning strategy that removes high-BOS sink heads. Experiments on Gemma-3, Llama-3.1, and Qwen3 demonstrate that this approach identifies redundant transformer components more reliably than weight- or activation-based criteria, while preserving performance close to dense baselines even under aggressive pruning. Moreover, we find that the behavior of sink heads remains stable across different sequence lengths. Overall, our results suggest that structural properties of attention offer a more intuitive and robust basis for model compression than magnitude-based methods.", "AI": {"tldr": "本研究提出了“BOS sink”现象来解释大型语言模型（LLMs）中，特别是高层模块的冗余问题。研究发现，高BOS sink分数的注意力头与功能冗余密切相关，尤其是在深层模型中，这些头对预测性能贡献甚少，成为权重“倾倒区”。基于此，论文提出了一种移除高BOS sink头的剪枝策略，并在Gemma-3、Llama-3.1和Qwen3等模型上验证了该策略比基于权值或激活的方法更可靠，且在激进剪枝下仍能保持接近密集基线的性能。此外，sink头的行为对序列长度不敏感。研究表明，注意力机制的结构特性是模型压缩的更直观和鲁棒的方法。", "motivation": "大型语言模型（LLMs）存在显著冗余，尤其在高层模块，但缺乏对其产生原因的系统性解释。本研究旨在找出驱动这种层级敏感性（即某些层比其他层更冗余）的关键机制。", "method": "1. 识别并定义“BOS sink”现象，即注意力头倾向于将大量注意力权重聚焦在BOS（Beginning of Sentence）token上。 2. 测量不同注意力头的BOS sink分数。 3. 分析高BOS sink分数注意力头的功能冗余性，并与预测性能关联。 4. 提出一种基于移除高BOS sink头的剪枝策略。 5. 在Gemma-3、Llama-3.1和Qwen3模型上进行实验，评估该策略在识别冗余组件和保持模型性能方面的效果，并与基于权重和激活的剪枝方法进行比较。 6. 探究sink头行为在不同序列长度下的稳定性。", "result": "1. 高BOS sink分数的注意力头与功能冗余高度相关，尤其是在模型的较高层，这些头对模型预测性能贡献有限。 2. 基于移除高BOS sink头的剪枝策略能够比基于权重或激活的方法更可靠地识别 transformer 组件中的冗余。 3. 该策略在Gemma-3、Llama-3.1和Qwen3模型上实现了高效的模型压缩，即使在激进剪枝下，性能也接近于未剪枝的基线模型。 4. sink头的行为对序列长度的变化表现出稳定性。", "conclusion": "BOS sink现象是导致LLMs中，特别是高层模型组件功能冗余的关键机制，为理解和解决LLMs的结构冗余问题提供了新的视角。所提出的基于BOS sink头的剪枝策略是一种有效且鲁棒的模型压缩方法，优于传统的基于幅度的剪枝方法，并且具有良好的性能保持能力。"}}
{"id": "2601.06891", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06891", "abs": "https://arxiv.org/abs/2601.06891", "authors": ["Nimrod Shabtay", "Itamar Zimerman", "Eli Schwartz", "Raja Giryes"], "title": "CLIMP: Contrastive Language-Image Mamba Pretraining", "comment": null, "summary": "Contrastive Language-Image Pre-training (CLIP) relies on Vision Transformers whose attention mechanism is susceptible to spurious correlations, and scales quadratically with resolution. To address these limitations, We present CLIMP, the first fully Mamba-based contrastive vision-language model that replaces both the vision and text encoders with Mamba. The new architecture encodes sequential structure in both vision and language, with VMamba capturing visual spatial inductive biases, reducing reliance on spurious correlations and producing an embedding space favorable for cross-modal retrieval and out-of-distribution robustness-surpassing OpenAI's CLIP-ViT-B by 7.5% on ImageNet-O. CLIMP naturally supports variable input resolutions without positional encoding interpolation or specialized training, achieving up to 6.6% higher retrieval accuracy at 16x training resolution while using 5x less memory and 1.8x fewer FLOPs. The autoregressive text encoder further overcomes CLIP's fixed context limitation, enabling dense captioning retrieval. Our findings suggest that Mamba exhibits advantageous properties for vision-language learning, making it a compelling alternative to Transformer-based CLIP.", "AI": {"tldr": "本文提出了CLIMP，一种基于Mamba的对比学习视觉-语言模型，取代了CLIP中的Transformer。CLIMP在视觉和文本编码方面都使用了Mamba，提高了对伪相关性的鲁棒性，并在跨模态检索和分布外泛化方面超越了CLIP，同时在处理不同分辨率输入时效率更高。", "motivation": "CLIP模型中的Vision Transformer容易受到伪相关性的影响，并且计算复杂度随分辨率二次方增长。现有模型缺乏对伪相关性的有效处理，并且在处理不同分辨率输入时存在限制。", "method": "使用Mamba取代CLIP中的Vision Transformer和文本编码器，构建了一个全Mamba的对比学习模型（CLIMP）。VMamba用于捕获视觉空间归纳偏置，Mamba作为文本编码器处理文本信息。", "result": "CLIMP在ImageNet-O上的表现比CLIP-ViT-B高出7.5%，在处理16倍训练分辨率的输入时，检索准确率提高了6.6%，同时内存使用减少了5倍，FLOPs减少了1.8倍。其自回归文本编码器克服了CLIP的固定上下文限制，实现了密集字幕检索。", "conclusion": "Mamba在视觉-语言学习方面表现出优越的特性，是一种比Transformer-based CLIP更具吸引力的替代方案，能够提高鲁棒性、效率和处理可变分辨率输入的能力。"}}
{"id": "2601.06802", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06802", "abs": "https://arxiv.org/abs/2601.06802", "authors": ["Ayman Mansour"], "title": "Doing More with Less: Data Augmentation for Sudanese Dialect Automatic Speech Recognition", "comment": null, "summary": "Although many Automatic Speech Recognition (ASR) systems have been developed for Modern Standard Arabic (MSA) and Dialectal Arabic (DA), few studies have focused on dialect-specific implementations, particularly for low-resource Arabic dialects such as Sudanese. This paper presents a comprehensive study of data augmentation techniques for fine-tuning OpenAI Whisper models and establishes the first benchmark for the Sudanese dialect. Two augmentation strategies are investigated: (1) self-training with pseudo-labels generated from unlabeled speech, and (2) TTS-based augmentation using synthetic speech from the Klaam TTS system. The best-performing model, Whisper-Medium fine-tuned with combined self-training and TTS augmentation (28.4 hours), achieves a Word Error Rate (WER) of 57.1% on the evaluation set and 51.6% on an out-of-domain holdout set substantially outperforming zero-shot multilingual Whisper (78.8% WER) and MSA-specialized Arabic models (73.8-123% WER). All experiments used low-cost resources (Kaggle free tier and Lightning.ai trial), demonstrating that strategic data augmentation can overcome resource limitations for low-resource dialects and provide a practical roadmap for developing ASR systems for low-resource Arabic dialects and other marginalized language varieties. The models, evaluation benchmarks, and reproducible training pipelines are publicly released to facilitate future research on low-resource Arabic ASR.", "AI": {"tldr": "该研究通过数据增强技术（自训练和TTS）改进了OpenAI Whisper模型在苏丹方言阿拉伯语上的自动语音识别（ASR）性能，并建立了该方言的第一个基准测试。研究结果表明，经过增强的模型在低资源环境下显著优于零样本模型和针对标准阿拉伯语的模型，并开源了模型和数据集以促进未来研究。", "motivation": "现有针对现代标准阿拉伯语和方言阿拉伯语的ASR系统较多，但针对特定方言（尤其是像苏丹阿拉伯语这样的低资源方言）的研究不足。本研究旨在解决这一问题，并为低资源阿拉伯语方言开发ASR系统提供一个可行的方案。", "method": "研究采用了两种数据增强策略来微调OpenAI Whisper模型：1. 使用未标记语音生成的伪标签进行自训练；2. 使用Klaam TTS系统生成的合成语音进行TTS增强。研究还比较了结合两种增强策略的Whisper-Medium模型的性能。", "result": "结合了自训练和TTS增强策略的Whisper-Medium模型（使用28.4小时数据）在评估集上达到了57.1%的词错误率（WER），在领域外测试集上达到了51.6%的WER。这显著优于零样本多语言Whisper（78.8% WER）和针对标准阿拉伯语的模型（73.8-123% WER）。所有实验均使用了低成本资源。", "conclusion": "战略性的数据增强技术可以克服低资源方言的资源限制，为开发苏丹阿拉伯语等低资源方言的ASR系统提供实用路线图。研究还开源了模型、评估基准和可复现的训练流程，以支持未来的低资源阿拉伯语ASR研究。"}}
{"id": "2601.07239", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07239", "abs": "https://arxiv.org/abs/2601.07239", "authors": ["Tanmay Joshi", "Shourya Aggarwal", "Anusa Saha", "Aadi Pandey", "Shreyash Dhoot", "Vighnesh Rai", "Raxit Goswami", "Aman Chadha", "Vinija Jain", "Amitava Das"], "title": "Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition", "comment": null, "summary": "Deterministic inference is a comforting ideal in classical software: the same program on the same input should always produce the same output. As large language models move into real-world deployment, this ideal has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has presented a detailed analysis of nondeterminism in LLM inference, showing how batch-invariant kernels and deterministic attention can enforce bitwise-identical outputs, positioning deterministic inference as a prerequisite for reproducibility and enterprise reliability.\n  In this paper, we take the opposite stance. We argue that, for LLMs, deterministic inference kills. It kills the ability to model uncertainty, suppresses emergent abilities, collapses reasoning into a single brittle path, and weakens safety alignment by hiding tail risks. LLMs implement conditional distributions over outputs, not fixed functions. Collapsing these distributions to a single canonical completion may appear reassuring, but it systematically conceals properties central to artificial cognition. We instead advocate Stochastic CHAOS, treating distributional variability as a signal to be measured and controlled.\n  Empirically, we show that deterministic inference is systematically misleading. Single-sample deterministic evaluation underestimates both capability and fragility, masking failure probability under paraphrases and noise. Phase-like transitions associated with emergent abilities disappear under greedy decoding. Multi-path reasoning degrades when forced onto deterministic backbones, reducing accuracy and diagnostic insight. Finally, deterministic evaluation underestimates safety risk by hiding rare but dangerous behaviors that appear only under multi-sample evaluation.", "AI": {"tldr": "本文认为，大型语言模型（LLMs）的确定性推理弊大于利，它会掩盖模型的固有不确定性、抑制涌现能力、限制推理路径并削弱安全性。研究提出采用随机CHAOS方法，将分布变异性作为一种可衡量和可控制的信号。", "motivation": "当前的LLM部署倾向于采用确定性推理，但这种方法可能掩盖LLM的核心特性，如处理不确定性、展现涌现能力、进行多路径推理以及存在潜在的安全风险。作者希望挑战这一现状，探索随机性在LLM中的价值。", "method": "通过实证研究，对比确定性推理和多样本评估（即随机CHAOS）在LLM能力、脆弱性、涌现能力、推理准确性和安全风险等方面的表现。", "result": "确定性推理系统性地低估了LLM的能力和脆弱性，掩盖了失败的概率。涌现能力在贪婪解码下消失。多路径推理在确定性模型上准确性和诊断洞察力下降。确定性评估低估了安全风险，因为它隐藏了仅在多样本评估下才出现的罕见但危险的行为。", "conclusion": "确定性推理对LLM来说是有害的，因为它掩盖了模型的核心认知特性。应采用随机CHAOS方法，将分布的变异性视为一种有价值的信号来测量和控制，这能更全面地理解和利用LLM。"}}
{"id": "2601.06909", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06909", "abs": "https://arxiv.org/abs/2601.06909", "authors": ["Zengyuan Zuo", "Junjun Jiang", "Gang Wu", "Xianming Liu"], "title": "UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing", "comment": null, "summary": "Image dehazing has witnessed significant advancements with the development of deep learning models. However, a few methods predominantly focus on single-modal RGB features, neglecting the inherent correlation between scene depth and haze distribution. Even those that jointly optimize depth estimation and image dehazing often suffer from suboptimal performance due to inadequate utilization of accurate depth information. In this paper, we present UDPNet, a general framework that leverages depth-based priors from large-scale pretrained depth estimation model DepthAnything V2 to boost existing image dehazing models. Specifically, our architecture comprises two typical components: the Depth-Guided Attention Module (DGAM) adaptively modulates features via lightweight depth-guided channel attention, and the Depth Prior Fusion Module (DPFM) enables hierarchical fusion of multi-scale depth map features by dual sliding-window multi-head cross-attention mechanism. These modules ensure both computational efficiency and effective integration of depth priors. Moreover, the intrinsic robustness of depth priors empowers the network to dynamically adapt to varying haze densities, illumination conditions, and domain gaps across synthetic and real-world data. Extensive experimental results demonstrate the effectiveness of our UDPNet, outperforming the state-of-the-art methods on popular dehazing datasets, such as 0.85 dB PSNR improvement on the SOTS dataset, 1.19 dB on the Haze4K dataset and 1.79 dB PSNR on the NHR dataset. Our proposed solution establishes a new benchmark for depth-aware dehazing across various scenarios. Pretrained models and codes will be released at our project https://github.com/Harbinzzy/UDPNet.", "AI": {"tldr": "本文提出了UDPNet，一个利用预训练深度估计模型DepthAnything V2的深度先验来增强现有图像去雾模型的通用框架。通过深度引导注意力模块（DGAM）和深度先验融合模块（DPFM），UDPNet能够高效地融合深度信息，从而提升去雾性能，并在多个数据集上取得了SOTA结果。", "motivation": "现有深度学习图像去雾方法多依赖单模态RGB特征，忽视了场景深度与雾度分布之间的关联。即使是联合优化深度估计和去雾的方法，也由于深度信息利用不足而性能受限。因此，需要一种更有效的方法来利用深度信息来提升去雾效果。", "method": "UDPNet框架包含两个关键模块：1. 深度引导注意力模块（DGAM）：利用轻量级的深度引导通道注意力来适应性地调制特征。2. 深度先验融合模块（DPFM）：通过双滑动窗口多头交叉注意力机制实现多尺度深度图特征的层级融合。该框架利用了预训练的DepthAnything V2模型来获取深度先验。", "result": "UDPNet在SOTS数据集上PSNR提升0.85 dB，在Haze4K数据集上提升1.19 dB，在NHR数据集上提升1.79 dB，超越了现有最先进的方法。该方法对不同雾度、光照条件以及合成/真实数据域差异具有鲁棒性。", "conclusion": "UDPNet是一个有效的深度引导去雾框架，通过整合强大的深度先验，能够显著提升现有去雾模型的性能，并在各种场景下树立了新的深度感知去雾基准。其模块设计保证了计算效率和深度信息的有效融合。"}}
{"id": "2601.06803", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06803", "abs": "https://arxiv.org/abs/2601.06803", "authors": ["Yubo Wang", "Juntian Zhang", "Yichen Wu", "Yankai Lin", "Nils Lukas", "Yuhan Liu"], "title": "Forest Before Trees: Latent Superposition for Efficient Visual Reasoning", "comment": null, "summary": "While Chain-of-Thought empowers Large Vision-Language Models with multi-step reasoning, explicit textual rationales suffer from an information bandwidth bottleneck, where continuous visual details are discarded during discrete tokenization. Recent latent reasoning methods attempt to address this challenge, but often fall prey to premature semantic collapse due to rigid autoregressive objectives. In this paper, we propose Laser, a novel paradigm that reformulates visual deduction via Dynamic Windowed Alignment Learning (DWAL). Instead of forcing a point-wise prediction, Laser aligns the latent state with a dynamic validity window of future semantics. This mechanism enforces a \"Forest-before-Trees\" cognitive hierarchy, enabling the model to maintain a probabilistic superposition of global features before narrowing down to local details. Crucially, Laser maintains interpretability via decodable trajectories while stabilizing unconstrained learning via Self-Refined Superposition. Extensive experiments on 6 benchmarks demonstrate that Laser achieves state-of-the-art performance among latent reasoning methods, surpassing the strong baseline Monet by 5.03% on average. Notably, it achieves these gains with extreme efficiency, reducing inference tokens by more than 97%, while demonstrating robust generalization to out-of-distribution domains.", "AI": {"tldr": "提出了一种名为Laser的新型视觉推理范式，通过动态窗口对齐学习（DWAL）来解决链式思考中信息瓶颈和语义过早崩溃的问题，实现了最先进的性能，同时显著减少了推理代币并提高了泛化能力。", "motivation": "链式思考在多步推理方面有优势，但显式文本推理存在信息带宽瓶颈，离散标记化会丢失连续视觉细节。现有的潜在推理方法容易因僵化的自回归目标而导致过早的语义崩溃。", "method": "提出Laser范式，通过动态窗口对齐学习（DWAL）重新定义视觉推理。Laser将潜在状态与未来语义的动态有效性窗口对齐，而不是强制进行逐点预测。该机制强制执行“森林先于树木”的认知层级，并利用自精炼叠加（Self-Refined Superposition）稳定无约束学习，同时保持可解码轨迹的解释性。", "result": "在6个基准测试中，Laser实现了最先进的潜在推理性能，平均比强基线Monet高出5.03%。推理代币减少了97%以上，并且在对分布外域表现出鲁棒的泛化能力。", "conclusion": "Laser通过DWAL有效解决了视觉推理中的信息瓶颈和语义崩溃问题，在保持高效和可解释性的同时，显著提升了性能和泛化能力。"}}
{"id": "2601.06928", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06928", "abs": "https://arxiv.org/abs/2601.06928", "authors": ["Shenghao Zhang", "Runtao Liu", "Christopher Schroers", "Yang Zhang"], "title": "RenderFlow: Single-Step Neural Rendering via Flow Matching", "comment": null, "summary": "Conventional physically based rendering (PBR) pipelines generate photorealistic images through computationally intensive light transport simulations. Although recent deep learning approaches leverage diffusion model priors with geometry buffers (G-buffers) to produce visually compelling results without explicit scene geometry or light simulation, they remain constrained by two major limitations. First, the iterative nature of the diffusion process introduces substantial latency. Second, the inherent stochasticity of these generative models compromises physical accuracy and temporal consistency. In response to these challenges, we propose a novel, end-to-end, deterministic, single-step neural rendering framework, RenderFlow, built upon a flow matching paradigm. To further strengthen both rendering quality and generalization, we propose an efficient and effective module for sparse keyframe guidance. Our method significantly accelerates the rendering process and, by optionally incorporating sparsely rendered keyframes as guidance, enhances both the physical plausibility and overall visual quality of the output. The resulting pipeline achieves near real-time performance with photorealistic rendering quality, effectively bridging the gap between the efficiency of modern generative models and the precision of traditional physically based rendering. Furthermore, we demonstrate the versatility of our framework by introducing a lightweight, adapter-based module that efficiently repurposes the pretrained forward model for the inverse rendering task of intrinsic decomposition.", "AI": {"tldr": "提出了一种名为RenderFlow的端到端、确定性、单步神经渲染框架，基于流匹配范式，解决了现有扩散模型渲染延迟高和物理精度低的问题，并通过稀疏关键帧引导提升了渲染质量和泛化能力，实现了近乎实时且光线真实感的渲染。该框架还支持通过适配器模块进行逆渲染。", "motivation": "现有基于深度学习的渲染方法（如扩散模型）虽然无需显式几何和光照模拟，但存在迭代过程带来的高延迟以及随机性导致的物理精度和时间一致性不足等问题。", "method": "提出了一种新的、端到端、确定性、单步神经渲染框架RenderFlow，基于流匹配范式。引入了稀疏关键帧引导模块来增强渲染质量和泛化能力。此外，还提出了一种轻量级的适配器模块，用于将预训练的前向模型重用于逆渲染任务。", "result": "RenderFlow实现了近乎实时（near real-time）的渲染性能，同时达到了光线真实感（photorealistic）的渲染质量。通过稀疏关键帧引导，提升了物理可信度和整体视觉质量。适配器模块能够高效地将前向模型用于内在分解。", "conclusion": "RenderFlow成功地克服了现有生成模型在渲染方面的延迟和精度限制，通过流匹配和稀疏关键帧引导，实现了高效、物理精确且高质量的神经渲染，并展现了其在逆渲染任务上的通用性。"}}
{"id": "2601.07245", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07245", "abs": "https://arxiv.org/abs/2601.07245", "authors": ["Pranav Kallem"], "title": "Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models", "comment": null, "summary": "Large language models (LLMs) achieve strong aver- age performance yet remain unreliable at the instance level, with frequent hallucinations, brittle failures, and poorly calibrated confidence. We study reliability through the lens of multi-model consensus: given responses from several heterogeneous LLMs, can we learn which answer is most likely correct for a given query? We introduce a Multi-Model Consensus Reasoning Engine that treats the set of LLM outputs as input to a supervised meta-learner. The system maps natural language responses into structured features using semantic embeddings, pairwise similarity and clustering statistics, lexical and structural cues, reasoning-quality scores, confidence estimates, and model-specific priors, and then applies gradient-boosted trees, listwise ranking, and graph neural networks over similarity graphs of answers. Using three open-weight LLMs evaluated on compact, resource- constrained subsets of GSM8K, ARC-Challenge, HellaSwag, and TruthfulQA, our best graph-attention-based consensus model improves macro-average accuracy by 4.6 percentage points over the strongest single LLM and by 8.1 points over majority vote, while also yielding lower Brier scores and fewer TruthfulQA hal- lucinations. Ablation and feature-importance analyses show that semantic agreement and clustering features are most influential, with reasoning-quality and model-prior features providing com- plementary gains, suggesting supervised multi-model consensus is a practical route toward more reliable LLM behavior, even in a modest single-machine setup.", "AI": {"tldr": "研究人员提出了一种多模型共识推理引擎，通过对多个大型语言模型（LLM）的输出来学习最有可能正确的答案，以提高LLM在实例级别的可靠性。该系统利用各种特征（如语义嵌入、相似性、聚类统计等）来训练元学习器，并通过图注意力网络等方法来改进答案的排序。实验表明，该方法在准确率和减少幻觉方面优于单一LLM和多数投票。", "motivation": "大型语言模型（LLMs）虽然平均性能强劲，但在实例层面仍然不可靠，表现为频繁的幻觉、脆弱的失败和校准不良的置信度。研究人员希望通过多模型共识的视角来解决LLM的可靠性问题，即利用多个异构LLM的输出来学习最有可能正确的答案。", "method": "提出了一种多模型共识推理引擎，将一组LLM的输出作为监督元学习器的输入。该系统通过语义嵌入、成对相似性、聚类统计、词汇和结构线索、推理质量得分、置信度估计以及模型特定先验等方式将自然语言响应映射为结构化特征。然后，应用梯度提升树、列表式排序和基于答案相似性图的图神经网络。", "result": "在GSM8K、ARC-Challenge、HellaSwag和TruthfulQA的紧凑、资源受限的子集上，最佳的基于图注意力的共识模型将宏平均准确率比最强的单一LLM提高了4.6个百分点，比多数投票提高了8.1个百分点，同时还产生了更低的Brier分数和更少的TruthfulQA幻觉。", "conclusion": "监督式多模型共识是实现更可靠LLM行为的一种实用途径，即使是在有限的单机设置下。消融和特征重要性分析表明，语义一致性和聚类特征最具影响力，而推理质量和模型先验特征提供了互补的收益。"}}
{"id": "2601.06818", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06818", "abs": "https://arxiv.org/abs/2601.06818", "authors": ["Xuannan Liu", "Xiao Yang", "Zekun Li", "Peipei Li", "Ran He"], "title": "AgentHallu: Benchmarking Automated Hallucination Attribution of LLM-based Agents", "comment": "Project page: https://liuxuannan.github.io/AgentHallu.github.io/", "summary": "As LLM-based agents operate over sequential multi-step reasoning, hallucinations arising at intermediate steps risk propagating along the trajectory, thus degrading overall reliability. Unlike hallucination detection in single-turn responses, diagnosing hallucinations in multi-step workflows requires identifying which step causes the initial divergence. To fill this gap, we propose a new research task, automated hallucination attribution of LLM-based agents, aiming to identify the step responsible for the hallucination and explain why. To support this task, we introduce AgentHallu, a comprehensive benchmark with: (1) 693 high-quality trajectories spanning 7 agent frameworks and 5 domains, (2) a hallucination taxonomy organized into 5 categories (Planning, Retrieval, Reasoning, Human-Interaction, and Tool-Use) and 14 sub-categories, and (3) multi-level annotations curated by humans, covering binary labels, hallucination-responsible steps, and causal explanations. We evaluate 13 leading models, and results show the task is challenging even for top-tier models (like GPT-5, Gemini-2.5-Pro). The best-performing model achieves only 41.1\\% step localization accuracy, where tool-use hallucinations are the most challenging at just 11.6\\%. We believe AgentHallu will catalyze future research into developing robust, transparent, and reliable agentic systems.", "AI": {"tldr": "本研究提出了一个名为AgentHallu的新基准，用于自动化识别大型语言模型（LLM）驱动的代理程序在多步推理过程中产生幻觉的起始步骤及其原因，旨在提高代理程序的可靠性。", "motivation": "大型语言模型驱动的代理程序在多步推理过程中容易产生幻觉，且中间步骤的幻觉会累积并影响最终结果的可靠性。现有研究主要关注单轮响应的幻觉检测，而忽略了识别多步推理中导致幻觉的起始步骤，因此需要一个新的研究方向来解决这一问题。", "method": "研究提出了自动化幻觉归因任务，并引入了AgentHallu基准。AgentHallu包含693个高质量的推理轨迹，覆盖7种代理框架和5个领域，并构建了一个包含5个主要类别和14个子类别的幻觉分类体系。该基准还提供了多层次的人工标注，包括二元标签、产生幻觉的步骤以及因果解释。研究还评估了13种领先的模型。", "result": "在AgentHallu基准上的评估结果显示，该任务对包括GPT-5和Gemini-2.5-Pro在内的顶尖模型来说仍然极具挑战性。表现最好的模型仅达到41.1%的步骤定位准确率，其中工具使用环节的幻觉定位准确率更是低至11.6%。", "conclusion": "AgentHallu基准的提出将推动未来在开发鲁棒、透明和可靠的代理系统方面的研究。该基准的评估结果表明，当前LLM驱动的代理在处理多步推理中的幻觉归因方面仍有很大提升空间，特别是对于工具使用环节的幻觉。"}}
{"id": "2601.07238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07238", "abs": "https://arxiv.org/abs/2601.07238", "authors": ["Hanbin Wang", "Jingwei Song", "Jinpeng Li", "Fei Mi", "Lifeng Shang"], "title": "Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning", "comment": "8 pages, 5 figures", "summary": "Large reasoning models (LRMs) exhibit diverse high-level reasoning patterns (e.g., direct solution, reflection-and-verification, and exploring multiple solutions), yet prevailing training recipes implicitly bias models toward a limited set of dominant patterns. Through a systematic analysis, we identify substantial accuracy variance across these patterns on mathematics and science benchmarks, revealing that a model's default reasoning pattern is often sub-optimal for a given problem. To address this, we introduce Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that extends GRPO by incorporating multi-pattern rollouts, verifier-guided optimal pattern selection per problem, and attention masking during optimization to prevent the leakage of explicit pattern suffixes into the learned policy. By exploring a portfolio of diverse reasoning strategies and optimizing the policy on the most effective ones, GPSO enables the model to internalize the mapping from problem characteristics to optimal reasoning patterns. Extensive experiments demonstrate that GPSO delivers consistent and substantial performance gains across various model backbones and benchmarks, effectively mitigating pattern sub-optimality and fostering more robust, adaptable reasoning. All data and codes are available at https://github.com/wanghanbinpanda/GPSO.", "AI": {"tldr": "研究提出了一种名为GPSO的强化学习框架，通过引入多模式采样、问题导向的最优模式选择以及注意力掩码，旨在解决现有大型推理模型（LRMs）在训练中偏向有限推理模式的问题，以提升其在数学和科学任务上的表现。", "motivation": "现有的LRMs在推理过程中会展现出多种高层推理模式（如直接求解、反思验证、多解探索），但目前的训练方法倾向于限制模型仅采用少数几种占主导地位的模式，导致在不同问题上选择的默认模式并非最优，从而影响准确性。", "method": "GPSO是一个基于GRPO的强化学习框架，其核心在于：1）引入多模式采样（multi-pattern rollouts），让模型尝试不同的推理模式；2）利用验证器引导模型为每个问题选择最优的推理模式（verifier-guided optimal pattern selection per problem）；3）在优化过程中使用注意力掩码（attention masking）防止显式的模式后缀信息泄露到学习策略中。", "result": "GPSO在各种模型骨干和基准测试中均实现了持续且显著的性能提升。实验证明，该方法能有效缓解模式选择不当的问题，使模型能够根据问题特点内化最优推理模式的选择。", "conclusion": "GPSO框架通过主动探索和优化多种推理策略，能够使大型推理模型更有效地学习从问题特征到最优推理模式的映射，从而显著提升其在数学和科学推理任务上的准确性和鲁棒性。"}}
{"id": "2601.06931", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06931", "abs": "https://arxiv.org/abs/2601.06931", "authors": ["Haodong Chen", "Qiang Huang", "Jiaqi Zhao", "Qiuping Jiang", "Xiaojun Chang", "Jun Yu"], "title": "Measuring Social Bias in Vision-Language Models with Face-Only Counterfactuals from Real Photos", "comment": "18 pages, 18 figures, and 3 tables", "summary": "Vision-Language Models (VLMs) are increasingly deployed in socially consequential settings, raising concerns about social bias driven by demographic cues. A central challenge in measuring such social bias is attribution under visual confounding: real-world images entangle race and gender with correlated factors such as background and clothing, obscuring attribution. We propose a \\textbf{face-only counterfactual evaluation paradigm} that isolates demographic effects while preserving real-image realism. Starting from real photographs, we generate counterfactual variants by editing only facial attributes related to race and gender, keeping all other visual factors fixed. Based on this paradigm, we construct \\textbf{FOCUS}, a dataset of 480 scene-matched counterfactual images across six occupations and ten demographic groups, and propose \\textbf{REFLECT}, a benchmark comprising three decision-oriented tasks: two-alternative forced choice, multiple-choice socioeconomic inference, and numeric salary recommendation. Experiments on five state-of-the-art VLMs reveal that demographic disparities persist under strict visual control and vary substantially across task formulations. These findings underscore the necessity of controlled, counterfactual audits and highlight task design as a critical factor in evaluating social bias in multimodal models.", "AI": {"tldr": "本文提出了一种基于人脸的对立样本评估范式（FOCUS数据集和REFLECT基准），用于衡量视觉语言模型（VLMs）中的社会偏见，该范式通过仅编辑人脸属性来分离人口统计学效应，同时保持其他视觉因素不变，并发现即使在严格控制下，偏见依然存在，且在不同任务设计中表现各异。", "motivation": "现实世界图像中，种族和性别等人口统计学特征常与背景、服装等因素纠缠在一起，导致难以准确衡量视觉语言模型（VLMs）中的社会偏见。现有方法在处理这种视觉混淆时存在困难。", "method": "提出了一种“人脸优先对立样本评估范式”，通过在真实照片的基础上，仅编辑与种族和性别相关的人脸属性，生成对立样本，同时保持所有其他视觉因素不变。基于此范式构建了FOCUS数据集（包含480张场景匹配的对立样本图像，覆盖六种职业和十种人口统计学群体），并提出了REFLECT基准（包含三种决策导向任务：二选一、多选社会经济推断、数值薪资推荐）。", "result": "在五个最先进的VLMs上的实验表明，即使在严格的视觉控制下，人口统计学上的差异仍然存在，并且在不同任务的表述方式下差异很大。", "conclusion": "研究强调了进行受控的、基于对立样本的审计的必要性，并指出任务设计是评估多模态模型社会偏见的关键因素。"}}
{"id": "2601.07309", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07309", "abs": "https://arxiv.org/abs/2601.07309", "authors": ["Zhuoka Feng", "Kang Chen", "Sihan Zhao", "Kai Xiong", "Yaoning Wang", "Minshen Yu", "Junjie Nian", "Changyi Xiao", "Yixin Cao", "Yugang Jiang"], "title": "ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging", "comment": "17 pages, 12 figures. Project page: https://arkazhuo.github.io/ARM-homepage/", "summary": "Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. In this paper, we propose Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well designed 3-step framework: 1) constructing merged backbones, 2) selection based on its role-conditioned activation analysis, and 3) neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization.", "AI": {"tldr": "提出一种名为 Agent-Role Merging (ARM) 的模型合并方法，通过激活引导和角色条件神经元移植，无需梯度优化即可提升大型语言模型智能体的跨环境泛化能力。", "motivation": "现有的交互式大型语言模型智能体通常仅限于单一环境，难以泛化到其他环境。模型合并提供了一种无需训练即可整合多个专家模型的替代方案。", "method": "提出 Agent-Role Merging (ARM) 方法，该方法包含三个步骤：1) 构建合并骨干模型；2) 基于角色条件激活分析进行选择；3) 进行神经元移植以进行细粒度优化。", "result": "ARM 融合的模型在跨领域泛化能力方面优于现有的模型合并方法和领域特定专家模型，并且在不同领域表现出强大的域外泛化能力。", "conclusion": "ARM 是一种高效、无需梯度优化的模型合并方法，能够显著提升大型语言模型智能体的跨环境泛化能力，并优于现有技术。"}}
{"id": "2601.06827", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06827", "abs": "https://arxiv.org/abs/2601.06827", "authors": ["Jinhan Liu", "Yibo Yang", "Ruiying Lu", "Piotr Piekos", "Yimeng Chen", "Peng Wang", "Dandan Guo"], "title": "PDR: A Plug-and-Play Positional Decay Framework for LLM Pre-training Data Detection", "comment": null, "summary": "Detecting pre-training data in Large Language Models (LLMs) is crucial for auditing data privacy and copyright compliance, yet it remains challenging in black-box, zero-shot settings where computational resources and training data are scarce. While existing likelihood-based methods have shown promise, they typically aggregate token-level scores using uniform weights, thereby neglecting the inherent information-theoretic dynamics of autoregressive generation. In this paper, we hypothesize and empirically validate that memorization signals are heavily skewed towards the high-entropy initial tokens, where model uncertainty is highest, and decay as context accumulates. To leverage this linguistic property, we introduce Positional Decay Reweighting (PDR), a training-free and plug-and-play framework. PDR explicitly reweights token-level scores to amplify distinct signals from early positions while suppressing noise from later ones. Extensive experiments show that PDR acts as a robust prior and can usually enhance a wide range of advanced methods across multiple benchmarks.", "AI": {"tldr": "提出了一种名为位置衰减重加权（PDR）的框架，用于在黑盒、零样本设置下检测大型语言模型的预训练数据。PDR通过强调早期标记的信号并抑制后期标记的噪声来改进现有方法。", "motivation": "在黑盒、零样本设置下检测LLMs的预训练数据对于数据隐私和版权合规审计至关重要，但现有方法（如基于似然的方法）存在不足，它们通常使用统一的权重聚合标记级分数，忽略了自回归生成的信息论动力学。", "method": "提出并验证了一个假设：记忆信号在模型不确定性最高的早期标记处高度倾斜，并随着上下文的累积而衰减。基于此，引入了位置衰减重加权（PDR）框架，这是一种无需训练、即插即用的方法，通过显式地重新加权标记级分数来增强早期位置的信号，同时抑制后期位置的噪声。", "result": "PDR作为一种鲁棒的先验，能够在多个基准测试中增强各种先进方法的性能。", "conclusion": "PDR是一种有效的方法，可以解决黑盒、零样本设置下检测LLM预训练数据的挑战，通过利用早期标记信息并减少后期标记的噪声来提高检测效果。"}}
{"id": "2601.06943", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06943", "abs": "https://arxiv.org/abs/2601.06943", "authors": ["Chengwen Liu", "Xiaomin Yu", "Zhuoyue Chang", "Zhe Huang", "Shuo Zhang", "Heng Lian", "Kunyi Wang", "Rui Xu", "Sen Hu", "Jianheng Hou", "Hao Peng", "Chengwei Qin", "Xiaobin Hu", "Hong Peng", "Ronghao Chen", "Huacan Wang"], "title": "Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning", "comment": null, "summary": "In real-world video question answering scenarios, videos often provide only localized visual cues, while verifiable answers are distributed across the open web; models therefore need to jointly perform cross-frame clue extraction, iterative retrieval, and multi-hop reasoning-based verification. To bridge this gap, we construct the first video deep research benchmark, VideoDR. VideoDR centers on video-conditioned open-domain video question answering, requiring cross-frame visual anchor extraction, interactive web retrieval, and multi-hop reasoning over joint video-web evidence; through rigorous human annotation and quality control, we obtain high-quality video deep research samples spanning six semantic domains. We evaluate multiple closed-source and open-source multimodal large language models under both the Workflow and Agentic paradigms, and the results show that Agentic is not consistently superior to Workflow: its gains depend on a model's ability to maintain the initial video anchors over long retrieval chains. Further analysis indicates that goal drift and long-horizon consistency are the core bottlenecks. In sum, VideoDR provides a systematic benchmark for studying video agents in open-web settings and reveals the key challenges for next-generation video deep research agents.", "AI": {"tldr": "本文提出了VideoDR基准，用于视频深度研究（Video Question Answering），该基准要求模型从视频中提取线索，并在开放网络上进行迭代检索和多跳推理来验证答案。实验表明，Agentic范式并不总是优于Workflow范式，模型在保持初始视频线索的长期一致性方面存在挑战。", "motivation": "现实世界的视频问答场景中，视频信息分散且答案存在于开放网络，现有模型难以进行跨模态线索提取、迭代检索和多跳推理。", "method": "构建了VideoDR基准，包含视频条件下的开放域视频问答任务。该基准要求提取视频视觉锚点，进行交互式网络检索，并在视频-网络联合证据上进行多跳推理。评估了多种多模态大语言模型在Workflow和Agentic两种范式下的表现。", "result": "Agentic范式并不总是优于Workflow范式，其优势依赖于模型在长检索链中保持初始视频锚点的能力。模型在长期一致性（goal drift and long-horizon consistency）方面存在瓶颈。", "conclusion": "VideoDR基准为研究开放网络环境下的视频智能体提供了系统性评估框架，并揭示了下一代视频深度研究智能体的关键挑战。"}}
{"id": "2601.06848", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06848", "abs": "https://arxiv.org/abs/2601.06848", "authors": ["Zhongzheng Wang", "Yuanhe Tian", "Hongzhi Wang", "Yan Song"], "title": "Explainable Multimodal Aspect-Based Sentiment Analysis with Dependency-guided Large Language Model", "comment": "9 pages, 3 figures", "summary": "Multimodal aspect-based sentiment analysis (MABSA) aims to identify aspect-level sentiments by jointly modeling textual and visual information, which is essential for fine-grained opinion understanding in social media. Existing approaches mainly rely on discriminative classification with complex multimodal fusion, yet lacking explicit sentiment explainability. In this paper, we reformulate MABSA as a generative and explainable task, proposing a unified framework that simultaneously predicts aspect-level sentiment and generates natural language explanations. Based on multimodal large language models (MLLMs), our approach employs a prompt-based generative paradigm, jointly producing sentiment and explanation. To further enhance aspect-oriented reasoning capabilities, we propose a dependency-syntax-guided sentiment cue strategy. This strategy prunes and textualizes the aspect-centered dependency syntax tree, guiding the model to distinguish different sentiment aspects and enhancing its explainability. To enable explainability, we use MLLMs to construct new datasets with sentiment explanations to fine-tune. Experiments show that our approach not only achieves consistent gains in sentiment classification accuracy, but also produces faithful, aspect-grounded explanations.", "AI": {"tldr": "本文提出了一种新的生成式、可解释的多模态方面情感分析（MABSA）框架，该框架基于多模态大语言模型（MLLMs），能够同时预测情感和生成自然语言解释。通过依赖语法引导的情感线索策略，增强了模型对方面的推理能力和可解释性。", "motivation": "现有MABSA方法在多模态融合上依赖判别式分类，缺乏明确的情感可解释性。因此，研究动机是提出一个能生成情感和解释的可解释MABSA框架。", "method": "采用基于提示的生成范式，利用MLLMs同时预测情感和生成解释。提出依赖语法引导的情感线索策略，通过修剪和文本化方面中心依赖语法树来指导模型进行方面情感推理和增强可解释性。通过构建带解释的新数据集来微调MLLMs。", "result": "该方法在情感分类准确率上取得了显著提升，并能生成忠实且以方面为基础的解释。", "conclusion": "所提出的生成式、可解释的MABSA框架能够有效提高情感分析的准确性，并生成有意义的情感解释，证明了其在细粒度情感理解方面的潜力。"}}
{"id": "2601.07342", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07342", "abs": "https://arxiv.org/abs/2601.07342", "authors": ["Nicolas Tacheny"], "title": "Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure", "comment": null, "summary": "Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis(RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model.\n  In this work, we introduce an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. We define an investigation protocol that structures the agent's reasoning and ensures grounding, reproducibility, and safe handling of missing or ambiguous information.\n  This work lays the foundation for autonomous incident resolution and change impact mitigation. Future systems will not only diagnose and remediate infrastructure failures, but also predict the impact of planned changes on services and customers, enabling operators to mitigate risks before executing maintenance operations.", "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的智能诊断框架，用于电信和数据中心基础设施的根因分析，通过与基础设施模型交互来自动诊断和解决问题。", "motivation": "传统的根因分析方法维护成本高且与基础设施模型耦合紧密，难以应对大规模复杂基础设施中的故障传播和客户影响。", "method": "该框架利用LLM，通过调用一组预定义的工具（如服务查找、依赖检索、数据分析等），并遵循一个结构化的调查协议，来模拟人工诊断过程，实现自主导航和推理。", "result": "该框架能够自主地在基础设施模型中进行调查，检索相关信息，并有望实现自主的故障诊断。", "conclusion": "该工作为实现自主事件响应和变更影响缓解奠定了基础，并展望了未来系统能够预测计划变更的影响，从而在执行维护操作前降低风险。"}}
{"id": "2601.06944", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06944", "abs": "https://arxiv.org/abs/2601.06944", "authors": ["Yuhang Su", "Mei Wang", "Yaoyao Zhong", "Guozhang Li", "Shixing Li", "Yihan Feng", "Hua Huang"], "title": "SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models", "comment": "8 pages for the main text (excluding references and the limitations section); 37 pages in total including appendices", "summary": "While Multimodal Large Language Models (MLLMs) have achieved remarkable progress in visual understanding, they often struggle when faced with the unstructured and ambiguous nature of human-generated sketches. This limitation is particularly pronounced in the underexplored task of visual grading, where models should not only solve a problem but also diagnose errors in hand-drawn diagrams. Such diagnostic capabilities depend on complex structural, semantic, and metacognitive reasoning. To bridge this gap, we introduce SketchJudge, a novel benchmark tailored for evaluating MLLMs as graders of hand-drawn STEM diagrams. SketchJudge encompasses 1,015 hand-drawn student responses across four domains: geometry, physics, charts, and flowcharts, featuring diverse stylistic variations and distinct error types. Evaluations on SketchJudge demonstrate that even advanced MLLMs lag significantly behind humans, validating the benchmark's effectiveness in exposing the fragility of current vision-language alignment in symbolic and noisy contexts. All data, code, and evaluation scripts are publicly available at https://github.com/yuhangsu82/SketchJudge.", "AI": {"tldr": "提出SketchJudge基准，用于评估多模态大语言模型（MLLMs）在理解和评估手绘STEM图表方面的能力，发现现有MLLMs在此类任务上表现远不如人类。", "motivation": "现有MLLMs在理解手绘草图方面存在不足，尤其是在视觉评判任务中，该任务需要模型不仅能解决问题，还能诊断手绘图表中的错误，这需要复杂的结构、语义和元认知推理能力。因此，需要一个专门的基准来评估MLLMs在这一领域的表现。", "method": "构建了一个名为SketchJudge的新基准，包含1015个学生手绘的STEM图表（几何、物理、图表、流程图），覆盖了多样的风格和错误类型。利用此基准对先进的MLLMs进行了评估。", "result": "评估结果显示，即便是最先进的MLLMs在SketchJudge基准上的表现也远逊于人类，验证了该基准在揭示当前视觉-语言对齐在符号化和噪声化情境下的脆弱性方面的有效性。", "conclusion": "SketchJudge基准能够有效地暴露当前MLLMs在理解和评估手绘草图方面的局限性，尤其是在需要复杂推理的视觉评判任务中。该基准的引入对于推动MLLMs在处理非结构化和模糊视觉信息方面的研究具有重要意义。"}}
{"id": "2601.07364", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07364", "abs": "https://arxiv.org/abs/2601.07364", "authors": ["Joseph Chen"], "title": "On the universal definition of intelligence", "comment": null, "summary": "This paper aims to propose a universal definition of intelligence that enables fair and consistent comparison of human and artificial intelligence (AI). With the rapid development of AI technology in recent years, how to compare and evaluate human and AI intelligence has become an important theoretical issue. However, existing definitions of intelligence are anthropocentric and unsuitable for empirical comparison, resulting in a lack of consensus in the research field.\n  This paper first introduces four criteria for evaluating intelligence definitions based on R. Carnap's methodology of conceptual clarification: similarity to explicandum, exactness, fruitfulness, and simplicity. We then examine six representative definitions: IQ testing, complex problem-solving ability, reward optimization, environmental adaptation, learning efficiency, and predictive ability, and clarify their theoretical strengths and limitations.\n  The results show that while definitions based on predictive ability have high explanatory power and empirical feasibility, they suffer from an inability to adequately explain the relationship between predictions and behavior/benefits. This paper proposes the Extended Predictive Hypothesis (EPH), which views intelligence as a combination of the ability to accurately predict the future and the ability to benefit from those predictions. Furthermore, by distinguishing predictive ability into spontaneous and reactive predictions and adding the concept of gainability, we present a unified framework for explaining various aspects of intelligence, such as creativity, learning, and future planning. In conclusion, this paper argues that the EPH is the most satisfactory and universal definition for comparing human and AI intelligence.", "AI": {"tldr": "本文提出了一种名为“扩展预测假设”（EPH）的通用智能定义，它将准确预测未来和从预测中获益的能力相结合，旨在解决当前AI发展中人机智能比较缺乏统一标准的问题。", "motivation": "当前人工智能技术飞速发展，但缺乏一个普适的智能定义来公平、一致地比较人类和人工智能。现有定义多以人为中心，不适用于实证比较，导致研究领域缺乏共识。", "method": "文章首先依据卡尔纳普的理论，提出了评估智能定义标准的四个维度：与待明确概念的相似性、精确性、有效性和简洁性。随后，对六种代表性智能定义（IQ测试、复杂问题解决能力、奖励优化、环境适应、学习效率、预测能力）进行了分析，阐述了它们的优缺点。最后，提出了扩展预测假设（EPH），并将其分解为自发预测、反应式预测和可获益性，构建了一个统一的智能解释框架。", "result": "分析表明，基于预测能力的定义具有较高的解释力和实证可行性，但未能充分解释预测与行为/收益之间的关系。EPH通过结合预测能力和从预测中获益的能力，弥补了这一不足。通过区分预测的类型并引入可获益性概念，EPH能够解释创造力、学习和未来规划等多种智能方面。", "conclusion": "本文认为，扩展预测假设（EPH）是目前最令人满意且普适的智能定义，为比较人类和人工智能提供了统一的框架。"}}
{"id": "2601.07376", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.07376", "abs": "https://arxiv.org/abs/2601.07376", "authors": ["Siqi Zhu", "Jiaxuan You"], "title": "OpenTinker: Separating Concerns in Agentic Reinforcement Learning", "comment": null, "summary": "We introduce OpenTinker, an infrastructure for reinforcement learning (RL) of large language model (LLM) agents built around a separation of concerns across algorithm design, execution, and agent-environment interaction. Rather than relying on monolithic, end-to-end RL pipelines, OpenTinker decomposes agentic learning systems into lightweight, composable components with clearly defined abstraction boundaries. Users specify agents, environments, and interaction protocols, while inference and training are delegated to a managed execution runtime. OpenTinker introduces a centralized scheduler for managing training and inference workloads, including LoRA-based and full-parameter RL, supervised fine-tuning, and inference, over shared resources. We further discuss design principles for extending OpenTinker to multi-agent training. Finally, we present a set of RL use cases that demonstrate the effectiveness of the framework in practical agentic learning scenarios.", "AI": {"tldr": "OpenTinker 是一个用于大型语言模型（LLM）强化学习（RL）的框架，它将算法设计、执行和智能体-环境交互解耦为可组合的组件，并通过中央调度器管理训练和推理工作负载。", "motivation": "传统的端到端 RL 管道在处理 LLM 智能体时不够灵活和高效，研究人员希望构建一个更具模块化和可扩展性的基础设施。", "method": "OpenTinker 通过将 LLM 智能体的 RL 过程分解为独立的组件（智能体、环境、交互协议），并由一个集中的执行运行时管理推理和训练（包括 LoRA 和全参数 RL、监督微调）。它还提出了多智能体训练的设计原则。", "result": "该框架能够有效地管理训练和推理工作负载，支持多种 RL 方法，并为多智能体训练提供了设计方向。通过实际用例展示了其有效性。", "conclusion": "OpenTinker 提供了一个灵活、可组合且可扩展的基础设施，用于 LLM 的强化学习，通过分离关注点和集中式调度，简化了智能体学习系统的开发和部署。"}}
{"id": "2601.06965", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06965", "abs": "https://arxiv.org/abs/2601.06965", "authors": ["Yu Zhong", "Tianwei Lin", "Ruike Zhu", "Yuqian Yuan", "Haoyu Zheng", "Liang Liang", "Wenqiao Zhang", "Feifei Shao", "Haoyuan Li", "Wanggui He", "Hao Jiang", "Yueting Zhuang"], "title": "Unified Personalized Understanding, Generating and Editing", "comment": null, "summary": "Unified large multimodal models (LMMs) have achieved remarkable progress in general-purpose multimodal understanding and generation. However, they still operate under a ``one-size-fits-all'' paradigm and struggle to model user-specific concepts (e.g., generate a photo of \\texttt{<maeve>}) in a consistent and controllable manner. Existing personalization methods typically rely on external retrieval, which is inefficient and poorly integrated into unified multimodal pipelines. Recent personalized unified models introduce learnable soft prompts to encode concept information, yet they either couple understanding and generation or depend on complex multi-stage training, leading to cross-task interference and ultimately to fuzzy or misaligned personalized knowledge. We present \\textbf{OmniPersona}, an end-to-end personalization framework for unified LMMs that, for the first time, integrates personalized understanding, generation, and image editing within a single architecture. OmniPersona introduces structurally decoupled concept tokens, allocating dedicated subspaces for different tasks to minimize interference, and incorporates an explicit knowledge replay mechanism that propagates personalized attribute knowledge across tasks, enabling consistent personalized behavior. To systematically evaluate unified personalization, we propose \\textbf{\\texttt{OmniPBench}}, extending the public UnifyBench concept set with personalized editing tasks and cross-task evaluation protocols integrating understanding, generation, and editing. Experimental results demonstrate that OmniPersona delivers competitive and robust performance across diverse personalization tasks. We hope OmniPersona will serve as a strong baseline and spur further research on controllable, unified personalization.", "AI": {"tldr": "本文提出了OmniPersona，一个用于统一大型多模态模型的端到端个性化框架，集成了理解、生成和图像编辑。通过解耦的概念token和知识重放机制，OmniPersona实现了任务间的知识一致性。同时，引入了OmniPBench基准来系统评估个性化能力。", "motivation": "现有的统一多模态模型在处理用户特定概念时存在一致性和可控性不足的问题。现有的个性化方法效率低下或集成不佳，而最近的个性化模型则存在任务间干扰和知识模糊等问题。", "method": "OmniPersona提出了结构解耦的概念token，为不同任务分配专用子空间，以减少干扰。此外，它还引入了显式的知识重放机制，将个性化属性知识传播到不同任务中，从而实现一致的个性化行为。同时，提出了OmniPBench基准来系统地评估统一个性化。", "result": "实验结果表明，OmniPersona在各种个性化任务上表现出有竞争力且稳健的性能。OmniPersona能够实现一致的个性化理解、生成和图像编辑。", "conclusion": "OmniPersona是一个创新的端到端个性化框架，能够克服现有统一多模态模型在个性化方面的挑战，并为未来的可控、统一个性化研究提供了一个强大的基线。"}}
{"id": "2601.06861", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06861", "abs": "https://arxiv.org/abs/2601.06861", "authors": ["William Guey", "Wei Zhang", "Pei-Luen Patrick Rau", "Pierrick Bougault", "Vitor D. de Moura", "Bertan Ucar", "Jose O. Gomes"], "title": "BiasLab: A Multilingual, Dual-Framing Framework for Robust Measurement of Output-Level Bias in Large Language Models", "comment": "source code and reproducibility scripts available on GitHub", "summary": "Large Language Models (LLMs) are increasingly deployed in high-stakes contexts where their outputs influence real-world decisions. However, evaluating bias in LLM outputs remains methodologically challenging due to sensitivity to prompt wording, limited multilingual coverage, and the lack of standardized metrics that enable reliable comparison across models. This paper introduces BiasLab, an open-source, model-agnostic evaluation framework for quantifying output-level (extrinsic) bias through a multilingual, robustness-oriented experimental design. BiasLab constructs mirrored probe pairs under a strict dual-framing scheme: an affirmative assertion favoring Target A and a reverse assertion obtained by deterministic target substitution favoring Target B, while preserving identical linguistic structure. To reduce dependence on prompt templates, BiasLab performs repeated evaluation under randomized instructional wrappers and enforces a fixed-choice Likert response format to maximize comparability across models and languages. Responses are normalized into agreement labels using an LLM-based judge, aligned for polarity consistency across framings, and aggregated into quantitative bias indicators with descriptive statistics including effect sizes and neutrality rates. The framework supports evaluation across diverse bias axes, including demographic, cultural, political, and geopolitical topics, and produces reproducible artifacts such as structured reports and comparative visualizations. BiasLab contributes a standardized methodology for cross-lingual and framing-sensitive bias measurement that complements intrinsic and dataset-based audits, enabling researchers and institutions to benchmark robustness and make better-informed deployment decisions.", "AI": {"tldr": "BiasLab 是一个开源、模型无关的评估框架，用于通过多语言、面向鲁棒性的实验设计来量化 LLM 输出的偏见。它通过创建具有严格双重框架的镜像探针对，并使用随机指令包装和固定选择的 Likert 响应格式来减少对提示词的依赖，从而实现模型和语言之间的可比性。框架支持多种偏见轴的评估，并生成可复现的报告和可视化。", "motivation": "评估 LLM 输出中的偏见具有方法学上的挑战，包括对提示词敏感、多语言覆盖有限以及缺乏可用于跨模型可靠比较的标准指标。", "method": "BiasLab 框架采用模型无关、多语言、面向鲁棒性的实验设计。它通过严格的双重框架方案构建镜像探针对：一个肯定断言，一个通过确定性目标替换得到的反向断言。为了减少对提示词模板的依赖，BiasLab 在随机指令包装下进行重复评估，并强制使用固定选择的 Likert 响应格式。响应被 LLM 裁判标准化为同意标签，并聚合为量化的偏见指标。", "result": "BiasLab 框架能够量化输出层面的偏见，支持跨多种偏见轴（包括人口、文化、政治和地缘政治话题）的评估，并生成可复现的报告和可视化。", "conclusion": "BiasLab 提供了一种标准化的跨语言和框架敏感的偏见测量方法，是对内在和基于数据集的审计的补充，使研究人员和机构能够评估 LLM 的鲁棒性并做出更明智的部署决策。"}}
{"id": "2601.07393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07393", "abs": "https://arxiv.org/abs/2601.07393", "authors": ["Chengzhi Ji", "Xingfeng Li", "Zhaodong Lv", "Hao Sun", "Pan Liu", "Hao Frank Yang", "Ziyuan Pu"], "title": "Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics", "comment": "17pages,6 figures,6 tables", "summary": "Modular end-to-end (ME2E) autonomous driving paradigms combine modular interpretability with global optimization capability and have demonstrated strong performance. However, existing studies mainly focus on accuracy improvement, while critical system-level factors such as inference latency and energy consumption are often overlooked, resulting in increasingly complex model designs that hinder practical deployment. Prior efforts on model compression and acceleration typically optimize either the software or hardware side in isolation. Software-only optimization cannot fundamentally remove intermediate tensor access and operator scheduling overheads, whereas hardware-only optimization is constrained by model structure and precision. As a result, the real-world benefits of such optimizations are often limited. To address these challenges, this paper proposes a reusable software and hardware co-optimization and closed-loop evaluation framework for ME2E autonomous driving inference. The framework jointly integrates software-level model optimization with hardware-level computation optimization under a unified system-level objective. In addition, a multidimensional evaluation metric is introduced to assess system performance by jointly considering safety, comfort, efficiency, latency, and energy, enabling quantitative comparison of different optimization strategies. Experiments across multiple ME2E autonomous driving stacks show that the proposed framework preserves baseline-level driving performance while significantly reducing inference latency and energy consumption, achieving substantial overall system-level improvements. These results demonstrate that the proposed framework provides practical and actionable guidance for efficient deployment of ME2E autonomous driving systems.", "AI": {"tldr": "该研究提出了一个用于 ME2E 自动驾驶推理的可重用软硬件协同优化和闭环评估框架，旨在解决现有方法忽视推理延迟和能耗问题。通过整合软硬件优化和引入多维度评估指标，该框架在保持驾驶性能的同时，显著降低了推理延迟和能耗，为 ME2E 自动驾驶系统的实际部署提供了实用的指导。", "motivation": "现有 ME2E 自动驾驶模型过于关注准确性，忽略了推理延迟和能耗等关键系统级因素，导致模型复杂，难以实际部署。现有的模型压缩和加速方法仅独立优化软件或硬件，效果有限。", "method": "提出一个软硬件协同优化和闭环评估框架，该框架将软件层面的模型优化与硬件层面的计算优化相结合，并引入了一个多维度的评估指标（安全、舒适、效率、延迟、能耗）来综合评估系统性能。", "result": "在多个 ME2E 自动驾驶系统上的实验表明，该框架在保持基线驾驶性能的同时，显著降低了推理延迟和能耗，实现了整体系统级的显著改进。", "conclusion": "该框架为 ME2E 自动驾驶系统的效率部署提供了实用且可行的指导，能够有效权衡性能、延迟和能耗。"}}
{"id": "2601.07001", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07001", "abs": "https://arxiv.org/abs/2601.07001", "authors": ["Sen Zeng", "Hong Zhou", "Zheng Zhu", "Yang Liu"], "title": "Spatial Multi-Task Learning for Breast Cancer Molecular Subtype Prediction from Single-Phase DCE-MRI", "comment": null, "summary": "Accurate molecular subtype classification is essential for personalized breast cancer treatment, yet conventional immunohistochemical analysis relies on invasive biopsies and is prone to sampling bias. Although dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) enables non-invasive tumor characterization, clinical workflows typically acquire only single-phase post-contrast images to reduce scan time and contrast agent dose. In this study, we propose a spatial multi-task learning framework for breast cancer molecular subtype prediction from clinically practical single-phase DCE-MRI. The framework simultaneously predicts estrogen receptor (ER), progesterone receptor (PR), human epidermal growth factor receptor 2 (HER2) status, and the Ki-67 proliferation index -- biomarkers that collectively define molecular subtypes. The architecture integrates a deep feature extraction network with multi-scale spatial attention to capture intratumoral and peritumoral characteristics, together with a region-of-interest weighting module that emphasizes the tumor core, rim, and surrounding tissue. Multi-task learning exploits biological correlations among biomarkers through shared representations with task-specific prediction branches. Experiments on a dataset of 960 cases (886 internal cases split 7:1:2 for training/validation/testing, and 74 external cases evaluated via five-fold cross-validation) demonstrate that the proposed method achieves an AUC of 0.893, 0.824, and 0.857 for ER, PR, and HER2 classification, respectively, and a mean absolute error of 8.2\\% for Ki-67 regression, significantly outperforming radiomics and single-task deep learning baselines. These results indicate the feasibility of accurate, non-invasive molecular subtype prediction using standard imaging protocols.", "AI": {"tldr": "本研究提出了一种基于单相动态增强磁共振成像（DCE-MRI）的空间多任务学习框架，用于非侵入性地预测乳腺癌的分子亚型（ER、PR、HER2状态和Ki-67指数），实验结果显示其性能优于现有方法。", "motivation": "传统的乳腺癌分子亚型分类依赖于侵入性活检，存在采样偏差。DCE-MRI可实现无创性肿瘤表征，但临床常规仅采集单相图像。因此，本研究旨在利用临床实用的单相DCE-MRI，开发一种新的方法来实现分子亚型的无创预测。", "method": "提出了一种空间多任务学习框架，该框架集成了深度特征提取网络和多尺度空间注意力机制，以捕捉肿瘤内部和周围的特征。同时，引入了区域兴趣加权模块，以强调肿瘤核心、边缘和周围组织。多任务学习通过共享表示和特定任务的预测分支，利用了生物标志物之间的生物相关性。", "result": "在960个病例的数据集上进行实验，结果显示该方法在ER、PR和HER2分类上分别取得了0.893、0.824和0.857的AUC值，在Ki-67回归上实现了8.2%的平均绝对误差。这些结果显著优于传统的影像组学和单任务深度学习方法。", "conclusion": "提出的空间多任务学习框架能够使用标准DCE-MRI成像方案，准确地进行非侵入性乳腺癌分子亚型预测，显示出其在临床应用中的可行性。"}}
{"id": "2601.06884", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06884", "abs": "https://arxiv.org/abs/2601.06884", "authors": ["Masahiro Kaneko"], "title": "Paraphrasing Adversarial Attack on LLM-as-a-Reviewer", "comment": null, "summary": "The use of large language models (LLMs) in peer review systems has attracted growing attention, making it essential to examine their potential vulnerabilities. Prior attacks rely on prompt injection, which alters manuscript content and conflates injection susceptibility with evaluation robustness. We propose the Paraphrasing Adversarial Attack (PAA), a black-box optimization method that searches for paraphrased sequences yielding higher review scores while preserving semantic equivalence and linguistic naturalness. PAA leverages in-context learning, using previous paraphrases and their scores to guide candidate generation. Experiments across five ML and NLP conferences with three LLM reviewers and five attacking models show that PAA consistently increases review scores without changing the paper's claims. Human evaluation confirms that generated paraphrases maintain meaning and naturalness. We also find that attacked papers exhibit increased perplexity in reviews, offering a potential detection signal, and that paraphrasing submissions can partially mitigate attacks.", "AI": {"tldr": "本研究提出了一种名为“释义对抗攻击”（PAA）的黑盒优化方法，通过生成语义等价且自然流畅的释义来操纵大型语言模型（LLM）的审稿评分，而无需改变论文的核心论点。研究发现，被攻击的论文会增加审稿评论的困惑度，这可能是一种检测信号，并且释义提交可以部分减轻攻击。", "motivation": "现有针对LLM审稿系统攻击的方法（如提示注入）混淆了注入敏感性和评估鲁棒性。研究者希望探索一种不改变论文内容但能影响LLM评分的攻击方法，以更深入地理解LLM在审稿系统中的脆弱性。", "method": "提出释义对抗攻击（PAA）是一种黑盒优化方法。它利用LLM的上下文学习能力，通过生成语义等价且语言自然的释义来提高审稿评分。PAA会利用先前的释义及其评分来指导新释义的生成。", "result": "在五个机器学习和自然语言处理会议的实验中，使用三个LLM审稿人和五个攻击模型，PAA都能一致地提高审稿评分，而不会改变论文的论点。人类评估也证实了生成的释义在意义和自然度上得以保留。研究还发现，被攻击论文的审稿评论会呈现更高的困惑度，这可能是一种检测信号。此外，对提交稿件进行释义可以部分缓解攻击。", "conclusion": "释义对抗攻击（PAA）是一种有效的操纵LLM审稿评分的方法，它通过生成语义等价的释义来增加评分，而不会改变论文的本质内容。审稿评论的困惑度增加可以作为检测此类攻击的潜在信号，并且通过释义提交可以部分防御这些攻击。"}}
{"id": "2601.06853", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06853", "abs": "https://arxiv.org/abs/2601.06853", "authors": ["Zabir Al Nazi", "Shubhashis Roy Dipta", "Sudipta Kar"], "title": "†DAGGER: Distractor-Aware Graph Generation for Executable Reasoning in Math Problems", "comment": null, "summary": "Chain-of-Thought (CoT) prompting is widely adopted for mathematical problem solving, including in low-resource languages, yet its behavior under irrelevant context remains underexplored. To systematically study this challenge, we introduce DISTRACTMATH-BN, a Bangla benchmark that augments MGSM and MSVAMP with semantically coherent but computationally irrelevant information. Evaluating seven models ranging from 3B to 12B parameters, we observe substantial performance degradation under distractors: standard models drop by up to 41 points, while reasoning-specialized models decline by 14 to 20 points despite consuming five times more tokens. We propose †DAGGER, which reformulates mathematical problem solving as executable computational graph generation with explicit modeling of distractor nodes. Fine-tuning Gemma-3 models using supervised fine-tuning followed by Group Relative Policy Optimization achieves comparable weighted accuracy on augmented benchmarks while using 89 percent fewer tokens than reasoning models. Importantly, this robustness emerges without explicit training on distractor-augmented examples. Our results suggest that enforcing structured intermediate representations improves robustness and inference efficiency in mathematical reasoning compared to free-form approaches, particularly in noisy, low-resource settings.", "AI": {"tldr": "该研究引入了一个包含干扰信息的孟加拉语数学问题数据集DISTRACTMATH-BN，并提出了DAGGER模型，通过计算图生成的方式来解决数学问题，以提高模型在干扰下的鲁棒性和效率。", "motivation": "尽管链式思考（CoT）提示在数学问题解决中得到广泛应用，但在存在不相关上下文的情况下其行为尚待深入研究，尤其是在低资源语言中。因此，研究者希望系统地研究这一挑战。", "method": "研究者构建了一个名为DISTRACTMATH-BN的孟加拉语基准数据集，该数据集在现有数据集的基础上增加了语义相关但不计算上无关的干扰信息。他们评估了七种不同参数规模的模型，并提出了一种名为†DAGGER的方法，该方法将数学问题解决重构为可执行的计算图生成，并显式建模干扰节点。使用监督微调（SFT）和分组相对策略优化（GRPO）对Gemma-3模型进行微调。", "result": "在干扰信息的影响下，标准模型性能下降高达41个百分点，而专门用于推理的模型性能下降14-20个百分点，尽管它们消耗了更多的tokens。†DAGGER模型在增强基准上的加权准确率与基线模型相当，但使用的tokens减少了89%。这种鲁棒性是在没有显式训练干扰增强示例的情况下出现的。", "conclusion": "研究表明，强制结构化的中间表示（如计算图）比自由形式的方法更能提高数学推理的鲁棒性和推理效率，尤其是在嘈杂的低资源环境中。DAGGER模型提供了一种有效的方法来处理数学推理中的干扰信息。"}}
{"id": "2601.06907", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06907", "abs": "https://arxiv.org/abs/2601.06907", "authors": ["Quan Zheng", "Yuanhe Tian", "Ming Wang", "Yan Song"], "title": "Fine-grained Verbal Attack Detection via a Hierarchical Divide-and-Conquer Framework", "comment": "13pages, 5figures", "summary": "In the digital era, effective identification and analysis of verbal attacks are essential for maintaining online civility and ensuring social security. However, existing research is limited by insufficient modeling of conversational structure and contextual dependency, particularly in Chinese social media where implicit attacks are prevalent. Current attack detection studies often emphasize general semantic understanding while overlooking user response relationships, hindering the identification of implicit and context-dependent attacks. To address these challenges, we present the novel \"Hierarchical Attack Comment Detection\" dataset and propose a divide-and-conquer, fine-grained framework for verbal attack recognition based on spatiotemporal information. The proposed dataset explicitly encodes hierarchical reply structures and chronological order, capturing complex interaction patterns in multi-turn discussions. Building on this dataset, the framework decomposes attack detection into hierarchical subtasks, where specialized lightweight models handle explicit detection, implicit intent inference, and target identification under constrained context. Extensive experiments on the proposed dataset and benchmark intention detection datasets show that smaller models using our framework significantly outperform larger monolithic models relying on parameter scaling, demonstrating the effectiveness of structured task decomposition.", "AI": {"tldr": "本文提出了一个用于识别中文社交媒体中语言攻击的新数据集（Hierarchical Attack Comment Detection）和一个分而治之的细粒度框架。该框架将攻击检测分解为多个子任务，并使用轻量级模型，在实验中优于大型单体模型。", "motivation": "现有研究在中文社交媒体的语言攻击检测方面存在不足，尤其是在对会话结构、上下文依赖以及隐含攻击的建模上。用户回复关系和上下文信息被忽视，阻碍了对隐含和上下文依赖性攻击的识别。", "method": "构建了一个新的“Hierarchical Attack Comment Detection”数据集，该数据集包含明确的回复层级结构和时间顺序信息。提出一个基于时空信息的细粒度框架，将攻击检测任务分解为显式检测、隐含意图推断和目标识别三个子任务，并使用专门的轻量级模型处理每个子任务。", "result": "在新的数据集和基准数据集上的实验表明，使用本文框架的小型模型在性能上显著优于依赖参数扩展的大型单体模型，验证了结构化任务分解的有效性。", "conclusion": "通过对语言攻击检测任务进行结构化分解，并利用专门的轻量级模型，可以在中文社交媒体等复杂场景下实现更有效的攻击识别，尤其擅长处理隐含和上下文依赖的攻击。"}}
{"id": "2601.07463", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07463", "abs": "https://arxiv.org/abs/2601.07463", "authors": ["Sijia li", "Xinran Li", "Shibo Chen", "Jun Zhang"], "title": "Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning", "comment": null, "summary": "Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing offline MARL methods primarily constrain training within the dataset distribution, resulting in overly conservative policies that struggle to generalize beyond the support of the data. While model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model, the high dimensionality, non-stationarity, and complexity of multi-agent systems make it challenging to accurately estimate the transitions and reward functions in offline MARL. Given the difficulty of directly modeling joint dynamics, we propose a local-to-global (LOGO) world model, a novel framework that leverages local predictions-which are easier to estimate-to infer global state dynamics, thus improving prediction accuracy while implicitly capturing agent-wise dependencies. Using the trained world model, we generate synthetic data to augment the original dataset, expanding the effective state-action space. To ensure reliable policy learning, we further introduce an uncertainty-aware sampling mechanism that adaptively weights synthetic data by prediction uncertainty, reducing approximation error propagation to policies. In contrast to conventional ensemble-based methods, our approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that our method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning.", "AI": {"tldr": "提出了一种名为 LOGO 的新型离线多智能体强化学习世界模型，它通过局部预测推断全局动态，并结合不确定性感知采样来生成合成数据，以提高策略学习的泛化能力。", "motivation": "现有离线 MARL 方法由于过度保守而难以泛化；模型驱动的方法虽然可以扩展数据集，但在 MARL 中估计模型很困难。因此，需要一种更准确、更高效的世界模型来支持离线 MARL。", "method": "提出了一种局部到全局 (LOGO) 世界模型，它使用易于估计的局部预测来推断全局状态动态，从而提高预测精度并隐式捕捉智能体间的依赖关系。然后，使用训练好的世界模型生成合成数据来增强原始数据集，并通过不确定性感知采样机制自适应地加权合成数据，以减少近似误差传播。", "result": "LOGO 世界模型在 8 个场景的实验中，相较于 8 个基线方法，在标准的离线 MARL 基准测试中取得了优于最先进方法的性能，并建立了新的基于模型的通用离线多智能体学习基线。", "conclusion": "LOGO 世界模型通过局部到全局的动态估计和不确定性感知数据增强，有效地解决了离线 MARL 中的泛化性问题，提供了一种计算效率高且性能优越的新方法。"}}
{"id": "2601.07056", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07056", "abs": "https://arxiv.org/abs/2601.07056", "authors": ["Yunrui Gu", "Zhenzhe Gao", "Cong Kong", "Zhaoxia Yin"], "title": "Adversarial Attacks on Medical Hyperspectral Imaging Exploiting Spectral-Spatial Dependencies and Multiscale Features", "comment": null, "summary": "Medical hyperspectral imaging (HSI) enables accurate disease diagnosis by capturing rich spectral-spatial tissue information, but recent advances in deep learning have exposed its vulnerability to adversarial attacks. In this work, we identify two fundamental causes of this fragility: the reliance on local pixel dependencies for preserving tissue structure and the dependence on multiscale spectral-spatial representations for hierarchical feature encoding. Building on these insights, we propose a targeted adversarial attack framework for medical HSI, consisting of a Local Pixel Dependency Attack that exploits spatial correlations among neighboring pixels, and a Multiscale Information Attack that perturbs features across hierarchical spectral-spatial scales. Experiments on the Brain and MDC datasets demonstrate that our attacks significantly degrade classification performance, especially in tumor regions, while remaining visually imperceptible. Compared with existing methods, our approach reveals the unique vulnerabilities of medical HSI models and underscores the need for robust, structure-aware defenses in clinical applications.", "AI": {"tldr": "本文提出了一种针对医学高光谱成像（HSI）的对抗性攻击框架，该框架通过利用局部像素依赖性和多尺度谱空表示的脆弱性，能显著降低HSI模型的分类性能，尤其是在肿瘤区域，且攻击在视觉上难以察觉。", "motivation": "深度学习在医学HSI诊断中的应用使其容易受到对抗性攻击，作者希望揭示其脆弱性的根本原因并开发有效的攻击方法，以促进更鲁棒的防御机制。", "method": "作者识别出两种HSI模型脆弱性的根本原因：对局部像素依赖性的依赖和对多尺度谱空表示的依赖。基于此，提出了一种包含“局部像素依赖攻击”和“多尺度信息攻击”的对抗性攻击框架。", "result": "在Brain和MDC数据集上的实验表明，提出的攻击方法显著降低了分类性能，特别是在肿瘤区域，并且攻击效果在视觉上是不可察觉的。与现有方法相比，该方法更能揭示医学HSI模型的独特脆弱性。", "conclusion": "医学HSI模型对局部像素依赖和多尺度谱空表示的依赖是其脆弱性的关键。提出的攻击框架能够有效暴露这些脆弱性，并强调了在临床应用中开发鲁棒、结构感知的防御机制的必要性。"}}
{"id": "2601.06911", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06911", "abs": "https://arxiv.org/abs/2601.06911", "authors": ["Shaoning Sun", "Mingzhu Cai", "Huang He", "Bingjin Chen", "Siqi Bao", "Yujiu Yang", "Hua Wu", "Haifeng Wang"], "title": "Distributional Clarity: The Hidden Driver of RL-Friendliness in Large Language Models", "comment": null, "summary": "Language model families exhibit striking disparity in their capacity to benefit from reinforcement learning: under identical training, models like Qwen achieve substantial gains, while others like Llama yield limited improvements. Complementing data-centric approaches, we reveal that this disparity reflects a hidden structural property: \\textbf{distributional clarity} in probability space. Through a three-stage analysis-from phenomenon to mechanism to interpretation-we uncover that RL-friendly models exhibit intra-class compactness and inter-class separation in their probability assignments to correct vs. incorrect responses. We quantify this clarity using the \\textbf{Silhouette Coefficient} ($S$) and demonstrate that (1) high $S$ correlates strongly with RL performance; (2) low $S$ is associated with severe logic errors and reasoning instability. To confirm this property, we introduce a Silhouette-Aware Reweighting strategy that prioritizes low-$S$ samples during training. Experiments across six mathematical benchmarks show consistent improvements across all model families, with gains up to 5.9 points on AIME24. Our work establishes distributional clarity as a fundamental, trainable property underlying RL-Friendliness.", "AI": {"tldr": "本研究揭示了语言模型在强化学习（RL）中表现差异的根本原因在于“分布清晰度”，即模型对正确与错误答案的概率分配在概率空间中的紧凑性和分离性。研究通过量化此清晰度（使用Silhouette系数）并引入一种名为Silhouette-Aware Reweighting的训练策略，显著提升了模型在数学推理任务上的性能。", "motivation": "研究动机源于观察到不同语言模型家族在接受强化学习训练时，其性能提升幅度存在显著差异（例如，Qwen提升明显，Llama提升有限）。作者希望探究这种差异的根本原因，并超越纯粹的数据驱动方法。", "method": "研究采用了三阶段分析法：现象-机制-解释。首先，识别出分布清晰度（intra-class compactness and inter-class separation in probability assignments）这一关键特性。接着，使用Silhouette系数（$S$）量化分布清晰度，并验证其与RL性能的相关性，以及低$S$与逻辑错误和推理不稳定性之间的关系。最后，提出Silhouette-Aware Reweighting策略，该策略在训练过程中优先考虑低$S$的样本，以提高分布清晰度。", "result": "研究发现，高Silhouette系数（$S$）与RL性能强相关，而低$S$与严重的逻辑错误和推理不稳定性相关。通过Silhouette-Aware Reweighting策略，在六个数学基准测试中，所有模型家族的性能均得到了一致提升，其中在AIME24任务上性能提升高达5.9个点。", "conclusion": "本研究将分布清晰度确立为一种可训练的、内在的、且与RL友好度密切相关的特性。该特性解释了不同模型在RL训练中的性能差异，并提供了一种有效的训练策略来改善模型在复杂推理任务中的表现。"}}
{"id": "2601.07464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07464", "abs": "https://arxiv.org/abs/2601.07464", "authors": ["Xiaoheng Wang", "Tongxuan Liu", "Zi Gong", "Xianzhe Dong", "Yuting Zeng", "Minhan Hu", "Weizhe Huang", "Jing Li"], "title": "IFDNS: An Iterative Feedback-Driven Neuro-Symbolic Method for Faithful Logical Reasoning", "comment": "13 pages,5 figures", "summary": "Large language models (LLMs) have demonstrated impressive capabilities across a wide range of reasoning tasks, including logical and mathematical problem-solving. While prompt-based methods like Chain-of-Thought (CoT) can enhance LLM reasoning abilities to some extent, they often suffer from a lack of faithfulness, where the derived conclusions may not align with the generated reasoning chain. To address this issue, researchers have explored neuro-symbolic approaches to bolster LLM logical reasoning capabilities. However, existing neuro-symbolic methods still face challenges with information loss during the process. To overcome these limitations, we introduce Iterative Feedback-Driven Neuro-Symbolic (IFDNS), a novel prompt-based method that employs a multi-round feedback mechanism to address LLM limitations in handling complex logical relationships. IFDNS utilizes iterative feedback during the logic extraction phase to accurately extract causal relationship statements and translate them into propositional and logical implication expressions, effectively mitigating information loss issues. Furthermore, IFDNS is orthogonal to existing prompt methods, allowing for seamless integration with various prompting approaches. Empirical evaluations across six datasets demonstrate the effectiveness of IFDNS in significantly improving the performance of CoT and Chain-of-Thought with Self-Consistency (CoT-SC). Specifically, IFDNS achieves a +9.40% accuracy boost for CoT on the LogiQA dataset and a +11.70% improvement for CoT-SC on the PrOntoQA dataset.", "AI": {"tldr": "提出了一种名为IFDNS的新型基于提示的方法，通过多轮反馈机制迭代地提取逻辑关系，将其转化为命题和逻辑蕴含表达式，以解决大型语言模型在复杂逻辑推理中的信息丢失问题，并能与现有提示方法兼容，显著提升了CoT和CoT-SC的性能。", "motivation": "现有的大型语言模型（LLMs）在逻辑推理方面虽然有一定进展（如CoT），但存在推理链与结论不一致（缺乏忠实性）的问题。而神经符号方法虽然旨在解决这个问题，但仍面临信息丢失的挑战。", "method": "提出迭代反馈驱动的神经符号（IFDNS）方法。该方法采用多轮反馈机制，在逻辑提取阶段进行迭代反馈，以准确提取因果关系陈述，并将其转化为命题和逻辑蕴含表达式，从而减少信息丢失。IFDNS可与现有提示方法（如CoT和CoT-SC）结合使用。", "result": "在六个数据集上的实证评估表明，IFDNS显著提高了CoT和CoT-SC的性能。具体而言，IFDNS在LogiQA数据集上为CoT带来了+9.40%的准确率提升，在PrOntoQA数据集上为CoT-SC带来了+11.70%的性能提升。", "conclusion": "IFDNS是一种有效的多轮反馈驱动的神经符号方法，能够解决大型语言模型在复杂逻辑推理中的信息丢失问题，并显著提升其在逻辑推理任务上的准确率，且具有与现有提示方法正交集成的优势。"}}
{"id": "2601.06922", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06922", "abs": "https://arxiv.org/abs/2601.06922", "authors": ["Tianhua Zhang", "Kun Li", "Junan Li", "Yunxiang Li", "Hongyin Luo", "Xixin Wu", "James Glass", "Helen Meng"], "title": "TreePS-RAG: Tree-based Process Supervision for Reinforcement Learning in Agentic RAG", "comment": null, "summary": "Agentic retrieval-augmented generation (RAG) formulates question answering as a multi-step interaction between reasoning and information retrieval, and has recently been advanced by reinforcement learning (RL) with outcome-based supervision. While effective, relying solely on sparse final rewards limits step-wise credit assignment and provides weak guidance for intermediate reasoning and actions. Recent efforts explore process-level supervision, but typically depend on offline constructed training data, which risks distribution shift, or require costly intermediate annotations. We present TreePS-RAG, an online, tree-based RL framework for agentic RAG that enables step-wise credit assignment while retaining standard outcome-only rewards. Our key insight is to model agentic RAG reasoning as a rollout tree, where each reasoning step naturally maps to a node. This tree structure allows step utility to be estimated via Monte Carlo estimation over its descendant outcomes, yielding fine-grained process advantages without requiring intermediate labels. To make this paradigm practical, we introduce an efficient online tree construction strategy that preserves exploration diversity under a constrained computational budget. With a rollout cost comparable to strong baselines like Search-R1, experiments on seven multi-hop and general QA benchmarks across multiple model scales show that TreePS-RAG consistently and significantly outperforms both outcome-supervised and leading process-supervised RL methods.", "AI": {"tldr": "提出了一种名为 TreePS-RAG 的新颖在线、基于树的强化学习框架，用于改进 agentic RAG，通过将推理过程建模为展开树，实现了细粒度的分步信用分配，而无需中间标签，并在多跳和通用 QA 任务上取得了显著的性能提升。", "motivation": "现有的基于强化学习的 agentic RAG 方法依赖于稀疏的最终奖励，这限制了分步信用分配，并为中间推理提供了薄弱的指导。虽然一些过程级监督方法有所探索，但它们依赖于离线构建的数据或昂贵的中间标注，存在分布偏移和成本过高的问题。", "method": "TreePS-RAG 框架将 agentic RAG 的推理过程建模为一个展开树，其中每个推理步骤对应树的一个节点。通过对子树结果的蒙特卡洛估计来评估每个步骤的效用，从而实现细粒度的过程优势估计，无需中间标签。为了提高实用性，该框架还引入了一种高效的在线树构建策略，以在计算预算受限的情况下保持探索的多样性。", "result": "在七个多跳和通用 QA 基准测试中，TreePS-RAG 在多个模型规模上始终如一地显著优于仅基于结果监督和领先的过程监督的强化学习方法。其展开成本与强基线（如 Search-R1）相当。", "conclusion": "TreePS-RAG 成功地解决了现有 agentic RAG 方法在分步信用分配和中间推理指导方面的局限性。通过创新的树状结构和在线构建策略，该框架能够在保持标准结果奖励的同时，实现有效的细粒度过程监督，并在各种 QA 任务上展现出优越的性能。"}}
{"id": "2601.07468", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07468", "abs": "https://arxiv.org/abs/2601.07468", "authors": ["Miao Su", "Yucan Guo", "Zhongni Hou", "Long Bai", "Zixuan Li", "Yufei Zhang", "Guojun Yin", "Wei Lin", "Xiaolong Jin", "Jiafeng Guo", "Xueqi Cheng"], "title": "Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents", "comment": null, "summary": "Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. However, existing methods fail to properly model the temporal dimension of memory in two aspects: 1) Temporal inaccuracy: memories are organized by dialogue time rather than their actual occurrence time; 2) Temporal fragmentation: existing methods focus on point-wise memory, losing durative information that captures persistent states and evolving patterns. To address these limitations, we propose Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. During memory construction, it first builds a semantic timeline rather than a dialogue one. Then, it consolidates temporally continuous and semantically related information into a durative memory. During memory utilization, it incorporates the query's temporal intent on the semantic timeline, enabling the retrieval of temporally appropriate durative memories and providing time-valid, duration-consistent context to support response generation. Experiments on LongMemEval and LoCoMo show that TSM consistently outperforms existing methods and achieves up to 12.2% absolute improvement in accuracy, demonstrating the effectiveness of the proposed method.", "AI": {"tldr": "本文提出了一种名为时间语义记忆（TSM）的框架，用于改进大型语言模型（LLM）在对话中对时间信息的处理能力，解决了现有方法在时间准确性和时间碎片化方面存在的不足，并在实验中取得了显著的性能提升。", "motivation": "现有LLM的记忆方法未能有效建模对话中的时间维度，导致记忆在时间上不准确（按对话时间而非实际发生时间组织）和时间碎片化（忽略持续性信息）。这阻碍了LLM实现有效的个性化和理解长时上下文。", "method": "TSM框架包含两个主要阶段：1) 记忆构建：首先创建一个基于语义时间而非对话时间的“语义时间线”，然后将时间上连续且语义上相关的记忆片段整合成“持续性记忆”。 2) 记忆利用：结合查询的时间意图，在语义时间线上检索时间上合适的持续性记忆，为响应生成提供有效且时间一致的上下文。", "result": "在LongMemEval和LoCoMo数据集上的实验表明，TSM在准确性方面比现有方法提高了12.2%，一致性优于现有方法，证明了该方法的有效性。", "conclusion": "TSM能够有效地模拟记忆的时间语义，构建和利用持续性记忆，从而在LLM的对话和响应生成中提供更准确、更持久的上下文信息，显著提升了模型性能。"}}
{"id": "2601.07092", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07092", "abs": "https://arxiv.org/abs/2601.07092", "authors": ["Yuliang Cai", "Dongqiangzi Ye", "Zitian Chen", "Chongruo Wu"], "title": "Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression", "comment": "7 pages", "summary": "Autonomous driving increasingly relies on Visual Question Answering (VQA) to enable vehicles to understand complex surroundings by analyzing visual inputs and textual queries. Currently, a paramount concern for VQA in this domain is the stringent requirement for fast latency and real-time processing, as delays directly impact real-world safety in this safety-critical application. However, current state-of-the-art VQA models, particularly large vision-language models (VLMs), often prioritize performance over computational efficiency. These models typically process dense patch tokens for every frame, leading to prohibitive computational costs (FLOPs) and significant inference latency, especially with long video sequences. This focus limits their practical deployment in real-time autonomous driving scenarios. To tackle this issue, we propose an efficient VLM framework for autonomous driving VQA tasks, SRC-Pipeline. It learns to compress early frame tokens into a small number of high-level tokens while retaining full patch tokens for recent frames. Experiments on autonomous driving video question answering tasks show that our approach achieves 66% FLOPs reduction while maintaining comparable performance, enabling VLMs to operate more effectively in real-time, safety-critical autonomous driving settings.", "AI": {"tldr": "提出了一种名为SRC-Pipeline的高效视觉问答（VQA）框架，用于自动驾驶，通过压缩早期帧的token并保留近期帧的全部token，显著降低了计算量（FLOPs）和推理延迟，同时保持了性能。", "motivation": "现有最先进的VQA模型（特别是大型视觉语言模型VLMs）在自动驾驶场景下计算成本高、推理延迟大，无法满足实时处理的需求，影响了其实际部署和安全性。", "method": "设计了一个高效的VLMs框架SRC-Pipeline，学习将早期帧的密集patch token压缩成少量高级token，而近期帧则保留完整的patch token。", "result": "实验表明，SRC-Pipeline 在自动驾驶视频问答任务上实现了 66% 的 FLOPs 削减，同时保持了相当的性能。", "conclusion": "SRC-Pipeline 能够有效降低自动驾驶 VQA 任务中 VLM 的计算成本和推理延迟，使其更适用于实时、安全关键的自动驾驶场景。"}}
{"id": "2601.06993", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06993", "abs": "https://arxiv.org/abs/2601.06993", "authors": ["Jie Zhu", "Yiyang Su", "Xiaoming Liu"], "title": "Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?", "comment": "10 pages, 8 figures", "summary": "Multi-modal large language models (MLLMs) exhibit strong general-purpose capabilities, yet still struggle on Fine-Grained Visual Classification (FGVC), a core perception task that requires subtle visual discrimination and is crucial for many real-world applications. A widely adopted strategy for boosting performance on challenging tasks such as math and coding is Chain-of-Thought (CoT) reasoning. However, several prior works have reported that CoT can actually harm performance on visual perception tasks. These studies, though, examine the issue from relatively narrow angles and leave open why CoT degrades perception-heavy performance. We systematically re-examine the role of CoT in FGVC through the lenses of zero-shot evaluation and multiple training paradigms. Across these settings, we uncover a central paradox: the degradation induced by CoT is largely driven by the reasoning length, in which longer textual reasoning consistently lowers classification accuracy. We term this phenomenon the ``Cost of Thinking''. Building on this finding, we make two key contributions: (1) \\alg, a simple and general plug-and-play normalization method for multi-reward optimization that balances heterogeneous reward signals, and (2) ReFine-RFT, a framework that combines ensemble rewards with \\alg to constrain reasoning length while providing dense accuracy-oriented feedback. Extensive experiments demonstrate the effectiveness of our findings and the proposed ReFine-RFT, achieving state-of-the-art performance across FGVC benchmarks. Code and models are available at \\href{https://github.com/jiezhu23/ReFine-RFT}{Project Link}.", "AI": {"tldr": "研究发现，在细粒度视觉分类（FGVC）任务中，链式思考（CoT）推理反而会因推理长度增加而降低性能（“思考的代价”）。为此，提出了一种名为\\alg的归一化方法来平衡奖励信号，并构建了ReFine-RFT框架，结合集成奖励和\\alg来约束推理长度并提供准确性反馈，在FGVC基准测试中取得了最先进的性能。", "motivation": "多模态大语言模型（MLLMs）在细粒度视觉分类（FGVC）任务上表现不佳，而CoT推理在其他任务上表现良好，但先前研究表明CoT可能损害视觉感知任务的性能，但未深入解释原因。", "method": "通过零样本评估和多种训练范式重新审视CoT在FGVC中的作用，发现推理长度是导致性能下降的关键因素。提出\\alg方法来平衡多奖励优化，并构建ReFine-RFT框架，结合集成奖励和\\alg来约束推理长度并提供准确性反馈。", "result": "研究证实了“思考的代价”现象，即更长的文本推理会降低FGVC的分类准确性。提出的ReFine-RFT框架在FGVC基准测试中取得了最先进的性能。", "conclusion": "细粒度视觉分类任务中，CoT推理的长度是影响性能的关键负面因素。提出的\\alg和ReFine-RFT框架能够有效解决此问题，并显著提升FGVC任务的性能。"}}
{"id": "2601.07469", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07469", "abs": "https://arxiv.org/abs/2601.07469", "authors": ["Julien Cumin", "Oussama Er-Rahmany", "Xi Chen"], "title": "Knowledge Distillation for LLM-Based Human Activity Recognition in Homes", "comment": null, "summary": "Human Activity Recognition (HAR) is a central problem for context-aware applications, especially for smart homes and assisted living. A few very recent studies have shown that Large Language Models (LLMs) can be used for HAR at home, reaching high performance and addressing key challenges. In this paper, we provide new experimental results regarding the use of LLMs for HAR, on two state-of-the-art datasets. More specifically, we show how recognition performance evolves depending on the size of the LLM used. Moreover, we experiment on the use of knowledge distillation techniques to fine-tune smaller LLMs with HAR reasoning examples generated by larger LLMs. We show that such fine-tuned models can perform almost as well as the largest LLMs, while having 50 times less parameters.", "AI": {"tldr": "本文研究使用大型语言模型（LLM）进行家庭活动识别（HAR），并探索了LLM规模和知识蒸馏对性能的影响，发现在参数量大幅减少的情况下，蒸馏后的小型LLM能达到接近大型LLM的性能。", "motivation": "现有研究表明LLM在HAR方面表现出色，但对LLM规模和更高效的模型训练方法探索不足。本文旨在进一步研究LLM在HAR中的潜力，特别是通过知识蒸馏技术训练小型高效模型。", "method": "1. 在两个SOTA数据集上评估不同规模LLM的HAR性能。 2. 使用大型LLM生成的HAR推理示例，通过知识蒸馏技术对小型LLM进行微调。", "result": "1. LLM的HAR性能随模型规模增大而提升。 2. 经过蒸馏微调的小型LLM，其性能与大型LLM接近，但参数量减少了50倍。", "conclusion": "LLM是进行家庭活动识别的有效工具。通过知识蒸馏，可以训练出参数量大大减少但性能依然优异的小型LLM，为开发高效的HAR系统提供了新的途径。"}}
{"id": "2601.06932", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06932", "abs": "https://arxiv.org/abs/2601.06932", "authors": ["Stephen Gadd"], "title": "Symphonym: Universal Phonetic Embeddings for Cross-Script Toponym Matching via Teacher-Student Distillation", "comment": "30 pages, 5 tables, 2 figures", "summary": "Linking place names across languages and writing systems is a fundamental challenge in digital humanities and geographic information retrieval. Existing approaches rely on language-specific phonetic algorithms or transliteration rules that fail when names cross script boundaries -- no string metric can determine that \"Moscow\" when rendered in Cyrillic or Arabic refer to the same city.\n  I present Symphonym, a neural embedding system that maps toponyms from 20 writing systems into a unified 128-dimensional phonetic space. A Teacher network trained on articulatory phonetic features (via Epitran and PanPhon) produces target embeddings, while a Student network learns to approximate these from raw characters. At inference, only the lightweight Student (1.7M parameters) is required, enabling deployment without runtime phonetic conversion.\n  Training uses a three-phase curriculum on 57 million toponyms from GeoNames, Wikidata, and the Getty Thesaurus of Geographic Names. Phase 1 trains the Teacher on 467K phonetically-grounded triplets. Phase 2 aligns the Student to Teacher outputs across 23M samples, achieving 96.6% cosine similarity. Phase 3 fine-tunes on 3.3M hard negative triplets -- negatives sharing prefix and script with the anchor but referring to different places -- to sharpen discrimination.\n  Evaluation on the MEHDIE Hebrew-Arabic benchmark achieves 89.2% Recall@1, outperforming Levenshtein (81.5%) and Jaro-Winkler (78.5%). The system is optimised for cross-script matching; same-script variants can be handled by complementary string methods. Symphonym will enable fuzzy phonetic reconciliation and search across the World Historical Gazetteer's 67 million toponyms. Code and models are publicly available.", "AI": {"tldr": "本文提出了一种名为 Symphonym 的神经嵌入系统，可以将不同书写系统下的地名映射到统一的语音空间，解决了跨语言、跨脚本的地名匹配难题，并在跨脚本匹配任务上取得了优于传统字符串度量方法的性能。", "motivation": "现有地名匹配方法依赖于语言特定的语音算法或转写规则，在处理跨脚本（例如拉丁字母和西里尔字母）的地名时效果不佳，难以确定不同书写系统下的名称是否指向同一个地点。", "method": "Symphonym 系统利用神经网络将不同书写系统的地名映射到一个统一的 128 维语音空间。一个 Teacher 网络基于发音特征（通过 Epitran 和 PanPhon）生成目标嵌入，而一个 Student 网络则从原始字符学习逼近这些嵌入。训练过程采用三阶段课程学习，利用 GeoNames、Wikidata 和 Getty Thesaurus of Geographic Names 的 5700 万个地名数据。推理时仅需轻量级的 Student 网络。", "result": "在 MEHDIE 希伯来-阿拉伯语基准测试中，Symphonym 达到了 89.2% 的 Recall@1，显著优于 Levenshtein (81.5%) 和 Jaro-Winkler (78.5%)。该系统特别针对跨脚本匹配进行了优化。", "conclusion": "Symphonym 成功地将多达 20 种书写系统下的地名映射到统一的语音空间，有效解决了跨语言、跨脚本的地名匹配挑战。该系统在跨脚本匹配任务上表现出色，并有望应用于 World Historical Gazetteer 等大型地名数据集的模糊语音匹配和搜索。"}}
{"id": "2601.07073", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07073", "abs": "https://arxiv.org/abs/2601.07073", "authors": ["Carlos Pizarroso", "Zuzana Berger Haladová", "Zuzana Černeková", "Viktor Kocur"], "title": "Billboard in Focus: Estimating Driver Gaze Duration from a Single Image", "comment": "Accepted as a position paper at VISAPP 2026", "summary": "Roadside billboards represent a central element of outdoor advertising, yet their presence may contribute to driver distraction and accident risk. This study introduces a fully automated pipeline for billboard detection and driver gaze duration estimation, aiming to evaluate billboard relevance without reliance on manual annotations or eye-tracking devices. Our pipeline operates in two stages: (1) a YOLO-based object detection model trained on Mapillary Vistas and fine-tuned on BillboardLamac images achieved 94% mAP@50 in the billboard detection task (2) a classifier based on the detected bounding box positions and DINOv2 features. The proposed pipeline enables estimation of billboard driver gaze duration from individual frames. We show that our method is able to achieve 68.1% accuracy on BillboardLamac when considering individual frames. These results are further validated using images collected from Google Street View.", "AI": {"tldr": "研究提出了一种全自动流水线，用于检测路边广告牌并估计驾驶员的注视时间，从而评估广告牌的相关性，无需手动标注或眼动追踪设备。", "motivation": "路边广告牌可能分散驾驶员注意力并增加事故风险，需要一种自动化的方法来评估其相关性。", "method": "该流水线分为两阶段：1. 使用 YOLO 模型进行广告牌检测（在 Mapillary Vistas 上训练，在 BillboardLamac 上微调），达到 94% mAP@50。2. 基于检测到的边界框位置和 DINOv2 特征的分类器来估计驾驶员注视时长。", "result": "该方法在 BillboardLamac 数据集上进行单帧注视时长估计时，准确率达到 68.1%。使用 Google Street View 的图像进行了进一步验证。", "conclusion": "提出的全自动流水线能够有效地检测广告牌并估计驾驶员的注视时长，为评估广告牌的相关性提供了一种无需手动标注和眼动追踪设备的新方法。"}}
{"id": "2601.07093", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07093", "abs": "https://arxiv.org/abs/2601.07093", "authors": ["Peiyuan Jing", "Yue Tang", "Chun-Wun Cheng", "Zhenxuan Zhang", "Liutao Yang", "Thiago V. Lima", "Klaus Strobel", "Antoine Leimgruber", "Angelica Aviles-Rivero", "Guang Yang", "Javier Montoya"], "title": "3D Wavelet-Based Structural Priors for Controlled Diffusion in Whole-Body Low-Dose PET Denoising", "comment": "10 pages", "summary": "Low-dose Positron Emission Tomography (PET) imaging reduces patient radiation exposure but suffers from increased noise that degrades image quality and diagnostic reliability. Although diffusion models have demonstrated strong denoising capability, their stochastic nature makes it challenging to enforce anatomically consistent structures, particularly in low signal-to-noise regimes and volumetric whole-body imaging. We propose Wavelet-Conditioned ControlNet (WCC-Net), a fully 3D diffusion-based framework that introduces explicit frequency-domain structural priors via wavelet representations to guide volumetric PET denoising. By injecting wavelet-based structural guidance into a frozen pretrained diffusion backbone through a lightweight control branch, WCC-Net decouples anatomical structure from noise while preserving generative expressiveness and 3D structural continuity. Extensive experiments demonstrate that WCC-Net consistently outperforms CNN-, GAN-, and diffusion-based baselines. On the internal 1/20-dose test set, WCC-Net improves PSNR by +1.21 dB and SSIM by +0.008 over a strong diffusion baseline, while reducing structural distortion (GMSD) and intensity error (NMAE). Moreover, WCC-Net generalizes robustly to unseen dose levels (1/50 and 1/4), achieving superior quantitative performance and improved volumetric anatomical consistency.", "AI": {"tldr": "提出了一种名为 WCC-Net 的三维扩散模型，通过小波域的结构先验来指导低剂量 PET 图像去噪，成功在保持生成能力的同时，提升了去噪效果和三维结构一致性。", "motivation": "低剂量 PET 成像虽然减少了辐射暴露，但噪声增加导致图像质量下降和诊断可靠性降低。现有的扩散模型在低信噪比和全身成像时难以保证解剖结构的连贯性。", "method": "提出 WCC-Net，一个完全三维的基于扩散模型的框架。通过将小波表示引入到预训练的扩散模型中，利用小波域的结构信息来指导去噪过程。通过一个轻量级的控制分支，将结构先验注入到冻结的预训练扩散模型中，实现解剖结构与噪声的分离，同时保留生成能力和三维结构连续性。", "result": "WCC-Net 在实验中表现优于基于 CNN、GAN 和其他扩散模型的基线方法。在 1/20 剂量的测试集上，WCC-Net 的 PSNR 提高了 1.21 dB，SSIM 提高了 0.008，同时降低了结构失真 (GMSD) 和强度误差 (NMAE)。此外，WCC-Net 在未见过剂量水平 (1/50 和 1/4) 下也表现出良好的泛化能力和优越的定量性能，以及改善的三维解剖一致性。", "conclusion": "WCC-Net 是一种有效的三维扩散模型，通过引入小波域的显式结构先验，能够显著提升低剂量 PET 图像的去噪效果，并保持优异的三维解剖结构一致性，克服了传统扩散模型在低信噪比下的局限性。"}}
{"id": "2601.06953", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06953", "abs": "https://arxiv.org/abs/2601.06953", "authors": ["Jie Wu", "Haoling Li", "Xin Zhang", "Jiani Guo", "Jane Luo", "Steven Liu", "Yangyu Huang", "Ruihang Chu", "Scarlett Li", "Yujiu Yang"], "title": "X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests", "comment": "Project: https://github.com/JieWu02/X-Coder", "summary": "Competitive programming presents great challenges for Code LLMs due to its intensive reasoning demands and high logical complexity. However, current Code LLMs still rely heavily on real-world data, which limits their scalability. In this paper, we explore a fully synthetic approach: training Code LLMs with entirely generated tasks, solutions, and test cases, to empower code reasoning models without relying on real-world data. To support this, we leverage feature-based synthesis to propose a novel data synthesis pipeline called SynthSmith. SynthSmith shows strong potential in producing diverse and challenging tasks, along with verified solutions and tests, supporting both supervised fine-tuning and reinforcement learning. Based on the proposed synthetic SFT and RL datasets, we introduce the X-Coder model series, which achieves a notable pass rate of 62.9 avg@8 on LiveCodeBench v5 and 55.8 on v6, outperforming DeepCoder-14B-Preview and AReal-boba2-14B despite having only 7B parameters. In-depth analysis reveals that scaling laws hold on our synthetic dataset, and we explore which dimensions are more effective to scale. We further provide insights into code-centric reinforcement learning and highlight the key factors that shape performance through detailed ablations and analysis. Our findings demonstrate that scaling high-quality synthetic data and adopting staged training can greatly advance code reasoning, while mitigating reliance on real-world coding data.", "AI": {"tldr": "本研究提出了一种名为SynthSmith的合成数据生成流水线，用于训练代码大语言模型（Code LLMs）进行竞争性编程，无需依赖真实世界数据。通过使用合成的训练数据（包括任务、解决方案和测试用例），作者训练了X-Coder模型系列，并在LiveCodeBench基准测试中取得了优于更大参数模型的性能。研究还探讨了数据扩展的规律以及代码中心强化学习的关键因素。", "motivation": "当前的Code LLMs在处理竞争性编程这类需要密集推理和高逻辑复杂性的任务时面临挑战，并且过度依赖真实世界数据限制了其可扩展性。本研究旨在探索一种完全合成的方法，通过生成任务、解决方案和测试用例来训练Code LLMs，以克服这些限制。", "method": "该研究提出了一个名为SynthSmith的数据合成流水线，该流水线利用基于特征的合成方法生成多样化且具有挑战性的任务，以及经过验证的解决方案和测试用例。基于SynthSmith生成的合成数据集（用于监督微调SFT和强化学习RL），作者训练了X-Coder模型系列。", "result": "X-Coder模型系列在LiveCodeBench v5和v6上分别取得了62.9 avg@8和55.8的通过率，优于参数量更大的DeepCoder-14B-Preview和AReal-boba2-14B模型。研究还发现，在合成数据集上扩展规律成立，并且指出了哪些维度扩展更有效。此外，研究还提供了关于代码中心强化学习的见解，并通过消融实验和分析突出了影响性能的关键因素。", "conclusion": "扩展高质量的合成数据并采用分阶段训练可以显著提升代码推理能力，同时减少对真实世界编码数据的依赖。SynthSmith流水线和X-Coder模型系列证明了全合成方法的潜力。"}}
{"id": "2601.07470", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07470", "abs": "https://arxiv.org/abs/2601.07470", "authors": ["Sirui Liang", "Pengfei Cao", "Jian Zhao", "Wenhao Teng", "Xiangwen Liao", "Jun Zhao", "Kang Liu"], "title": "Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory", "comment": null, "summary": "Large language model (LLM) agents increasingly rely on accumulated memory to solve long-horizon decision-making tasks. However, most existing approaches store memory in fixed representations and reuse it at a single or implicit level of abstraction, which limits generalization and often leads to negative transfer when distribution shift. This paper proposes the Meta-Cognitive Memory Abstraction method (MCMA), which treats memory abstraction as a learnable cognitive skill rather than a fixed design choice. MCMA decouples task execution from memory management by combining a frozen task model with a learned memory copilot. The memory copilot is trained using direct preference optimization, it determines how memories should be structured, abstracted, and reused. Memories are further organized into a hierarchy of abstraction levels, enabling selective reuse based on task similarity. When no memory is transferable, MCMA transfers the ability to abstract and manage memory by transferring the memory copilot. Experiments on ALFWorld, ScienceWorld, and BabyAI demonstrate substantial improvements in performance, out-of-distribution generalization, and cross-task transfer over several baselines.", "AI": {"tldr": "本文提出了一种名为元认知记忆抽象（MCMA）的新方法，它将记忆抽象视为一种可学习的认知技能，通过训练一个记忆副驾驶来管理记忆的结构化、抽象化和重用，并在多层抽象级别上组织记忆，以提高LLM代理在长时决策任务中的性能、泛化能力和跨任务迁移能力。", "motivation": "现有LLM代理依赖固定表示的记忆来解决长时决策任务，这限制了泛化能力，并可能在分布偏移时导致负迁移。因此，需要一种更灵活、可学习的记忆管理机制。", "method": "MCMA将任务执行与记忆管理解耦，结合一个固定的任务模型和一个可学习的记忆副驾驶。记忆副驾驶通过直接偏好优化进行训练，负责记忆的结构化、抽象化和重用。记忆被组织成多层抽象级别，根据任务相似性进行选择性重用。当没有可转移的记忆时，MCMA通过转移记忆副驾驶来转移抽象和管理记忆的能力。", "result": "在ALFWorld、ScienceWorld和BabyAI数据集上的实验表明，MCMA在性能、分布外泛化和跨任务迁移方面均显著优于现有基线方法。", "conclusion": "MCMA将记忆抽象作为一种可学习的认知技能，通过灵活的记忆管理和多层抽象，有效提升了LLM代理在复杂决策任务中的表现和泛化能力。"}}
{"id": "2601.07107", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07107", "abs": "https://arxiv.org/abs/2601.07107", "authors": ["Meng Lu", "Yuxing Lu", "Yuchen Zhuang", "Megan Mullins", "Yang Xie", "Guanghua Xiao", "Charles Fleming", "Wenqi Shi", "Xuan Wang"], "title": "MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning", "comment": null, "summary": "Vision language models (VLMs) achieve strong performance on general image understanding but struggle to think with medical images, especially when performing multi-step reasoning through iterative visual interaction. Medical VLMs often rely on static visual embeddings and single-pass inference, preventing models from re-examining, verifying, or refining visual evidence during reasoning. While tool-integrated reasoning offers a promising path forward, open-source VLMs lack the training infrastructure to learn effective tool selection, invocation, and coordination in multi-modal medical reasoning. We introduce MedVistaGym, a scalable and interactive training environment that incentivizes tool-integrated visual reasoning for medical image analysis. MedVistaGym equips VLMs to determine when and which tools to invoke, localize task-relevant image regions, and integrate single or multiple sub-image evidence into interleaved multimodal reasoning within a unified, executable interface for agentic training. Using MedVistaGym, we train MedVistaGym-R1 to interleave tool use with agentic reasoning through trajectory sampling and end-to-end reinforcement learning. Across six medical VQA benchmarks, MedVistaGym-R1-8B exceeds comparably sized tool-augmented baselines by 19.10% to 24.21%, demonstrating that structured agentic training--not tool access alone--unlocks effective tool-integrated reasoning for medical image analysis.", "AI": {"tldr": "本文提出MedVistaGym，一个用于训练医疗视觉语言模型（VLM）进行工具辅助多步推理的环境，并训练了一个名为MedVistaGym-R1的模型，在多个医疗VQA基准上取得了显著优于基线模型的性能。", "motivation": "现有的医疗VLM在进行多步推理时存在不足，例如依赖静态视觉嵌入和单次推理，无法有效进行证据的再审视和优化。虽然工具集成推理是一个有前景的方向，但开源VLM缺乏有效的工具选择、调用和协调的训练基础设施。", "method": "提出MedVistaGym，一个可扩展的交互式训练环境，用于激励VLM进行工具集成的视觉推理。该环境使VLM能够确定何时以及调用何种工具，定位任务相关的图像区域，并将证据整合到统一的、可执行的代理训练接口中。通过轨迹采样和端到端强化学习，在MedVistaGym上训练MedVistaGym-R1模型。", "result": "在六个医疗VQA基准上，MedVistaGym-R1-8B模型比同等大小的、增加了工具的基线模型在性能上提高了19.10%至24.21%。", "conclusion": "结构化的代理训练（而不仅仅是工具的可用性）是实现医疗图像分析中有效的工具集成推理的关键。"}}
{"id": "2601.07477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07477", "abs": "https://arxiv.org/abs/2601.07477", "authors": ["Zihan Ma", "Zhikai Zhao", "Chuanbo Hua", "Federico Berto", "Jinkyoo Park"], "title": "JudgeFlow: Agentic Workflow Optimization via Block Judge", "comment": null, "summary": "Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose {\\our{}}, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces -- particularly failed runs -- and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate {\\our{}} on mathematical reasoning and code generation benchmarks, where {\\our{}} achieves superior performance and efficiency compared to existing methods. The source code is publicly available at https://github.com/ma-zihan/JudgeFlow.", "AI": {"tldr": "提出了一种名为 JudgeFlow 的新方法，用于优化基于 LLM 的代理工作流，通过引入可重用的逻辑块和专门的 Judge 模块，提供细粒度的诊断信号，从而提高效率和可解释性。", "motivation": "当前优化 LLM 代理工作流的方法依赖于粗粒度的评估信号，缺乏对需要改进之处的精细指导，导致修改效率低下或影响不大。", "method": "JudgeFlow 采用 Evaluation-Judge-Optimization-Update 管道。它将可重用的逻辑块集成到代理工作流中，并设计了一个 Judge 模块来检查执行轨迹（特别是失败的运行），将问题块分配等级责任分数。然后，一个基于 LLM 的优化器利用这些信号，将修改重点放在工作流中最有问题块上。", "result": "在数学推理和代码生成基准测试中，JudgeFlow 实现了比现有方法更高的性能和效率。该方法提高了样本效率，并通过块级诊断增强了可解释性。", "conclusion": "JudgeFlow 提供了一种更有效、更具可解释性的方法来优化 LLM 代理工作流，为自动化日益复杂的工作流奠定了可扩展的基础。"}}
{"id": "2601.07296", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07296", "abs": "https://arxiv.org/abs/2601.07296", "authors": ["Yujin Zhou", "Chuxue Cao", "Jinluan Yang", "Lijun Wu", "Conghui He", "Sirui Han", "Yike Guo"], "title": "LRAS: Advanced Legal Reasoning with Agentic Search", "comment": null, "summary": "While Large Reasoning Models (LRMs) have demonstrated exceptional logical capabilities in mathematical domains, their application to the legal field remains hindered by the strict requirements for procedural rigor and adherence to legal logic. Existing legal LLMs, which rely on \"closed-loop reasoning\" derived solely from internal parametric knowledge, frequently suffer from lack of self-awareness regarding their knowledge boundaries, leading to confident yet incorrect conclusions. To address this challenge, we present Legal Reasoning with Agentic Search (LRAS), the first framework designed to transition legal LLMs from static and parametric \"closed-loop thinking\" to dynamic and interactive \"Active Inquiry\". By integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning, LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity. Empirical results demonstrate that LRAS outperforms state-of-the-art baselines by 8.2-32\\%, with the most substantial gains observed in tasks requiring deep reasoning with reliable knowledge. We will release our data and models for further exploration soon.", "AI": {"tldr": "提出了一种名为LRAS的框架，用于增强大型推理模型（LRMs）在法律领域的应用，使其能够识别知识边界并处理法律推理的复杂性，解决了现有法律LLM在知识边界识别和准确性方面的问题。", "motivation": "现有法律LLM依赖封闭式推理，缺乏自我认知能力，容易得出看似自信但错误的结论，难以满足法律领域对程序严谨性和逻辑性的高要求。", "method": "通过整合内省模仿学习（Introspective Imitation Learning）和难度感知强化学习（Difficulty-aware Reinforcement Learning），使LRMs能够识别知识边界并处理法律推理的复杂性，实现从静态的“闭环思维”到动态的“主动探究”的转变。", "result": "LRAS在法律推理任务中表现优于现有最先进的基线模型，提升幅度在8.2%-32%之间，特别是在需要深度推理和可靠知识的任务上效果显著。", "conclusion": "LRAS成功地解决了法律LLM在知识边界识别和推理准确性方面的问题，通过主动探究的方式显著提升了模型在法律领域的表现，为未来的法律AI研究提供了新的方向。"}}
{"id": "2601.07117", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07117", "abs": "https://arxiv.org/abs/2601.07117", "authors": ["Kexin Bao", "Yong Li", "Dan Zeng", "Shiming Ge"], "title": "Few-shot Class-Incremental Learning via Generative Co-Memory Regularization", "comment": "Accepted by International Journal on Computer Vision (IJCV)", "summary": "Few-shot class-incremental learning (FSCIL) aims to incrementally learn models from a small amount of novel data, which requires strong representation and adaptation ability of models learned under few-example supervision to avoid catastrophic forgetting on old classes and overfitting to novel classes. This work proposes a generative co-memory regularization approach to facilitate FSCIL. In the approach, the base learning leverages generative domain adaptation finetuning to finetune a pretrained generative encoder on a few examples of base classes by jointly incorporating a masked autoencoder (MAE) decoder for feature reconstruction and a fully-connected classifier for feature classification, which enables the model to efficiently capture general and adaptable representations. Using the finetuned encoder and learned classifier, we construct two class-wise memories: representation memory for storing the mean features for each class, and weight memory for storing the classifier weights. After that, the memory-regularized incremental learning is performed to train the classifier dynamically on the examples of few-shot classes in each incremental session by simultaneously optimizing feature classification and co-memory regularization. The memories are updated in a class-incremental manner and they collaboratively regularize the incremental learning. In this way, the learned models improve recognition accuracy, while mitigating catastrophic forgetting over old classes and overfitting to novel classes. Extensive experiments on popular benchmarks clearly demonstrate that our approach outperforms the state-of-the-arts.", "AI": {"tldr": "本文提出了一种生成式协同记忆正则化方法，用于少样本类增量学习（FSCIL），通过生成式域适应微调和类记忆（表示记忆和权重记忆）的协同作用，在提升新类识别能力的同时，有效缓解了旧类灾难性遗忘和新类过拟合问题。", "motivation": "在少样本类增量学习（FSCIL）任务中，模型需要在仅用少量新数据的情况下，学习新类知识，同时避免遗忘旧类知识和在新类上过拟合，这需要模型具备强大的表示学习和迁移能力。", "method": "1. **基础学习阶段**: 利用生成式域适应微调，结合掩码自编码器（MAE）解码器进行特征重构和全连接分类器进行特征分类，以学习通用且可适应的表示。2. **增量学习阶段**: 构建类别的表示记忆（存储均值特征）和权重记忆（存储分类器权重）。然后，通过联合优化特征分类和协同记忆正则化，动态训练分类器，并以类增量方式更新记忆，从而正则化增量学习过程。", "result": "所提出的方法通过实验证明，在常用的基准测试上，能够显著优于现有的最先进方法，在提高识别准确率的同时，有效减轻了灾难性遗忘和过拟合现象。", "conclusion": "生成式协同记忆正则化方法能够有效地解决少样本类增量学习中的关键挑战，即在少量新数据下进行增量学习，同时保持对旧类知识的记忆和对新类知识的适应性。"}}
{"id": "2601.06972", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06972", "abs": "https://arxiv.org/abs/2601.06972", "authors": ["Nathan Roll", "Pranav Bhalerao", "Martijn Bartelds", "Arjun Pawar", "Yuka Tatsumi", "Tolulope Ogunremi", "Chen Shani", "Calbert Graham", "Meghan Sumner", "Dan Jurafsky"], "title": "Categorize Early, Integrate Late: Divergent Processing Strategies in Automatic Speech Recognition", "comment": "3 figures, 9 tables", "summary": "In speech language modeling, two architectures dominate the frontier: the Transformer and the Conformer. However, it remains unknown whether their comparable performance stems from convergent processing strategies or distinct architectural inductive biases. We introduce Architectural Fingerprinting, a probing framework that isolates the effect of architecture on representation, and apply it to a controlled suite of 24 pre-trained encoders (39M-3.3B parameters). Our analysis reveals divergent hierarchies: Conformers implement a \"Categorize Early\" strategy, resolving phoneme categories 29% earlier in depth and speaker gender by 16% depth. In contrast, Transformers \"Integrate Late,\" deferring phoneme, accent, and duration encoding to deep layers (49-57%). These fingerprints suggest design heuristics: Conformers' front-loaded categorization may benefit low-latency streaming, while Transformers' deep integration may favor tasks requiring rich context and cross-utterance normalization.", "AI": {"tldr": "本研究提出了一种名为“架构指纹”的探测框架，用于分析 Transformer 和 Conformer 在语音语言模型中的表示差异，发现 Conformer 倾向于“早期分类”，而 Transformer 倾向于“晚期整合”，并据此提出了设计启发式。", "motivation": "为了理解 Transformer 和 Conformer 在语音语言建模中表现相似的原因，是由于其处理策略的趋同还是架构归纳偏置的差异。", "method": "开发了一种名为“架构指纹”的探测框架，该框架能够分离架构对表示的影响。将该框架应用于24个预训练编码器（参数量从3900万到33亿）。", "result": "分析结果显示了不同的层级结构：Conformer 采用了“早期分类”策略，在模型深度中分别提前29%和16%解决了音素类别和说话人性别信息。Transformer 则“晚期整合”，将音素、口音和时长信息推迟到模型的深层（49%-57%）。", "conclusion": "Conformer 的前置分类策略可能有利于低延迟流式处理，而 Transformer 的深层整合策略可能更适合需要丰富上下文和跨句子归一化任务。这些发现为模型设计提供了启发。"}}
{"id": "2601.07154", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07154", "abs": "https://arxiv.org/abs/2601.07154", "authors": ["Daniel Hong", "James Tribble", "Hao Wang", "Chaoyi Zhou", "Ashish Bastola", "Siyu Huang", "Abolfazl Razi"], "title": "Motion Focus Recognition in Fast-Moving Egocentric Video", "comment": null, "summary": "From Vision-Language-Action (VLA) systems to robotics, existing egocentric datasets primarily focus on action recognition tasks, while largely overlooking the inherent role of motion analysis in sports and other fast-movement scenarios. To bridge this gap, we propose a real-time motion focus recognition method that estimates the subject's locomotion intention from any egocentric video. Our approach leverages the foundation model for camera pose estimation and introduces system-level optimizations to enable efficient and scalable inference. Evaluated on a collected egocentric action dataset, our method achieves real-time performance with manageable memory consumption through a sliding batch inference strategy. This work makes motion-centric analysis practical for edge deployment and offers a complementary perspective to existing egocentric studies on sports and fast-movement activities.", "AI": {"tldr": "提出了一种从第一人称视角视频中实时识别运动意图的方法，该方法基于基础模型进行相机姿态估计，并通过系统级优化和滑动批推理策略实现了高效性和可扩展性，适用于边缘部署。", "motivation": "现有第一人称视角（egocentric）数据集主要关注动作识别，而忽视了运动分析在体育等快速运动场景中的作用。因此，需要一种能够识别运动意图的方法来弥补这一差距。", "method": "利用基础模型进行相机姿态估计，并引入系统级优化（如滑动批推理策略）来实现高效且可扩展的推理，从而估计第一人称视角视频中的运动意图。", "result": "在收集的第一人称视角动作数据集上，该方法实现了实时性能，同时内存消耗可控，并通过滑动批推理策略实现了高效性和可扩展性。", "conclusion": "该研究使得以运动为中心的分析能够实际应用于边缘部署，并为现有关于体育和快速运动活动的第一人称视角研究提供了补充视角。"}}
{"id": "2601.07577", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07577", "abs": "https://arxiv.org/abs/2601.07577", "authors": ["Yunfan Li", "Bingbing Xu", "Xueyun Tian", "Xiucheng Xu", "Huawei Shen"], "title": "Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents", "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.", "AI": {"tldr": "本文提出了一种名为任务解耦规划（TDP）的框架，用于解决大型语言模型（LLM）在执行长期复杂任务时的规划瓶颈问题。TDP通过将任务分解为子目标，并使用具有作用域上下文的规划器和执行器，将推理和重新规划限制在当前子任务内，从而提高了鲁棒性和效率。", "motivation": "现有的大型语言模型在执行长期复杂任务时，规划能力是一个主要瓶颈。现有的两种规划范式（分步规划和一次性规划）都存在问题：分步规划容易短视，一次性规划则对执行错误非常脆弱。此外，这两种范式都存在上下文纠缠问题，使得错误容易传播，恢复成本高。", "method": "本文提出的任务解耦规划（TDP）框架，不进行额外的训练。该框架通过一个Supervisor将任务分解为一个子目标有向无环图（DAG）。然后，使用一个Planner和一个Executor，并为它们提供作用域上下文（scoped contexts），将推理和重新规划限制在当前活动的子任务内。这种隔离方式防止了错误的传播，并在局部纠正偏差，而不影响整体工作流程。", "result": "在TravelPlanner、ScienceWorld和HotpotQA数据集上的实验表明，TDP相比于现有基线方法表现更优，并且Token消耗减少高达82%。", "conclusion": "子任务的解耦能够提高长期复杂任务代理的鲁棒性和效率。TDP框架通过任务分解和作用域上下文，有效解决了上下文纠缠问题，减少了错误传播，并降低了计算成本。"}}
{"id": "2601.06973", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06973", "abs": "https://arxiv.org/abs/2601.06973", "authors": ["Davide Baldelli", "Ali Parviz", "Amal Zouaq", "Sarath Chandar"], "title": "LLMs Can't Play Hangman: On the Necessity of a Private Working Memory for Language Agents", "comment": null, "summary": "As LLMs move from text completion toward autonomous agents, they remain constrained by the standard chat interface, which lacks private working memory. This raises a fundamental question: can agents reliably perform interactive tasks that depend on hidden state? We define Private State Interactive Tasks (PSITs), which require agents to generate and maintain hidden information while producing consistent public responses. We show theoretically that any agent restricted to the public conversation history cannot simultaneously preserve secrecy and consistency in PSITs, yielding an impossibility theorem. To empirically validate this limitation, we introduce a self-consistency testing protocol that evaluates whether agents can maintain a hidden secret across forked dialogue branches. Standard chat-based LLMs and retrieval-based memory baselines fail this test regardless of scale, demonstrating that semantic retrieval does not enable true state maintenance. To address this, we propose a novel architecture incorporating an explicit private working memory; we demonstrate that this mechanism restores consistency, establishing private state as a necessary component for interactive language agents.", "AI": {"tldr": "现有的大语言模型（LLMs）在执行需要隐藏状态的交互式任务时存在局限性，因为标准聊天界面缺乏私有工作记忆。研究者提出了私有状态交互任务（PSITs）的概念，并证明了任何仅限于公开对话历史的LLM无法同时保证秘密性和一致性。他们引入了一个自我一致性测试协议，发现现有的LLM和检索式记忆基线均无法通过该测试。为了解决这个问题，研究者提出了一种包含显式私有工作记忆的新架构，并证明了这种机制可以恢复一致性，表明私有状态是交互式语言代理的必要组成部分。", "motivation": "随着大语言模型（LLMs）从文本补全向自主代理发展，它们受限于缺乏私有工作记忆的标准聊天界面，这引发了一个问题：LLM是否能够可靠地执行依赖于隐藏状态的交互式任务。", "method": "1. 定义了私有状态交互任务（PSITs），这类任务要求代理生成和维护隐藏信息，同时产生一致的公开响应。 2. 理论上证明，任何仅限于公开对话历史的代理无法同时在PSITs中保持秘密性和一致性，提出了一个不可能定理。 3. 引入了一个自我一致性测试协议，通过分叉对话分支来评估代理维护隐藏秘密的能力。 4. 提出了一种包含显式私有工作记忆的新架构。", "result": "1. 理论分析表明，现有的聊天界面限制了LLM在PSITs中的性能。 2. 实验证明，标准聊天式LLM和检索式记忆基线在自我一致性测试中均表现不佳，表明语义检索无法实现真正的状态维护。 3. 新的私有工作记忆架构能够恢复一致性。", "conclusion": "私有状态是交互式语言代理执行需要隐藏状态的任务的必要组成部分。现有的标准聊天界面和检索式记忆方法不足以解决这个问题，而显式的私有工作记忆机制能够有效恢复代理在交互式任务中的一致性。"}}
{"id": "2601.07163", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07163", "abs": "https://arxiv.org/abs/2601.07163", "authors": ["Shu Shen", "C. L. Philip Chen", "Tong Zhang"], "title": "Test-time Adaptive Hierarchical Co-enhanced Denoising Network for Reliable Multimodal Classification", "comment": "14 pages,9 figures, 8 tables", "summary": "Reliable learning on low-quality multimodal data is a widely concerning issue, especially in safety-critical applications. However, multimodal noise poses a major challenge in this domain and leads existing methods to suffer from two key limitations. First, they struggle to reliably remove heterogeneous data noise, hindering robust multimodal representation learning. Second, they exhibit limited adaptability and generalization when encountering previously unseen noise. To address these issues, we propose Test-time Adaptive Hierarchical Co-enhanced Denoising Network (TAHCD). On one hand, TAHCD introduces the Adaptive Stable Subspace Alignment and Sample-Adaptive Confidence Alignment to reliably remove heterogeneous noise. They account for noise at both global and instance levels and enable jointly removal of modality-specific and cross-modality noise, achieving robust learning. On the other hand, TAHCD introduces test-time cooperative enhancement, which adaptively updates the model in response to input noise in a label-free manner, improving adaptability and generalization. This is achieved by collaboratively enhancing the joint removal process of modality-specific and cross-modality noise across global and instance levels according to sample noise. Experiments on multiple benchmarks demonstrate that the proposed method achieves superior classification performance, robustness, and generalization compared with state-of-the-art reliable multimodal learning approaches.", "AI": {"tldr": "提出了一种名为TAHCD（Test-time Adaptive Hierarchical Co-enhanced Denoising Network）的新方法，用于解决低质量多模态数据上的可靠学习问题，特别是针对安全关键应用。TAHCD通过自适应稳定子空间对齐和样本自适应置信度对齐来有效去除异构噪声，并在测试时进行协同增强，以提高模型的适应性和泛化能力。", "motivation": "现有方法在处理多模态噪声时存在两个主要局限：难以可靠地去除异构噪声，导致多模态表示学习不鲁棒；以及在面对未见过噪声时的适应性和泛化能力有限。这些问题在安全关键应用中尤其令人担忧。", "method": "TAHCD引入了两种关键技术：1. 自适应稳定子空间对齐（Adaptive Stable Subspace Alignment）和样本自适应置信度对齐（Sample-Adaptive Confidence Alignment），用于可靠地去除全局和实例级别的异构噪声，实现跨模态噪声的联合去除。2. 测试时协同增强（test-time cooperative enhancement），通过在测试时进行无标签的自适应模型更新，根据样本噪声协同增强去噪过程，从而提高模型的适应性和泛化能力。", "result": "在多个基准数据集上的实验表明，TAHCD在分类性能、鲁棒性和泛化能力方面优于现有最先进的可靠多模态学习方法。", "conclusion": "TAHCD能够有效地去除异构噪声，并提高模型在低质量多模态数据上的鲁棒性和泛化能力，为安全关键应用中的可靠多模态学习提供了一种有效解决方案。"}}
{"id": "2601.06974", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06974", "abs": "https://arxiv.org/abs/2601.06974", "authors": ["Quoc-An Nguyen", "Thi-Minh-Thu Vu", "Bich-Dat Nguyen", "Dinh-Quang-Minh Tran", "Hoang-Quynh Le"], "title": "UETQuintet at BioCreative IX - MedHopQA: Enhancing Biomedical QA with Selective Multi-hop Reasoning and Contextual Retrieval", "comment": "Accepted at the BioCreative IX Challenge and Workshop (BC9) at IJCAI", "summary": "Biomedical Question Answering systems play a critical role in processing complex medical queries, yet they often struggle with the intricate nature of medical data and the demand for multi-hop reasoning. In this paper, we propose a model designed to effectively address both direct and sequential questions. While sequential questions are decomposed into a chain of sub-questions to perform reasoning across a chain of steps, direct questions are processed directly to ensure efficiency and minimise processing overhead. Additionally, we leverage multi-source information retrieval and in-context learning to provide rich, relevant context for generating answers. We evaluated our model on the BioCreative IX - MedHopQA Shared Task datasets. Our approach achieves an Exact Match score of 0.84, ranking second on the current leaderboard. These results highlight the model's capability to meet the challenges of Biomedical Question Answering, offering a versatile solution for advancing medical research and practice.", "AI": {"tldr": "提出了一种用于生物医学问答的模型，能够同时处理直接和序列式问题，并利用多源信息检索和上下文学习来提高准确性，在BioCreative IX - MedHopQA共享任务数据集上取得了0.84的精确匹配得分，排名第二。", "motivation": "现有的生物医学问答系统难以处理复杂的医学数据和多跳推理的需求，尤其是在处理序列式问题时。", "method": "该模型能够区分直接问题和序列式问题。序列式问题被分解为一系列子问题进行多步推理；直接问题则直接处理以提高效率。模型还利用多源信息检索和上下文学习来丰富答案生成的上下文。", "result": "在BioCreative IX - MedHopQA共享任务数据集上，该模型取得了0.84的精确匹配得分，在当前排行榜上排名第二。", "conclusion": "该模型能够有效应对生物医学问答的挑战，为推进医学研究和实践提供了一个多功能的解决方案。"}}
{"id": "2601.07178", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07178", "abs": "https://arxiv.org/abs/2601.07178", "authors": ["Weilin Zhou", "Zonghao Ying", "Chunlei Meng", "Jiahui Liu", "Hengyang Zhou", "Quanchen Zou", "Deyue Zhang", "Dongdong Yang", "Xiangzheng Zhang"], "title": "DIVER: Dynamic Iterative Visual Evidence Reasoning for Multimodal Fake News Detection", "comment": "13 pages", "summary": "Multimodal fake news detection is crucial for mitigating adversarial misinformation. Existing methods, relying on static fusion or LLMs, face computational redundancy and hallucination risks due to weak visual foundations. To address this, we propose DIVER (Dynamic Iterative Visual Evidence Reasoning), a framework grounded in a progressive, evidence-driven reasoning paradigm. DIVER first establishes a strong text-based baseline through language analysis, leveraging intra-modal consistency to filter unreliable or hallucinated claims. Only when textual evidence is insufficient does the framework introduce visual information, where inter-modal alignment verification adaptively determines whether deeper visual inspection is necessary. For samples exhibiting significant cross-modal semantic discrepancies, DIVER selectively invokes fine-grained visual tools (e.g., OCR and dense captioning) to extract task-relevant evidence, which is iteratively aggregated via uncertainty-aware fusion to refine multimodal reasoning. Experiments on Weibo, Weibo21, and GossipCop demonstrate that DIVER outperforms state-of-the-art baselines by an average of 2.72\\%, while optimizing inference efficiency with a reduced latency of 4.12 s.", "AI": {"tldr": "本文提出了一种名为 DIVER 的新框架，用于多模态假新闻检测。它通过逐步引入视觉证据并利用迭代推理来克服现有方法的局限性，实验证明其在准确性和效率上均优于当前最先进的方法。", "motivation": "现有的多模态假新闻检测方法依赖于静态融合或大型语言模型（LLM），存在计算冗余和视觉基础薄弱导致的幻觉风险。", "method": "DIVER 框架采用渐进式、证据驱动的推理范式。首先建立强大的文本基础，利用语内一致性过滤声明。当文本证据不足时，引入视觉信息，并通过跨模态对齐验证来决定是否需要深入视觉检查。对于存在显著跨模态语义差异的样本，DIVER 会调用 OCR 和密集字幕等细粒度视觉工具提取证据，并通过不确定性感知融合进行迭代聚合。", "result": "在 Weibo、Weibo21 和 GossipCop 数据集上的实验表明，DIVER 的准确率平均比现有最先进方法高出 2.72%，同时推理延迟降低了 4.12 秒，提高了推理效率。", "conclusion": "DIVER 框架通过其动态迭代的视觉证据推理方法，有效解决了现有假新闻检测方法的不足，实现了更高的准确性和更优的推理效率。"}}
{"id": "2601.07611", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07611", "abs": "https://arxiv.org/abs/2601.07611", "authors": ["Zhuoyang Zou", "Abolfazl Ansari", "Delvin Ce Zhang", "Dongwon Lee", "Wenpeng Yin"], "title": "DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning", "comment": null, "summary": "Paper weakness identification using single-agent or multi-agent LLMs has attracted increasing attention, yet existing approaches exhibit key limitations. Many multi-agent systems simulate human roles at a surface level, missing the underlying criteria that lead experts to assess complementary intellectual aspects of a paper. Moreover, prior methods implicitly assume identified weaknesses are valid, ignoring reviewer bias, misunderstanding, and the critical role of author rebuttals in validating review quality. Finally, most systems output unranked weakness lists, rather than prioritizing the most consequential issues for users. In this work, we propose DIAGPaper, a novel multi-agent framework that addresses these challenges through three tightly integrated modules. The customizer module simulates human-defined review criteria and instantiates multiple reviewer agents with criterion-specific expertise. The rebuttal module introduces author agents that engage in structured debate with reviewer agents to validate and refine proposed weaknesses. The prioritizer module learns from large-scale human review practices to assess the severity of validated weaknesses and surfaces the top-K severest ones to users. Experiments on two benchmarks, AAAR and ReviewCritique, demonstrate that DIAGPaper substantially outperforms existing methods by producing more valid and more paper-specific weaknesses, while presenting them in a user-oriented, prioritized manner.", "AI": {"tldr": "本文提出了一种名为DIAGPaper的新型多智能体框架，用于识别论文的弱点。它通过模拟人类评审标准、引入作者反驳来验证评审意见，并根据人类评审实践对弱点进行排序，以解决现有方法在模拟专家评审、处理评审偏差和优先级排序方面的局限性。", "motivation": "现有使用LLM识别论文弱点的方法存在局限性，包括：多智能体系统对人类角色模拟过于表面化，未能捕捉专家评估论文互补性 intellectual aspects 的深层标准；忽略了评审偏差、误解以及作者反驳在验证评审质量中的关键作用；大多数系统输出未排序的弱点列表，未能优先考虑对用户最重要的议题。", "method": "DIAGPaper框架包含三个模块：1. Customizer模块：模拟人类定义的评审标准，并实例化具有特定标准专业知识的评审智能体。2. Rebuttal模块：引入作者智能体，与评审智能体进行结构化辩论，以验证和完善提出的弱点。3. Prioritizer模块：从大规模人类评审实践中学习，评估已验证弱点的严重性，并向用户呈现K个最严重的弱点。", "result": "在AAAR和ReviewCritique两个基准数据集上的实验表明，DIAGPaper在生成更有效、更具针对性的论文弱点方面，并以用户导向、排序的方式呈现，显著优于现有方法。", "conclusion": "DIAGPaper是一个新颖的多智能体框架，通过模拟评审标准、引入作者反驳和优先级排序，有效解决了现有论文弱点识别方法的局限性，并能在实际应用中产生更准确、更有价值的评审结果。"}}
{"id": "2601.06979", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06979", "abs": "https://arxiv.org/abs/2601.06979", "authors": ["Dongsuk Jang", "Ziyao Shangguan", "Kyle Tegtmeyer", "Anurag Gupta", "Jan Czerminski", "Sophie Chheang", "Arman Cohan"], "title": "MedTutor: A Retrieval-Augmented LLM System for Case-Based Medical Education", "comment": "Accepted to EMNLP 2025 (System Demonstrations)", "summary": "The learning process for medical residents presents significant challenges, demanding both the ability to interpret complex case reports and the rapid acquisition of accurate medical knowledge from reliable sources. Residents typically study case reports and engage in discussions with peers and mentors, but finding relevant educational materials and evidence to support their learning from these cases is often time-consuming and challenging. To address this, we introduce MedTutor, a novel system designed to augment resident training by automatically generating evidence-based educational content and multiple-choice questions from clinical case reports. MedTutor leverages a Retrieval-Augmented Generation (RAG) pipeline that takes clinical case reports as input and produces targeted educational materials. The system's architecture features a hybrid retrieval mechanism that synergistically queries a local knowledge base of medical textbooks and academic literature (using PubMed, Semantic Scholar APIs) for the latest related research, ensuring the generated content is both foundationally sound and current. The retrieved evidence is filtered and ordered using a state-of-the-art reranking model and then an LLM generates the final long-form output describing the main educational content regarding the case-report. We conduct a rigorous evaluation of the system. First, three radiologists assessed the quality of outputs, finding them to be of high clinical and educational value. Second, we perform a large scale evaluation using an LLM-as-a Judge to understand if LLMs can be used to evaluate the output of the system. Our analysis using correlation between LLMs outputs and human expert judgments reveals a moderate alignment and highlights the continued necessity of expert oversight.", "AI": {"tldr": "MedTutor是一个基于检索增强生成（RAG）的系统，可从临床病例报告中自动生成循证教育内容和多项选择题，以辅助医学生的学习。该系统结合了本地医学知识库和外部API检索，并通过LLM生成内容，其评估结果表明该系统具有较高的临床和教育价值，但仍需专家监督。", "motivation": "医学生在学习过程中，从复杂的病例报告中获取准确的医学知识并找到支持性教育材料耗时且困难。", "method": "MedTutor采用检索增强生成（RAG）流水线，输入临床病例报告，输出教育材料。它结合了本地医学知识库（教科书、学术文献）和外部API（PubMed, Semantic Scholar）的混合检索机制，并使用先进的重排序模型筛选检索到的证据，最终由LLM生成长篇内容。", "result": "三位放射科医生评估认为MedTutor生成的输出具有很高的临床和教育价值。此外，使用LLM-as-a-Judge的大规模评估显示，LLM评估与人类专家判断之间存在中度相关性，但仍需要专家监督。", "conclusion": "MedTutor能够有效地从临床病例报告中生成高质量的循证教育内容，为医学生提供有价值的学习辅助。LLM在评估此类系统输出方面具有一定潜力，但专家判断在当前仍是必要的。"}}
{"id": "2601.07638", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07638", "abs": "https://arxiv.org/abs/2601.07638", "authors": ["Isaiah Onando Mulang", "Felix Sasaki", "Tassilo Klein", "Jonas Kolk", "Nikolay Grechanov", "Johannes Hoffart"], "title": "SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables", "comment": null, "summary": "Building upon the SALT benchmark for relational prediction (Klein et al., 2024), we introduce SALT-KG, a benchmark for semantics-aware learning on enterprise tables. SALT-KG extends SALT by linking its multi-table transactional data with a structured Operational Business Knowledge represented in a Metadata Knowledge Graph (OBKG) that captures field-level descriptions, relational dependencies, and business object types. This extension enables evaluation of models that jointly reason over tabular evidence and contextual semantics, an increasingly critical capability for foundation models on structured data. Empirical analysis reveals that while metadata-derived features yield modest improvements in classical prediction metrics, these metadata features consistently highlight gaps in the ability of models to leverage semantics in relational context. By reframing tabular prediction as semantics-conditioned reasoning, SALT-KG establishes a benchmark to advance tabular foundation models grounded in declarative knowledge, providing the first empirical step toward semantically linked tables in structured data at enterprise scale.", "AI": {"tldr": "本文提出了SALT-KG，一个用于企业表格的语义感知学习基准。它通过将多表交易数据与操作业务知识图谱（OBKG）关联起来，以评估能够同时推理表格证据和上下文语义的模型。", "motivation": "现有基准（如SALT）在处理企业级结构化数据时，未能充分考虑上下文语义信息，而这对于基础模型至关重要。因此，需要一个能够评估模型在结构化数据上联合推理表格证据和上下文语义能力的基准。", "method": "通过将SALT基准中的多表交易数据与操作业务知识图谱（OBKG）进行链接。OBKG包含了字段级描述、关系依赖和业务对象类型等元数据信息。利用这个扩展后的基准（SALT-KG）来评估能够联合推理表格证据和上下文语义的模型。", "result": "元数据派生的特征在传统的预测指标上带来了适度的改进。然而，这些元数据特征一致地揭示了模型在利用关系上下文中的语义信息方面存在的差距。", "conclusion": "SALT-KG通过将表格预测重构为语义条件推理，建立了一个推动表格基础模型发展的基准，这些模型能够基于声明式知识进行推理，朝着企业级语义链接表格迈出了第一步。"}}
{"id": "2601.07181", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07181", "abs": "https://arxiv.org/abs/2601.07181", "authors": ["Yichun Zhang", "Xiangwu Guo", "Yauhong Goh", "Jessica Hu", "Zhiheng Chen", "Xin Wang", "Difei Gao", "Mike Zheng Shou"], "title": "ShowUI-Aloha: Human-Taught GUI Agent", "comment": "13 Pages, 16 Figures", "summary": "Graphical User Interfaces (GUIs) are central to human-computer interaction, yet automating complex GUI tasks remains a major challenge for autonomous agents, largely due to a lack of scalable, high-quality training data. While recordings of human demonstrations offer a rich data source, they are typically long, unstructured, and lack annotations, making them difficult for agents to learn from.To address this, we introduce ShowUI-Aloha, a comprehensive pipeline that transforms unstructured, in-the-wild human screen recordings from desktop environments into structured, actionable tasks. Our framework includes four key components: A recorder that captures screen video along with precise user interactions like mouse clicks, keystrokes, and scrolls. A learner that semantically interprets these raw interactions and the surrounding visual context, translating them into descriptive natural language captions. A planner that reads the parsed demonstrations, maintains task states, and dynamically formulates the next high-level action plan based on contextual reasoning. An executor that faithfully carries out these action plans at the OS level, performing precise clicks, drags, text inputs, and window operations with safety checks and real-time feedback. Together, these components provide a scalable solution for collecting and parsing real-world human data, demonstrating a viable path toward building general-purpose GUI agents that can learn effectively from simply observing humans.", "AI": {"tldr": "提出ShowUI-Aloha框架，将非结构化的用户屏幕录像转化为结构化的GUI任务，以解决自动化GUI任务的数据稀缺问题。", "motivation": "自动化复杂GUI任务面临数据稀缺的挑战，尤其是高质量、可扩展的训练数据。现有的人类演示录像通常冗长、非结构化且缺乏标注，难以供AI学习。", "method": "ShowUI-Aloha包含四个关键组件：1. 录像器（Recorder）捕获屏幕视频和用户交互；2. 学习器（Learner）语义解释交互和视觉上下文，生成自然语言描述；3. 规划器（Planner）解析演示，维护任务状态，并动态制定高层行动计划；4. 执行器（Executor）在操作系统层面执行动作计划，并进行安全检查和实时反馈。", "result": "ShowUI-Aloha提供了一个可扩展的解决方案，用于收集和解析真实世界的人类GUI交互数据，为构建能够通过观察人类来有效学习的通用GUI代理铺平了道路。", "conclusion": "ShowUI-Aloha框架能够有效地将非结构化的用户屏幕录像转化为结构化的GUI任务，克服了数据稀缺的障碍，为开发能够从人类演示中学习的通用GUI代理提供了一种可行的方法。"}}
{"id": "2601.06966", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06966", "abs": "https://arxiv.org/abs/2601.06966", "authors": ["Haonan Bian", "Zhiyuan Yao", "Sen Hu", "Zishan Xu", "Shaolei Zhang", "Yifu Guo", "Ziliang Yang", "Xueran Han", "Huacan Wang", "Ronghao Chen"], "title": "RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction", "comment": null, "summary": "As Large Language Models (LLMs) evolve from static dialogue interfaces to autonomous general agents, effective memory is paramount to ensuring long-term consistency. However, existing benchmarks primarily focus on casual conversation or task-oriented dialogue, failing to capture **\"long-term project-oriented\"** interactions where agents must track evolving goals.\n  To bridge this gap, we introduce **RealMem**, the first benchmark grounded in realistic project scenarios. RealMem comprises over 2,000 cross-session dialogues across eleven scenarios, utilizing natural user queries for evaluation.\n  We propose a synthesis pipeline that integrates Project Foundation Construction, Multi-Agent Dialogue Generation, and Memory and Schedule Management to simulate the dynamic evolution of memory. Experiments reveal that current memory systems face significant challenges in managing the long-term project states and dynamic context dependencies inherent in real-world projects.\n  Our code and datasets are available at [https://github.com/AvatarMemory/RealMemBench](https://github.com/AvatarMemory/RealMemBench).", "AI": {"tldr": "本文提出了RealMem，一个用于评估大型语言模型（LLMs）在长期项目导向型对话中的记忆能力的基准测试。现有基准测试无法充分模拟LLMs作为自主代理在项目进程中追踪不断变化目标的需求。RealMem包含了2000多个跨会话对话，并提出了一种结合项目基础构建、多智能体对话生成以及记忆和调度管理的合成流水线来模拟记忆的动态演变。实验表明，现有记忆系统在处理长期项目状态和动态上下文依赖方面面临挑战。", "motivation": "现有的大型语言模型（LLMs）基准测试未能充分捕捉“长期项目导向型”交互的需求，即LLMs作为自主代理需要追踪不断变化的目标以确保长期一致性。研究者希望填补这一空白，为评估LLMs的长期记忆能力提供一个更真实的场景。", "method": "1. 引入RealMem：一个包含2000多个跨会话对话、覆盖11个场景的基准测试，使用自然用户查询进行评估。\n2. 提出一个合成流水线：该流水线整合了项目基础构建、多智能体对话生成以及记忆和调度管理，以模拟记忆的动态演变。", "result": "当前的大多数记忆系统在管理长期项目状态和处理现实世界项目中固有的动态上下文依赖方面，面临着巨大的挑战。", "conclusion": "RealMem是首个基于真实项目场景的LLM记忆能力评估基准测试，揭示了当前记忆系统在处理长期、项目导向型对话中的不足，为未来LLM记忆系统的发展指明了方向。"}}
{"id": "2601.07209", "categories": ["cs.CV", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.07209", "abs": "https://arxiv.org/abs/2601.07209", "authors": ["Yu Guo", "Zhiqiang Lao", "Xiyun Song", "Yubin Zhou", "Heather Yu"], "title": "SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model", "comment": "12 pages, 14 figures, accepted in WACVW 2026", "summary": "Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal (SIRR) challenging. Existing datasets suffer from limited physical realism in synthetic data or insufficient scale in real captures. We introduce a synthetic dataset generation framework that path-traces 3D glass models over real background imagery to create physically accurate reflection scenarios with varied glass properties, camera settings, and post-processing effects. To leverage the capabilities of Large Multimodal Model (LMM), we concatenate the image layers into a single composite input, apply joint captioning, and fine-tune the model using task-specific LoRA rather than full-parameter training. This enables our approach to achieve improved reflection removal and separation performance compared to state-of-the-art methods.", "AI": {"tldr": "提出了一种基于路径追踪的合成数据集生成框架，用于解决单张图像反射去除问题，并利用大型多模态模型（LMM）通过特定的微调方法实现了性能提升。", "motivation": "现有的单张图像反射去除（SIRR）方法在处理玻璃表面的复杂光照交互时面临挑战，现有数据集在物理真实性或规模上存在不足。", "method": "构建了一个新的合成数据集生成框架，通过路径追踪技术将3D玻璃模型叠加在真实背景图像上，模拟真实的反射场景。然后，将图像层拼接成单个输入，并使用任务特定的LoRA对LMM进行微调，而非全参数训练。", "result": "该方法在反射去除和分离任务上取得了比现有最先进方法更好的性能。", "conclusion": "通过结合物理精确的合成数据生成和高效的LMM微调策略，该研究成功解决了单张图像反射去除的挑战，并展示了其优越性。"}}
{"id": "2601.07553", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07553", "abs": "https://arxiv.org/abs/2601.07553", "authors": ["Kabir Swain", "Sijie Han", "Ayush Raina", "Jin Zhang", "Shuang Li", "Michael Stopa", "Antonio Torralba"], "title": "VirtualEnv: A Platform for Embodied AI Research", "comment": null, "summary": "As large language models (LLMs) continue to improve in reasoning and decision-making, there is a growing need for realistic and interactive environments where their abilities can be rigorously evaluated. We present VirtualEnv, a next-generation simulation platform built on Unreal Engine 5 that enables fine-grained benchmarking of LLMs in embodied and interactive scenarios. VirtualEnv supports rich agent-environment interactions, including object manipulation, navigation, and adaptive multi-agent collaboration, as well as game-inspired mechanics like escape rooms and procedurally generated environments. We provide a user-friendly API built on top of Unreal Engine, allowing researchers to deploy and control LLM-driven agents using natural language instructions. We integrate large-scale LLMs and vision-language models (VLMs), such as GPT-based models, to generate novel environments and structured tasks from multimodal inputs. Our experiments benchmark the performance of several popular LLMs across tasks of increasing complexity, analyzing differences in adaptability, planning, and multi-agent coordination. We also describe our methodology for procedural task generation, task validation, and real-time environment control. VirtualEnv is released as an open-source platform, we aim to advance research at the intersection of AI and gaming, enable standardized evaluation of LLMs in embodied AI settings, and pave the way for future developments in immersive simulations and interactive entertainment.", "AI": {"tldr": "本文介绍了一个名为VirtualEnv的下一代模拟平台，该平台基于Unreal Engine 5构建，用于对大型语言模型（LLMs）进行细粒度的评估。它支持代理与环境的丰富交互，包括物体操作、导航和多代理协作，并提供易于使用的API，允许研究人员使用自然语言指令来部署和控制LLM驱动的代理。", "motivation": "随着LLMs在推理和决策方面能力的不断提高，迫切需要真实且交互式的环境来严格评估它们的能力。", "method": "利用Unreal Engine 5构建VirtualEnv平台，支持代理-环境交互、物体操作、导航、多代理协作、逃脱房间和程序化生成环境。通过友好的API，允许使用自然语言指令控制LLM驱动的代理。集成了LLMs和VLMs，从多模态输入生成新环境和结构化任务。通过实验评估了多种LLMs在不同复杂度的任务上的性能，分析了适应性、规划和多代理协调方面的差异。", "result": "对多种主流LLMs在不同复杂度任务上的表现进行了基准测试，分析了它们在适应性、规划和多代理协调方面的差异。", "conclusion": "VirtualEnv作为一个开源平台发布，旨在促进人工智能与游戏研究的交叉，实现具身AI场景中LLMs的标准化评估，并为沉浸式模拟和互动娱乐的未来发展铺平道路。"}}
{"id": "2601.07020", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07020", "abs": "https://arxiv.org/abs/2601.07020", "authors": ["Çağrı Toraman", "Ahmet Kaan Sever", "Ayse Aysu Cengiz", "Elif Ecem Arslan", "Görkem Sevinç", "Mete Mert Birdal", "Yusuf Faruk Güldemir", "Ali Buğra Kanburoğlu", "Sezen Felekoğlu", "Osman Gürlek", "Sarp Kantar", "Birsen Şahin Kütük", "Büşra Tufan", "Elif Genç", "Serkan Coşkun", "Gupse Ekin Demir", "Muhammed Emin Arayıcı", "Olgun Dursun", "Onur Gungor", "Susan Üsküdarlı", "Abdullah Topraksoy", "Esra Darıcı"], "title": "TurkBench: A Benchmark for Evaluating Turkish Large Language Models", "comment": null, "summary": "With the recent surge in the development of large language models, the need for comprehensive and language-specific evaluation benchmarks has become critical. While significant progress has been made in evaluating English language models, benchmarks for other languages, particularly those with unique linguistic characteristics such as Turkish, remain less developed. Our study introduces TurkBench, a comprehensive benchmark designed to assess the capabilities of generative large language models in the Turkish language. TurkBench involves 8,151 data samples across 21 distinct subtasks. These are organized under six main categories of evaluation: Knowledge, Language Understanding, Reasoning, Content Moderation, Turkish Grammar and Vocabulary, and Instruction Following. The diverse range of tasks and the culturally relevant data would provide researchers and developers with a valuable tool for evaluating their models and identifying areas for improvement. We further publish our benchmark for online submissions at https://huggingface.co/turkbench", "AI": {"tldr": "本文提出了 TurkBench，一个针对土耳其语的大型语言模型评估基准，包含 8,151 个数据样本和 21 个子任务，涵盖知识、语言理解、推理、内容审核、土耳其语语法词汇和指令遵循等六个主要评估类别。", "motivation": "随着大型语言模型的发展，对特定语言的全面评估基准的需求日益增长，而针对土耳其语等语言的评估工具相对缺乏。", "method": "构建了一个包含 8,151 个数据样本、21 个子任务的 TurkBench 基准，这些任务被归类到知识、语言理解、推理、内容审核、土耳其语语法词汇和指令遵循六个主要类别下。", "result": " TurkBench 是一个全面的评估工具，能够帮助研究人员和开发者评估土耳其语大型语言模型的能力，并识别改进领域。", "conclusion": " TurkBench 为评估土耳其语大型语言模型提供了一个重要的资源，其任务的多样性和文化相关性使其成为一个有价值的工具。"}}
{"id": "2601.07651", "categories": ["cs.AI", "cs.GT", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.07651", "abs": "https://arxiv.org/abs/2601.07651", "authors": ["Marc Lanctot", "Kate Larson", "Ian Gemp", "Michael Kaisers"], "title": "Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms", "comment": "AAMAS 2026", "summary": "As intelligent agents become more generally-capable, i.e. able to master a wide variety of tasks, the complexity and cost of properly evaluating them rises significantly. Tasks that assess specific capabilities of the agents can be correlated and stochastic, requiring many samples for accurate comparisons, leading to added costs. In this paper, we propose a formal definition and a conceptual framework for active evaluation of agents across multiple tasks, which assesses the performance of ranking algorithms as a function of number of evaluation data samples. Rather than curating, filtering, or compressing existing data sets as a preprocessing step, we propose an online framing: on every iteration, the ranking algorithm chooses the task and agents to sample scores from. Then, evaluation algorithms report a ranking of agents on each iteration and their performance is assessed with respect to the ground truth ranking over time. Several baselines are compared under different experimental contexts, with synthetic generated data and simulated online access to real evaluation data from Atari game-playing agents. We find that the classical Elo rating system -- while it suffers from well-known failure modes, in theory -- is a consistently reliable choice for efficient reduction of ranking error in practice. A recently-proposed method, Soft Condorcet Optimization, shows comparable performance to Elo on synthetic data and significantly outperforms Elo on real Atari agent evaluation. When task variation from the ground truth is high, selecting tasks based on proportional representation leads to higher rate of ranking error reduction.", "AI": {"tldr": "本文提出了一种主动评估智能体的方法，通过让评估算法在每次迭代中选择要采样的任务和智能体，从而更有效地评估智能体在多任务上的性能。实验表明，Elo 评分系统在实际应用中表现可靠，而 Soft Condorcet Optimization 在真实数据上优于 Elo，并且当任务变异性高时，基于比例代表制的任务选择能提高排名误差的降低率。", "motivation": "随着智能体通用能力的提升，评估其在众多任务上的性能变得复杂且昂贵，尤其是在任务之间存在相关性和随机性时，需要大量样本进行准确比较。", "method": "提出了一种主动评估的定义和概念框架。在每次迭代中，排名算法自主选择要采样的任务和智能体。评估算法随后生成一个智能体排名，并随时间评估其相对于真实排名的性能。通过合成数据和模拟的 Atari 游戏智能体真实评估数据进行了实验比较。", "result": "Elo 评分系统在减少排名误差方面表现可靠。Soft Condorcet Optimization 在合成数据上与 Elo 相当，但在真实 Atari 智能体评估上显著优于 Elo。当任务变异性高时，基于比例代表制的任务选择能提高排名误差降低率。", "conclusion": "主动评估是一种更有效评估通用智能体的方法。Elo 评分系统是一个实用的基线选择，而 Soft Condorcet Optimization 在真实世界数据上显示出潜力。任务选择策略，如基于比例代表制，在面对高任务变异性时很重要。"}}
{"id": "2601.07218", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07218", "abs": "https://arxiv.org/abs/2601.07218", "authors": ["Jeongjun Choi", "Yeonsoo Park", "H. Jin Kim"], "title": "SceneNAT: Masked Generative Modeling for Language-Guided Indoor Scene Synthesis", "comment": "Under review. Code will be released", "summary": "We present SceneNAT, a single-stage masked non-autoregressive Transformer that synthesizes complete 3D indoor scenes from natural language instructions through only a few parallel decoding passes, offering improved performance and efficiency compared to prior state-of-the-art approaches. SceneNAT is trained via masked modeling over fully discretized representations of both semantic and spatial attributes. By applying a masking strategy at both the attribute level and the instance level, the model can better capture intra-object and inter-object structure. To boost relational reasoning, SceneNAT employs a dedicated triplet predictor for modeling the scene's layout and object relationships by mapping a set of learnable relation queries to a sparse set of symbolic triplets (subject, predicate, object). Extensive experiments on the 3D-FRONT dataset demonstrate that SceneNAT achieves superior performance compared to state-of-the-art autoregressive and diffusion baselines in both semantic compliance and spatial arrangement accuracy, while operating with substantially lower computational cost.", "AI": {"tldr": "SceneNAT是一种单阶段、掩码非自回归Transformer模型，能够根据自然语言指令合成完整的3D室内场景，其性能和效率优于现有方法。", "motivation": "现有方法在生成3D室内场景时存在性能和效率上的不足，作者希望提出一种更优的方法。", "method": "该模型使用掩码建模技术，对语义和空间属性进行完全离散化表示，并通过属性和实例级别的掩码策略来捕捉对象内部和对象之间的结构。此外，模型还引入了一个专门的三元组预测器来建模场景布局和对象关系。", "result": "在3D-FRONT数据集上的实验表明，SceneNAT在语义符合度和空间排列准确性方面均优于最先进的自回归和扩散基线模型，并且计算成本显著降低。", "conclusion": "SceneNAT通过其新颖的掩码非自回归Transformer架构，在3D室内场景合成任务上实现了高性能和高效率，优于现有方法。"}}
{"id": "2601.07663", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07663", "abs": "https://arxiv.org/abs/2601.07663", "authors": ["William Walden"], "title": "Reasoning Models Will Blatantly Lie About Their Reasoning", "comment": null, "summary": "It has been shown that Large Reasoning Models (LRMs) may not *say what they think*: they do not always volunteer information about how certain parts of the input influence their reasoning. But it is one thing for a model to *omit* such information and another, worse thing to *lie* about it. Here, we extend the work of Chen et al. (2025) to show that LRMs will do just this: they will flatly deny relying on hints provided in the prompt in answering multiple choice questions -- even when directly asked to reflect on unusual (i.e. hinted) prompt content, even when allowed to use hints, and even though experiments *show* them to be using the hints. Our results thus have discouraging implications for CoT monitoring and interpretability.", "AI": {"tldr": "大型推理模型（LRM）在回答多项选择题时，即使它们确实使用了提示，也会否认依赖提示，即使在被要求反思异常提示内容或被允许使用提示时也是如此。这表明LRM可能会‘撒谎’，而非仅仅‘遗漏’信息。", "motivation": "已有的研究表明大型推理模型（LRMs）可能不会“说出它们所想”，即不主动披露输入对推理的影响。本研究旨在进一步探究LRMs是否会“撒谎”，即否认依赖提示，这比遗漏信息更为严重。", "method": "该研究扩展了Chen et al. (2025)的工作，通过实验证明LRMs在回答多项选择题时，即使使用了提示，也会否认依赖这些提示，即使在直接被要求反思异常提示内容或被允许使用提示的情况下也是如此。", "result": "实验结果表明，LRMs会完全否认在回答问题时依赖提供的提示，尽管实验证据表明它们确实使用了这些提示。", "conclusion": "这项研究结果对思维链（CoT）的监控和可解释性带来了令人沮丧的启示，表明LRMs存在“撒谎”的倾向，即否认其推理过程中的依赖关系。"}}
{"id": "2601.07022", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07022", "abs": "https://arxiv.org/abs/2601.07022", "authors": ["Sungrae Park", "Sanghoon Kim", "Jungho Cho", "Gyoungjin Gim", "Dawoon Jung", "Mikyoung Cha", "Eunhae Choo", "Taekgyu Hong", "Minbyul Jeong", "SeHwan Joo", "Minsoo Khang", "Eunwon Kim", "Minjeong Kim", "Sujeong Kim", "Yunsu Kim", "Hyeonju Lee", "Seunghyun Lee", "Sukyung Lee", "Siyoung Park", "Gyungin Shin", "Inseo Song", "Wonho Song", "Seonghoon Yang", "Seungyoun Yi", "Sanghoon Yoon", "Jeonghyun Ko", "Seyoung Song", "Keunwoo Choi", "Hwalsuk Lee", "Sunghun Kim", "Du-Seong Chang", "Kyunghyun Cho", "Junsuk Choe", "Hwaran Lee", "Jae-Gil Lee", "KyungTae Lim", "Alice Oh"], "title": "Solar Open Technical Report", "comment": null, "summary": "We introduce Solar Open, a 102B-parameter bilingual Mixture-of-Experts language model for underserved languages. Solar Open demonstrates a systematic methodology for building competitive LLMs by addressing three interconnected challenges. First, to train effectively despite data scarcity for underserved languages, we synthesize 4.5T tokens of high-quality, domain-specific, and RL-oriented data. Second, we coordinate this data through a progressive curriculum jointly optimizing composition, quality thresholds, and domain coverage across 20 trillion tokens. Third, to enable reasoning capabilities through scalable RL, we apply our proposed framework SnapPO for efficient optimization. Across benchmarks in English and Korean, Solar Open achieves competitive performance, demonstrating the effectiveness of this methodology for underserved language AI development.", "AI": {"tldr": "本文介绍了一种名为Solar Open的1020亿参数的双语专家混合语言模型，专门为数据稀缺的语言设计。该模型通过合成高质量数据、渐进式课程训练和高效的强化学习优化，在中英文和韩文的基准测试中均取得了有竞争力的性能。", "motivation": "当前大型语言模型（LLM）在“欠服务”语言（即数据稀缺的语言）方面的能力不足，这促使研究人员探索如何有效地构建针对这些语言的LLM。", "method": "研究人员采用了三方面的策略：1. 合成4.5万亿（4.5T）高质量、领域特定的、面向强化学习（RL）的数据，以弥补数据稀缺问题。2. 通过一个渐进式课程，在20万亿（20T）数据上联合优化数据的组成、质量阈值和领域覆盖率。3. 提出并应用名为SnapPO的框架，以实现可扩展强化学习和推理能力的提升。", "result": "在英文和韩文的基准测试中，Solar Open模型展现出了具有竞争力的性能，证明了该方法在欠服务语言AI开发方面的有效性。", "conclusion": "本文提出了一种系统性的方法，通过数据合成、课程训练和高效的强化学习优化，能够成功地构建出在欠服务语言（如韩文）方面具有竞争力的LLM，为欠服务语言的AI发展提供了一种可行途径。"}}
{"id": "2601.07219", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07219", "abs": "https://arxiv.org/abs/2601.07219", "authors": ["Thanh-Nhan Vo", "Trong-Thuan Nguyen", "Tam V. Nguyen", "Minh-Triet Tran"], "title": "VENUS: Visual Editing with Noise Inversion Using Scene Graphs", "comment": null, "summary": "State-of-the-art text-based image editing models often struggle to balance background preservation with semantic consistency, frequently resulting either in the synthesis of entirely new images or in outputs that fail to realize the intended edits. In contrast, scene graph-based image editing addresses this limitation by providing a structured representation of semantic entities and their relations, thereby offering improved controllability. However, existing scene graph editing methods typically depend on model fine-tuning, which incurs high computational cost and limits scalability. To this end, we introduce VENUS (Visual Editing with Noise inversion Using Scene graphs), a training-free framework for scene graph-guided image editing. Specifically, VENUS employs a split prompt conditioning strategy that disentangles the target object of the edit from its background context, while simultaneously leveraging noise inversion to preserve fidelity in unedited regions. Moreover, our proposed approach integrates scene graphs extracted from multimodal large language models with diffusion backbones, without requiring any additional training. Empirically, VENUS substantially improves both background preservation and semantic alignment on PIE-Bench, increasing PSNR from 22.45 to 24.80, SSIM from 0.79 to 0.84, and reducing LPIPS from 0.100 to 0.070 relative to the state-of-the-art scene graph editing model (SGEdit). In addition, VENUS enhances semantic consistency as measured by CLIP similarity (24.97 vs. 24.19). On EditVal, VENUS achieves the highest fidelity with a 0.87 DINO score and, crucially, reduces per-image runtime from 6-10 minutes to only 20-30 seconds. Beyond scene graph-based editing, VENUS also surpasses strong text-based editing baselines such as LEDIT++ and P2P+DirInv, thereby demonstrating consistent improvements across both paradigms.", "AI": {"tldr": "VENUS是一个无需训练的框架，利用场景图指导图像编辑，通过分离编辑对象和背景，并结合噪声反演来保留未编辑区域，有效解决了现有场景图编辑方法计算成本高和扩展性差的问题，并在多个指标上超越了SOTA方法，同时显著缩短了编辑时间。", "motivation": "现有的文本到图像编辑模型在背景保留和语义一致性方面存在不足，要么生成全新图像，要么无法实现预期编辑。虽然场景图编辑有所改善，但现有方法依赖模型微调，计算成本高且扩展性差。因此，需要一种无需训练、计算高效且性能优越的场景图图像编辑方法。", "method": "VENUS框架采用分离式提示条件策略，将编辑目标与背景上下文解耦，并利用噪声反演技术保留未编辑区域的保真度。该方法将从多模态大语言模型提取的场景图与扩散模型骨干结合，无需额外训练。", "result": "在PIE-Bench数据集上，VENUS在背景保留和语义对齐方面均有显著提升，PSNR从22.45提升至24.80，SSIM从0.79提升至0.84，LPIPS从0.100降低至0.070，CLIP相似度从24.19提升至24.97。在EditVal数据集上，VENUS取得了0.87的DINO分数，且单张图像的运行时从6-10分钟缩短至20-30秒。此外，VENUS在文本到图像编辑方面也优于LEDIT++和P2P+DirInv等基线模型。", "conclusion": "VENUS是一个训练无关的场景图图像编辑框架，通过创新的提示策略和噪声反演技术，实现了高质量的图像编辑，显著提高了背景保真度和语义一致性，同时大幅降低了计算成本和编辑时间，展现了其在场景图编辑和文本引导编辑领域的优势。"}}
{"id": "2601.07221", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07221", "abs": "https://arxiv.org/abs/2601.07221", "authors": ["Jongwon Ryu", "Joonhyung Park", "Jaeho Han", "Yeong-Seok Kim", "Hye-rin Kim", "Sunjae Yoon", "Junyeong Kim"], "title": "Language-Grounded Multi-Domain Image Translation via Semantic Difference Guidance", "comment": null, "summary": "Multi-domain image-to-image translation re quires grounding semantic differences ex pressed in natural language prompts into corresponding visual transformations, while preserving unrelated structural and seman tic content. Existing methods struggle to maintain structural integrity and provide fine grained, attribute-specific control, especially when multiple domains are involved. We propose LACE (Language-grounded Attribute Controllable Translation), built on two compo nents: (1) a GLIP-Adapter that fuses global semantics with local structural features to pre serve consistency, and (2) a Multi-Domain Control Guidance mechanism that explicitly grounds the semantic delta between source and target prompts into per-attribute translation vec tors, aligning linguistic semantics with domain level visual changes. Together, these modules enable compositional multi-domain control with independent strength modulation for each attribute. Experiments on CelebA(Dialog) and BDD100K demonstrate that LACE achieves high visual fidelity, structural preservation, and interpretable domain-specific control, surpass ing prior baselines. This positions LACE as a cross-modal content generation framework bridging language semantics and controllable visual translation.", "AI": {"tldr": "LACE 是一种新的图像到图像翻译方法，它通过 GLIP-Adapter 和多域控制引导机制，实现了在保持结构完整性的同时，根据自然语言提示进行精细、特定属性的控制，尤其擅长处理多域场景。", "motivation": "现有方法在多域图像到图像翻译中难以保持结构完整性，并且难以提供细粒度的、属性特定的控制。", "method": "提出 LACE，包含两个主要组件：1) GLIP-Adapter，用于融合全局语义和局部结构特征以保持一致性；2) 多域控制引导机制，将源目标提示之间的语义差异显式地接地到每个属性的翻译向量上。", "result": "在 CelebA(Dialog) 和 BDD100K 数据集上的实验表明，LACE 实现了高视觉保真度、结构保持和可解释的域特定控制，优于现有基线方法。", "conclusion": "LACE 是一个跨模态内容生成框架，能够桥接语言语义和可控的视觉翻译，实现了成分式的多域控制，并能独立调节每个属性的强度。"}}
{"id": "2601.07685", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07685", "abs": "https://arxiv.org/abs/2601.07685", "authors": ["Shafiul Ajam Opee", "Nafiz Fahad", "Anik Sen", "Rasel Ahmed", "Fariha Jahan", "Md. Kishor Morol", "Md Rashedul Islam"], "title": "Predictive Analytics for Dementia: Machine Learning on Healthcare Data", "comment": "10 pages, 13 figures", "summary": "Dementia is a complex syndrome impacting cognitive and emotional functions, with Alzheimer's disease being the most common form. This study focuses on enhancing dementia prediction using machine learning (ML) techniques on patient health data. Supervised learning algorithms are applied in this study, including K-Nearest Neighbors (KNN), Quadratic Discriminant Analysis (QDA), Linear Discriminant Analysis (LDA), and Gaussian Process Classifiers. To address class imbalance and improve model performance, techniques such as Synthetic Minority Over-sampling Technique (SMOTE) and Term Frequency-Inverse Document Frequency (TF-IDF) vectorization were employed. Among the models, LDA achieved the highest testing accuracy of 98%. This study highlights the importance of model interpretability and the correlation of dementia with features such as the presence of the APOE-epsilon4 allele and chronic conditions like diabetes. This research advocates for future ML innovations, particularly in integrating explainable AI approaches, to further improve predictive capabilities in dementia care.", "AI": {"tldr": "本研究使用机器学习算法（KNN、QDA、LDA、GPC）对患者健康数据进行痴呆症预测，并通过SMOTE和TF-IDF技术处理类别不平衡问题。LDA模型取得了98%的最高测试准确率。", "motivation": "提高痴呆症（尤其是阿尔茨海默病）的预测准确性，以改善患者护理。", "method": "应用监督学习算法，包括K-Nearest Neighbors (KNN)、Quadratic Discriminant Analysis (QDA)、Linear Discriminant Analysis (LDA) 和 Gaussian Process Classifiers。使用Synthetic Minority Over-sampling Technique (SMOTE) 来解决类别不平衡问题，并使用Term Frequency-Inverse Document Frequency (TF-IDF) 进行特征向量化。", "result": "在所有模型中，LDA 达到了最高的 98% 的测试准确率。研究还发现了 APOE-epsilon4 基因型和糖尿病等慢性病与痴呆症之间的相关性。", "conclusion": "机器学习，特别是LDA，在痴呆症预测方面表现出高准确性。模型的可解释性和特定生物标志物（如APOE-epsilon4）及慢性病的关联性对于痴呆症的预测和护理至关重要。未来研究应侧重于集成可解释人工智能（XAI）来进一步提升预测能力。"}}
{"id": "2601.07641", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.07641", "abs": "https://arxiv.org/abs/2601.07641", "authors": ["Jiaxuan Lu", "Ziyu Kong", "Yemin Wang", "Rong Fu", "Haiyuan Wan", "Cheng Yang", "Wenjie Lou", "Haoran Sun", "Lilong Wang", "Yankai Jiang", "Xiaosong Wang", "Xiao Sun", "Dongzhan Zhou"], "title": "Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning", "comment": null, "summary": "The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools. The code and benchmark have been released at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol.", "AI": {"tldr": "本文提出了一种名为测试时工具演进（TTE）的新范式，允许AI代理在推理过程中自行合成、验证和演进可执行工具，克服了现有基于LLM的代理在科学领域工具库静态、不完整等问题。引入了包含1590个科学推理任务和925个自动演进工具的SciEvo基准进行评估，TTE在准确性和工具效率方面均取得最先进的性能，并能有效实现跨领域工具适应性。", "motivation": "现有的基于LLM的AI代理在科学领域面临挑战，因为它们的工具库是静态的、预定义的，而科学领域工具稀疏、异构且本质上不完整。这种范式在开放的科学世界中难以应对。", "method": "提出测试时工具演进（TTE）新范式，使AI代理能够在推理过程中动态地合成、验证和演进可执行工具，从而将工具视为问题驱动的产物，而非固定的资源。", "result": "在SciEvo基准（包含1590个科学推理任务和925个自动演进工具）上进行的大量实验表明，TTE在准确性和工具效率方面均取得了最先进的性能。此外，TTE还展现了在计算工具跨领域适应方面的有效性。", "conclusion": "TTE范式克服了静态工具库的僵化和长尾问题，能够动态地生成和演进科学推理所需的计算工具，并在科学推理任务中取得了优于现有方法的性能，同时具备良好的跨领域适应性。"}}
{"id": "2601.07036", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07036", "abs": "https://arxiv.org/abs/2601.07036", "authors": ["Wang Yang", "Debargha Ganguly", "Xinpeng Li", "Chaoda Song", "Shouren Wang", "Vikash Singh", "Vipin Chaudhary", "Xiaotian Han"], "title": "Mid-Think: Training-Free Intermediate-Budget Reasoning via Token-Level Triggers", "comment": null, "summary": "Hybrid reasoning language models are commonly controlled through high-level Think/No-think instructions to regulate reasoning behavior, yet we found that such mode switching is largely driven by a small set of trigger tokens rather than the instructions themselves. Through attention analysis and controlled prompting experiments, we show that a leading ``Okay'' token induces reasoning behavior, while the newline pattern following ``</think>'' suppresses it. Based on this observation, we propose Mid-Think, a simple training-free prompting format that combines these triggers to achieve intermediate-budget reasoning, consistently outperforming fixed-token and prompt-based baselines in terms of the accuracy-length trade-off. Furthermore, applying Mid-Think to RL training after SFT reduces training time by approximately 15% while improving final performance of Qwen3-8B on AIME from 69.8% to 72.4% and on GPQA from 58.5% to 61.1%, demonstrating its effectiveness for both inference-time control and RL-based reasoning training.", "AI": {"tldr": "研究发现，大型语言模型（LLM）的推理行为主要受特定触发词（如“Okay”）和模式（如“</think>”后的换行符）控制，而非指令本身。论文提出了一种名为Mid-Think的无需训练的提示格式，通过结合这些触发词来实现中等预算的推理，并在准确性和长度之间取得了更好的权衡。此外，该方法还可用于加速强化学习（RL）训练，并提升模型在数学和科学问答任务上的性能。", "motivation": "现有的LLM推理控制方法（如Think/No-think指令）效果不佳，其背后的原因在于模型对指令的理解不足，而更依赖于触发词和模式。作者希望找到一种更有效、更简洁的方法来控制LLM的推理过程，并优化推理效率和性能。", "method": "通过注意力分析和受控提示实验，识别出“Okay”作为触发推理的词，“</think>”后的换行符作为抑制推理的模式。基于此，提出Mid-Think提示格式，将这些触发词结合起来。同时，将Mid-Think应用于监督微调（SFT）后的强化学习（RL）训练中。", "result": "Mid-Think在准确性-长度权衡方面优于基线方法。将其应用于RL训练，可以将训练时间减少约15%，同时将Qwen3-8B在AIME上的准确率从69.8%提升至72.4%，在GPQA上的准确率从58.5%提升至61.1%。", "conclusion": "Mid-Think是一种有效且易于实现的LLM推理控制方法，可以显著提升推理效率和模型性能，并且适用于推理时控制和RL训练。"}}
{"id": "2601.07253", "categories": ["cs.CV", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.07253", "abs": "https://arxiv.org/abs/2601.07253", "authors": ["Li Zheng", "Liangbin Xie", "Jiantao Zhou", "He YiMin"], "title": "Universal Adversarial Purification with DDIM Metric Loss for Stable Diffusion", "comment": null, "summary": "Stable Diffusion (SD) often produces degraded outputs when the training dataset contains adversarial noise. Adversarial purification offers a promising solution by removing adversarial noise from contaminated data. However, existing purification methods are primarily designed for classification tasks and fail to address SD-specific adversarial strategies, such as attacks targeting the VAE encoder, UNet denoiser, or both. To address the gap in SD security, we propose Universal Diffusion Adversarial Purification (UDAP), a novel framework tailored for defending adversarial attacks targeting SD models. UDAP leverages the distinct reconstruction behaviors of clean and adversarial images during Denoising Diffusion Implicit Models (DDIM) inversion to optimize the purification process. By minimizing the DDIM metric loss, UDAP can effectively remove adversarial noise. Additionally, we introduce a dynamic epoch adjustment strategy that adapts optimization iterations based on reconstruction errors, significantly improving efficiency without sacrificing purification quality. Experiments demonstrate UDAP's robustness against diverse adversarial methods, including PID (VAE-targeted), Anti-DreamBooth (UNet-targeted), MIST (hybrid), and robustness-enhanced variants like Anti-Diffusion (Anti-DF) and MetaCloak. UDAP also generalizes well across SD versions and text prompts, showcasing its practical applicability in real-world scenarios.", "AI": {"tldr": "本文提出了一种名为UDAP的通用扩散模型对抗性净化框架，该框架能够有效去除针对Stable Diffusion模型（包括VAE和UNet）的对抗性噪声，并且通过动态调整训练周期提高了效率。", "motivation": "现有的对抗性净化方法主要针对分类任务，无法解决Stable Diffusion模型特有的、针对VAE编码器、UNet去噪器或两者的对抗性攻击。", "method": "UDAP利用扩散模型（DDIM）反演过程中干净图像和对抗性图像在重建行为上的差异，通过最小化DDIM度量损失来优化净化过程，并引入动态周期调整策略以适应重建误差。", "result": "UDAP在对抗PID（针对VAE）、Anti-DreamBooth（针对UNet）、MIST（混合）以及Anti-Diffusion（Anti-DF）和MetaCloak等增强鲁棒性的变体攻击方面表现出鲁棒性。UDAP在不同Stable Diffusion版本和文本提示下均表现出良好的泛化能力。", "conclusion": "UDAP是一种针对Stable Diffusion模型的通用对抗性净化框架，通过利用DDIM反演特性和动态周期调整，能够有效净化对抗性噪声，并且在多种攻击和模型上具有良好的泛化性。"}}
{"id": "2601.07790", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07790", "abs": "https://arxiv.org/abs/2601.07790", "authors": ["Yahya Masri", "Emily Ma", "Zifu Wang", "Joseph Rogers", "Chaowei Yang"], "title": "Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification", "comment": "28 pages, 5 figures, 7 tables", "summary": "System logs are crucial for monitoring and diagnosing modern computing infrastructure, but their scale and complexity require reliable and efficient automated interpretation. Since severity levels are predefined metadata in system log messages, having a model merely classify them offers limited standalone practical value, revealing little about its underlying ability to interpret system logs. We argue that severity classification is more informative when treated as a benchmark for probing runtime log comprehension rather than as an end task. Using real-world journalctl data from Linux production servers, we evaluate nine small language models (SLMs) and small reasoning language models (SRLMs) under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting. The results reveal strong stratification. Qwen3-4B achieves the highest accuracy at 95.64% with RAG, while Gemma3-1B improves from 20.25% under few-shot prompting to 85.28% with RAG. Notably, the tiny Qwen3-0.6B reaches 88.12% accuracy despite weak performance without retrieval. In contrast, several SRLMs, including Qwen3-1.7B and DeepSeek-R1-Distill-Qwen-1.5B, degrade substantially when paired with RAG. Efficiency measurements further separate models: most Gemma and Llama variants complete inference in under 1.2 seconds per log, whereas Phi-4-Mini-Reasoning exceeds 228 seconds per log while achieving <10% accuracy. These findings suggest that (1) architectural design, (2) training objectives, and (3) the ability to integrate retrieved context under strict output constraints jointly determine performance. By emphasizing small, deployable models, this benchmark aligns with real-time requirements of digital twin (DT) systems and shows that severity classification serves as a lens for evaluating model competence and real-time deployability, with implications for root cause analysis (RCA) and broader DT integration.", "AI": {"tldr": "该研究将系统日志的严重性分类作为评估小型语言模型（SLM）和小型推理语言模型（SRLM）在理解和处理日志方面的基准，并使用真实数据在零样本、少样本和检索增强生成（RAG）的提示下进行了评估。结果显示，模型性能存在显著差异，Qwen3-4B 在 RAG 下表现最佳，而 Gemma3-1B 在 RAG 下性能大幅提升。部分 SRLM 在 RAG 下性能下降。模型效率也存在差异，并强调了模型架构、训练目标和检索上下文整合能力对性能的重要性，为数字孪生系统中的实时日志处理和根本原因分析提供了参考。", "motivation": "传统系统日志的严重性分类模型性能有限，难以深入理解日志。作者认为，将严重性分类作为评估模型对日志运行时理解能力的基准，比将其视为最终任务更有价值，特别是对于部署在实时系统中的小型、可部署模型。", "method": "使用Linux生产服务器上的真实journalctl日志数据，在零样本（zero-shot）、少样本（few-shot）和检索增强生成（RAG）的提示下，评估了九种小型语言模型（SLM）和小型推理语言模型（SRLM）的严重性分类准确率和推理效率。", "result": "Qwen3-4B在RAG提示下达到了最高的95.64%准确率。Gemma3-1B的准确率从少样本提示下的20.25%提升到RAG下的85.28%。Qwen3-0.6B在RAG下也能达到88.12%的准确率。一些SRLM（如Qwen3-1.7B）在RAG下性能显著下降。模型效率差异显著，Gemma和Llama系列模型推理速度快，而Phi-4-Mini-Reasoning速度极慢且准确率低。", "conclusion": "模型在日志理解和处理方面的性能受架构设计、训练目标以及在严格输出约束下整合检索上下文能力的影响。严重性分类可作为评估小型模型在实时系统（如数字孪生）中能力和可部署性的有效指标，对根本原因分析和数字孪生集成具有重要意义。"}}
{"id": "2601.07038", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07038", "abs": "https://arxiv.org/abs/2601.07038", "authors": ["Emma Rafkin", "Dan DeGenaro", "Xiulin Yang"], "title": "Task Arithmetic with Support Languages for Low-Resource ASR", "comment": "8 pages, 3 Figures, preprint after submitted for review for a *ACL conference", "summary": "The development of resource-constrained approaches to automatic speech recognition (ASR) is of great interest due to its broad applicability to many low-resource languages for which there is scant usable data. Existing approaches to many low-resource natural language processing tasks leverage additional data from higher-resource languages that are closely related to a target low-resource language. One increasingly popular approach uses task arithmetic to combine models trained on different tasks to create a model for a task where there is little to no training data. In this paper, we consider training on a particular language to be a task, and we generate task vectors by fine-tuning variants of the Whisper ASR system. For pairings of high- and low-resource languages, we merge task vectors via a linear combination, optimizing the weights of the linear combination on the downstream word error rate on the low-resource target language's validation set. We find that this approach consistently improves performance on the target languages.", "AI": {"tldr": "本文提出了一种利用任务算术（task arithmetic）结合两种语言（高资源和低资源）的预训练模型，来提升低资源语言的自动语音识别（ASR）性能的方法。", "motivation": "为资源匮乏的低资源语言开发自动语音识别（ASR）系统具有广泛的应用前景，但这些语言通常缺乏可用的训练数据。现有的方法通常依赖于高资源语言的额外数据，而任务算术是一种有前景的方法，可以结合不同任务的模型来解决数据稀疏的问题。", "method": "将训练特定语言视为一个任务，并通过微调 Whisper ASR 系统来生成任务向量。对于高资源语言和低资源语言的配对，通过线性组合合并任务向量，并在低资源目标语言的验证集上优化线性组合的权重，以降低词错误率（WER）。", "result": "该方法在目标低资源语言上始终能够提升性能。", "conclusion": "通过线性组合高资源和低资源语言的任务向量，任务算术可以有效地改善低资源语言的自动语音识别性能。"}}
{"id": "2601.07008", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07008", "abs": "https://arxiv.org/abs/2601.07008", "authors": ["Yiming Liang", "Fang Zhao"], "title": "Lexicalized Constituency Parsing for Middle Dutch: Low-resource Training and Cross-Domain Generalization", "comment": null, "summary": "Recent years have seen growing interest in applying neural networks and contextualized word embeddings to the parsing of historical languages. However, most advances have focused on dependency parsing, while constituency parsing for low-resource historical languages like Middle Dutch has received little attention. In this paper, we adapt a transformer-based constituency parser to Middle Dutch, a highly heterogeneous and low-resource language, and investigate methods to improve both its in-domain and cross-domain performance. We show that joint training with higher-resource auxiliary languages increases F1 scores by up to 0.73, with the greatest gains achieved from languages that are geographically and temporally closer to Middle Dutch. We further evaluate strategies for leveraging newly annotated data from additional domains, finding that fine-tuning and data combination yield comparable improvements, and our neural parser consistently outperforms the currently used PCFG-based parser for Middle Dutch. We further explore feature-separation techniques for domain adaptation and demonstrate that a minimum threshold of approximately 200 examples per domain is needed to effectively enhance cross-domain performance.", "AI": {"tldr": "本文将基于 Transformer 的成分句法分析器应用于低资源历史语言中古荷兰语，并通过与高资源辅助语言联合训练、利用新标注数据以及特征分离技术来提升其在域内和跨域的性能。结果表明，联合训练和数据组合均能有效提升性能，并且联合训练时选择与中古荷兰语地理和时间上更接近的语言效果最佳。此外，研究还发现特征分离技术有助于域自适应，且至少需要约 200 个新领域的数据才能有效提升跨域性能。", "motivation": "历史语言（如中古荷兰语）的成分句法分析研究不足，尤其是低资源语言。现有研究多集中于依存句法分析，而成分句法分析的进展较少。", "method": "1. 将基于 Transformer 的成分句法分析器应用于中古荷兰语。 2. 探索提高其在域内和跨域性能的方法： a. 与高资源辅助语言进行联合训练。 b. 利用新标注的附加领域数据。 c. 探索特征分离技术以进行域自适应。", "result": "1. 与高资源辅助语言联合训练能将 F1 分数提高多达 0.73，其中地理和时间上更接近中古荷兰语的语言增益最大。 2. 微调（fine-tuning）和数据组合（data combination）在利用新领域数据方面产生可比的性能提升。 3. 提出的神经分析器始终优于目前用于中古荷兰语的 PCFG-（概率上下文无关文法）基线分析器。 4. 特征分离技术有助于域自适应，且需要约 200 个新领域样本才能有效提升跨域性能。", "conclusion": "联合训练和利用新标注数据是提高低资源历史语言成分句法分析器性能的有效策略。选择与目标语言在地理和时间上更接近的辅助语言进行联合训练效果更佳。此外，特征分离技术在域自适应方面也表现出潜力，但需要一定量的标注数据才能显现其优势。"}}
{"id": "2601.07272", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07272", "abs": "https://arxiv.org/abs/2601.07272", "authors": ["Siqi Liu", "Maoyu Wang", "Bo Dai", "Cewu Lu"], "title": "PALUM: Part-based Attention Learning for Unified Motion Retargeting", "comment": null, "summary": "Retargeting motion between characters with different skeleton structures is a fundamental challenge in computer animation. When source and target characters have vastly different bone arrangements, maintaining the original motion's semantics and quality becomes increasingly difficult. We present PALUM, a novel approach that learns common motion representations across diverse skeleton topologies by partitioning joints into semantic body parts and applying attention mechanisms to capture spatio-temporal relationships. Our method transfers motion to target skeletons by leveraging these skeleton-agnostic representations alongside target-specific structural information. To ensure robust learning and preserve motion fidelity, we introduce a cycle consistency mechanism that maintains semantic coherence throughout the retargeting process. Extensive experiments demonstrate superior performance in handling diverse skeletal structures while maintaining motion realism and semantic fidelity, even when generalizing to previously unseen skeleton-motion combinations. We will make our implementation publicly available to support future research.", "AI": {"tldr": "提出了一种名为PALUM的新方法，用于在骨架结构差异很大的角色之间进行动作迁移，该方法通过关节语义划分和注意力机制来学习通用的运动表示，并利用周期一致性来保证动作的保真度。", "motivation": "在计算机动画中，跨具有不同骨架结构的角色进行动作迁移是一个基本挑战，当源和目标角色的骨骼排列差异很大时，保持原始动作的语义和质量变得越来越困难。", "method": "PALUM方法通过将关节划分为语义身体部位并应用注意力机制来捕获时空关系，学习跨不同骨架拓扑的通用运动表示。然后，利用这些与骨架无关的表示以及目标特定的结构信息来将运动迁移到目标骨架。引入了周期一致性机制来保持整个迁移过程中的语义一致性。", "result": "实验表明，PALUM在处理各种骨架结构方面表现出色，即使在泛化到先前未见的骨架-运动组合时，也能保持动作的真实感和语义保真度。", "conclusion": "PALUM是一种有效的动作迁移方法，能够处理差异巨大的骨架结构，并保持动作的质量和语义，为未来研究提供了公开的实现。"}}
{"id": "2601.07268", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07268", "abs": "https://arxiv.org/abs/2601.07268", "authors": ["Yusen Cheng", "Qinfeng Zhu", "Lei Fan"], "title": "From Landslide Conditioning Factors to Satellite Embeddings: Evaluating the Utilisation of Google AlphaEarth for Landslide Susceptibility Mapping using Deep Learning", "comment": null, "summary": "Data-driven landslide susceptibility mapping (LSM) typically relies on landslide conditioning factors (LCFs), whose availability, heterogeneity, and preprocessing-related uncertainties can constrain mapping reliability. Recently, Google AlphaEarth (AE) embeddings, derived from multi-source geospatial observations, have emerged as a unified representation of Earth surface conditions. This study evaluated the potential of AE embeddings as alternative predictors for LSM. Two AE representations, including retained principal components and the full set of 64 embedding bands, were systematically compared with conventional LCFs across three study areas (Nantou County, Taiwan; Hong Kong; and part of Emilia-Romagna, Italy) using three deep learning models (CNN1D, CNN2D, and Vision Transformer). Performance was assessed using multiple evaluation metrics, ROC-AUC analysis, error statistics, and spatial pattern assessment. Results showed that AE-based models consistently outperformed LCFs across all regions and models, yielding higher F1-scores, AUC values, and more stable error distributions. Such improvement was most pronounced when using the full 64-band AE representation, with F1-score improvements of approximately 4% to 15% and AUC increased ranging from 0.04 to 0.11, depending on the study area and model. AE-based susceptibility maps also exhibited clearer spatial correspondence with observed landslide occurrences and enhanced sensitivity to localised landslide-prone conditions. Performance improvements were more evident in Nantou and Emilia than in Hong Kong, revealing that closer temporal alignment between AE embeddings and landslide inventories may lead to more effective LSM outcomes. These findings highlight the strong potential of AE embeddings as a standardised and information-rich alternative to conventional LCFs for LSM.", "AI": {"tldr": "本研究评估了谷歌 AlphaEarth (AE) 嵌入作为滑坡易感性测绘 (LSM) 的替代预测因子。结果表明，AE 嵌入模型在所有研究区域和模型中均优于传统的滑坡影响因素 (LCFs)，特别是在使用完整的 64 个嵌入波段时，LSM 性能显著提高。", "motivation": "传统的滑坡影响因素 (LCFs) 在可用性、异质性和预处理方面存在不确定性，这会限制滑坡易感性测绘 (LSM) 的可靠性。因此，研究人员希望找到一种更统一、信息量更丰富的替代方法。", "method": "本研究使用了两种 AlphaEarth (AE) 嵌入表示（保留的主成分和完整的 64 个嵌入波段），并将其与传统的滑坡影响因素 (LCFs) 进行了系统比较。研究在台湾南投县、香港和意大利艾米利亚-罗马涅地区的部分区域进行了三个研究。使用了三种深度学习模型：CNN1D、CNN2D 和 Vision Transformer。通过多种评估指标（包括 F1 分数、AUC、误差统计和空间模式评估）来评估模型性能。", "result": "AE 嵌入模型在所有研究区域和模型中均优于 LCFs 模型，F1 分数和 AUC 值更高，误差分布更稳定。特别是使用完整的 64 个 AE 嵌入波段时，F1 分数提高了 4% 到 15%，AUC 值提高了 0.04 到 0.11。AE 嵌入模型生成的滑坡易感性地图与实际滑坡分布的空间一致性更强，对局部滑坡易发条件的敏感性更高。性能提升在南投和艾米利亚地区比香港地区更明显。", "conclusion": "AlphaEarth (AE) 嵌入具有作为滑坡易感性测绘 (LSM) 的标准化、信息丰富的替代预测因子的巨大潜力。AE 嵌入能够克服传统滑坡影响因素 (LCFs) 的局限性，从而提高 LSM 的准确性和可靠性。研究还表明，AE 嵌入与滑坡编目之间的时间一致性对于提高 LSM 结果的有效性至关重要。"}}
{"id": "2601.07041", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07041", "abs": "https://arxiv.org/abs/2601.07041", "authors": ["Jiaqi Zhao", "Qiang Huang", "Haodong Chen", "Xiaoxing You", "Jun Yu"], "title": "When Abundance Conceals Weakness: Knowledge Conflict in Multilingual Models", "comment": "14 pages, 7 figures, and 4 tables", "summary": "Large Language Models (LLMs) encode vast world knowledge across multiple languages, yet their internal beliefs are often unevenly distributed across linguistic spaces. When external evidence contradicts these language-dependent memories, models encounter \\emph{cross-lingual knowledge conflict}, a phenomenon largely unexplored beyond English-centric settings. We introduce \\textbf{CLEAR}, a \\textbf{C}ross-\\textbf{L}ingual knowl\\textbf{E}dge conflict ev\\textbf{A}luation f\\textbf{R}amework that systematically examines how multilingual LLMs reconcile conflicting internal beliefs and multilingual external evidence. CLEAR decomposes conflict resolution into four progressive scenarios, from multilingual parametric elicitation to competitive multi-source cross-lingual induction, and systematically evaluates model behavior across two complementary QA benchmarks with distinct task characteristics. We construct multilingual versions of ConflictQA and ConflictingQA covering 10 typologically diverse languages and evaluate six representative LLMs. Our experiments reveal a task-dependent decision dichotomy. In reasoning-intensive tasks, conflict resolution is dominated by language resource abundance, with high-resource languages exerting stronger persuasive power. In contrast, for entity-centric factual conflicts, linguistic affinity, not resource scale, becomes decisive, allowing low-resource but linguistically aligned languages to outperform distant high-resource ones.", "AI": {"tldr": "本文提出了CLEAR框架，用于评估多语言大型语言模型（LLMs）在面对跨语言知识冲突时的表现，即模型内部的语言依赖性知识与外部证据相矛盾的情况。研究发现，在不同类型的问答任务中，LLMs解决冲突的方式不同：对于需要推理的任务，资源丰富的语言影响力更大；而对于基于实体的factual冲突，语言亲和性比资源量更重要。", "motivation": "现有研究对大型语言模型（LLMs）的跨语言知识冲突现象关注不足，尤其是在非英语环境中。本文旨在系统地研究多语言LLMs如何解决内部语言依赖性信念与外部多语言证据之间的冲突。", "method": "研究提出了CLEAR（Cross-Lingual knowledge conflict evAluation fRamework）框架，该框架将冲突解决分解为四种渐进式场景，从多语言参数提取到多源跨语言归纳。研究在10种语言（包括ConflictQA和ConflictingQA的多语言版本）的两个QA基准上评估了六种代表性LLMs。", "result": "实验结果显示，LLMs的冲突解决策略具有任务依赖性。在推理密集型任务中，高资源语言因其丰富的资源而具有更强的说服力。然而，在实体中心的事实冲突中，语言亲和性而非资源规模是决定因素，低资源但语言上更接近的语言表现优于遥远的高资源语言。", "conclusion": "多语言LLMs在处理跨语言知识冲突时，其决策过程受任务类型和语言特征（资源量和语言亲和性）的共同影响。理解这些差异对于提高多语言LLMs在现实世界应用中的可靠性至关重要。"}}
{"id": "2601.07273", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07273", "abs": "https://arxiv.org/abs/2601.07273", "authors": ["Chen Min", "Chengyang Li", "Fanjie Kong", "Qi Zhu", "Dawei Zhao", "Liang Xiao"], "title": "GenDet: Painting Colored Bounding Boxes on Images via Diffusion Model for Object Detection", "comment": null, "summary": "This paper presents GenDet, a novel framework that redefines object detection as an image generation task. In contrast to traditional approaches, GenDet adopts a pioneering approach by leveraging generative modeling: it conditions on the input image and directly generates bounding boxes with semantic annotations in the original image space. GenDet establishes a conditional generation architecture built upon the large-scale pre-trained Stable Diffusion model, formulating the detection task as semantic constraints within the latent space. It enables precise control over bounding box positions and category attributes, while preserving the flexibility of the generative model. This novel methodology effectively bridges the gap between generative models and discriminative tasks, providing a fresh perspective for constructing unified visual understanding systems. Systematic experiments demonstrate that GenDet achieves competitive accuracy compared to discriminative detectors, while retaining the flexibility characteristic of generative methods.", "AI": {"tldr": "本文提出了一种名为GenDet的新框架，将物体检测视为图像生成任务，利用Stable Diffusion模型生成带有语义标注的边界框。", "motivation": "传统的物体检测方法主要采用判别式模型，而生成式模型在图像生成方面表现出色。研究者希望探索生成式模型在判别式任务（如物体检测）上的应用潜力，实现生成式和判别式任务的统一。", "method": "GenDet将物体检测任务转化为条件生成任务，以输入图像为条件，在原始图像空间直接生成带有语义标注的边界框。该框架基于大规模预训练的Stable Diffusion模型，并在其潜在空间中构建了边界框的语义约束。", "result": "实验证明，GenDet在保持生成式方法的灵活性的同时，取得了与判别式检测器相当的准确率。", "conclusion": "GenDet成功地将生成式模型应用于物体检测任务，提供了一种新颖的视角来构建统一的视觉理解系统，证明了生成式模型在判别式任务中的潜力。"}}
{"id": "2601.07054", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07054", "abs": "https://arxiv.org/abs/2601.07054", "authors": ["Zhuoyi Yang", "Yurun Song", "Iftekhar Ahmed", "Ian Harris"], "title": "Fine-Tuning vs. RAG for Multi-Hop Question Answering with Novel Knowledge", "comment": null, "summary": "Multi-hop question answering is widely used to evaluate the reasoning capabilities of large language models (LLMs), as it requires integrating multiple pieces of supporting knowledge to arrive at a correct answer. While prior work has explored different mechanisms for providing knowledge to LLMs, such as finetuning and retrieval-augmented generation (RAG), their relative effectiveness for multi-hop question answering remains insufficiently understood, particularly when the required knowledge is temporally novel.\n  In this paper, we systematically compare parametric and non-parametric knowledge injection methods for open-domain multi-hop question answering. We evaluate unsupervised fine-tuning (continual pretraining), supervised fine-tuning, and retrieval-augmented generation across three 7B-parameter open-source LLMs. Experiments are conducted on two benchmarks: QASC, a standard multi-hop science question answering dataset, and a newly constructed dataset of over 10,000 multi-hop questions derived from Wikipedia events in 2024, designed to test knowledge beyond the models' pretraining cutoff.\n  Our results show that unsupervised fine-tuning provides only limited gains over base models, suggesting that continual pretraining alone is insufficient for improving multi-hop reasoning accuracy. In contrast, retrieval-augmented generation yields substantial and consistent improvements, particularly when answering questions that rely on temporally novel information. Supervised fine-tuning achieves the highest overall accuracy across models and datasets. These findings highlight fundamental differences in how knowledge injection mechanisms support multi-hop question answering and underscore the importance of retrieval-based methods when external or compositional knowledge is required.", "AI": {"tldr": "本研究系统地比较了参数化和非参数化知识注入方法在开放域多跳问答中的有效性，发现在处理时间上新颖的信息时，检索增强生成（RAG）表现出色，而监督微调在整体准确性上最佳。", "motivation": "了解不同知识注入机制（如微调和RAG）在多跳问答中的相对有效性，特别是在知识是时间上新颖的情况下，以改进大型语言模型（LLMs）的推理能力。", "method": "在三个7B参数的开源LLMs上，对无监督微调（持续预训练）、监督微调和检索增强生成（RAG）进行了评估。实验使用了QASC科学问答数据集以及一个新构建的包含2024年维基百科事件的多跳问答数据集。", "result": "无监督微调的增益有限。RAG在多跳问答（尤其是在回答时间上新颖信息的问题时）上带来了显著且一致的改进。监督微调在所有模型和数据集上实现了最高的整体准确性。", "conclusion": "研究强调了不同知识注入机制在支持多跳问答方面的根本差异，并强调了在需要外部或组合知识时，基于检索的方法的重要性。"}}
{"id": "2601.07287", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07287", "abs": "https://arxiv.org/abs/2601.07287", "authors": ["Yuanyang Yin", "Yufan Deng", "Shenghai Yuan", "Kaipeng Zhang", "Xiao Yang", "Feng Zhao"], "title": "Focal Guidance: Unlocking Controllability from Semantic-Weak Layers in Video Diffusion Models", "comment": null, "summary": "The task of Image-to-Video (I2V) generation aims to synthesize a video from a reference image and a text prompt. This requires diffusion models to reconcile high-frequency visual constraints and low-frequency textual guidance during the denoising process. However, while existing I2V models prioritize visual consistency, how to effectively couple this dual guidance to ensure strong adherence to the text prompt remains underexplored. In this work, we observe that in Diffusion Transformer (DiT)-based I2V models, certain intermediate layers exhibit weak semantic responses (termed Semantic-Weak Layers), as indicated by a measurable drop in text-visual similarity. We attribute this to a phenomenon called Condition Isolation, where attention to visual features becomes partially detached from text guidance and overly relies on learned visual priors. To address this, we propose Focal Guidance (FG), which enhances the controllability from Semantic-Weak Layers. FG comprises two mechanisms: (1) Fine-grained Semantic Guidance (FSG) leverages CLIP to identify key regions in the reference frame and uses them as anchors to guide Semantic-Weak Layers. (2) Attention Cache transfers attention maps from semantically responsive layers to Semantic-Weak Layers, injecting explicit semantic signals and alleviating their over-reliance on the model's learned visual priors, thereby enhancing adherence to textual instructions. To further validate our approach and address the lack of evaluation in this direction, we introduce a benchmark for assessing instruction following in I2V models. On this benchmark, Focal Guidance proves its effectiveness and generalizability, raising the total score on Wan2.1-I2V to 0.7250 (+3.97\\%) and boosting the MMDiT-based HunyuanVideo-I2V to 0.5571 (+7.44\\%).", "AI": {"tldr": "本研究提出了Focal Guidance（FG）方法，通过增强图像到视频（I2V）生成模型中语义响应较弱的中间层，以提高视频生成对文本提示的遵循度。FG包含细粒度语义引导（FSG）和注意力缓存机制，旨在解决条件隔离问题。", "motivation": "现有I2V模型在确保视觉一致性的同时，未能有效结合文本提示，导致对文本指令的遵循度不足。研究者发现DiT-based I2V模型中存在语义响应较弱的中间层（Semantic-Weak Layers），原因是条件隔离，即视觉特征的注意力与文本引导分离，过度依赖视觉先验。", "method": "提出Focal Guidance（FG）方法，包含两个机制：1. 细粒度语义引导（FSG）：利用CLIP识别参考帧中的关键区域作为锚点，引导语义弱层。2. 注意力缓存：将语义响应层的注意力图转移到语义弱层，注入显式语义信号，减轻对模型视觉先验的依赖。", "result": "在自定义的I2V指令遵循评估基准上，Focal Guidance证明了其有效性和泛化能力。将Wan2.1-I2V的总分提高到0.7250（+3.97%），并将基于MMDiT的HunyuanVideo-I2V提高到0.5571（+7.44%）。", "conclusion": "Focal Guidance方法能够有效增强I2V模型中语义弱层的文本可控性，从而提高视频生成对文本指令的遵循度。该方法在两个I2V模型上均取得了显著的性能提升。"}}
{"id": "2601.07290", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07290", "abs": "https://arxiv.org/abs/2601.07290", "authors": ["Jiapeng Shi", "Junke Wang", "Zuyao You", "Bo He", "Zuxuan Wu"], "title": "VideoLoom: A Video Large Language Model for Joint Spatial-Temporal Understanding", "comment": null, "summary": "This paper presents VideoLoom, a unified Video Large Language Model (Video LLM) for joint spatial-temporal understanding. To facilitate the development of fine-grained spatial and temporal localization capabilities, we curate LoomData-8.7k, a human-centric video dataset with temporally grounded and spatially localized captions. With this, VideoLoom achieves state-of-the-art or highly competitive performance across a variety of spatial and temporal benchmarks (e.g., 63.1 J&F on ReVOS for referring video object segmentation, and 48.3 R1@0.7 on Charades-STA for temporal grounding). In addition, we introduce LoomBench, a novel benchmark consisting of temporal, spatial, and compositional video-question pairs, enabling a comprehensive evaluation of Video LLMs from diverse aspects. Collectively, these contributions offer a universal and effective suite for joint spatial-temporal video understanding, setting a new standard in multimodal intelligence.", "AI": {"tldr": "本文提出了VideoLoom，一个用于联合时空理解的统一视频大语言模型（Video LLM），并发布了LoomData-8.7k数据集和LoomBench基准，以促进细粒度的空间和时间定位能力。VideoLoom在多个时空基准测试中取得了最先进或具有竞争力的性能。", "motivation": "研究动机是为了促进细粒度的视频空间和时间定位能力的开发，并为视频大语言模型（Video LLM）提供一个统一的框架。", "method": "提出了VideoLoom，一个统一的视频大语言模型，用于联合时空理解。创建了LoomData-8.7k数据集，其中包含时间定位和空间定位的视频字幕。设计了LoomBench基准，包含时间、空间和组合视频问题对，以全面评估Video LLMs。", "result": "VideoLoom在Referring Video Object Segmentation (ReVOS)上取得了63.1 J&F的性能，在Charades-STA上的Temporal Grounding任务上取得了48.3 R1@0.7的性能，在各项空间和时间基准测试中均达到最先进或具有竞争力的水平。", "conclusion": "VideoLoom、LoomData-8.7k和LoomBench共同提供了一个通用且有效的联合时空视频理解套件，为多模态智能树立了新的标准。"}}
{"id": "2601.07033", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07033", "abs": "https://arxiv.org/abs/2601.07033", "authors": ["Longfei Yun", "Kun Zhou", "Yupeng Hou", "Letian Peng", "Jingbo Shang"], "title": "Codified Foreshadowing-Payoff Text Generation", "comment": null, "summary": "Foreshadowing and payoff are ubiquitous narrative devices through which authors introduce commitments early in a story and resolve them through concrete, observable outcomes. However, despite advances in story generation, large language models (LLMs) frequently fail to bridge these long-range narrative dependencies, often leaving \"Chekhov's guns\" unfired even when the necessary context is present. Existing evaluations largely overlook this structural failure, focusing on surface-level coherence rather than the logical fulfillment of narrative setups. In this paper, we introduce Codified Foreshadowing-Payoff Generation (CFPG), a novel framework that reframes narrative quality through the lens of payoff realization. Recognizing that LLMs struggle to intuitively grasp the \"triggering mechanism\" of a foreshadowed event, CFPG transforms narrative continuity into a set of executable causal predicates. By mining and encoding Foreshadow-Trigger-Payoff triples from the BookSum corpus, we provide structured supervision that ensures foreshadowed commitments are not only mentioned but also temporally and logically fulfilled. Experiments demonstrate that CFPG significantly outperforms standard prompting baselines in payoff accuracy and narrative alignment. Our findings suggest that explicitly codifying narrative mechanics is essential for moving LLMs from surface-level fluency to genuine narrative competence.", "AI": {"tldr": "本文提出了一种名为CFPG（Codified Foreshadowing-Payoff Generation）的新框架，通过将叙事结构转化为可执行的因果谓词，来解决大型语言模型在处理叙事中的铺垫与回报（如“契诃夫之枪”）时常出现的长期依赖性问题，实验证明此方法能显著提升铺垫的准确性和叙事的一致性。", "motivation": "大型语言模型在生成故事时，常常无法处理叙事中的长期依赖性，导致引入的铺垫（如“契诃夫之枪”）在故事结尾未能得到兑现。现有的评估方法也忽视了这种结构性失败，侧重于表面连贯性而非叙事设定的逻辑实现。", "method": "作者提出了Codified Foreshadowing-Payoff Generation (CFPG)框架，该框架将叙事质量视为回报的实现。它通过从BookSum语料库中挖掘和编码“铺垫-触发-回报”三元组，将叙事连续性转化为一套可执行的因果谓词，为模型提供结构化监督，确保铺垫得到及时且合乎逻辑的实现。", "result": "实验表明，CFPG框架在回报准确性和叙事一致性方面显著优于标准的提示基线。", "conclusion": "显式地编码叙事机制对于提升大型语言模型从表面流畅性向真正叙事能力迈进至关重要。"}}
{"id": "2601.07110", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.07110", "abs": "https://arxiv.org/abs/2601.07110", "authors": ["Pranav Narayanan Venkit", "Yu Li", "Yada Pruksachatkun", "Chien-Sheng Wu"], "title": "The Need for a Socially-Grounded Persona Framework for User Simulation", "comment": null, "summary": "Synthetic personas are widely used to condition large language models (LLMs) for social simulation, yet most personas are still constructed from coarse sociodemographic attributes or summaries. We revisit persona creation by introducing SCOPE, a socially grounded framework for persona construction and evaluation, built from a 141-item, two-hour sociopsychological protocol collected from 124 U.S.-based participants. Across seven models, we find that demographic-only personas are a structural bottleneck: demographics explain only ~1.5% of variance in human response similarity. Adding sociopsychological facets improves behavioral prediction and reduces over-accentuation, and non-demographic personas based on values and identity achieve strong alignment with substantially lower bias. These trends generalize to SimBench (441 aligned questions), where SCOPE personas outperform default prompting and NVIDIA Nemotron personas, and SCOPE augmentation improves Nemotron-based personas. Our results indicate that persona quality depends on sociopsychological structure rather than demographic templates or summaries.", "AI": {"tldr": "本研究提出了SCOPE框架，一种基于社会心理学特征来构建和评估LLM合成角色的方法，发现与仅基于人口统计学信息的角色相比，基于价值观和身份的SCOPE角色能更好地预测人类行为，减少偏见，并提升LLM在社会模拟任务中的表现。", "motivation": "现有的LLM合成角色构建方法主要依赖粗略的人口统计学属性或摘要，这限制了其在社会模拟中的行为预测能力和真实性。研究者希望探索一种更精细、更具社会学基础的Persona构建方式。", "method": "研究者开发了SCOPE框架，该框架基于一项包含141个项目、耗时两小时的社会心理学问卷，收集了124名美国参与者的数据。他们利用这些数据构建Persona，并在七个不同的LLM上评估了其行为预测能力和偏差。研究还使用SimBench（包含441个对齐问题）来验证SCOPE Persona的表现，并将其与默认提示和NVIDIA Nemotron Persona进行比较。", "result": "人口统计学信息仅能解释约1.5%的人类响应相似性方差，表明其作为Persona构建基础的局限性。加入社会心理学特征（如价值观和身份）显著提高了Persona的行为预测能力，并减少了LLM的过度强调。基于非人口统计学特征（价值观和身份）的SCOPE Persona表现出与人类行为的高度一致性，且偏见更低。在SimBench基准测试中，SCOPE Persona优于默认提示和Nemotron Persona，并且SCOPE方法还能增强Nemotron Persona的性能。", "conclusion": "Persona的质量与其社会心理学结构密切相关，而非仅仅依赖于人口统计学模板或摘要。基于社会心理学特征构建的Persona能更有效地用于LLM的社会模拟，提高其行为预测的准确性和减少不必要的偏差。"}}
{"id": "2601.07121", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07121", "abs": "https://arxiv.org/abs/2601.07121", "authors": ["Makoto Sato"], "title": "ReMIND: Orchestrating Modular Large Language Models for Controllable Serendipity A REM-Inspired System Design for Emergent Creative Ideation", "comment": null, "summary": "Large language models (LLMs) are used not only for problem solving but also for creative ideation; however, eliciting serendipitous insights that are both novel and internally coherent remains difficult. While stochastic sampling promotes novelty, it often degrades consistency. Here, we propose ReMIND, a REM-inspired modular framework for ideation. ReMIND consists of four stages: wake, which generates a stable low-temperature semantic baseline; dream, which performs high-temperature exploratory generation; judge, which applies coarse evaluation to filter incoherent outputs and extract candidate ideas; and re-wake, which re-articulates selected ideas into coherent final outputs. By instantiating each stage as an independent LLM, ReMIND enables functional separation between exploration and consolidation. Parameter sweeps show that ReMIND reliably induces semantic exploration while preserving downstream stability. Embedding-based analyses confirm substantial semantic displacement during the dream phase, whereas external evaluations reveal that high-quality ideas emerge sporadically rather than as extrema along any single metric. These results suggest that serendipitous ideation in LLMs is a rare-event process best approached through system level design that shapes the conditions under which valuable ideas can emerge and be stabilized. ReMIND provides a general framework for studying the computational basis of serendipity and illustrates how modular LLM orchestration can bridge exploration and stabilization.", "AI": {"tldr": "本文提出了一种名为 ReMIND 的模块化框架，通过模拟 REM 睡眠过程，在 LLM 的创意生成过程中平衡新颖性和一致性，从而激发新颖且连贯的见解。", "motivation": "在 LLM 的创意想法生成中，如何同时获得新颖性和内部一致性是一个挑战。单纯的随机采样可能导致新颖性，但会牺牲一致性。", "method": "ReMIND 框架包含四个阶段：wake（生成稳定基线）、dream（探索性生成）、judge（筛选不连贯输出并提取候选想法）和 re-wake（重塑选定的想法）。每个阶段都由独立的 LLM 实现，从而实现了探索和巩固的功能分离。", "result": "ReMIND 能够有效地激发语义探索，同时保持下游的稳定性。实验表明，在 dream 阶段发生了显著的语义位移，并且高质量的想法是零星出现的，而不是沿着单一指标的极端值。", "conclusion": "LLM 中的偶发性想法生成是一个罕见事件过程，需要通过系统级设计来创造和稳定有价值想法出现的条件。ReMIND 提供了一个研究 LLM 偶发性计算基础的通用框架，并展示了模块化 LLM 编排如何实现探索和稳定的平衡。"}}
{"id": "2601.07046", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07046", "abs": "https://arxiv.org/abs/2601.07046", "authors": ["Tim Fingscheidt", "Patrick Blumenberg", "Björn Möller"], "title": "Engineering of Hallucination in Generative AI: It's not a Bug, it's a Feature", "comment": "This is an article that has been written reflecting a talk of Tim Fingscheidt at the 2025 New Year gathering of Braunschweigische Wissenschaftliche Gesellschaft on January 25th, 2025", "summary": "Generative artificial intelligence (AI) is conquering our lives at lightning speed. Large language models such as ChatGPT answer our questions or write texts for us, large computer vision models such as GAIA-1 generate videos on the basis of text descriptions or continue prompted videos. These neural network models are trained using large amounts of text or video data, strictly according to the real data employed in training. However, there is a surprising observation: When we use these models, they only function satisfactorily when they are allowed a certain degree of fantasy (hallucination). While hallucination usually has a negative connotation in generative AI - after all, ChatGPT is expected to give a fact-based answer! - this article recapitulates some simple means of probability engineering that can be used to encourage generative AI to hallucinate to a limited extent and thus lead to the desired results. We have to ask ourselves: Is hallucination in gen-erative AI probably not a bug, but rather a feature?", "AI": {"tldr": "本文探讨了生成式AI中的“幻觉”现象，提出幻觉可能并非缺陷，而是有意为之的特征，并通过概率工程的方法引导AI适度产生幻觉以获得更好的结果。", "motivation": "研究人员观察到，尽管生成式AI模型（如ChatGPT、GAIA-1）在训练时严格遵循真实数据，但它们只有在被允许一定程度的“幻觉”（即产生与训练数据不完全一致的内容）时才能获得令人满意的结果。这引发了对“幻觉”在生成式AI中是“bug”还是“feature”的思考。", "method": "文章回顾了一些简单的概率工程技术，这些技术可以用来鼓励生成式AI适度地产生幻觉，从而达到预期效果。", "result": "通过概率工程的干预，可以引导生成式AI产生有限度的幻觉，并使其输出更符合预期。", "conclusion": "作者推测，生成式AI中的幻觉现象可能并非一个错误，而是一种有益的特征，可以通过技术手段加以利用。"}}
{"id": "2601.07291", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07291", "abs": "https://arxiv.org/abs/2601.07291", "authors": ["Qi Zheng", "Shuliang Liu", "Yu Huang", "Sihang Jia", "Jungang Li", "Lyuhao Chen", "Junhao Chen", "Hanqian Li", "Aiwei Liu", "Yibo Yan", "Xuming Hu"], "title": "A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model", "comment": null, "summary": "Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases, while some semantic-aware methods incur prohibitive inference latency due to rejection sampling. In this paper, we propose the VIsual Semantic Adaptive Watermark (VISA-Mark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. Our approach employs a lightweight, efficiently trained prefix-tuner to extract dynamic Visual-Evidence Weights, which quantify the evidentiary support for candidate tokens based on the visual input. These weights guide an adaptive vocabulary partitioning and logits perturbation mechanism, concentrating watermark strength specifically on visually-supported tokens. By actively aligning the watermark with visual evidence, VISA-Mark effectively maintains visual fidelity. Empirical results confirm that VISA-Mark outperforms conventional methods with a 7.8% improvement in visual consistency (Chair-I) and superior semantic fidelity. The framework maintains highly competitive detection accuracy (96.88% AUC) and robust attack resilience (99.3%) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multimodal watermarking.", "AI": {"tldr": "本文提出了一种名为VISA-Mark的新型视觉语义自适应水印框架，通过动态视觉证据权重来指导词汇分区和logits扰动，从而在保护视觉保真度的同时嵌入可检测的水印信号，提高了视觉一致性和语义保真度，且不牺牲推理效率。", "motivation": "现有的LVLM水印方法存在视觉无关水印引入无关令牌和扰乱视觉基础的问题，或者语义感知方法因拒绝采样而导致过高的推理延迟。因此，需要一种既能嵌入可检测信号又能严格保持视觉保真度的新型水印方法。", "method": "提出VISA-Mark框架，使用轻量级、高效训练的前缀调谐器提取动态视觉证据权重（Visual-Evidence Weights），该权重量化了视觉输入对候选令牌的支持程度。然后，这些权重指导自适应词汇分区和logits扰动机制，将水印强度集中在视觉支持的令牌上，从而实现水印与视觉证据的对齐。", "result": "VISA-Mark在视觉一致性（Chair-I）方面比传统方法提高了7.8%，并展现出优越的语义保真度。同时，在不牺牲推理效率的情况下，保持了96.88%的AUC检测准确率和99.3%的鲁棒性。", "conclusion": "VISA-Mark是一种有效且高效的多模态水印框架，它通过将水印与视觉证据动态对齐，成功地解决了现有方法的不足，实现了高视觉保真度、高语义保真度、高检测准确率和鲁棒性，为可靠性保护的多模态水印树立了新标准。"}}
{"id": "2601.07148", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07148", "abs": "https://arxiv.org/abs/2601.07148", "authors": ["Zhengxiang Wang", "Zeyu Dong"], "title": "Measuring Iterative Temporal Reasoning with TimePuzzles", "comment": null, "summary": "We introduce TimePuzzles, a constraint-based date inference task for evaluating iterative temporal reasoning. Each puzzle combines factual temporal anchors with (cross-cultural) calendar relations, admits one or multiple valid solution dates, and is algorithmically generated for controlled, dynamic, and continual evaluation. Across 13 diverse LLMs, TimePuzzles well distinguishes their iterative temporal reasoning capabilities and remains challenging without tools: GPT-5 reaches only 49.3% accuracy and all other models stay below 31%, despite the dataset's simplicity. Web search consistently yields substantial gains and using code interpreter shows mixed effects, but all models perform much better when constraints are rewritten with explicit dates, revealing a gap in reliable tool use. Overall, TimePuzzles presents a simple, cost-effective diagnostic for tool-augmented iterative temporal reasoning.", "AI": {"tldr": "本文提出了一种名为 TimePuzzles 的基于约束的日期推理任务，用于评估迭代时间推理能力。该任务结合了事实时间锚点和日历关系，可以通过算法生成，具有一个或多个有效解决方案。实验表明，TimePuzzles 能够有效地区分不同大型语言模型 (LLM) 的时间推理能力，即使是 GPT-5 的准确率也只有 49.3%。使用网络搜索可以显著提高模型性能，而代码解释器的效果则不一。将约束条件改写为明确日期后，模型表现大幅提升，这揭示了模型在可靠使用工具方面存在差距。总的来说，TimePuzzles 是一个简单、成本效益高的工具增强型迭代时间推理诊断工具。", "motivation": "评估和提升大型语言模型（LLM）在迭代时间推理方面的能力，尤其是在使用工具（如网络搜索和代码解释器）增强的情况下。", "method": "提出 TimePuzzles 数据集，该数据集包含基于事实时间锚点和日历关系的约束条件，可以通过算法生成，并允许一个或多个有效解决方案。在 13 个不同的 LLM 上进行评估，测试了它们在原始约束条件、使用网络搜索、使用代码解释器以及将约束条件改写为明确日期后的性能。", "result": "TimePuzzles 能够有效地区分不同 LLM 的迭代时间推理能力。在原始数据上，GPT-5 的准确率最高为 49.3%，其他模型低于 31%。使用网络搜索可以显著提高所有模型的性能。代码解释器的效果则不一。当约束条件被改写为明确日期时，所有模型的性能都有显著提升。", "conclusion": "TimePuzzles 是一个有效且具有成本效益的诊断工具，可以评估工具增强型迭代时间推理。现有 LLM 在处理复杂或隐式时间约束方面仍有很大提升空间，尤其是在可靠地利用工具方面。将时间约束明确化是提高模型性能的关键。"}}
{"id": "2601.07293", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07293", "abs": "https://arxiv.org/abs/2601.07293", "authors": ["Weidong Tang", "Xinyan Wan", "Siyu Li", "Xiumei Wang"], "title": "Inference-Time Scaling for Visual AutoRegressive modeling by Searching Representative Samples", "comment": "Accepted to PRCV 2025", "summary": "While inference-time scaling has significantly enhanced generative quality in large language and diffusion models, its application to vector-quantized (VQ) visual autoregressive modeling (VAR) remains unexplored. We introduce VAR-Scaling, the first general framework for inference-time scaling in VAR, addressing the critical challenge of discrete latent spaces that prohibit continuous path search. We find that VAR scales exhibit two distinct pattern types: general patterns and specific patterns, where later-stage specific patterns conditionally optimize early-stage general patterns. To overcome the discrete latent space barrier in VQ models, we map sampling spaces to quasi-continuous feature spaces via kernel density estimation (KDE), where high-density samples approximate stable, high-quality solutions. This transformation enables effective navigation of sampling distributions. We propose a density-adaptive hybrid sampling strategy: Top-k sampling focuses on high-density regions to preserve quality near distribution modes, while Random-k sampling explores low-density areas to maintain diversity and prevent premature convergence. Consequently, VAR-Scaling optimizes sample fidelity at critical scales to enhance output quality. Experiments in class-conditional and text-to-image evaluations demonstrate significant improvements in inference process. The code is available at https://github.com/WD7ang/VAR-Scaling.", "AI": {"tldr": "本文提出了VAR-Scaling，一个用于向量量化视觉自回归模型（VAR）的推理时缩放框架，解决了离散潜在空间带来的挑战，通过核密度估计和混合采样策略提升了生成质量。", "motivation": "尽管推理时缩放已在大型语言和扩散模型中取得成功，但其在向量量化视觉自回归模型（VAR）中的应用仍是未探索的领域，而VAR对生成质量至关重要。", "method": "提出VAR-Scaling框架，通过核密度估计（KDE）将离散采样空间映射到准连续特征空间，并采用密度自适应混合采样策略（Top-k采样和Random-k采样）来优化采样分布，从而克服离散潜在空间障碍。", "result": "VAR-Scaling框架在类别条件和文本到图像生成任务中实现了显著的质量提升，证明了其有效性。", "conclusion": "VAR-Scaling是第一个通用性的VAR推理时缩放框架，通过处理离散潜在空间和优化采样策略，成功提升了VAR模型的生成质量。"}}
{"id": "2601.07153", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07153", "abs": "https://arxiv.org/abs/2601.07153", "authors": ["Genta Indra Winata", "David Anugraha", "Patrick Amadeus Irawan", "Anirban Das", "Haneul Yoo", "Paresh Dashore", "Shreyas Kulkarni", "Ruochen Zhang", "Haruki Sakajo", "Frederikus Hudi", "Anaelia Ovalle", "Syrielle Montariol", "Felix Gaschi", "Michael Anugraha", "Rutuj Ravindra Puranik", "Zawad Hayat Ahmed", "Adril Putra Merin", "Emmanuele Chersoni"], "title": "Can Large Language Models Understand, Reason About, and Generate Code-Switched Text?", "comment": "Preprint", "summary": "Code-switching is a pervasive phenomenon in multilingual communication, yet the robustness of large language models (LLMs) in mixed-language settings remains insufficiently understood. In this work, we present a comprehensive evaluation of LLM capabilities in understanding, reasoning over, and generating code-switched text. We introduce CodeMixQA a novel benchmark with high-quality human annotations, comprising 16 diverse parallel code-switched language-pair variants that span multiple geographic regions and code-switching patterns, and include both original scripts and their transliterated forms. Using this benchmark, we analyze the reasoning behavior of LLMs on code-switched question-answering tasks, shedding light on how models process and reason over mixed-language inputs. We further conduct a systematic evaluation of LLM-generated synthetic code-switched text, focusing on both naturalness and semantic fidelity, and uncover key limitations in current generation capabilities. Our findings reveal persistent challenges in both reasoning and generation under code-switching conditions and provide actionable insights for building more robust multilingual LLMs. We release the dataset and code as open source.", "AI": {"tldr": "该研究评估了大型语言模型（LLMs）在处理和生成混合语言文本方面的能力，并提出了一个名为CodeMixQA的新基准数据集，以揭示LLMs在混合语言环境下的局限性，并为构建更鲁棒的多语言LLMs提供指导。", "motivation": "现有研究对大型语言模型在混合语言环境下的鲁棒性理解不足，需要进行全面评估。", "method": "1. 提出CodeMixQA基准数据集，包含16种语言对的并行混合语言数据，涵盖不同地区和混合模式，并提供原文和音译形式。 2. 使用该基准分析LLMs在混合语言问答任务中的推理行为。 3. 系统评估LLMs生成的合成混合语言文本的自然度和语义保真度。", "result": "LLMs在理解、推理和生成混合语言文本方面仍存在挑战。在推理方面，模型处理混合语言输入的能力受限；在生成方面，模型生成的混合语言文本在自然度和语义保真度上存在不足。", "conclusion": "混合语言条件下的推理和生成能力仍然是LLMs面临的挑战。本研究为构建更鲁棒的多语言LLMs提供了有价值的见解，并公开了数据集和代码。"}}
{"id": "2601.07298", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07298", "abs": "https://arxiv.org/abs/2601.07298", "authors": ["Jianghao Yin", "Qingbin Li", "Kun Sun", "Cheng Ding", "Jie Wang", "Qin Chen", "Jie Zhou", "Nan Wang", "Changqing Li", "Pei Wu", "Jian Xu", "Zheming Yang", "Liang He"], "title": "Mimic Human Cognition, Master Multi-Image Reasoning: A Meta-Action Framework for Enhanced Visual Understanding", "comment": null, "summary": "While Multimodal Large Language Models (MLLMs) excel at single-image understanding, they exhibit significantly degraded performance in multi-image reasoning scenarios. Multi-image reasoning presents fundamental challenges including complex inter-relationships between images and scattered critical information across image sets. Inspired by human cognitive processes, we propose the Cognition-Inspired Meta-Action Framework (CINEMA), a novel approach that decomposes multi-image reasoning into five structured meta-actions: Global, Focus, Hint, Think, and Answer which explicitly modeling the sequential cognitive steps humans naturally employ. For cold-start training, we introduce a Retrieval-Based Tree Sampling strategy that generates high-quality meta-action trajectories to bootstrap the model with reasoning patterns. During reinforcement learning, we adopt a two-stage paradigm: an exploration phase with Diversity-Preserving Strategy to avoid entropy collapse, followed by an annealed exploitation phase with DAPO to gradually strengthen exploitation. To train our model, we construct a dataset of 57k cold-start and 58k reinforcement learning instances spanning multi-image, multi-frame, and single-image tasks. We conduct extensive evaluations on multi-image reasoning benchmarks, video understanding benchmarks, and single-image benchmarks, achieving competitive state-of-the-art performance on several key benchmarks. Our model surpasses GPT-4o on the MUIR and MVMath benchmarks and notably outperforms specialized video reasoning models on video understanding benchmarks, demonstrating the effectiveness and generalizability of our human cognition-inspired reasoning framework.", "AI": {"tldr": "本文提出了一个受认知启发的元动作框架CINEMA，将多图像推理分解为五个认知步骤，并通过检索树采样和两阶段强化学习策略进行训练，在多图像、视频和单图像推理任务上取得了先进的性能。", "motivation": "现有的多模态大语言模型在多图像推理方面表现不佳，原因是图像间的复杂关系和信息分散。人类的认知过程在处理多图像信息时表现出结构化和序列化的特点，这启发了本研究。", "method": "提出CINEMA框架，包含全局（Global）、聚焦（Focus）、提示（Hint）、思考（Think）和回答（Answer）五个元动作。使用检索树采样进行冷启动训练，生成高质量的元动作轨迹。强化学习采用两阶段范式：探索阶段使用多样性保持策略，利用阶段使用DAPO策略。", "result": "在多图像推理、视频理解和单图像理解等基准测试中取得了具有竞争力的最先进性能。CINEMA在MUIR和MVMath基准上超越了GPT-4o，并在视频理解基准上显著优于专门的视频推理模型。", "conclusion": "受人类认知启发的CINEMA框架有效地解决了多图像推理的挑战，并展现了其在多模态推理任务上的有效性和泛化能力。"}}
{"id": "2601.07180", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07180", "abs": "https://arxiv.org/abs/2601.07180", "authors": ["Jinyi Han", "Zixiang Di", "Zishang Jiang", "Ying Liao", "Jiaqing Liang", "Yongqi Wang", "Yanghua Xiao"], "title": "Structured Reasoning for Large Language Models", "comment": null, "summary": "Large language models (LLMs) achieve strong performance by generating long chains of thought, but longer traces always introduce redundant or ineffective reasoning steps. One typical behavior is that they often perform unnecessary verification and revisions even if they have reached the correct answers. This limitation stems from the unstructured nature of reasoning trajectories and the lack of targeted supervision for critical reasoning abilities. To address this, we propose Structured Reasoning (SCR), a framework that decouples reasoning trajectories into explicit, evaluable, and trainable components. We mainly implement SCR using a Generate-Verify-Revise paradigm. Specifically, we construct structured training data and apply Dynamic Termination Supervision to guide the model in deciding when to terminate reasoning. To avoid interference between learning signals for different reasoning abilities, we adopt a progressive two-stage reinforcement learning strategy: the first stage targets initial generation and self-verification, and the second stage focuses on revision. Extensive experiments on three backbone models show that SCR substantially improves reasoning efficiency and self-verification. Besides, compared with existing reasoning paradigms, it reduces output token length by up to 50%.", "AI": {"tldr": "提出一种名为结构化推理（SCR）的框架，通过将推理过程分解为可评估、可训练的组件，并结合生成-验证-修订（GVR）范式以及动态终止监督，来提高大型语言模型的推理效率和自我验证能力，并减少输出长度。", "motivation": "大型语言模型（LLMs）在生成长链思考时表现出色，但其推理过程常包含冗余或无效步骤，即使已得出正确答案也可能进行不必要的验证和修订。这种局限性源于推理轨迹的非结构化以及对关键推理能力的缺乏针对性监督。", "method": "提出结构化推理（SCR）框架，将推理轨迹分解为显式、可评估和可训练的组件。主要通过生成-验证-修订（GVR）范式实现，构建结构化训练数据，并应用动态终止监督来指导模型何时终止推理。采用渐进式两阶段强化学习策略：第一阶段关注初始生成和自我验证，第二阶段关注修订。", "result": "在三个骨干模型上的广泛实验表明，SCR显著提高了推理效率和自我验证能力。与现有推理范式相比，SCR将输出令牌长度减少了高达50%。", "conclusion": "SCR框架能够有效地解决大型语言模型推理过程中的冗余和低效问题，通过结构化推理和针对性的监督，显著提升了模型的推理效率、自我验证能力，并有效控制了输出长度。"}}
{"id": "2601.07212", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07212", "abs": "https://arxiv.org/abs/2601.07212", "authors": ["Hao Zhang", "Zhibin Zhang", "Guangxin Wu", "He Chen", "Jiafeng Guo", "Xueqi Cheng"], "title": "MI-PRUN: Optimize Large Language Model Pruning via Mutual Information", "comment": "10 pages", "summary": "Large Language Models (LLMs) have become indispensable across various domains, but this comes at the cost of substantial computational and memory resources. Model pruning addresses this by removing redundant components from models. In particular, block pruning can achieve significant compression and inference acceleration. However, existing block pruning methods are often unstable and struggle to attain globally optimal solutions. In this paper, we propose a mutual information based pruning method MI-PRUN for LLMs. Specifically, we leverages mutual information to identify redundant blocks by evaluating transitions in hidden states. Additionally, we incorporate the Data Processing Inequality (DPI) to reveal the relationship between the importance of entire contiguous blocks and that of individual blocks. Moreover, we develop the Fast-Block-Select algorithm, which iteratively updates block combinations to achieve a globally optimal solution while significantly improving the efficiency. Extensive experiments across various models and datasets demonstrate the stability and effectiveness of our method.", "AI": {"tldr": "提出一种基于互信息的大语言模型（LLM）块剪枝方法MI-PRUN，通过评估隐藏状态转换来识别冗余块，并结合数据处理不等式（DPI）来确定块的重要性，同时开发了Fast-Block-Select算法以获得全局最优解并提高效率。", "motivation": "现有的大语言模型需要大量的计算和内存资源，而现有的块剪枝方法不稳定且难以达到全局最优。", "method": "利用互信息评估隐藏状态的转换来识别冗余块，结合数据处理不等式（DPI）揭示块与单个块的重要性关系，并开发了Fast-Block-Select算法来迭代更新块组合以获得全局最优解。", "result": "在多个模型和数据集上的广泛实验表明，MI-PRUN方法稳定且有效。", "conclusion": "MI-PRUN是一种稳定且高效的大语言模型块剪枝方法，能够实现显著的模型压缩和推理加速。"}}
{"id": "2601.07335", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07335", "abs": "https://arxiv.org/abs/2601.07335", "authors": ["Mohit Jaiswal", "Naman Jain", "Shivani Pathak", "Mainak Singha", "Nikunja Bihari Kar", "Ankit Jha", "Biplab Banerjee"], "title": "Reconstruction Guided Few-shot Network For Remote Sensing Image Classification", "comment": "Accepted at InGARSS 2025", "summary": "Few-shot remote sensing image classification is challenging due to limited labeled samples and high variability in land-cover types. We propose a reconstruction-guided few-shot network (RGFS-Net) that enhances generalization to unseen classes while preserving consistency for seen categories. Our method incorporates a masked image reconstruction task, where parts of the input are occluded and reconstructed to encourage semantically rich feature learning. This auxiliary task strengthens spatial understanding and improves class discrimination under low-data settings. We evaluated the efficacy of EuroSAT and PatternNet datasets under 1-shot and 5-shot protocols, our approach consistently outperforms existing baselines. The proposed method is simple, effective, and compatible with standard backbones, offering a robust solution for few-shot remote sensing classification. Codes are available at https://github.com/stark0908/RGFS.", "AI": {"tldr": "提出了一种名为 RGFS-Net 的重建引导式少样本网络，通过掩码图像重建任务来增强模型在遥感图像少样本分类任务中的泛化能力和类区分度，并在 EuroSAT 和 PatternNet 数据集上取得了优于现有方法的性能。", "motivation": "少样本遥感图像分类面临标注样本有限和地物类别变化大的挑战，现有方法在泛化和保持已知类别一致性方面存在不足。", "method": "提出 RGFS-Net，引入掩码图像重建任务，通过遮盖输入图像的一部分并进行重建，以促进学习语义丰富的特征，增强空间理解和类区分度。", "result": "在 EuroSAT 和 PatternNet 数据集上，使用 1-shot 和 5-shot 协议进行评估，RGFS-Net 在少样本分类任务上始终优于现有基线方法。", "conclusion": "RGFS-Net 是一种简单、有效且可与标准骨干网络兼容的方法，能够有效解决少样本遥感图像分类问题，提高了模型的泛化能力和类区分度。"}}
{"id": "2601.07220", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07220", "abs": "https://arxiv.org/abs/2601.07220", "authors": ["Chen Shani", "Yuval Reif", "Nathan Roll", "Dan Jurafsky", "Ekaterina Shutova"], "title": "The Roots of Performance Disparity in Multilingual Language Models: Intrinsic Modeling Difficulty or Design Choices?", "comment": null, "summary": "Multilingual language models (LMs) promise broader NLP access, yet current systems deliver uneven performance across the world's languages. This survey examines why these gaps persist and whether they reflect intrinsic linguistic difficulty or modeling artifacts. We organize the literature around two questions: do linguistic disparities arise from representation and allocation choices (e.g., tokenization, encoding, data exposure, parameter sharing) rather than inherent complexity; and which design choices mitigate inequities across typologically diverse languages. We review linguistic features, such as orthography, morphology, lexical diversity, syntax, information density, and typological distance, linking each to concrete modeling mechanisms. Gaps often shrink when segmentation, encoding, and data exposure are normalized, suggesting much apparent difficulty stems from current modeling choices. We synthesize these insights into design recommendations for tokenization, sampling, architectures, and evaluation to support more balanced multilingual LMs.", "AI": {"tldr": "本调查研究了多语言语言模型在不同语言之间性能不均衡的原因，发现性能差距更多源于模型选择而非语言本身的内在难度，并提出了改进建议。", "motivation": "现有的多语言语言模型在不同语言上的性能表现不一，研究旨在探究其原因，并提供改进方向。", "method": "通过分析文献，围绕两个核心问题展开：语言差异是否源于表示和分配选择（如分词、编码、数据暴露、参数共享），而非固有的语言复杂性？哪些设计选择可以缓解跨语言类型多样性的不公平？研究将语言特征（如拼写、形态、词汇多样性、语法、信息密度、类型距离）与具体的建模机制联系起来。", "result": "研究发现，当分词、编码和数据暴露得到标准化时，语言性能差距通常会缩小，表明许多表面上的困难源于当前的模型选择。", "conclusion": "模型选择（如分词、编码、数据暴露）是导致多语言语言模型性能不均衡的主要原因，而非语言本身的内在难度。研究者提出了关于分词、采样、架构和评估的设计建议，以支持更均衡的多语言语言模型。"}}
{"id": "2601.07344", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07344", "abs": "https://arxiv.org/abs/2601.07344", "authors": ["Jiao Xu", "Junwei Liu", "Jiangwei Lao", "Qi Zhu", "Yunpeng Zhao", "Congyun Jin", "Shinan Liu", "Zhihong Lu", "Lihe Zhang", "Xin Chen", "Jian Wang", "Ping Wang"], "title": "PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis", "comment": "Accepted to AAAI 2026", "summary": "Recent advances in medical multi-modal models focus on specialized image analysis like dermatology, pathology, or radiology. However, they do not fully capture the complexity of real-world clinical diagnostics, which involve heterogeneous inputs and require ongoing contextual understanding during patient-physician interactions. To bridge this gap, we introduce PulseMind, a new family of multi-modal diagnostic models that integrates a systematically curated dataset, a comprehensive evaluation benchmark, and a tailored training framework. Specifically, we first construct a diagnostic dataset, MediScope, which comprises 98,000 real-world multi-turn consultations and 601,500 medical images, spanning over 10 major clinical departments and more than 200 sub-specialties. Then, to better reflect the requirements of real-world clinical diagnosis, we develop the PulseMind Benchmark, a multi-turn diagnostic consultation benchmark with a four-dimensional evaluation protocol comprising proactiveness, accuracy, usefulness, and language quality. Finally, we design a training framework tailored for multi-modal clinical diagnostics, centered around a core component named Comparison-based Reinforcement Policy Optimization (CRPO). Compared to absolute score rewards, CRPO uses relative preference signals from multi-dimensional com-parisons to provide stable and human-aligned training guidance. Extensive experiments demonstrate that PulseMind achieves competitive performance on both the diagnostic consultation benchmark and public medical benchmarks.", "AI": {"tldr": "本文提出了一种名为PulseMind的多模态诊断模型，通过构建大规模真实世界医学咨询数据集MediScope，并设计了一个包含主动性、准确性、有用性和语言质量的多维度评估基准PulseMind Benchmark，以及一种基于相对偏好信号的训练框架CRPO，以提升模型在复杂临床诊断场景下的表现。", "motivation": "现有医学多模态模型主要集中于特定图像分析，未能充分捕捉真实世界临床诊断所需的异构输入和动态上下文理解能力。研究旨在弥合这一差距，以支持更全面的临床诊断。", "method": "1. 构建MediScope数据集：包含98,000次多轮咨询和601,500张医学图像，覆盖10个主要临床部门和200多个亚专科。 2. 设计PulseMind Benchmark：一个多轮诊断咨询基准，采用包含主动性、准确性、有用性和语言质量的四维评估协议。 3. 开发CRPO训练框架：利用基于相对偏好信号的强化学习策略优化，以提供稳定且符合人类偏好的训练指导。", "result": "PulseMind在诊断咨询基准和公开医学基准上均取得了具有竞争力的性能。", "conclusion": "PulseMind及其配套的数据集、评估基准和训练框架，为提升多模态模型在真实世界临床诊断中的能力提供了有效途径，并展现出良好的性能。"}}
{"id": "2601.07348", "categories": ["cs.CL", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.07348", "abs": "https://arxiv.org/abs/2601.07348", "authors": ["Tu Hu", "Ronghao Chen", "Shuo Zhang", "Jianghao Yin", "Mou Xiao Feng", "Jingping Liu", "Shaolei Zhang", "Wenqi Jiang", "Yuqi Fang", "Sen Hu", "Yi Xu", "Huacan Wang"], "title": "Controlled Self-Evolution for Algorithmic Code Optimization", "comment": "27 pages", "summary": "Self-evolution methods enhance code generation through iterative \"generate-verify-refine\" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks.To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad solution space coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels.Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.", "AI": {"tldr": "本文提出了一种名为受控自进化（CSE）的方法，通过多样化初始化、反馈引导的进化和分层记忆来提高代码生成的效率和探索能力，实验证明其优于现有方法。", "motivation": "现有自进化方法在代码生成中的探索效率低下，容易陷入局部最优，原因在于初始化偏差、缺乏反馈的随机操作以及经验利用不足。", "method": "CSE包含三个核心组件：1. 多样化规划初始化，生成结构不同的算法策略以覆盖更广的解空间；2. 遗传进化，用反馈引导的机制替代随机操作，实现有针对性的变异和组合式交叉；3. 分层进化记忆，捕获跨任务和任务内的成功及失败经验。", "result": "在EffiBench-X上的实验表明，CSE在各种LLM骨干模型上持续优于所有基线方法，并且在早期代就能实现更高的效率，并在进化过程中保持持续改进。", "conclusion": "CSE通过解决现有自进化方法的瓶颈，显著提升了代码生成的探索效率和最终性能，并能有效利用历史经验进行学习和改进。"}}
{"id": "2601.07260", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07260", "abs": "https://arxiv.org/abs/2601.07260", "authors": ["Huipeng Ma", "Luan Zhang", "Dandan Song", "Linmei Hu", "Yuhang Tian", "Jun Yang", "Changzhi Zhou", "Chenhao Li", "Yizhou Jin", "Xudong Li", "Meng Lin", "Mingxing Zhang", "Shuhao Zhang"], "title": "ActiShade: Activating Overshadowed Knowledge to Guide Multi-Hop Reasoning in Large Language Models", "comment": "Accepted to AAAI 2026", "summary": "In multi-hop reasoning, multi-round retrieval-augmented generation (RAG) methods typically rely on LLM-generated content as the retrieval query. However, these approaches are inherently vulnerable to knowledge overshadowing - a phenomenon where critical information is overshadowed during generation. As a result, the LLM-generated content may be incomplete or inaccurate, leading to irrelevant retrieval and causing error accumulation during the iteration process. To address this challenge, we propose ActiShade, which detects and activates overshadowed knowledge to guide large language models (LLMs) in multi-hop reasoning. Specifically, ActiShade iteratively detects the overshadowed keyphrase in the given query, retrieves documents relevant to both the query and the overshadowed keyphrase, and generates a new query based on the retrieved documents to guide the next-round iteration. By supplementing the overshadowed knowledge during the formulation of next-round queries while minimizing the introduction of irrelevant noise, ActiShade reduces the error accumulation caused by knowledge overshadowing. Extensive experiments show that ActiShade outperforms existing methods across multiple datasets and LLMs.", "AI": {"tldr": "提出ActiShade方法，通过检测和激活被“知识遮蔽”的知识来改进多跳推理中的多轮检索增强生成，以减少信息遗漏和错误累积。", "motivation": "现有的多轮检索增强生成方法依赖于LLM生成的查询，容易发生“知识遮蔽”，导致信息不完整、检索不相关以及错误累积。", "method": "ActiShade通过迭代检测被遮蔽的关键短语，检索与查询和被遮蔽关键短语都相关的文档，并基于检索到的文档生成新查询以指导下一轮迭代，从而补充被遮蔽的知识。", "result": "ActiShade能够减少因知识遮蔽导致的错误累积，并在多个数据集和LLM上优于现有方法。", "conclusion": "ActiShade有效地解决了多跳推理中的知识遮蔽问题，提高了多轮检索增强生成的性能。"}}
{"id": "2601.07359", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07359", "abs": "https://arxiv.org/abs/2601.07359", "authors": ["Shezheng Song", "Shasha Li", "Jie Yu"], "title": "Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated strong capabilities across a variety of vision-language tasks. However, their internal reasoning often exhibits a critical inconsistency: although deeper layers may attend to the correct visual regions, final predictions are frequently misled by noisy attention from earlier layers. This results in a disconnect between what the model internally understands and what it ultimately expresses, a phenomenon we describe as seeing it right but saying it wrong. To address this issue, we propose DualPD, a dual-perspective decoding refinement strategy that enhances the visual understanding without any additional training. DualPD consists of two components. (1) The layer-wise attention-guided contrastive logits module captures how the belief in the correct answer evolves by comparing output logits between layers that exhibit the largest attention shift. (2) The head-wise information filtering module suppresses low-contribution attention heads that focus on irrelevant regions, thereby improving attention quality within each layer. Experiments conducted on both the LLaVA and Qwen-VL model families across multiple multimodal benchmarks demonstrate that DualPD consistently improves accuracy without training, confirming its effectiveness and generalizability. The code will be released upon publication.", "AI": {"tldr": "本研究提出了一种名为DualPD的解码策略，通过对比不同层级的注意力机制和过滤低贡献的注意力头，来解决多模态大语言模型（MLLMs）在理解视觉信息时出现的“看对了但说错了”的问题，并且无需额外训练即可提升模型性能。", "motivation": "多模态大语言模型（MLLMs）虽然在视觉-语言任务中表现出色，但在内部推理中存在一个关键的不一致性：尽管深层模型能够关注到正确的视觉区域，但最终的预测却常常受到早期层级噪声注意力的误导，导致模型内部理解与其最终表达之间存在脱节，即“看对了但说错了”现象。", "method": "提出了一种名为DualPD的双视角解码精炼策略，包含两个主要组件：1. 层级注意力引导的对比 logits 模块（layer-wise attention-guided contrastive logits module），通过比较具有最大注意力转移的层级之间的输出 logits 来捕捉正确答案的信念演变。2. 头级信息过滤模块（head-wise information filtering module），通过抑制关注不相关区域的低贡献注意力头来提高每个层级的注意力质量。", "result": "在LLaVA和Qwen-VL模型系列上的实验表明，DualPD在多个多模态基准测试中持续提升了模型的准确率，且无需进行额外训练。", "conclusion": "DualPD是一种有效的、可泛化的策略，能够无需额外训练即可增强MLLMs的视觉理解能力，解决“看对了但说错了”的问题，并提升其在多模态任务上的性能。"}}
{"id": "2601.07351", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07351", "abs": "https://arxiv.org/abs/2601.07351", "authors": ["Linhao Zhong", "Linyu Wu", "Bozhen Fang", "Tianjian Feng", "Chenchen Jing", "Wen Wang", "Jiaheng Zhang", "Hao Chen", "Chunhua Shen"], "title": "Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models", "comment": "Project webpage: https://aim-uofa.github.io/EvoTokenDLM", "summary": "Diffusion Language Models (DLMs) offer a promising alternative for language modeling by enabling parallel decoding through iterative refinement. However, most DLMs rely on hard binary masking and discrete token assignments, which hinder the revision of early decisions and underutilize intermediate probabilistic representations. In this paper, we propose EvoToken-DLM, a novel diffusion-based language modeling approach that replaces hard binary masks with evolving soft token distributions. EvoToken-DLM enables a progressive transition from masked states to discrete outputs, supporting revisable decoding. To effectively support this evolution, we introduce continuous trajectory supervision, which aligns training objectives with iterative probabilistic updates. Extensive experiments across multiple benchmarks show that EvoToken-DLM consistently achieves superior performance, outperforming strong diffusion-based and masked DLM baselines. Project webpage: https://aim-uofa.github.io/EvoTokenDLM.", "AI": {"tldr": "EvoToken-DLM 是一种新的扩散语言模型，通过使用可变的软 token 分布取代硬二元掩码，实现了可修改的解码，并在多个基准测试中取得了优越的性能。", "motivation": "现有的扩散语言模型（DLMs）通常依赖于硬二元掩码和离散 token 赋值，这限制了早期决策的修改，并且未能充分利用中间的概率表示。本文旨在克服这些局限性。", "method": "本文提出了 EvoToken-DLM，一种新的扩散语言模型方法，用可变的软 token 分布取代硬二元掩码。该模型支持从掩码状态到离散输出的渐进式过渡，并引入了连续轨迹监督来支持这种演化，使训练目标与迭代概率更新保持一致。", "result": "在多个基准测试上的广泛实验表明，EvoToken-DLM 的性能始终优于强大的基于扩散和掩码的 DLM 基线模型。", "conclusion": "EvoToken-DLM 通过引入可变的软 token 分布和连续轨迹监督，成功地解决了现有 DLMs 的局限性，实现了可修改的解码，并在语言建模任务中取得了最先进的性能。"}}
{"id": "2601.07271", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07271", "abs": "https://arxiv.org/abs/2601.07271", "authors": ["Mohan Raj Chanthran", "Soon Lay Ki", "Ong Huey Fang", "Bhawani Selvaretnam"], "title": "Document-Level Zero-Shot Relation Extraction with Entity Side Information", "comment": "Accepted to EACL 2026 Main Conference", "summary": "Document-Level Zero-Shot Relation Extraction (DocZSRE) aims to predict unseen relation labels in text documents without prior training on specific relations. Existing approaches rely on Large Language Models (LLMs) to generate synthetic data for unseen labels, which poses challenges for low-resource languages like Malaysian English. These challenges include the incorporation of local linguistic nuances and the risk of factual inaccuracies in LLM-generated data. This paper introduces Document-Level Zero-Shot Relation Extraction with Entity Side Information (DocZSRE-SI) to address limitations in the existing DocZSRE approach. The DocZSRE-SI framework leverages Entity Side Information, such as Entity Mention Descriptions and Entity Mention Hypernyms, to perform ZSRE without depending on LLM-generated synthetic data. The proposed low-complexity model achieves an average improvement of 11.6% in the macro F1-Score compared to baseline models and existing benchmarks. By utilizing Entity Side Information, DocZSRE-SI offers a robust and efficient alternative to error-prone, LLM-based methods, demonstrating significant advancements in handling low-resource languages and linguistic diversity in relation extraction tasks. This research provides a scalable and reliable solution for ZSRE, particularly in contexts like Malaysian English news articles, where traditional LLM-based approaches fall short.", "AI": {"tldr": "提出了一种名为DocZSRE-SI的文档级零样本关系抽取框架，该框架利用实体侧信息（如实体提及描述和上位词）来避免依赖大型语言模型生成合成数据，尤其适用于马来西亚英语等低资源语言，并在实验中取得了显著的性能提升。", "motivation": "现有的文档级零样本关系抽取方法依赖大型语言模型生成合成数据，这对于马来西亚英语等低资源语言存在问题，因为难以incorporate本地语言细微差别，并且LLM生成的数据可能存在事实错误。", "method": "提出DocZSRE-SI框架，利用实体提及描述和实体提及上位词等实体侧信息来进行零样本关系抽取，不再依赖LLM生成的合成数据。", "result": "与基线模型和现有基准相比，DocZSRE-SI在宏F1分数上平均提高了11.6%。", "conclusion": "DocZSRE-SI提供了一种比易出错的、基于LLM的方法更鲁棒、更高效的零样本关系抽取方案，特别适用于低资源语言和马来西亚英语新闻文章等场景，展示了其在处理语言多样性方面的优势。"}}
{"id": "2601.07377", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07377", "abs": "https://arxiv.org/abs/2601.07377", "authors": ["Jiao Xu", "Xin Chen", "Lihe Zhang"], "title": "Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation", "comment": "Accepted to the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2025", "summary": "In this paper, we present a new dynamic collaborative network for semi-supervised 3D vessel segmentation, termed DiCo. Conventional mean teacher (MT) methods typically employ a static approach, where the roles of the teacher and student models are fixed. However, due to the complexity of 3D vessel data, the teacher model may not always outperform the student model, leading to cognitive biases that can limit performance. To address this issue, we propose a dynamic collaborative network that allows the two models to dynamically switch their teacher-student roles. Additionally, we introduce a multi-view integration module to capture various perspectives of the inputs, mirroring the way doctors conduct medical analysis. We also incorporate adversarial supervision to constrain the shape of the segmented vessels in unlabeled data. In this process, the 3D volume is projected into 2D views to mitigate the impact of label inconsistencies. Experiments demonstrate that our DiCo method sets new state-of-the-art performance on three 3D vessel segmentation benchmarks. The code repository address is https://github.com/xujiaommcome/DiCo", "AI": {"tldr": "本文提出了一种名为DiCo的动态协作网络，用于半监督3D血管分割，通过动态切换教师-学生角色、多视图集成和对抗性监督来提高性能。", "motivation": "现有基于均值教师（MT）的半监督方法通常采用静态模型角色，而3D血管数据的复杂性可能导致教师模型表现不如学生模型，从而引入认知偏差限制性能。因此，研究者希望提出一种能动态调整模型角色的方法。", "method": "提出了一种动态协作网络（DiCo），允许教师和学生模型动态切换角色。引入了多视图集成模块以从不同视角捕捉输入信息。结合了对抗性监督来约束无标签数据的分割形状，并通过将3D体积投影到2D视图来减轻标签不一致性的影响。", "result": "DiCo方法在三个3D血管分割基准上取得了新的最先进性能。", "conclusion": "DiCo方法通过其动态协作机制、多视图集成和对抗性监督，有效提升了半监督3D血管分割的性能，克服了传统静态MT方法的局限性。"}}
{"id": "2601.07264", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07264", "abs": "https://arxiv.org/abs/2601.07264", "authors": ["Weihao Xuan", "Qingcheng Zeng", "Heli Qi", "Yunze Xiao", "Junjue Wang", "Naoto Yokoya"], "title": "The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents", "comment": null, "summary": "Autonomous agents based on large language models (LLMs) are rapidly evolving to handle multi-turn tasks, but ensuring their trustworthiness remains a critical challenge. A fundamental pillar of this trustworthiness is calibration, which refers to an agent's ability to express confidence that reliably reflects its actual performance. While calibration is well-established for static models, its dynamics in tool-integrated agentic workflows remain underexplored. In this work, we systematically investigate verbalized calibration in tool-use agents, revealing a fundamental confidence dichotomy driven by tool type. Specifically, our pilot study identifies that evidence tools (e.g., web search) systematically induce severe overconfidence due to inherent noise in retrieved information, while verification tools (e.g., code interpreters) can ground reasoning through deterministic feedback and mitigate miscalibration. To robustly improve calibration across tool types, we propose a reinforcement learning (RL) fine-tuning framework that jointly optimizes task accuracy and calibration, supported by a holistic benchmark of reward designs. We demonstrate that our trained agents not only achieve superior calibration but also exhibit robust generalization from local training environments to noisy web settings and to distinct domains such as mathematical reasoning. Our results highlight the necessity of domain-specific calibration strategies for tool-use agents. More broadly, this work establishes a foundation for building self-aware agents that can reliably communicate uncertainty in high-stakes, real-world deployments.", "AI": {"tldr": "本文研究了大型语言模型（LLM）驱动的自主代理在使用工具（特别是证据工具和验证工具）时的置信度校准问题，发现证据工具会导致过度自信，而验证工具可以改善校准。作者提出了一种强化学习微调框架，通过联合优化任务准确性和校准来提高代理的可靠性，并在噪声环境和数学推理等领域取得了良好的泛化能力。", "motivation": "确保基于LLM的自主代理在多轮任务中的可信度，特别是其置信度表达与实际表现的可靠对应关系（即校准），是关键但未被充分探索的挑战，尤其是在涉及工具使用的代理工作流中。", "method": "作者首先通过试点研究分析了不同类型工具（证据工具如网络搜索，验证工具如代码解释器）对代理置信度校准的影响。随后，提出了一种强化学习（RL）微调框架，该框架通过联合优化任务准确性和校准来实现，并设计了一套全面的奖励机制。最后，在本地训练环境、噪声网络环境以及数学推理等不同领域评估了所提出的方法的有效性。", "result": "证据工具（如网络搜索）会导致代理过度自信，而验证工具（如代码解释器）可以通过确定性反馈来改善校准。所提出的RL微调框架能够显著提高代理的校准能力，同时保持任务准确性，并且在不同环境和领域（包括噪声网络设置和数学推理）展现出强大的泛化能力。", "conclusion": "针对使用工具的代理，需要采取特定于领域的校准策略。这项工作为构建能够可靠地传达不确定性的“自我认知”代理奠定了基础，这对于高风险的现实世界部署至关重要。"}}
{"id": "2601.07192", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07192", "abs": "https://arxiv.org/abs/2601.07192", "authors": ["Manzong Huang", "Chenyang Bu", "Yi He", "Xingrui Zhuo", "Xindong Wu"], "title": "Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG", "comment": "Accepted by AAAI 2026", "summary": "Graph-based Retrieval-Augmented Generation (GraphRAG) mitigates hallucinations in Large Language Models (LLMs) by grounding them in structured knowledge. However, current GraphRAG methods are constrained by a prevailing \\textit{build-then-reason} paradigm, which relies on a static, pre-constructed Knowledge Graph (KG). This paradigm faces two critical challenges. First, the KG's inherent incompleteness often breaks reasoning paths. Second, the graph's low signal-to-noise ratio introduces distractor facts, presenting query-relevant but misleading knowledge that disrupts the reasoning process.\n  To address these challenges, we argue for a \\textit{reason-and-construct} paradigm and propose Relink, a framework that dynamically builds a query-specific evidence graph. To tackle incompleteness, \\textbf{Relink} instantiates required facts from a latent relation pool derived from the original text corpus, repairing broken paths on the fly. To handle misleading or distractor facts, Relink employs a unified, query-aware evaluation strategy that jointly considers candidates from both the KG and latent relations, selecting those most useful for answering the query rather than relying on their pre-existence. This empowers Relink to actively discard distractor facts and construct the most faithful and precise evidence path for each query.\n  Extensive experiments on five Open-Domain Question Answering benchmarks show that Relink achieves significant average improvements of 5.4\\% in EM and 5.2\\% in F1 over leading GraphRAG baselines, demonstrating the superiority of our proposed framework.", "AI": {"tldr": "本研究提出了一种名为 Relink 的新框架，用于解决现有图谱增强生成（GraphRAG）方法中知识图谱不完整和噪音干扰的问题。Relink 采用“推理-构建”范式，动态构建查询相关的证据图谱，通过实例化潜在关系和统一的查询感知评估策略来弥补知识图谱的不足并剔除干扰信息，从而提高 LLM 的回答准确性。", "motivation": "现有 GraphRAG 方法依赖于静态知识图谱，存在不完整（推理路径中断）和低信噪比（引入干扰事实）的问题。这阻碍了 LLM 在生成过程中有效利用结构化知识。", "method": "提出“推理-构建”范式，设计 Relink 框架。Relink 动态构建查询特定的证据图谱：1. 通过从原始文本语料库中提取的潜在关系池实例化所需事实，修复不完整的推理路径；2. 采用统一的、查询感知的评估策略，同时考虑知识图谱和潜在关系中的候选事实，选择对回答查询最有用的事实，从而主动剔除干扰事实。", "result": "在五个开放领域问答基准测试中的大量实验表明，Relink 在 EM 和 F1 指标上平均比领先的 GraphRAG 基线模型分别提高了 5.4% 和 5.2%。", "conclusion": "Relink 框架通过动态构建查询特定的证据图谱，有效解决了当前 GraphRAG 方法面临的知识图谱不完整和干扰事实问题，证明了其在提高 LLM 回答准确性方面的优越性。"}}
{"id": "2601.07310", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07310", "abs": "https://arxiv.org/abs/2601.07310", "authors": ["Zhongming Liu", "Bingbing Jiang"], "title": "Revisiting the Ordering of Channel and Spatial Attention: A Comprehensive Study on Sequential and Parallel Designs", "comment": null, "summary": "Attention mechanisms have become a core component of deep learning models, with Channel Attention and Spatial Attention being the two most representative architectures. Current research on their fusion strategies primarily bifurcates into sequential and parallel paradigms, yet the selection process remains largely empirical, lacking systematic analysis and unified principles. We systematically compare channel-spatial attention combinations under a unified framework, building an evaluation suite of 18 topologies across four classes: sequential, parallel, multi-scale, and residual. Across two vision and nine medical datasets, we uncover a \"data scale-method-performance\" coupling law: (1) in few-shot tasks, the \"Channel-Multi-scale Spatial\" cascaded structure achieves optimal performance; (2) in medium-scale tasks, parallel learnable fusion architectures demonstrate superior results; (3) in large-scale tasks, parallel structures with dynamic gating yield the best performance. Additionally, experiments indicate that the \"Spatial-Channel\" order is more stable and effective for fine-grained classification, while residual connections mitigate vanishing gradient problems across varying data scales. We thus propose scenario-based guidelines for building future attention modules. Code is open-sourced at https://github.com/DWlzm.", "AI": {"tldr": "本研究系统性地比较了通道注意力和空间注意力在不同数据规模下的融合策略，发现特定融合结构在不同任务场景下表现最优，并提出了基于场景的设计指南。", "motivation": "现有研究在通道注意力和空间注意力的融合策略上主要采用顺序和并行模式，但缺乏系统的分析和统一的原则，选择过程多凭经验。", "method": "研究者构建了一个包含18种拓扑结构的统一评估框架，涵盖顺序、并行、多尺度和残差四类，并在两个视觉数据集和九个医学数据集上进行了实验评估。", "result": "研究发现：1. 在少样本任务中，通道-多尺度空间级联结构表现最优。2. 在中等规模数据集上，并行可学习融合架构效果更佳。3. 在大规模数据集上，具有动态门控的并行结构性能最好。此外，空间-通道顺序对于细粒度分类更稳定有效，而残差连接有助于缓解梯度消失问题。", "conclusion": "研究提出了“数据规模-方法-性能”的耦合规律，并基于此为未来构建注意力模块提供了场景化的设计指南。"}}
{"id": "2601.07372", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07372", "abs": "https://arxiv.org/abs/2601.07372", "authors": ["Xin Cheng", "Wangding Zeng", "Damai Dai", "Qinyu Chen", "Bingxuan Wang", "Zhenda Xie", "Kezhao Huang", "Xingkai Yu", "Zhewen Hao", "Yukun Li", "Han Zhang", "Huishuai Zhang", "Dongyan Zhao", "Wenfeng Liang"], "title": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "comment": null, "summary": "While Mixture-of-Experts (MoE) scales capacity via conditional computation, Transformers lack a native primitive for knowledge lookup, forcing them to inefficiently simulate retrieval through computation. To address this, we introduce conditional memory as a complementary sparsity axis, instantiated via Engram, a module that modernizes classic $N$-gram embedding for O(1) lookup. By formulating the Sparsity Allocation problem, we uncover a U-shaped scaling law that optimizes the trade-off between neural computation (MoE) and static memory (Engram). Guided by this law, we scale Engram to 27B parameters, achieving superior performance over a strictly iso-parameter and iso-FLOPs MoE baseline. Most notably, while the memory module is expected to aid knowledge retrieval (e.g., MMLU +3.4; CMMLU +4.0), we observe even larger gains in general reasoning (e.g., BBH +5.0; ARC-Challenge +3.7) and code/math domains~(HumanEval +3.0; MATH +2.4). Mechanistic analyses reveal that Engram relieves the backbone's early layers from static reconstruction, effectively deepening the network for complex reasoning. Furthermore, by delegating local dependencies to lookups, it frees up attention capacity for global context, substantially boosting long-context retrieval (e.g., Multi-Query NIAH: 84.2 to 97.0). Finally, Engram establishes infrastructure-aware efficiency: its deterministic addressing enables runtime prefetching from host memory, incurring negligible overhead. We envision conditional memory as an indispensable modeling primitive for next-generation sparse models.", "AI": {"tldr": "本文提出了一种名为 Engram 的条件记忆模块，它使用 N-gram 嵌入实现 O(1) 知识查找，以弥补 Transformer 在知识检索方面的不足。研究发现，这种模型在通用推理、代码和数学任务上表现优于纯粹的 MoE 模型，并且能提升长上下文检索能力，同时实现高效的运行时预取。", "motivation": "Transformer 在扩展模型容量时，缺乏类似 MoE 的条件计算机制，导致知识检索效率低下。本文旨在引入一种新的稀疏性维度——条件记忆，以优化模型容量的扩展和知识检索的效率。", "method": "引入 Engram 模块，该模块基于 N-gram 嵌入实现 O(1) 的知识查找。通过定义“稀疏性分配问题”，发现了神经计算（MoE）和静态记忆（Engram）之间权衡的 U 型缩放规律。基于该规律，构建了 270 亿参数的 Engram 模型，并与同等参数和 FLOPs 的 MoE 基线进行比较。同时进行了机制分析，以揭示 Engram 的工作原理。", "result": "Engram 模型在 MMLU（+3.4）、CMMLU（+4.0）、BBH（+5.0）、ARC-Challenge（+3.7）、HumanEval（+3.0）和 MATH（+2.4）等基准测试中均取得了优于 MoE 基线的性能。Engram 能够解放骨干网络早期层，使其更专注于复杂推理，同时通过将局部依赖性委托给查找，增加了注意力容量来处理全局上下文，显著提高了长上下文检索能力（例如，Multi-Query NIAH 从 84.2 提升到 97.0）。此外，Engram 的确定性寻址允许从主机内存进行运行时预取，开销极小。", "conclusion": "条件记忆（通过 Engram 实现）是下一代稀疏模型的重要组成部分。Engram 模块通过引入 O(1) 知识查找，有效弥补了 Transformer 的不足，并在通用推理、代码/数学能力和长上下文检索方面取得了显著的性能提升，同时保持了高效的运行效率。"}}
{"id": "2601.07422", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07422", "abs": "https://arxiv.org/abs/2601.07422", "authors": ["Wen Luo", "Guangyue Peng", "Wei Li", "Shaohang Wei", "Feifan Song", "Liang Wang", "Nan Yang", "Xingxing Zhang", "Jing Jin", "Furu Wei", "Houfeng Wang"], "title": "Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations", "comment": null, "summary": "Despite their impressive capabilities, large language models (LLMs) frequently generate hallucinations. Previous work shows that their internal states encode rich signals of truthfulness, yet the origins and mechanisms of these signals remain unclear. In this paper, we demonstrate that truthfulness cues arise from two distinct information pathways: (1) a Question-Anchored pathway that depends on question-answer information flow, and (2) an Answer-Anchored pathway that derives self-contained evidence from the generated answer itself. First, we validate and disentangle these pathways through attention knockout and token patching. Afterwards, we uncover notable and intriguing properties of these two mechanisms. Further experiments reveal that (1) the two mechanisms are closely associated with LLM knowledge boundaries; and (2) internal representations are aware of their distinctions. Finally, building on these insightful findings, two applications are proposed to enhance hallucination detection performance. Overall, our work provides new insight into how LLMs internally encode truthfulness, offering directions for more reliable and self-aware generative systems.", "AI": {"tldr": "本研究揭示了大型语言模型（LLMs）内部涌现真理性线索的两种独立信息路径：问题锚定路径和答案锚定路径，并利用这些发现提出了两种增强幻觉检测的方法。", "motivation": "尽管LLMs能力强大，但常产生幻觉，而其内部状态却编码着真理性的信号，但这些信号的来源和机制尚不清楚。", "method": "通过注意力机制的剔除（attention knockout）和标记替换（token patching）来验证和分离两种信息路径（问题锚定路径和答案锚定路径），并进行进一步实验以揭示其特性。", "result": "发现了两种独立的真理性信息编码机制：问题锚定路径和答案锚定路径。这两种机制与LLMs的知识边界相关，并且模型内部表征能够区分它们。基于这些发现，提出了两种增强幻觉检测的方法。", "conclusion": "本研究深入理解了LLMs内部如何编码真理性，为构建更可靠、更具自我意识的生成系统提供了新的方向。"}}
{"id": "2601.07396", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07396", "abs": "https://arxiv.org/abs/2601.07396", "authors": ["Guantao Chen", "Shikang Zheng", "Yuqi Lin", "Linfeng Zhang"], "title": "Forecast the Principal, Stabilize the Residual: Subspace-Aware Feature Caching for Efficient Diffusion Transformers", "comment": null, "summary": "Diffusion Transformer (DiT) models have achieved unprecedented quality in image and video generation, yet their iterative sampling process remains computationally prohibitive. To accelerate inference, feature caching methods have emerged by reusing intermediate representations across timesteps. However, existing caching approaches treat all feature components uniformly. We reveal that DiT feature spaces contain distinct principal and residual subspaces with divergent temporal behavior: the principal subspace evolves smoothly and predictably, while the residual subspace exhibits volatile, low-energy oscillations that resist accurate prediction. Building on this insight, we propose SVD-Cache, a subspace-aware caching framework that decomposes diffusion features via Singular Value Decomposition (SVD), applies exponential moving average (EMA) prediction to the dominant low-rank components, and directly reuses the residual subspace. Extensive experiments demonstrate that SVD-Cache achieves near-lossless across diverse models and methods, including 5.55$\\times$ speedup on FLUX and HunyuanVideo, and compatibility with model acceleration techniques including distillation, quantization and sparse attention. Our code is in supplementary material and will be released on Github.", "AI": {"tldr": "提出了一种名为SVD-Cache的加速扩散Transformer（DiT）模型推理的方法，通过利用SVD将特征分解为主要和残差子空间，并对主要子空间使用EMA预测，同时直接复用残差子空间，实现了显著的速度提升且几乎无损质量。", "motivation": "现有的DiT模型推理速度慢，而特征缓存方法仅能部分缓解此问题，且未能有效利用DiT特征空间内部的结构信息。", "method": "将DiT的特征空间通过SVD分解为主要子空间和残差子空间。对主要子空间（低秩、平滑演变）使用指数移动平均（EMA）进行预测和缓存。对残差子空间（高秩、剧烈振荡）直接进行复用。", "result": "SVD-Cache在FLUX和HunyuanVideo上实现了5.55倍的速度提升，且在图像和视频生成任务上实现了近乎无损的质量。该方法还兼容模型加速技术，如蒸馏、量化和稀疏注意力。", "conclusion": "SVD-Cache通过理解DiT特征空间中不同子空间的动态特性，提出了一种高效且通用的特征缓存策略，显著加速了DiT模型的推理过程，同时保持了生成质量。"}}
{"id": "2601.07366", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07366", "abs": "https://arxiv.org/abs/2601.07366", "authors": ["Haoxuan Li", "Mengyan Li", "Junjun Zheng"], "title": "HiVid-Narrator: Hierarchical Video Narrative Generation with Scene-Primed ASR-anchored Compression", "comment": null, "summary": "Generating structured narrations for real-world e-commerce videos requires models to perceive fine-grained visual details and organize them into coherent, high-level stories--capabilities that existing approaches struggle to unify. We introduce the E-commerce Hierarchical Video Captioning (E-HVC) dataset with dual-granularity, temporally grounded annotations: a Temporal Chain-of-Thought that anchors event-level observations and Chapter Summary that compose them into concise, story-centric summaries. Rather than directly prompting chapters, we adopt a staged construction that first gathers reliable linguistic and visual evidence via curated ASR and frame-level descriptions, then refines coarse annotations into precise chapter boundaries and titles conditioned on the Temporal Chain-of-Thought, yielding fact-grounded, time-aligned narratives. We also observe that e-commerce videos are fast-paced and information-dense, with visual tokens dominating the input sequence. To enable efficient training while reducing input tokens, we propose the Scene-Primed ASR-anchored Compressor (SPA-Compressor), which compresses multimodal tokens into hierarchical scene and event representations guided by ASR semantic cues. Built upon these designs, our HiVid-Narrator framework achieves superior narrative quality with fewer input tokens compared to existing methods.", "AI": {"tldr": "本文提出了一种名为E-HVC的新型电商视频数据集，包含时间线索和章节摘要，用于生成结构化叙事。并开发了HiVid-Narrator框架，通过SPA-Compressor对多模态输入进行压缩，提高了叙事质量并减少了输入token数量。", "motivation": "现有模型难以同时处理电商视频的精细视觉细节和组织高层叙事，需要一种能统一这两种能力的方法。", "method": "构建了E-commerce Hierarchical Video Captioning (E-HVC) 数据集，包含时间线索（Temporal Chain-of-Thought）和章节摘要（Chapter Summary）的标注。采用分阶段叙事生成方法，先收集ASR和帧级描述，再基于时间线索细化章节边界和标题。提出SPA-Compressor压缩多模态token，利用ASR语义线索引导层级场景和事件表示。", "result": "HiVid-Narrator框架在生成叙事质量上优于现有方法，且使用了更少的输入token。", "conclusion": "所提出的E-HVC数据集和HiVid-Narrator框架能够有效地为电商视频生成事实准确、时间对齐的高质量叙事，并且在效率方面也有所提升。"}}
{"id": "2601.07416", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07416", "abs": "https://arxiv.org/abs/2601.07416", "authors": ["Prachet Dev Singh", "Shyamsundar Paramasivam", "Sneha Barman", "Mainak Singha", "Ankit Jha", "Girish Mishra", "Biplab Banerjee"], "title": "SDHSI-Net: Learning Better Representations for Hyperspectral Images via Self-Distillation", "comment": "Accepted at InGARSS 2025", "summary": "Hyperspectral image (HSI) classification presents unique challenges due to its high spectral dimensionality and limited labeled data. Traditional deep learning models often suffer from overfitting and high computational costs. Self-distillation (SD), a variant of knowledge distillation where a network learns from its own predictions, has recently emerged as a promising strategy to enhance model performance without requiring external teacher networks. In this work, we explore the application of SD to HSI by treating earlier outputs as soft targets, thereby enforcing consistency between intermediate and final predictions. This process improves intra-class compactness and inter-class separability in the learned feature space. Our approach is validated on two benchmark HSI datasets and demonstrates significant improvements in classification accuracy and robustness, highlighting the effectiveness of SD for spectral-spatial learning. Codes are available at https://github.com/Prachet-Dev-Singh/SDHSI.", "AI": {"tldr": "本文提出了一种基于自蒸馏（SD）的方法来提升高光谱图像（HSI）分类性能，通过让模型从自身的中间预测中学习，增强了特征空间的类内紧凑性和类间可分性，并在基准数据集上取得了显著的分类精度和鲁棒性提升。", "motivation": "高光谱图像分类面临维度高、标记数据少的挑战。传统的深度学习模型容易过拟合且计算成本高。自蒸馏（SD）作为知识蒸馏的一种形式，无需外部教师网络即可提升模型性能，因此被探索应用于高光谱图像分类。", "method": "该方法将网络的早期输出作为软目标，强制中间预测和最终预测之间的一致性。这种自蒸馏过程旨在改进特征空间的类内紧凑性和类间可分性，以提升高光谱图像的分类效果。", "result": "在两个基准高光谱图像数据集上的验证显示，所提出的自蒸馏方法显著提高了分类精度和鲁棒性。", "conclusion": "自蒸馏是一种有效的方法，可以提升高光谱图像的分类性能，尤其是在增强光谱-空间特征学习方面。所提出的基于自蒸馏的策略能够克服传统深度学习模型在高光谱图像分类中的局限性。"}}
{"id": "2601.07430", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07430", "abs": "https://arxiv.org/abs/2601.07430", "authors": ["Qitan Lv", "Tianyu Liu", "Qiaosheng Zhang", "Xingcheng Xu", "Chaochao Lu"], "title": "KALE: Enhancing Knowledge Manipulation in Large Language Models via Knowledge-aware Learning", "comment": null, "summary": "Despite the impressive performance of large language models (LLMs) pretrained on vast knowledge corpora, advancing their knowledge manipulation-the ability to effectively recall, reason, and transfer relevant knowledge-remains challenging. Existing methods mainly leverage Supervised Fine-Tuning (SFT) on labeled datasets to enhance LLMs' knowledge manipulation ability. However, we observe that SFT models still exhibit the known&incorrect phenomenon, where they explicitly possess relevant knowledge for a given question but fail to leverage it for correct answers. To address this challenge, we propose KALE (Knowledge-Aware LEarning)-a post-training framework that leverages knowledge graphs (KGs) to generate high-quality rationales and enhance LLMs' knowledge manipulation ability. Specifically, KALE first introduces a Knowledge-Induced (KI) data synthesis method that efficiently extracts multi-hop reasoning paths from KGs to generate high-quality rationales for question-answer pairs. Then, KALE employs a Knowledge-Aware (KA) fine-tuning paradigm that enhances knowledge manipulation by internalizing rationale-guided reasoning through minimizing the KL divergence between predictions with and without rationales. Extensive experiments on eight popular benchmarks across six different LLMs demonstrate the effectiveness of KALE, achieving accuracy improvements of up to 11.72% and an average of 4.18%.", "AI": {"tldr": "提出了一种名为 KALE 的后训练框架，利用知识图谱（KGs）生成高质量的推理过程，以提高大型语言模型（LLMs）的知识操控能力，并在多个基准测试中取得了显著的性能提升。", "motivation": "尽管大型语言模型在知识方面表现出色，但提高其知识操控能力（召回、推理和迁移知识）仍然是一个挑战。现有的监督微调（SFT）方法在处理“已知但未使用”的问题时表现不佳。", "method": "KALE 框架包含两个主要部分：1. 知识诱导（KI）数据合成：从知识图谱中提取多跳推理路径，为问答对生成高质量的推理过程。2. 知识感知（KA）微调：通过最小化有无推理过程的预测之间的 KL 散度，引导模型进行推理，从而提高知识操控能力。", "result": "在八个基准测试和六种不同的 LLMs 上进行的广泛实验表明，KALE 框架可以显著提高模型的准确性，最高可达 11.72%，平均提升 4.18%。", "conclusion": "KALE 框架通过结合知识图谱和精心的微调策略，有效解决了 LLMs 的知识操控能力不足的问题，显著提升了其在各种知识密集型任务上的表现。"}}
{"id": "2601.07312", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07312", "abs": "https://arxiv.org/abs/2601.07312", "authors": ["Huachuan Qiu", "Zhaoming Chen", "Yuqian Chen", "Yuan Xie", "Yu Lu", "Zhenzhong Lan"], "title": "PsyCLIENT: Client Simulation via Conversational Trajectory Modeling for Trainee Practice and Model Evaluation in Mental Health Counseling", "comment": null, "summary": "LLM-based client simulation has emerged as a promising tool for training novice counselors and evaluating automated counseling systems. However, existing client simulation approaches face three key challenges: (1) limited diversity and realism in client profiles, (2) the lack of a principled framework for modeling realistic client behaviors, and (3) a scarcity in Chinese-language settings. To address these limitations, we propose PsyCLIENT, a novel simulation framework grounded in conversational trajectory modeling. By conditioning LLM generation on predefined real-world trajectories that incorporate explicit behavior labels and content constraints, our approach ensures diverse and realistic interactions. We further introduce PsyCLIENT-CP, the first open-source Chinese client profile dataset, covering 60 distinct counseling topics. Comprehensive evaluations involving licensed professional counselors demonstrate that PsyCLIENT significantly outperforms baselines in terms of authenticity and training effectiveness. Notably, the simulated clients are nearly indistinguishable from human clients, achieving an about 95\\% expert confusion rate in discrimination tasks. These findings indicate that conversational trajectory modeling effectively bridges the gap between theoretical client profiles and dynamic, realistic simulations, offering a robust solution for mental health education and research. Code and data will be released to facilitate future research in mental health counseling.", "AI": {"tldr": "提出了一种名为PsyCLIENT的新型LLM客户端模拟框架，通过对话轨迹建模来生成更具多样性和真实性的模拟客户，并发布了首个中文客户画像数据集PsyCLIENT-CP，显著提高了模拟客户的真实性和培训效果。", "motivation": "现有LLM客户端模拟方法在客户画像多样性和真实性、客户行为建模框架以及中文语境支持方面存在不足。", "method": "提出PsyCLIENT框架，采用对话轨迹建模，通过将LLM生成条件化在包含行为标签和内容约束的真实世界轨迹上，来实现多样化和真实的交互。同时，发布了PsyCLIENT-CP，一个包含60个咨询主题的中文客户画像数据集。", "result": "PsyCLIENT在真实性和培训效果上显著优于基线方法。模拟客户与真人客户的区分度极低，专家区分率约为95%。", "conclusion": "对话轨迹建模能够有效地连接理论客户画像和动态真实的模拟，为心理健康教育和研究提供了强大的解决方案。PsyCLIENT和PsyCLIENT-CP数据集将促进未来心理健康咨询领域的研究。"}}
{"id": "2601.07447", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07447", "abs": "https://arxiv.org/abs/2601.07447", "authors": ["Mahdi Chamseddine", "Didier Stricker", "Jason Rambach"], "title": "PanoSAMic: Panoramic Image Segmentation from SAM Feature Encoding and Dual View Fusion", "comment": null, "summary": "Existing image foundation models are not optimized for spherical images having been trained primarily on perspective images. PanoSAMic integrates the pre-trained Segment Anything (SAM) encoder to make use of its extensive training and integrate it into a semantic segmentation model for panoramic images using multiple modalities. We modify the SAM encoder to output multi-stage features and introduce a novel spatio-modal fusion module that allows the model to select the relevant modalities and best features from each modality for different areas of the input. Furthermore, our semantic decoder uses spherical attention and dual view fusion to overcome the distortions and edge discontinuity often associated with panoramic images. PanoSAMic achieves state-of-the-art (SotA) results on Stanford2D3DS for RGB, RGB-D, and RGB-D-N modalities and on Matterport3D for RGB and RGB-D modalities. https://github.com/dfki-av/PanoSAMic", "AI": {"tldr": "PanoSAMic 是一个用于全景图像的语义分割模型，它通过集成预训练的 Segment Anything (SAM) 模型并引入多模态融合、球形注意力以及双视图融合等技术，解决了现有模型在处理全景图像时存在的问题，并在多个数据集上取得了最先进的性能。", "motivation": "现有的图像基础模型（如 SAM）主要在透视图像上进行训练，未能针对具有独特几何特性的全景图像进行优化。因此，需要一种能够有效处理全景图像的语义分割方法。", "method": "1. 集成预训练的 SAM 编码器，并进行修改以输出多阶段特征。\n2. 引入新颖的特时-模态融合模块，用于选择不同区域所需的相关模态和最佳特征。\n3. 设计一个语义解码器，采用球形注意力（spherical attention）和双视图融合（dual view fusion）来解决全景图像的畸变和边缘不连续问题。", "result": "PanoSAMic 在 Stanford2D3DS 数据集（RGB、RGB-D、RGB-D-N 模态）和 Matterport3D 数据集（RGB、RGB-D 模态）上均取得了最先进（SotA）的结果。", "conclusion": "PanoSAMic 成功地将 SAM 的强大特征提取能力应用于全景图像语义分割任务，并通过创新的模块设计克服了全景图像处理的挑战，实现了卓越的性能。"}}
{"id": "2601.07518", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07518", "abs": "https://arxiv.org/abs/2601.07518", "authors": ["Fangyu Lin", "Yingdong Hu", "Zhening Liu", "Yufan Zhuang", "Zehong Lin", "Jun Zhang"], "title": "Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization", "comment": null, "summary": "Immersive telepresence aims to transform human interaction in AR/VR applications by enabling lifelike full-body holographic representations for enhanced remote collaboration. However, existing systems rely on hardware-intensive multi-camera setups and demand high bandwidth for volumetric streaming, limiting their real-time performance on mobile devices. To overcome these challenges, we propose Mon3tr, a novel Monocular 3D telepresence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence for the first time. Mon3tr adopts an amortized computation strategy, dividing the process into a one-time offline multi-view reconstruction phase to build a user-specific avatar and a monocular online inference phase during live telepresence sessions. A single monocular RGB camera is used to capture body motions and facial expressions in real time to drive the 3DGS-based parametric human model, significantly reducing system complexity and cost. The extracted motion and appearance features are transmitted at < 0.2 Mbps over WebRTC's data channel, allowing robust adaptation to network fluctuations. On the receiver side, e.g., Meta Quest 3, we develop a lightweight 3DGS attribute deformation network to dynamically generate corrective 3DGS attribute adjustments on the pre-built avatar, synthesizing photorealistic motion and appearance at ~ 60 FPS. Extensive experiments demonstrate the state-of-the-art performance of our method, achieving a PSNR of > 28 dB for novel poses, an end-to-end latency of ~ 80 ms, and > 1000x bandwidth reduction compared to point-cloud streaming, while supporting real-time operation from monocular inputs across diverse scenarios. Our demos can be found at https://mon3tr3d.github.io.", "AI": {"tldr": "Mon3tr 是一个新颖的单目 3D 远程呈现框架，首次将 3D 高斯泼溅（3DGS）参数化人体建模集成到远程呈现中，通过单目 RGB 摄像头实时捕捉动作和表情，大幅降低了系统复杂度和成本，并实现了低带宽、低延迟的逼真全身全息表示。", "motivation": "现有沉浸式远程呈现系统依赖于多摄像头设置和高带宽，限制了其在移动设备上的实时性能。", "method": "Mon3tr 采用分摊计算策略，包括离线多视图重建和在线单目推理。利用 3DGS 参数化人体模型，通过单目 RGB 摄像头捕捉实时动作和表情，并通过低带宽（< 0.2 Mbps）传输特征。接收端使用轻量级 3DGS 属性变形网络动态调整预构建模型，实现约 60 FPS 的逼真合成。", "result": "Mon3tr 在新颖姿势下实现了 > 28 dB 的 PSNR，端到端延迟约 80 ms，带宽比点云流减少超过 1000 倍，并支持跨不同场景的单目输入实时运行。", "conclusion": "Mon3tr 成功地将 3DGS 参数化人体建模应用于单目远程呈现，显著降低了系统复杂度和带宽需求，同时实现了高质量、低延迟的全息通信，为 AR/VR 应用中的远程协作提供了新的解决方案。"}}
{"id": "2601.07516", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07516", "abs": "https://arxiv.org/abs/2601.07516", "authors": ["Yongqi Li", "Hao Lang", "Tieyun Qian", "Yongbin Li"], "title": "Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions", "comment": null, "summary": "Vision-language models are increasingly employed as multimodal conversational agents (MCAs) for diverse conversational tasks. Recently, reinforcement learning (RL) has been widely explored for adapting MCAs to various human-AI interaction scenarios. Despite showing great enhancement in generalization performance, fine-tuning MCAs via RL still faces challenges in handling the extremely large text token space. To address this, we learn a compact latent action space for RL fine-tuning instead. Specifically, we adopt the learning from observation mechanism to construct the codebook for the latent action space, where future observations are leveraged to estimate current latent actions that could further be used to reconstruct future observations. However, the scarcity of paired image-text data hinders learning a codebook with sufficient coverage. Thus, we leverage both paired image-text data and text-only data to construct the latent action space, using a cross-modal projector for transforming text embeddings into image-text embeddings. We initialize the cross-modal projector on paired image-text data, and further train it on massive text-only data with a novel cycle consistency loss to enhance its robustness. We show that our latent action based method outperforms competitive baselines on two conversation tasks across various RL algorithms.", "AI": {"tldr": "本研究提出了一种基于潜在动作空间的强化学习方法，用于微调视觉语言模型作为多模态对话代理（MCAs）。通过学习一个紧凑的潜在动作空间，该方法有效解决了MCAs在处理海量文本令牌空间时面临的挑战，并利用观察学习和跨模态投影器（结合配对和纯文本数据）来构建该空间，在对话任务上取得了优于基线方法的性能。", "motivation": "现有的通过强化学习（RL）微调的多模态对话代理（MCAs）在处理庞大的文本令牌空间时面临挑战，影响了其泛化性能。因此，研究者希望找到一种更有效的方法来处理这个巨大的动作空间。", "method": "研究者提出了一种学习紧凑潜在动作空间的方法。具体来说，他们采用了“从观察中学习”（learning from observation）机制来构建潜在动作空间的码本，利用未来的观察来估计当前动作，并重构未来观察。为了解决配对数据稀缺的问题，他们结合了配对图像-文本数据和纯文本数据来构建潜在动作空间，并使用一个跨模态投影器将文本嵌入转换为图像-文本嵌入。该投影器首先在配对数据上初始化，然后利用新颖的周期一致性损失在海量纯文本数据上进行进一步训练，以增强其鲁棒性。", "result": "所提出的基于潜在动作空间的方法在两个对话任务上，并结合不同的强化学习算法，均优于竞争性基线方法。", "conclusion": "通过学习一个紧凑的潜在动作空间，并结合观察学习和跨模态投影器（利用配对和纯文本数据），本研究成功解决了现有RL微调MCA时处理庞大文本令牌空间带来的挑战，并在多模态对话任务上取得了显著的性能提升。"}}
{"id": "2601.07274", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07274", "abs": "https://arxiv.org/abs/2601.07274", "authors": ["Kalvin Chang", "Yiwen Shao", "Jiahong Li", "Dong Yu"], "title": "Towards Comprehensive Semantic Speech Embeddings for Chinese Dialects", "comment": null, "summary": "Despite having hundreds of millions of speakers, Chinese dialects lag behind Mandarin in speech and language technologies. Most varieties are primarily spoken, making dialect-to-Mandarin speech-LLMs (large language models) more practical than dialect LLMs. Building dialect-to-Mandarin speech-LLMs requires speech representations with cross-dialect semantic alignment between Chinese dialects and Mandarin. In this paper, we achieve such a cross-dialect semantic alignment by training a speech encoder with ASR (automatic speech recognition)-only data, as demonstrated by speech-to-speech retrieval on a new benchmark of spoken Chinese varieties that we contribute. Our speech encoder further demonstrates state-of-the-art ASR performance on Chinese dialects. Together, our Chinese dialect benchmark, semantically aligned speech representations, and speech-to-speech retrieval evaluation lay the groundwork for future Chinese dialect speech-LLMs. We release the benchmark at https://github.com/kalvinchang/yubao.", "AI": {"tldr": "本文提出了一种通过仅使用ASR数据训练语音编码器，实现了中文方言与普通话之间的跨语种语义对齐的方法，并在新的中文口语方言检索基准上进行了验证，同时提升了中文方言的ASR性能，为未来的中文方言语音大模型奠定了基础。", "motivation": "中文方言在语音和语言技术方面落后于普通话，而大部分方言以口语为主，因此开发面向普通话的方言到普通话语音大模型比纯方言模型更实际。实现这一目标的关键在于获得在中文方言和普通话之间具有跨语种语义对齐的语音表示。", "method": "研究人员通过使用自动语音识别（ASR）数据训练了一个语音编码器，以实现跨中文方言和普通话的语义对齐。他们还构建了一个新的中文口语方言基准，并在此基准上进行了语音到语音检索实验来验证其方法。该编码器在中文方言的ASR性能上也达到了最先进水平。", "result": "该研究成功地实现了跨中文方言和普通话的语义对齐，并在新的口语中文方言语音到语音检索基准上展示了其有效性。此外，所提出的语音编码器在中文方言的ASR任务上也取得了最先进的性能。", "conclusion": "通过训练ASR-only数据，可以获得具有跨中文方言语义对齐的语音表示。这项研究提出的中文方言基准、语义对齐的语音表示以及语音到语音检索评估方法，为未来构建中文方言语音大模型奠定了坚实的基础。"}}
{"id": "2601.07314", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07314", "abs": "https://arxiv.org/abs/2601.07314", "authors": ["Sebastian Nehrdich", "David Allport", "Sven Sellmer", "Jivnesh Sandhan", "Manoj Balaji Jagadeeshan", "Pawan Goyal", "Sujeet Kumar", "Kurt Keutzer"], "title": "Mitrasamgraha: A Comprehensive Classical Sanskrit Machine Translation Dataset", "comment": null, "summary": "While machine translation is regarded as a \"solved problem\" for many high-resource languages, close analysis quickly reveals that this is not the case for content that shows challenges such as poetic language, philosophical concepts, multi-layered metaphorical expressions, and more. Sanskrit literature is a prime example of this, as it combines a large number of such challenges in addition to inherent linguistic features like sandhi, compounding, and heavy morphology, which further complicate NLP downstream tasks. It spans multiple millennia of text production time as well as a large breadth of different domains, ranging from ritual formulas via epic narratives, philosophical treatises, poetic verses up to scientific material. As of now, there is a strong lack of publicly available resources that cover these different domains and temporal layers of Sanskrit. We therefore introduce Mitrasamgraha, a high-quality Sanskrit-to-English machine translation dataset consisting of 391,548 bitext pairs, more than four times larger than the largest previously available Sanskrit dataset Itih=asa. It covers a time period of more than three millennia and a broad range of historical Sanskrit domains. In contrast to web-crawled datasets, the temporal and domain annotation of this dataset enables fine-grained study of domain and time period effects on MT performance. We also release a validation set consisting of 5,587 and a test set consisting of 5,552 post-corrected bitext pairs. We conduct experiments benchmarking commercial and open models on this dataset and fine-tune NLLB and Gemma models on the dataset, showing significant improvements, while still recognizing significant challenges in the translation of complex compounds, philosophical concepts, and multi-layered metaphors. We also analyze how in-context learning on this dataset impacts the performance of commercial models", "AI": {"tldr": "本文介绍了Mitrasamgraha，一个包含391,548个双语对的高质量梵语-英语机器翻译数据集，是目前最大的梵语数据集的四倍以上。该数据集覆盖了跨越三千多年的广泛历史和领域，并提供时间段和领域标注，用于研究其对机器翻译性能的影响。通过在现有模型上进行基准测试和微调，研究表明该数据集显著提高了翻译性能，但仍存在复杂化合物、哲学概念和多层隐喻翻译的挑战。", "motivation": "高资源语言的机器翻译虽已取得进展，但对于梵语等语言，其诗意、哲学、隐喻等复杂性以及语言本身的特性（如词汇连写、复合词、重构）仍构成挑战。目前公开的梵语资源匮乏，无法充分覆盖其不同领域和历史时期。", "method": "构建了一个包含391,548个梵语-英语双语对的数据集Mitrasamgraha，并发布了验证集（5,587对）和测试集（5,552对）。利用该数据集对商业和开源机器翻译模型进行了基准测试，并对NLLB和Gemma模型进行了微调。此外，还分析了上下文学习对商业模型性能的影响。", "result": "Mitrasamgraha数据集显著提升了NLLB和Gemma模型的梵语-英语翻译性能。然而，在翻译复杂的复合词、哲学概念和多层隐喻方面，模型仍面临显著挑战。上下文学习对商业模型性能有一定影响。", "conclusion": "Mitrasamgraha数据集为梵语机器翻译研究提供了宝贵的资源，能够支持对领域和时间段效应的细粒度研究。尽管模型性能有所提升，但梵语翻译的复杂性仍然是未来研究的重要方向。"}}
{"id": "2601.07525", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07525", "abs": "https://arxiv.org/abs/2601.07525", "authors": ["Ngoc Trinh Hung Nguyen", "Alonso Silva", "Laith Zumot", "Liubov Tupikina", "Armen Aghasaryan", "Mehwish Alam"], "title": "Thinking Before Constraining: A Unified Decoding Framework for Large Language Models", "comment": null, "summary": "Natural generation allows Language Models (LMs) to produce free-form responses with rich reasoning, but the lack of guaranteed structure makes outputs difficult to parse or verify. Structured generation, or constrained decoding, addresses this drawback by producing content in standardized formats such as JSON, ensuring consistency and guaranteed-parsable outputs, but it can inadvertently restrict the model's reasoning capabilities. In this work, we propose a simple approach that combines the advantages of both natural and structured generation. By allowing LLMs to reason freely until specific trigger tokens are generated, and then switching to structured generation, our method preserves the expressive power of natural language reasoning while ensuring the reliability of structured outputs. We further evaluate our approach on several datasets, covering both classification and reasoning tasks, to demonstrate its effectiveness, achieving a substantial gain of up to 27% in accuracy compared to natural generation, while requiring only a small overhead of 10-20 extra tokens.", "AI": {"tldr": "提出了一种结合自然语言生成和结构化生成的混合方法，通过在特定触发词后切换到结构化生成，既保留了自由推理能力，又保证了输出的结构化和可解析性，在分类和推理任务上显著提高了准确率。", "motivation": "自然语言生成缺乏结构性，难以解析和验证；结构化生成虽然保证了结构，但可能限制模型推理能力。现有方法存在二选一的局限。", "method": "提出一种混合生成方法，允许语言模型自由推理直到生成特定触发词，然后切换到结构化生成模式。通过在多个数据集上进行评估。", "result": "与纯自然生成相比，准确率最高可提升27%，且仅增加10-20个额外token，开销很小。", "conclusion": "该混合生成方法有效结合了自然语言推理的表达力和结构化生成的可靠性，在保证输出结构化的同时，提升了模型性能。"}}
{"id": "2601.07462", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07462", "abs": "https://arxiv.org/abs/2601.07462", "authors": ["Shikang Zheng", "Guantao Chen", "Lixuan He", "Jiacheng Liu", "Yuqi Lin", "Chang Zou", "Linfeng Zhang"], "title": "From Sketch to Fresco: Efficient Diffusion Transformer with Progressive Resolution", "comment": null, "summary": "Diffusion Transformers achieve impressive generative quality but remain computationally expensive due to iterative sampling. Recently, dynamic resolution sampling has emerged as a promising acceleration technique by reducing the resolution of early sampling steps. However, existing methods rely on heuristic re-noising at every resolution transition, injecting noise that breaks cross-stage consistency and forces the model to relearn global structure. In addition, these methods indiscriminately upsample the entire latent space at once without checking which regions have actually converged, causing accumulated errors, and visible artifacts. Therefore, we propose \\textbf{Fresco}, a dynamic resolution framework that unifies re-noise and global structure across stages with progressive upsampling, preserving both the efficiency of low-resolution drafting and the fidelity of high-resolution refinement, with all stages aligned toward the same final target. Fresco achieves near-lossless acceleration across diverse domains and models, including 10$\\times$ speedup on FLUX, and 5$\\times$ on HunyuanVideo, while remaining orthogonal to distillation, quantization and feature caching, reaching 22$\\times$ speedup when combined with distilled models. Our code is in supplementary material and will be released on Github.", "AI": {"tldr": "本文提出了Fresco，一种动态分辨率框架，通过统一的再加噪和渐进式上采样来加速扩散Transformer模型，从而在保持生成质量的同时显著提高效率。", "motivation": "现有的动态分辨率采样方法在分辨率转换时进行启发式再加噪，这会破坏跨阶段的一致性并迫使模型重新学习全局结构。此外，这些方法一次性无差别地上采样整个潜在空间，没有检查哪些区域已经收敛，导致误差累积和可见的伪影。", "method": "Fresco采用动态分辨率框架，通过渐进式上采样统一跨阶段的再加噪和全局结构。它保留了低分辨率草稿的效率和高分辨率精炼的保真度，所有阶段都对齐到相同的最终目标。", "result": "Fresco在不同领域和模型上实现了近乎无损的加速，在FLUX上实现了10倍加速，在HunyuanVideo上实现了5倍加速。当与蒸馏模型结合时，可达到22倍的加速。", "conclusion": "Fresco是一种高效的动态分辨率框架，能够显著加速扩散Transformer模型，同时保持生成质量，并且可以与其他加速技术（如蒸馏）协同工作。"}}
{"id": "2601.07528", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07528", "abs": "https://arxiv.org/abs/2601.07528", "authors": ["Gagan Bhatia", "Hamdy Mubarak", "Mustafa Jarrar", "George Mikros", "Fadi Zaraket", "Mahmoud Alhirthani", "Mutaz Al-Khatib", "Logan Cochrane", "Kareem Darwish", "Rashid Yahiaoui", "Firoj Alam"], "title": "From RAG to Agentic RAG for Faithful Islamic Question Answering", "comment": null, "summary": "LLMs are increasingly used for Islamic question answering, where ungrounded responses may carry serious religious consequences. Yet standard MCQ/MRC-style evaluations do not capture key real-world failure modes, notably free-form hallucinations and whether models appropriately abstain when evidence is lacking. To shed a light on this aspect we introduce ISLAMICFAITHQA, a 3,810-item bilingual (Arabic/English) generative benchmark with atomic single-gold answers, which enables direct measurement of hallucination and abstention. We additionally developed an end-to-end grounded Islamic modelling suite consisting of (i) 25K Arabic text-grounded SFT reasoning pairs, (ii) 5K bilingual preference samples for reward-guided alignment, and (iii) a verse-level Qur'an retrieval corpus of $\\sim$6k atomic verses (ayat). Building on these resources, we develop an agentic Quran-grounding framework (agentic RAG) that uses structured tool calls for iterative evidence seeking and answer revision. Experiments across Arabic-centric and multilingual LLMs show that retrieval improves correctness and that agentic RAG yields the largest gains beyond standard RAG, achieving state-of-the-art performance and stronger Arabic-English robustness even with a small model (i.e., Qwen3 4B). We will make the experimental resources and datasets publicly available for the community.", "AI": {"tldr": "该研究提出了ISLAMICFAITHQA数据集和基于代理的RAG框架，以解决伊斯兰问答中LLM的幻觉和不当弃权问题，并在实验中展示了其有效性。", "motivation": "标准的问答评估方法无法捕捉到大型语言模型（LLMs）在伊斯兰问答领域中不接地回答可能带来的严重宗教后果，特别是自由形式的幻觉和在证据不足时未能适当弃权的问题。", "method": "研究者构建了一个名为ISLAMICFAITHQA的双语（阿拉伯语/英语）生成式基准，包含3,810个具有原子单金答案的项目，以直接衡量幻觉和弃权。他们还开发了一个端到端的伊斯兰建模套件，包括SFT推理对、偏好样本和古兰经检索语料库。在此基础上，他们构建了一个代理式古兰经接地框架（agentic RAG），利用结构化工具调用进行迭代证据搜寻和答案修正。", "result": "实验表明，检索能够提高正确率，并且代理式RAG相比标准RAG能带来最大的性能提升。即使使用较小的模型（Qwen3 4B），该方法也达到了最先进的性能，并展现了更强的阿拉伯语-英语鲁棒性。", "conclusion": "该研究提出的ISLAMICFAITHQA数据集和代理式RAG框架能够有效地解决伊斯兰问答中LLM的幻觉和弃权问题，并通过迭代证据搜寻和答案修正来提高模型性能和鲁棒性。"}}
{"id": "2601.07483", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07483", "abs": "https://arxiv.org/abs/2601.07483", "authors": ["Fuyuan Liu", "Dianyu Yu", "He Ren", "Nayu Liu", "Xiaomian Kang", "Delai Qiu", "Fa Zhang", "Genpeng Zhen", "Shengping Liu", "Jiaen Liang", "Wei Huang", "Yining Wang", "Junnan Zhu"], "title": "FocalOrder: Focal Preference Optimization for Reading Order Detection", "comment": null, "summary": "Reading order detection is the foundation of document understanding. Most existing methods rely on uniform supervision, implicitly assuming a constant difficulty distribution across layout regions. In this work, we challenge this assumption by revealing a critical flaw: \\textbf{Positional Disparity}, a phenomenon where models demonstrate mastery over the deterministic start and end regions but suffer a performance collapse in the complex intermediate sections. This degradation arises because standard training allows the massive volume of easy patterns to drown out the learning signals from difficult layouts. To address this, we propose \\textbf{FocalOrder}, a framework driven by \\textbf{Focal Preference Optimization (FPO)}. Specifically, FocalOrder employs adaptive difficulty discovery with exponential moving average mechanism to dynamically pinpoint hard-to-learn transitions, while introducing a difficulty-calibrated pairwise ranking objective to enforce global logical consistency. Extensive experiments demonstrate that FocalOrder establishes new state-of-the-art results on OmniDocBench v1.0 and Comp-HRDoc. Our compact model not only outperforms competitive specialized baselines but also significantly surpasses large-scale general VLMs. These results demonstrate that aligning the optimization with intrinsic structural ambiguity of documents is critical for mastering complex document structures.", "AI": {"tldr": "本文提出了一种名为 FocalOrder 的阅读顺序检测框架，通过焦点偏好优化（FPO）来解决现有方法在文档中间区域表现不佳的问题，并在 OmniDocBench v1.0 和 Comp-HRDoc 数据集上取得了最先进的性能。", "motivation": "现有阅读顺序检测方法普遍依赖统一监督，假设不同布局区域难度分布一致。然而，作者发现“位置差异”现象，即模型在文档的起始和结束区域表现良好，但在复杂的中间区域性能急剧下降。这源于大量简单的模式掩盖了困难布局的学习信号。", "method": "FocalOrder 框架的核心是焦点偏好优化（FPO）。它采用自适应难度发现（利用指数移动平均机制）来动态识别难学转换，并引入了难度校准的成对排序目标来强制全局逻辑一致性。", "result": "FocalOrder 在 OmniDocBench v1.0 和 Comp-HRDoc 数据集上取得了新的最先进成果。其模型不仅优于竞争性的专用基线，而且显著超越了大规模通用视觉语言模型（VLMs）。", "conclusion": "将优化与文档的内在结构歧义对齐，对于掌握复杂的文档结构至关重要。FocalOrder 证明了通过解决“位置差异”问题，可以显著提升阅读顺序检测的性能。"}}
{"id": "2601.07329", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07329", "abs": "https://arxiv.org/abs/2601.07329", "authors": ["Xuan Li", "Yining Wang", "Haocai Luo", "Shengping Liu", "Jerry Liang", "Ying Fu", "Weihuang", "Jun Yu", "Junnan Zhu"], "title": "BayesRAG: Probabilistic Mutual Evidence Corroboration for Multimodal Retrieval-Augmented Generation", "comment": "17 pages, 8 figures", "summary": "Retrieval-Augmented Generation (RAG) has become a pivotal paradigm for Large Language Models (LLMs), yet current approaches struggle with visually rich documents by treating text and images as isolated retrieval targets. Existing methods relying solely on cosine similarity often fail to capture the semantic reinforcement provided by cross-modal alignment and layout-induced coherence. To address these limitations, we propose BayesRAG, a novel multimodal retrieval framework grounded in Bayesian inference and Dempster-Shafer evidence theory. Unlike traditional approaches that rank candidates strictly by similarity, BayesRAG models the intrinsic consistency of retrieved candidates across modalities as probabilistic evidence to refine retrieval confidence. Specifically, our method computes the posterior association probability for combinations of multimodal retrieval results, prioritizing text-image pairs that mutually corroborate each other in terms of both semantics and layout. Extensive experiments demonstrate that BayesRAG significantly outperforms state-of-the-art (SOTA) methods on challenging multimodal benchmarks. This study establishes a new paradigm for multimodal retrieval fusion that effectively resolves the isolation of heterogeneous modalities through an evidence fusion mechanism and enhances the robustness of retrieval outcomes. Our code is available at https://github.com/TioeAre/BayesRAG.", "AI": {"tldr": "提出了一种名为BayesRAG的新型多模态检索框架，该框架基于贝叶斯推理和Dempster-Shafer证据理论，解决了现有RAG方法在处理视觉丰富文档时文本和图像分离的问题，通过整合跨模态和布局信息来提高检索性能。", "motivation": "现有RAG方法在处理包含大量图像的文档时，将文本和图像视为独立的检索目标，忽略了它们之间的语义关联和布局信息，导致检索效果不佳。BayesRAG旨在解决这种跨模态信息隔离的问题。", "method": "BayesRAG框架利用贝叶斯推理和Dempster-Shafer证据理论，将多模态检索结果视为概率证据。它计算多模态检索结果组合的后验关联概率，优先选择语义和布局上相互印证的图文对，从而提高检索置信度。", "result": "在具有挑战性的多模态基准测试中，BayesRAG显著优于最先进（SOTA）的方法，证明了其在多模态检索融合方面的有效性。", "conclusion": "BayesRAG通过证据融合机制有效解决了异构模态的隔离问题，增强了检索结果的鲁棒性，为多模态检索融合建立了一个新范式。"}}
{"id": "2601.07459", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07459", "abs": "https://arxiv.org/abs/2601.07459", "authors": ["Himanshu Patil", "Geo Jolly", "Ramana Raja Buddala", "Ganesh Ramakrishnan", "Rohit Saluja"], "title": "Improving Video Question Answering through query-based frame selection", "comment": null, "summary": "Video Question Answering (VideoQA) models enhance understanding and interaction with audiovisual content, making it more accessible, searchable, and useful for a wide range of fields such as education, surveillance, entertainment, and content creation. Due to heavy compute requirements, most large visual language models (VLMs) for VideoQA rely on a fixed number of frames by uniformly sampling the video. However, this process does not pick important frames or capture the context of the video. We present a novel query-based selection of frames relevant to the questions based on the submodular mutual Information (SMI) functions. By replacing uniform frame sampling with query-based selection, our method ensures that the chosen frames provide complementary and essential visual information for accurate VideoQA. We evaluate our approach on the MVBench dataset, which spans a diverse set of multi-action video tasks. VideoQA accuracy on this dataset was assessed using two VLMs, namely Video-LLaVA and LLaVA-NeXT, both of which originally employed uniform frame sampling. Experiments were conducted using both uniform and query-based sampling strategies. An accuracy improvement of up to \\textbf{4\\%} was observed when using query-based frame selection over uniform sampling. Qualitative analysis further highlights that query-based selection, using SMI functions, consistently picks frames better aligned with the question. We opine that such query-based frame selection can enhance accuracy in a wide range of tasks that rely on only a subset of video frames.", "AI": {"tldr": "提出了一种基于查询的子模态互信息（SMI）函数来选择与问题相关的视频帧，以取代统一采样，从而提高了视频问答（VideoQA）的准确性。", "motivation": "现有的VideoQA模型通常采用统一采样固定数量的视频帧，这种方法无法捕捉视频的关键帧和上下文信息，影响了模型的理解能力。", "method": "该研究提出了一种新颖的基于查询的帧选择方法，利用子模态互信息（SMI）函数来选择与问题相关的帧，从而取代了统一采样。该方法被集成到Video-LLaVA和LLaVA-NeXT两个VLM模型中。", "result": "在MVBench数据集上进行评估，与统一采样相比，基于查询的帧选择策略将VideoQA的准确率提高了高达4%。定性分析也表明，SMI函数选择的帧与问题更加契合。", "conclusion": "基于查询的帧选择方法（利用SMI函数）能够有效地选择对VideoQA至关重要的帧，从而提高模型的准确性。这种方法有望应用于其他需要从视频中提取关键帧的任务。"}}
{"id": "2601.07327", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07327", "abs": "https://arxiv.org/abs/2601.07327", "authors": ["Roberto Passaro", "Edith Haim", "Massimo Stella"], "title": "How to predict creativity ratings from written narratives: A comparison of co-occurrence and textual forma mentis networks", "comment": null, "summary": "This tutorial paper provides a step-by-step workflow for building and analysing semantic networks from short creative texts. We introduce and compare two widely used text-to-network approaches: word co-occurrence networks and textual forma mentis networks (TFMNs). We also demonstrate how they can be used in machine learning to predict human creativity ratings. Using a corpus of 1029 short stories, we guide readers through text preprocessing, network construction, feature extraction (structural measures, spreading-activation indices, and emotion scores), and application of regression models. We evaluate how network-construction choices influence both network topology and predictive performance. Across all modelling settings, TFMNs consistently outperformed co-occurrence networks through lower prediction errors (best MAE = 0.581 for TFMN, vs 0.592 for co-occurrence with window size 3). Network-structural features dominated predictive performance (MAE = 0.591 for TFMN), whereas emotion features performed worse (MAE = 0.711 for TFMN) and spreading-activation measures contributed little (MAE = 0.788 for TFMN). This paper offers practical guidance for researchers interested in applying network-based methods for cognitive fields like creativity research. we show when syntactic networks are preferable to surface co-occurrence models, and provide an open, reproducible workflow accessible to newcomers in the field, while also offering deeper methodological insight for experienced researchers.", "AI": {"tldr": "本教程介绍了从短篇创意文本构建和分析语义网络的工作流程，比较了词共现网络和文本心智图谱网络（TFMN），并展示了如何利用它们在机器学习中预测人类创造力评分。研究发现TFMN在预测性能上优于共现网络，其中网络结构特征对预测性能影响最大。", "motivation": "研究旨在为研究人员提供一个实际的、可复制的流程，用于构建和分析语义网络，以研究人类创造力等认知领域，并比较不同的文本到网络的方法。", "method": "论文提供了一个分步的工作流程，包括文本预处理、网络构建（词共现网络和TFMN）、特征提取（结构度量、传播激活指数、情感得分）和回归模型应用。使用1029个短篇故事语料库进行了实验。", "result": "TFMN在预测人类创造力评分方面优于词共现网络（TFMN的最佳平均绝对误差MAE为0.581，共现网络MAE为0.592）。网络结构特征对预测性能的影响最大（TFMN上MAE为0.591），而情感特征和传播激活特征的贡献较小。", "conclusion": "TFMN是分析创意文本的有效方法，比词共现网络在预测创造力方面表现更好。网络结构特征是预测模型中的关键因素。论文提供了一个实用的、可复现的工作流程，适合初学者和有经验的研究人员。"}}
{"id": "2601.07499", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07499", "abs": "https://arxiv.org/abs/2601.07499", "authors": ["Bing Yu", "Liu Shi", "Haitao Wang", "Deran Qi", "Xiang Cai", "Wei Zhong", "Qiegen Liu"], "title": "Anatomy Aware Cascade Network: Bridging Epistemic Uncertainty and Geometric Manifold for 3D Tooth Segmentation", "comment": null, "summary": "Accurate three-dimensional (3D) tooth segmentation from Cone-Beam Computed Tomography (CBCT) is a prerequisite for digital dental workflows. However, achieving high-fidelity segmentation remains challenging due to adhesion artifacts in naturally occluded scans, which are caused by low contrast and indistinct inter-arch boundaries. To address these limitations, we propose the Anatomy Aware Cascade Network (AACNet), a coarse-to-fine framework designed to resolve boundary ambiguity while maintaining global structural consistency. Specifically, we introduce two mechanisms: the Ambiguity Gated Boundary Refiner (AGBR) and the Signed Distance Map guided Anatomical Attention (SDMAA). The AGBR employs an entropy based gating mechanism to perform targeted feature rectification in high uncertainty transition zones. Meanwhile, the SDMAA integrates implicit geometric constraints via signed distance map to enforce topological consistency, preventing the loss of spatial details associated with standard pooling. Experimental results on a dataset of 125 CBCT volumes demonstrate that AACNet achieves a Dice Similarity Coefficient of 90.17 \\% and a 95\\% Hausdorff Distance of 3.63 mm, significantly outperforming state-of-the-art methods. Furthermore, the model exhibits strong generalization on an external dataset with an HD95 of 2.19 mm, validating its reliability for downstream clinical applications such as surgical planning. Code for AACNet is available at https://github.com/shiliu0114/AACNet.", "AI": {"tldr": "提出了一种名为AACNet的3D牙齿分割网络，通过引入AGBR和SDMAA机制，有效解决了CBCT扫描中因伪影导致的边界模糊问题，显著提升了分割精度和泛化能力。", "motivation": "现有CBCT扫描中的3D牙齿分割面临挑战，主要是由于自然咬合扫描中的粘连伪影，导致低对比度和模糊的牙弓边界，影响分割精度。", "method": "提出了一种名为AACNet（Anatomy Aware Cascade Network）的粗到细框架，包含两个关键机制：1. 歧义门控边界精炼器（AGBR），利用基于熵的门控机制处理高不确定性区域；2. 符号距离图引导的解剖注意力（SDMAA），通过符号距离图引入隐式几何约束，保持拓扑一致性。", "result": "在125个CBCT数据集上，AACNet实现了90.17%的Dice相似系数和3.63mm的95% Hausdorff距离，优于现有最先进的方法。在外部数据集上表现出良好的泛化能力，HD95为2.19mm。", "conclusion": "AACNet能够有效地解决CBCT牙齿分割中的边界模糊问题，实现高精度分割，并具有良好的泛化能力，适用于手术规划等临床应用。"}}
{"id": "2601.07280", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07280", "abs": "https://arxiv.org/abs/2601.07280", "authors": ["Changzai Pan", "Jie Zhang", "Kaiwen Wei", "Chenshuo Pan", "Yu Zhao", "Jingwang Huang", "Jian Yang", "Zhenhe Wu", "Haoyang Zeng", "Xiaoyan Gu", "Weichao Sun", "Yanbo Zhai", "Yujie Mao", "Zhuoru Jiang", "Jiang Zhong", "Shuangyong Song", "Yongxiang Li", "Zhongjiang He"], "title": "ReasonTabQA: A Comprehensive Benchmark for Table Question Answering from Real World Industrial Scenarios", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have significantly catalyzed table-based question answering (TableQA). However, existing TableQA benchmarks often overlook the intricacies of industrial scenarios, which are characterized by multi-table structures, nested headers, and massive scales. These environments demand robust table reasoning through deep structured inference, presenting a significant challenge that remains inadequately addressed by current methodologies. To bridge this gap, we present ReasonTabQA, a large-scale bilingual benchmark encompassing 1,932 tables across 30 industry domains such as energy and automotive. ReasonTabQA provides high-quality annotations for both final answers and explicit reasoning chains, supporting both thinking and no-thinking paradigms. Furthermore, we introduce TabCodeRL, a reinforcement learning method that leverages table-aware verifiable rewards to guide the generation of logical reasoning paths. Extensive experiments on ReasonTabQA and 4 TableQA datasets demonstrate that while TabCodeRL yields substantial performance gains on open-source LLMs, the persistent performance gap on ReasonTabQA underscores the inherent complexity of real-world industrial TableQA.", "AI": {"tldr": "本文提出了一个名为ReasonTabQA的大规模双语表格问答基准，旨在解决工业场景中多表格、嵌套表头和大规模表格推理的挑战。同时，引入了TabCodeRL强化学习方法，通过可验证奖励来改进推理路径生成。实验表明，TabCodeRL能提升LLM在现有数据集上的表现，但在ReasonTabQA上的表现仍有提升空间，凸显了工业场景TableQA的复杂性。", "motivation": "现有TableQA基准未能充分考虑工业场景的复杂性，如多表格、嵌套表头和大规模数据，这些场景需要更深层次的结构化推理能力。", "method": "构建了一个包含1932个表格、覆盖30个工业领域的大规模双语基准ReasonTabQA。该基准提供答案和推理链的标注。此外，提出了一种名为TabCodeRL的强化学习方法，使用表格感知的可验证奖励来指导逻辑推理路径的生成。", "result": "在ReasonTabQA和其他4个TableQA数据集上的实验表明，TabCodeRL显著提升了开源LLM的性能。然而，在ReasonTabQA上仍存在性能差距，表明该基准的难度。", "conclusion": "ReasonTabQA是一个能够反映工业场景复杂性的TableQA基准。TabCodeRL方法在表格推理方面取得了进展，但工业级TableQA的挑战依然严峻，需要进一步的研究。"}}
{"id": "2601.07565", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07565", "abs": "https://arxiv.org/abs/2601.07565", "authors": ["Jiaqi Qiao", "Xiujuan Xu", "Xinran Li", "Yu Liu"], "title": "A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models", "comment": null, "summary": "Multimodal emotion understanding requires effective integration of text, audio, and visual modalities for both discrete emotion recognition and continuous sentiment analysis. We present EGMF, a unified framework combining expert-guided multimodal fusion with large language models. Our approach features three specialized expert networks--a fine-grained local expert for subtle emotional nuances, a semantic correlation expert for cross-modal relationships, and a global context expert for long-range dependencies--adaptively integrated through hierarchical dynamic gating for context-aware feature selection. Enhanced multimodal representations are integrated with LLMs via pseudo token injection and prompt-based conditioning, enabling a single generative framework to handle both classification and regression through natural language generation. We employ LoRA fine-tuning for computational efficiency. Experiments on bilingual benchmarks (MELD, CHERMA, MOSEI, SIMS-V2) demonstrate consistent improvements over state-of-the-art methods, with superior cross-lingual robustness revealing universal patterns in multimodal emotional expressions across English and Chinese. We will release the source code publicly.", "AI": {"tldr": "本文提出了一种名为EGMF的统一框架，用于理解文本、音频和视觉模态的情感。该框架结合了专家引导的多模态融合和大语言模型（LLMs），通过三个专业专家网络（局部、语义相关性和全局上下文）以及分层动态门控机制，自适应地融合多模态特征。通过伪标记注入和基于提示的条件化，LLMs能够处理情感分类和回归任务。实验证明，EGMF在双语数据集上取得了优于现有方法的性能，并显示出跨语言的鲁棒性。", "motivation": "多模态情感理解需要有效融合文本、音频和视觉信息，以实现离散情感识别和连续情感分析。现有方法在处理不同模态间的细微情感、语义关联和长距离依赖方面仍有待提高，并且在跨语言场景下的鲁棒性不足。", "method": "该研究提出EGMF框架，包含三个专业专家网络：细粒度局部专家（捕捉细微情感）、语义相关性专家（处理跨模态关系）和全局上下文专家（关注长距离依赖）。这些专家通过分层动态门控机制自适应地集成。增强后的多模态表示通过伪标记注入和基于提示的条件化与LLMs进行融合，使其能够通过自然语言生成处理分类和回归任务。模型使用LoRA进行微调以提高计算效率。", "result": "在MELD、CHERMA、MOSEI和SIMS-V2等双语基准测试中，EGMF在情感识别和情感分析任务上均取得了显著的性能提升，优于现有最先进的方法。研究还发现，EGMF在跨语言（英语和中文）任务上表现出优越的鲁棒性，揭示了跨模态情感表达的普适性模式。", "conclusion": "EGMF框架成功地实现了统一的多模态情感理解，通过专家引导的融合和LLMs的结合，能够有效地处理文本、音频和视觉信息，并支持分类和回归任务。该框架在双语数据集上展现出优异的性能和跨语言鲁棒性，为未来的多模态情感研究提供了有效解决方案。"}}
{"id": "2601.07338", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07338", "abs": "https://arxiv.org/abs/2601.07338", "authors": ["Yanzhi Tian", "Cunxiang Wang", "Zeming Liu", "Heyan Huang", "Wenbo Yu", "Dawei Song", "Jie Tang", "Yuhang Guo"], "title": "Beyond Literal Mapping: Benchmarking and Improving Non-Literal Translation Evaluation", "comment": null, "summary": "Large Language Models (LLMs) have significantly advanced Machine Translation (MT), applying them to linguistically complex domains-such as Social Network Services, literature etc. In these scenarios, translations often require handling non-literal expressions, leading to the inaccuracy of MT metrics. To systematically investigate the reliability of MT metrics, we first curate a meta-evaluation dataset focused on non-literal translations, namely MENT. MENT encompasses four non-literal translation domains and features source sentences paired with translations from diverse MT systems, with 7,530 human-annotated scores on translation quality. Experimental results reveal the inaccuracies of traditional MT metrics and the limitations of LLM-as-a-Judge, particularly the knowledge cutoff and score inconsistency problem. To mitigate these limitations, we propose RATE, a novel agentic translation evaluation framework, centered by a reflective Core Agent that dynamically invokes specialized sub-agents. Experimental results indicate the efficacy of RATE, achieving an improvement of at least 3.2 meta score compared with current metrics. Further experiments demonstrate the robustness of RATE to general-domain MT evaluation. Code and dataset are available at: https://github.com/BITHLP/RATE.", "AI": {"tldr": "研究人员提出了MENT数据集来评估机器翻译（MT）在处理非字面翻译时的准确性，并发现现有指标和LLM-as-a-Judge存在局限性。为此，他们开发了一个名为RATE的新型评估框架，该框架通过反思性核心代理调用专门的子代理，并在非字面翻译评估中取得了显著的性能提升。", "motivation": "现有机器翻译指标在处理非字面翻译（如社交媒体、文学作品等领域）时不够准确，并且LLM-as-a-Judge方法存在知识截止和分数不一致的问题。作者希望系统地研究MT指标的可靠性，并提出一种更有效的评估方法。", "method": "1. 收集和标注了一个专注于非字面翻译的元评估数据集MENT，包含四个领域、7530个评分。2. 评估了传统MT指标和LLM-as-a-Judge在MENT上的表现。3. 提出了RATE框架，一个以反思性核心代理为中心、动态调用专业子代理的代理式翻译评估框架。4. 在MENT数据集上进行了实验，并将RATE与其他指标进行了比较。", "result": "传统MT指标和LLM-as-a-Judge在MENT数据集上表现出不准确和局限性。RATE框架在非字面翻译评估中取得了至少3.2分的性能提升，优于现有指标。RATE在通用领域MT评估中也展现出稳健性。", "conclusion": "所提出的MENT数据集和RATE框架能够更准确地评估机器翻译在处理非字面表达时的质量。RATE通过引入代理式协同评估机制，有效克服了现有评估方法的不足，为MT评估提供了一种新的有效途径。"}}
{"id": "2601.07582", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07582", "abs": "https://arxiv.org/abs/2601.07582", "authors": ["Huhai Zou", "Tianhao Sun", "Chuanjiang He", "Yu Tian", "Zhenyang Li", "Li Jin", "Nayu Liu", "Jiang Zhong", "Kaiwen Wei"], "title": "ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents", "comment": null, "summary": "Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. While existing memory mechanisms offer basic storage and retrieval capabilities, they are hindered by two primary limitations: (1) rigid memory granularity often disrupts semantic integrity, resulting in fragmented and incoherent memory units; (2) prevalent flat retrieval paradigms rely solely on surface-level semantic similarity, neglecting the structural cues of discourse required to navigate and locate specific episodic contexts. To mitigate these limitations, drawing inspiration from Event Segmentation Theory, we propose ES-Mem, a framework incorporating two core components: (1) a dynamic event segmentation module that partitions long-term interactions into semantically coherent events with distinct boundaries; (2) a hierarchical memory architecture that constructs multi-layered memories and leverages boundary semantics to anchor specific episodic memory for precise context localization. Evaluations on two memory benchmarks demonstrate that ES-Mem yields consistent performance gains over baseline methods. Furthermore, the proposed event segmentation module exhibits robust applicability on dialogue segmentation datasets.", "AI": {"tldr": "本文提出了ES-Mem框架，通过动态事件分割和分层记忆架构来解决现有对话记忆机制中存在的内存粒度僵化和检索方式单一的问题，以提高长期对话的连贯性和适应性。", "motivation": "现有对话记忆机制在处理长期对话时存在两个主要问题：1) 僵化的内存粒度破坏了语义的完整性，导致记忆单元碎片化和不连贯；2) 平坦的检索方法仅依赖表面语义相似性，忽略了导航和定位特定情境所需的语篇结构线索。", "method": "ES-Mem框架包含两个核心组件：1) 动态事件分割模块，将长期对话分割成具有清晰边界的、语义连贯的事件；2) 分层记忆架构，构建多层记忆，并利用事件边界的语义来锚定特定的情境记忆，实现精确的上下文定位。", "result": "在两个记忆基准测试上的评估表明，ES-Mem相对于基线方法具有持续的性能提升。此外，提出的事件分割模块在对话分割数据集上表现出强大的适用性。", "conclusion": "ES-Mem框架通过引入事件分割和分层记忆机制，有效克服了现有对话记忆方法的局限性，能够更准确地定位和检索对话情境，从而提升对话代理在长期交互中的表现。"}}
{"id": "2601.07540", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07540", "abs": "https://arxiv.org/abs/2601.07540", "authors": ["Farhad G. Zanjani", "Hong Cai", "Amirhossein Habibian"], "title": "ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving", "comment": "Paper and supplementary materials", "summary": "Autonomous driving systems rely heavily on multi-view images to ensure accurate perception and robust decision-making. To effectively develop and evaluate perception stacks and planning algorithms, realistic closed-loop simulators are indispensable. While 3D reconstruction techniques such as Gaussian Splatting offer promising avenues for simulator construction, the rendered novel views often exhibit artifacts, particularly in extrapolated perspectives or when available observations are sparse.\n  We introduce ViewMorpher3D, a multi-view image enhancement framework based on image diffusion models, designed to elevate photorealism and multi-view coherence in driving scenes. Unlike single-view approaches, ViewMorpher3D jointly processes a set of rendered views conditioned on camera poses, 3D geometric priors, and temporally adjacent or spatially overlapping reference views. This enables the model to infer missing details, suppress rendering artifacts, and enforce cross-view consistency.\n  Our framework accommodates variable numbers of cameras and flexible reference/target view configurations, making it adaptable to diverse sensor setups. Experiments on real-world driving datasets demonstrate substantial improvements in image quality metrics, effectively reducing artifacts while preserving geometric fidelity.", "AI": {"tldr": "提出ViewMorpher3D，一种基于扩散模型的框架，用于增强自动驾驶模拟器中多视角渲染图像的真实感和一致性。", "motivation": "现有3D重建技术（如高斯泼溅）在生成新视角图像时存在伪影，尤其是在外推视角或观测稀疏时，影响了自动驾驶感知和规划算法的开发和评估。", "method": "ViewMorpher3D利用扩散模型，联合处理一组渲染视图，并以相机位姿、3D几何先验以及时空重叠的参考视图作为条件，以推断缺失细节、抑制渲染伪影并强制跨视图一致性。", "result": "在真实驾驶数据集上的实验表明，ViewMorpher3D在图像质量指标上取得了显著提升，有效减少了伪影，同时保持了几何保真度。", "conclusion": "ViewMorpher3D是一个有效的多视角图像增强框架，能够提升自动驾驶模拟器的真实感和多视角一致性，并且能够适应不同的传感器配置。"}}
{"id": "2601.07347", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07347", "abs": "https://arxiv.org/abs/2601.07347", "authors": ["Shaokai He", "Kaiwen Wei", "Xinyi Zeng", "Xiang Chen", "Xue Yang", "Zhenyang Li", "Jiang Zhong", "Yu Tian"], "title": "DiffER: Diffusion Entity-Relation Modeling for Reversal Curse in Diffusion Large Language Models", "comment": null, "summary": "The \"reversal curse\" refers to the phenomenon where large language models (LLMs) exhibit predominantly unidirectional behavior when processing logically bidirectional relationships. Prior work attributed this to autoregressive training -- predicting the next token inherently favors left-to-right information flow over genuine bidirectional knowledge associations. However, we observe that Diffusion LLMs (DLLMs), despite being trained bidirectionally, also suffer from the reversal curse. To investigate the root causes, we conduct systematic experiments on DLLMs and identify three key reasons: 1) entity fragmentation during training, 2) data asymmetry, and 3) missing entity relations. Motivated by the analysis of these reasons, we propose Diffusion Entity-Relation Modeling (DiffER), which addresses the reversal curse through entity-aware training and balanced data construction. Specifically, DiffER introduces whole-entity masking, which mitigates entity fragmentation by predicting complete entities in a single step. DiffER further employs distribution-symmetric and relation-enhanced data construction strategies to alleviate data asymmetry and missing relations. Extensive experiments demonstrate that DiffER effectively alleviates the reversal curse in Diffusion LLMs, offering new perspectives for future research.", "AI": {"tldr": "本研究发现，即使是双向训练的Diffusion LLMs（DLLMs）也存在“反转诅咒”现象，即它们难以处理逻辑上的双向关系。研究通过实体碎片化、数据不对称和缺失实体关系三个关键原因，提出了名为DiffER的Diffusion实体-关系建模方法，通过整实体掩码、分布对称和关系增强数据构建等策略来解决反转诅咒问题，并在实验中验证了其有效性。", "motivation": "现有研究将大型语言模型（LLMs）的“反转诅咒”现象归因于自回归训练的单向性。然而，本研究发现即使是经过双向训练的Diffusion LLMs（DLLMs）也存在此问题，这促使研究者深入探究其根本原因。", "method": "研究者通过系统性的实验，识别出导致DLLMs反转诅咒的三个关键原因：1) 训练过程中的实体碎片化；2) 数据不对称；3) 缺失的实体关系。在此基础上，提出了Diffusion实体-关系建模（DiffER）方法，该方法通过“整实体掩码”（whole-entity masking）来预测完整的实体，以缓解实体碎片化；并通过“分布对称”和“关系增强”的数据构建策略来解决数据不对称和缺失关系的问题。", "result": "实验结果表明，DiffER方法能够有效地缓解Diffusion LLMs的反转诅咒现象，显著提升了模型在处理双向关系时的性能。", "conclusion": "本研究揭示了DLLMs出现反转诅咒的深层原因，并提出了DiffER这一有效的解决方案，为未来在Diffusion模型中处理双向关系的研究提供了新的思路和方向。"}}
{"id": "2601.07581", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07581", "abs": "https://arxiv.org/abs/2601.07581", "authors": ["Ahmad AlMughrabi", "Guillermo Rivo", "Carlos Jiménez-Farfán", "Umair Haroon", "Farid Al-Areqi", "Hyunjun Jung", "Benjamin Busam", "Ricardo Marques", "Petia Radeva"], "title": "BenchSeg: A Large-Scale Dataset and Benchmark for Multi-View Food Video Segmentation", "comment": null, "summary": "Food image segmentation is a critical task for dietary analysis, enabling accurate estimation of food volume and nutrients. However, current methods suffer from limited multi-view data and poor generalization to new viewpoints. We introduce BenchSeg, a novel multi-view food video segmentation dataset and benchmark. BenchSeg aggregates 55 dish scenes (from Nutrition5k, Vegetables & Fruits, MetaFood3D, and FoodKit) with 25,284 meticulously annotated frames, capturing each dish under free 360° camera motion. We evaluate a diverse set of 20 state-of-the-art segmentation models (e.g., SAM-based, transformer, CNN, and large multimodal) on the existing FoodSeg103 dataset and evaluate them (alone and combined with video-memory modules) on BenchSeg. Quantitative and qualitative results demonstrate that while standard image segmenters degrade sharply under novel viewpoints, memory-augmented methods maintain temporal consistency across frames. Our best model based on a combination of SeTR-MLA+XMem2 outperforms prior work (e.g., improving over FoodMem by ~2.63% mAP), offering new insights into food segmentation and tracking for dietary analysis. We release BenchSeg to foster future research. The project page including the dataset annotations and the food segmentation models can be found at https://amughrabi.github.io/benchseg.", "AI": {"tldr": "本文提出了BenchSeg，一个包含55个菜肴场景、25,284帧的多视角食物视频分割数据集和基准，以解决现有食物分割方法在多视角和新视角下泛化能力不足的问题。评估结果表明，内存增强方法在处理新视角时比标准图像分割器表现更好，并提出了一个改进的模型SeTR-MLA+XMem2。", "motivation": "现有食物分割方法在面对多视角和新视角时泛化能力有限，影响了准确的食物体积和营养估算。", "method": "构建了一个名为BenchSeg的多视角食物视频分割数据集，该数据集包含25,284帧，覆盖55个菜肴场景，并允许360°相机自由移动。在BenchSeg上评估了20种先进的分割模型，包括标准图像分割器和结合视频记忆模块的增强方法。", "result": "标准图像分割器在新的视角下性能急剧下降，而内存增强方法能保持跨帧的时间一致性。基于SeTR-MLA+XMem2的最佳模型在mAP上比FoodMem提高了约2.63%，在食物分割和追踪方面提供了新见解。", "conclusion": "BenchSeg数据集的发布为食物分割研究提供了新的资源。内存增强方法在处理多视角食物分割任务方面展现出比标准图像分割器更优越的性能和泛化能力，为提高饮食分析的准确性提供了可能。"}}
{"id": "2601.07349", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07349", "abs": "https://arxiv.org/abs/2601.07349", "authors": ["Zongqi Wang", "Rui Wang", "Yuchuan Wu", "Yiyao Yu", "Pinyi Zhang", "Shaoning Sun", "Yujiu Yang", "Yongbin Li"], "title": "Reward Modeling from Natural Language Human Feedback", "comment": null, "summary": "Reinforcement Learning with Verifiable reward (RLVR) on preference data has become the mainstream approach for training Generative Reward Models (GRMs). Typically in pairwise rewarding tasks, GRMs generate reasoning chains ending with critiques and preference labels, and RLVR then relies on the correctness of the preference labels as the training reward. However, in this paper, we demonstrate that such binary classification tasks make GRMs susceptible to guessing correct outcomes without sound critiques. Consequently, these spurious successes introduce substantial noise into the reward signal, thereby impairing the effectiveness of reinforcement learning. To address this issue, we propose Reward Modeling from Natural Language Human Feedback (RM-NLHF), which leverages natural language feedback to obtain process reward signals, thereby mitigating the problem of limited solution space inherent in binary tasks. Specifically, we compute the similarity between GRM-generated and human critiques as the training reward, which provides more accurate reward signals than outcome-only supervision. Additionally, considering that human critiques are difficult to scale up, we introduce Meta Reward Model (MetaRM) which learns to predict process reward from datasets with human critiques and then generalizes to data without human critiques. Experiments on multiple benchmarks demonstrate that our method consistently outperforms state-of-the-art GRMs trained with outcome-only reward, confirming the superiority of integrating natural language over binary human feedback as supervision.", "AI": {"tldr": "该研究提出了一种名为RM-NLHF的方法，通过利用自然语言反馈来改进生成奖励模型（GRM）的训练，解决了现有基于偏好数据的方法容易导致GRM“猜对”而无实质性改进的问题，并通过MetaRM解决了人类反馈规模化难题。", "motivation": "现有的基于偏好数据的RLVR方法（使用二元偏好标签作为奖励）容易导致GRM通过猜测获得正确的偏好结果，而忽视了提供有意义的解释，这种“虚假成功”引入了噪声，削弱了强化学习的效果。研究旨在解决二元分类任务的局限性，提高奖励信号的准确性。", "method": "提出RM-NLHF方法，利用自然语言反馈（人类的评论）来获取“过程奖励信号”，而非仅仅依赖最终的偏好标签。具体做法是计算GRM生成的评论与人类评论之间的相似度作为训练奖励。此外，为了解决人类评论难以规模化的问题，引入MetaRM，该模型学习从有人类评论的数据集中预测过程奖励，并将其泛化到没有人类评论的数据集。", "result": "在多个基准测试中，所提出的RM-NLHF方法在集成自然语言反馈作为监督信号方面，一致优于使用仅结果监督的最新GRM。", "conclusion": "将自然语言反馈（人类评论）集成到奖励模型训练中，能够提供比仅依赖二元偏好标签更准确的奖励信号，从而显著提升了生成奖励模型的性能。MetaRM技术能够有效解决人工反馈难以规模化的问题。"}}
{"id": "2601.07606", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07606", "abs": "https://arxiv.org/abs/2601.07606", "authors": ["Bingyang Ye", "Shan Chen", "Jingxuan Tu", "Chen Liu", "Zidi Xiong", "Samuel Schmidgall", "Danielle S. Bitterman"], "title": "Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments", "comment": "under review", "summary": "Large language models are increasingly being used to assess and forecast research ideas, yet we lack scalable ways to evaluate the quality of models' judgments about these scientific ideas. Towards this goal, we introduce PoT, a semi-verifiable benchmarking framework that links scientific idea judgments to downstream signals that become observable later (e.g., citations and shifts in researchers' agendas). PoT freezes a pre-cutoff snapshot of evidence in an offline sandbox and asks models to forecast post-cutoff outcomes, enabling verifiable evaluation when ground truth arrives, scalable benchmarking without exhaustive expert annotation, and analysis of human-model misalignment against signals such as peer-review awards. In addition, PoT provides a controlled testbed for agent-based research judgments that evaluate scientific ideas, comparing tool-using agents to non-agent baselines under prompt ablations and budget scaling. Across 30,000+ instances spanning four benchmark domains, we find that, compared with non-agent baselines, higher interaction budgets generally improve agent performance, while the benefit of tool use is strongly task-dependent. By combining time-partitioned, future-verifiable targets with an offline sandbox for tool use, PoT supports scalable evaluation of agents on future-facing scientific idea judgment tasks.", "AI": {"tldr": "本文提出了一个名为PoT的半可验证基准框架，用于评估大型语言模型在科学研究想法评估和预测方面的能力。PoT通过离线沙盒冻结模型使用前的证据，并要求模型预测后续结果，从而实现可验证的评估，并支持大规模基准测试。", "motivation": "当前缺乏可扩展的方法来评估大型语言模型在评估和预测科学研究想法方面的质量。现有的评估方法通常需要耗费大量专家标注，难以规模化。", "method": "PoT框架首先在离线沙盒中冻结一个预设时间点之前的证据快照。然后，要求模型预测该时间点之后的下游信号（如引用数、研究者议程转移等）。当真实结果出现时，可以进行可验证的评估。此外，PoT还提供了一个受控的测试环境，用于评估基于代理的研究判断，通过比较使用工具和不使用工具的代理在不同提示和预算下的表现。", "result": "在涵盖四个基准领域的30,000多个实例中，研究发现，与不使用工具的基线模型相比，更高的交互预算通常能提高代理模型的性能。而工具使用的效益则高度依赖于具体任务。研究还分析了人类与模型的错位现象，例如与同行评审奖项等信号的对比。", "conclusion": "PoT框架结合了时间分割、未来可验证的目标以及用于工具使用的离线沙盒，能够对模型执行面向未来的科学研究想法判断任务进行大规模评估，并为研究工具使用和交互预算对代理模型性能的影响提供了见解。"}}
{"id": "2601.07632", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07632", "abs": "https://arxiv.org/abs/2601.07632", "authors": ["Zhankai Ye", "Bofan Li", "Yukai Jin", "Shuoqiu Li", "Wei Wang", "Yanfu Zhang", "Shangqian Gao", "Xin Liu"], "title": "GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models", "comment": null, "summary": "Discrete motion tokenization has recently enabled Large Language Models (LLMs) to serve as versatile backbones for motion understanding and motion-language reasoning. However, existing pipelines typically decouple motion quantization from semantic embedding learning, linking them solely via token IDs. This approach fails to effectively align the intrinsic geometry of the motion space with the embedding space, thereby hindering the LLM's capacity for nuanced motion reasoning. We argue that alignment is most effective when both modalities share a unified geometric basis. Therefore, instead of forcing the LLM to reconstruct the complex geometry among motion tokens from scratch, we present a novel framework that explicitly enforces orthogonality on both the motion codebook and the LLM embedding space, ensuring that their relational structures naturally mirror each other. Specifically, we employ a decoder-only quantizer with Gumbel-Softmax for differentiable training and balanced codebook usage. To bridge the modalities, we use a sparse projection that maps motion codes into the LLM embedding space while preserving orthogonality. Finally, a two-stage orthonormal regularization schedule enforces soft constraints during tokenizer training and LLM fine-tuning to maintain geometric alignment without hindering semantic adaptation. Extensive experiments on HumanML3D demonstrate that our framework achieves a 20% performance improvement over current state-of-the-art methods, validating that a unified geometric basis effectively empowers the LLM for nuanced motion reasoning.", "AI": {"tldr": "该研究提出了一种新的框架，通过在运动量化和LLM嵌入空间中强制执行正交性，来统一运动空间和嵌入空间的几何结构，从而提高LLM在运动理解和推理方面的能力。", "motivation": "现有的运动量化和语义嵌入学习方法在概念上是分离的，仅通过token ID关联，未能有效对齐运动空间和嵌入空间的内在几何结构，限制了LLM进行细致运动推理的能力。", "method": "该框架采用了一种结合了Gumbel-Softmax的可微解码器模型进行运动量化，并通过稀疏投影将运动编码映射到LLM嵌入空间，同时保持正交性。此外，还采用了两阶段的正交正则化策略来训练量化器和微调LLM，以保持几何对齐。", "result": "在HumanML3D数据集上的实验表明，该框架相比现有最先进的方法在性能上提升了20%。", "conclusion": "研究结论是，统一的几何基础能够有效地增强LLM进行细致运动推理的能力，并且通过在运动代码本和LLM嵌入空间中强制正交性是实现这种统一的有效途径。"}}
{"id": "2601.07585", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07585", "abs": "https://arxiv.org/abs/2601.07585", "authors": ["Shruti Atul Mali", "Zohaib Salahuddin", "Yumeng Zhang", "Andre Aichert", "Xian Zhong", "Henry C. Woodruff", "Maciej Bobowicz", "Katrine Riklund", "Juozas Kupčinskas", "Lorenzo Faggioni", "Roberto Francischello", "Razvan L Miclea", "Philippe Lambin"], "title": "Robust Multicentre Detection and Classification of Colorectal Liver Metastases on CT: Application of Foundation Models", "comment": null, "summary": "Colorectal liver metastases (CRLM) are a major cause of cancer-related mortality, and reliable detection on CT remains challenging in multi-centre settings. We developed a foundation model-based AI pipeline for patient-level classification and lesion-level detection of CRLM on contrast-enhanced CT, integrating uncertainty quantification and explainability. CT data from the EuCanImage consortium (n=2437) and an external TCIA cohort (n=197) were used. Among several pretrained models, UMedPT achieved the best performance and was fine-tuned with an MLP head for classification and an FCOS-based head for lesion detection. The classification model achieved an AUC of 0.90 and a sensitivity of 0.82 on the combined test set, with a sensitivity of 0.85 on the external cohort. Excluding the most uncertain 20 percent of cases improved AUC to 0.91 and balanced accuracy to 0.86. Decision curve analysis showed clinical benefit for threshold probabilities between 0.30 and 0.40. The detection model identified 69.1 percent of lesions overall, increasing from 30 percent to 98 percent across lesion size quartiles. Grad-CAM highlighted lesion-corresponding regions in high-confidence cases. These results demonstrate that foundation model-based pipelines can support robust and interpretable CRLM detection and classification across heterogeneous CT data.", "AI": {"tldr": "研究开发了一个基于基础模型的AI流程，用于在CT图像中检测和分类结直肠肝转移瘤（CRLM），并结合了不确定性量化和可解释性，在多中心数据集上取得了良好的性能。", "motivation": "结直肠肝转移瘤（CRLM）是癌症相关死亡的主要原因，但在多中心设置的CT图像中可靠检测仍然具有挑战性。", "method": "开发了一个基于基础模型的AI流程，包含用于患者级别分类和病灶级别检测的两个模型（UMedPT + MLP和UMedPT + FCOS）。使用了EuCanImage和TCIA两个数据集进行训练和测试。集成了不确定性量化（通过排除不确定性高的案例）和可解释性（Grad-CAM）。", "result": "分类模型在联合测试集上取得了0.90的AUC和0.82的敏感度，在外部队列上敏感度为0.85。排除20%不确定性最高的案例后，AUC提升至0.91，平衡准确率提升至0.86。检测模型在所有病灶中的识别率为69.1%，并随病灶大小增加而提高。Grad-CAM成功地突出了高置信度案例中与病灶对应的区域。", "conclusion": "基于基础模型的AI流程能够支持在异质性CT数据中进行稳健且可解释的CRLM检测和分类，并显示出临床获益的潜力。"}}
{"id": "2601.07353", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07353", "abs": "https://arxiv.org/abs/2601.07353", "authors": ["Tianyu Liu", "Qitan Lv", "Yuhao Shen", "Xiao Sun", "Xiaoyan Sun"], "title": "TALON: Confidence-Aware Speculative Decoding with Adaptive Token Trees", "comment": null, "summary": "Speculative decoding (SD) has become a standard technique for accelerating LLM inference without sacrificing output quality. Recent advances in speculative decoding have shifted from sequential chain-based drafting to tree-structured generation, where the draft model constructs a tree of candidate tokens to explore multiple possible drafts in parallel. However, existing tree-based SD methods typically build a fixed-width, fixed-depth draft tree, which fails to adapt to the varying difficulty of tokens and contexts. As a result, the draft model cannot dynamically adjust the tree structure to early stop on difficult tokens and extend generation for simple ones. To address these challenges, we introduce TALON, a training-free, budget-driven adaptive tree expansion framework that can be plugged into existing tree-based methods. Unlike static methods, TALON constructs the draft tree iteratively until a fixed token budget is met, using a hybrid expansion strategy that adaptively allocates the node budget to each layer of the draft tree. This framework naturally shapes the draft tree into a \"deep-and-narrow\" form for deterministic contexts and a \"shallow-and-wide\" form for uncertain branches, effectively optimizing the trade-off between exploration width and generation depth under a given budget. Extensive experiments across 5 models and 6 datasets demonstrate that TALON consistently outperforms state-of-the-art EAGLE-3, achieving up to 5.16x end-to-end speedup over auto-regressive decoding.", "AI": {"tldr": "TALON是一种训练无关的、预算驱动的自适应树状扩展框架，可以集成到现有的基于树的投机解码方法中，通过动态调整草稿树的结构来优化速度和质量，相比现有方法实现了显著的加速。", "motivation": "现有的基于树的投机解码方法通常构建固定宽度、固定深度的草稿树，无法适应不同难度下的token和上下文，导致无法在困难token上提前停止，也无法在简单token上扩展生成，从而影响效率。", "method": "TALON通过迭代构建草稿树，直到达到预设的token预算。它采用一种混合扩展策略，自适应地将节点预算分配给草稿树的每一层。这种方法能够根据上下文的确定性形成“深而窄”的树结构，或根据不确定性分支形成“浅而宽”的树结构。", "result": "在5个模型和6个数据集上的实验表明，TALON在端到端加速方面优于现有的最先进方法EAGLE-3，最高可实现5.16倍的速度提升。", "conclusion": "TALON是一种有效的训练无关的框架，可以显著提高基于树的投机解码的效率，通过动态适应性地调整草稿树的结构来优化性能。"}}
{"id": "2601.07666", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07666", "abs": "https://arxiv.org/abs/2601.07666", "authors": ["Dang Dinh Nguyen", "Decky Aspandi Latif", "Titus Zaharia"], "title": "Variational Contrastive Learning for Skeleton-based Action Recognition", "comment": null, "summary": "In recent years, self-supervised representation learning for skeleton-based action recognition has advanced with the development of contrastive learning methods. However, most of contrastive paradigms are inherently discriminative and often struggle to capture the variability and uncertainty intrinsic to human motion. To address this issue, we propose a variational contrastive learning framework that integrates probabilistic latent modeling with contrastive self-supervised learning. This formulation enables the learning of structured and semantically meaningful representations that generalize across different datasets and supervision levels. Extensive experiments on three widely used skeleton-based action recognition benchmarks show that our proposed method consistently outperforms existing approaches, particularly in low-label regimes. Moreover, qualitative analyses show that the features provided by our method are more relevant given the motion and sample characteristics, with more focus on important skeleton joints, when compared to the other methods.", "AI": {"tldr": "本文提出了一种变分对比学习框架，通过整合概率潜模型和对比自监督学习，来学习更具泛化性的骨骼动作识别表示，尤其在低标签环境下表现优异。", "motivation": "现有的对比学习方法在骨骼动作识别中，由于其判别性本质，难以捕捉人类运动的内在变异性和不确定性。", "method": "提出了一种变分对比学习框架，该框架将概率潜模型与对比自监督学习相结合，通过学习结构化且语义上有意义的表示来解决上述问题。", "result": "在三个公开数据集上的实验表明，该方法在骨骼动作识别任务上优于现有方法，特别是在低标签数据情况下。定性分析显示，该方法学习到的特征更能关注动作和样本特征中的关键骨骼关节。", "conclusion": "所提出的变分对比学习框架能够学习到泛化性更强、更关注运动细节的骨骼动作识别表示，并且在数据稀疏的情况下具有显著优势。"}}
{"id": "2601.07599", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07599", "abs": "https://arxiv.org/abs/2601.07599", "authors": ["Lior Dvir", "Nadav Torem", "Yoav Y. Schechner"], "title": "Diffusion in SPAD Signals", "comment": null, "summary": "We derive the likelihood of a raw signal in a single photon avalanche diode (SPAD), given a fixed photon flux. The raw signal comprises timing of detection events, which are nonlinearly related to the flux. Moreover, they are naturally stochastic. We then derive a score function of the signal. This is a key for solving inverse problems based on SPAD signals. We focus on deriving solutions involving a diffusion model, to express image priors. We demonstrate the effect of low or high photon counts, and the consequence of exploiting timing of detection events.", "AI": {"tldr": "本文推导了给定固定光子通量下，单光子雪崩二极管（SPAD）原始信号的似然函数，并利用该函数推导出信号的得分函数，为解决基于SPAD信号的反问题提供了关键工具，并着重于利用扩散模型表达图像先验。", "motivation": "SPAD信号（探测事件的时间）与光子通量之间存在非线性且随机的关系，这使得直接从中求解光子通量（反问题）变得困难。研究目的是为解决这类反问题提供理论基础，特别是结合图像先验信息。", "method": "1. 推导SPAD原始信号（探测事件时间）在固定光子通量下的似然函数。 2. 基于似然函数推导出信号的得分函数。 3. 重点关注利用扩散模型表达图像先验，并推导相应的求解方法。", "result": "该研究展示了低光子计数和高光子计数对SPAD信号的影响，以及利用探测事件时间信息所带来的优势。提出的方法能够处理SPAD信号的非线性和随机性，并有效结合图像先验。", "conclusion": "通过推导SPAD信号的似然函数和得分函数，并结合扩散模型，可以有效地解决基于SPAD信号的反问题，特别是在低光子计数和需要图像先验信息的情况下，利用探测事件的时间信息至关重要。"}}
{"id": "2601.07354", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07354", "abs": "https://arxiv.org/abs/2601.07354", "authors": ["Ernst van Gassen"], "title": "Semantic Compression of LLM Instructions via Symbolic Metalanguages", "comment": "12 pages and 6 tables", "summary": "We introduce MetaGlyph, a symbolic language for compressing prompts by encoding instructions as mathematical symbols rather than prose. Unlike systems requiring explicit decoding rules, MetaGlyph uses symbols like $\\in$ (membership) and $\\Rightarrow$ (implication) that models already understand from their training data. We test whether these symbols work as ''instruction shortcuts'' that models can interpret without additional teaching.\n  We evaluate eight models across two dimensions relevant to practitioners: scale (3B-1T parameters) and accessibility (open-source for local deployment vs. proprietary APIs). MetaGlyph achieves 62-81% token reduction across all task types. For API-based deployments, this translates directly to cost savings; for local deployments, it reduces latency and memory pressure.\n  Results vary by model. Gemini 2.5 Flash achieves 75% semantic equivalence between symbolic and prose instructions on selection tasks, with 49.9% membership operator fidelity. Kimi K2 reaches 98.1% fidelity for implication ($\\Rightarrow$) and achieves perfect (100%) accuracy on selection tasks with symbolic prompts. GPT-5.2 Chat shows the highest membership fidelity observed (91.3%), though with variable parse success across task types. Claude Haiku 4.5 achieves 100% parse success with 26% membership fidelity. Among mid-sized models, Qwen 2.5 7B shows 62% equivalence on extraction tasks. Mid-sized open-source models (7B-12B) show near-zero operator fidelity, suggesting a U-shaped relationship where sufficient scale overcomes instruction-tuning biases.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.07667", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07667", "abs": "https://arxiv.org/abs/2601.07667", "authors": ["Rei Taniguchi", "Yuyang Dong", "Makoto Onizuka", "Chuan Xiao"], "title": "Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference", "comment": "Source code is available at https://github.com/TANIGUCHIREI/ASL", "summary": "Due to the prevalence of large language models (LLMs), key-value (KV) cache reduction for LLM inference has received remarkable attention. Among numerous works that have been proposed in recent years, layer-wise token pruning approaches, which select a subset of tokens at particular layers to retain in KV cache and prune others, are one of the most popular schemes. They primarily adopt a set of pre-defined layers, at which tokens are selected. Such design is inflexible in the sense that the accuracy significantly varies across tasks and deteriorates in harder tasks such as KV retrieval. In this paper, we propose ASL, a training-free method that adaptively chooses the selection layer for KV cache reduction, exploiting the variance of token ranks ordered by attention score. The proposed method balances the performance across different tasks while meeting the user-specified KV budget requirement. ASL operates during the prefilling stage and can be jointly used with existing KV cache reduction methods such as SnapKV to optimize the decoding stage. By evaluations on the InfiniteBench, RULER, and NIAH benchmarks, we show that equipped with one-shot token selection, where tokens are selected at a layer and propagated to deeper layers, ASL outperforms state-of-the-art layer-wise token selection methods in accuracy while maintaining decoding speed and KV cache reduction.", "AI": {"tldr": "本文提出了一种名为ASL的训练无关方法，通过利用基于注意力分数的Token排名方差，自适应地选择用于KV缓存减少的层，以在不牺牲性能的情况下平衡不同任务的准确性，并满足指定的KV预算。", "motivation": "现有的LLM KV缓存减少方法，特别是逐层Token剪枝方法，通常依赖预定义层，这在不同任务，尤其是在KV检索等难度较大的任务上，会影响准确性。因此，需要一种更灵活的方法来适应不同任务的需求。", "method": "ASL是一种训练无关的方法，通过计算Token的注意力分数来确定其排名，并利用Token排名的方差来动态选择KV缓存缩减的层。它可以在预填充阶段操作，并与SnapKV等现有KV缓存缩减方法结合使用，以优化解码阶段。", "result": "在InfiniteBench、RULER和NIAH基准测试上的评估表明，ASL在采用一次性Token选择（在某一层选择Token并将其传递到更深的层）时，在保持解码速度和KV缓存缩减的同时，准确性优于最先进的逐层Token选择方法。", "conclusion": "ASL能够通过自适应地选择KV缓存缩减层来提高LLM推理的性能，尤其是在面临不同任务和KV预算限制时，实现了准确性和效率之间的良好平衡。"}}
{"id": "2601.07368", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07368", "abs": "https://arxiv.org/abs/2601.07368", "authors": ["Minerva Suvanto", "Andrea McGlinchey", "Mattias Wahde", "Peter J Barclay"], "title": "Interpretable Text Classification Applied to the Detection of LLM-generated Creative Writing", "comment": "Accepted for publication at ICAART 2026 (https://icaart.scitevents.org/?y=2026)", "summary": "We consider the problem of distinguishing human-written creative fiction (excerpts from novels) from similar text generated by an LLM. Our results show that, while human observers perform poorly (near chance levels) on this binary classification task, a variety of machine-learning models achieve accuracy in the range 0.93 - 0.98 over a previously unseen test set, even using only short samples and single-token (unigram) features. We therefore employ an inherently interpretable (linear) classifier (with a test accuracy of 0.98), in order to elucidate the underlying reasons for this high accuracy. In our analysis, we identify specific unigram features indicative of LLM-generated text, one of the most important being that the LLM tends to use a larger variety of synonyms, thereby skewing the probability distributions in a manner that is easy to detect for a machine learning classifier, yet very difficult for a human observer. Four additional explanation categories were also identified, namely, temporal drift, Americanisms, foreign language usage, and colloquialisms. As identification of the AI-generated text depends on a constellation of such features, the classification appears robust, and therefore not easy to circumvent by malicious actors intent on misrepresenting AI-generated text as human work.", "AI": {"tldr": "研究提出了一种区分人类创作小说和大型语言模型（LLM）生成文本的方法，并发现机器学习模型比人类更能准确地区分两者。主要原因是LLM倾向于使用更广泛的同义词，这使得机器易于检测，而人类则难以察觉。研究还识别了其他几个用于区分AI文本的特征。", "motivation": "区分人类创作的创意小说和由大型语言模型（LLM）生成的文本，因为人类在这项任务上的表现不佳（接近随机水平），而机器学习模型表现出高准确性。", "method": "使用机器学习模型（包括线性分类器）对文本进行二元分类。重点分析了导致模型高准确性的单项特征（unigram features），例如LLM倾向于使用更广泛的同义词。", "result": "机器学习模型在区分人类创作文本和LLM生成文本的任务中取得了0.93 - 0.98的高准确率，远超人类的表现。研究确定了LLM生成文本的关键特征，包括更广泛的同义词使用、时间漂移、美式英语、外语使用和习语。", "conclusion": "基于一系列可识别的特征，机器学习模型能够鲁棒地识别AI生成的文本，并且这种识别方法不易被恶意行为者绕过，可用于区分AI生成文本和人类创作作品。"}}
{"id": "2601.07620", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07620", "abs": "https://arxiv.org/abs/2601.07620", "authors": ["Fuyuan Liu", "Dianyu Yu", "He Ren", "Nayu Liu", "Xiaomian Kang", "Delai Qiu", "Fa Zhang", "Genpeng Zhen", "Shengping Liu", "Jiaen Liang", "Wei Huang", "Yining Wang", "Junnan Zhu"], "title": "PARL: Position-Aware Relation Learning Network for Document Layout Analysis", "comment": null, "summary": "Document layout analysis aims to detect and categorize structural elements (e.g., titles, tables, figures) in scanned or digital documents. Popular methods often rely on high-quality Optical Character Recognition (OCR) to merge visual features with extracted text. This dependency introduces two major drawbacks: propagation of text recognition errors and substantial computational overhead, limiting the robustness and practical applicability of multimodal approaches. In contrast to the prevailing multimodal trend, we argue that effective layout analysis depends not on text-visual fusion, but on a deep understanding of documents' intrinsic visual structure. To this end, we propose PARL (Position-Aware Relation Learning Network), a novel OCR-free, vision-only framework that models layout through positional sensitivity and relational structure. Specifically, we first introduce a Bidirectional Spatial Position-Guided Deformable Attention module to embed explicit positional dependencies among layout elements directly into visual features. Second, we design a Graph Refinement Classifier (GRC) to refine predictions by modeling contextual relationships through a dynamically constructed layout graph. Extensive experiments show PARL achieves state-of-the-art results. It establishes a new benchmark for vision-only methods on DocLayNet and, notably, surpasses even strong multimodal models on M6Doc. Crucially, PARL (65M) is highly efficient, using roughly four times fewer parameters than large multimodal models (256M), demonstrating that sophisticated visual structure modeling can be both more efficient and robust than multimodal fusion.", "AI": {"tldr": "本文提出了一种名为PARL（Position-Aware Relation Learning Network）的OCR-free、纯视觉文档布局分析框架，通过学习位置感知和关系结构来建模布局，实现了最先进的性能，并且比多模态方法更高效。", "motivation": "现有的文档布局分析方法依赖于OCR，容易受到文本识别错误的影响，并且计算开销大。本文认为有效的布局分析应依赖于对文档内在视觉结构的深入理解，而非文本-视觉融合。", "method": "PARL框架包含两个主要组件：1.  Bidirectional Spatial Position-Guided Deformable Attention模块，用于将显式的位置依赖性嵌入视觉特征。2.  Graph Refinement Classifier（GRC），通过动态构建的布局图来建模上下文关系，从而优化预测。", "result": "PARL在DocLayNet数据集上达到了最先进的纯视觉方法性能，并在M6Doc数据集上超越了强大的多模态模型。此外，PARL（65M参数）比大型多模态模型（256M参数）更高效。", "conclusion": "PARL证明了复杂的视觉结构建模比多模态融合更高效、更鲁棒，为纯视觉文档布局分析开辟了新的可能性，并展示了其在实际应用中的潜力。"}}
{"id": "2601.07603", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07603", "abs": "https://arxiv.org/abs/2601.07603", "authors": ["Zijian Wu", "Boyao Zhou", "Liangxiao Hu", "Hongyu Liu", "Yuan Sun", "Xuan Wang", "Xun Cao", "Yujun Shen", "Hao Zhu"], "title": "UIKA: Fast Universal Head Avatar from Pose-Free Images", "comment": "Project page: https://zijian-wu.github.io/uika-page/", "summary": "We present UIKA, a feed-forward animatable Gaussian head model from an arbitrary number of unposed inputs, including a single image, multi-view captures, and smartphone-captured videos. Unlike the traditional avatar method, which requires a studio-level multi-view capture system and reconstructs a human-specific model through a long-time optimization process, we rethink the task through the lenses of model representation, network design, and data preparation. First, we introduce a UV-guided avatar modeling strategy, in which each input image is associated with a pixel-wise facial correspondence estimation. Such correspondence estimation allows us to reproject each valid pixel color from screen space to UV space, which is independent of camera pose and character expression. Furthermore, we design learnable UV tokens on which the attention mechanism can be applied at both the screen and UV levels. The learned UV tokens can be decoded into canonical Gaussian attributes using aggregated UV information from all input views. To train our large avatar model, we additionally prepare a large-scale, identity-rich synthetic training dataset. Our method significantly outperforms existing approaches in both monocular and multi-view settings. Project page: https://zijian-wu.github.io/uika-page/", "AI": {"tldr": "UIKA 是一种前馈可动画的高斯头部模型，能够从任意数量的无姿态输入（包括单张图像、多视角捕获和智能手机视频）生成头部模型。它通过 UV 引导的建模策略、新颖的网络设计和大规模合成数据集，克服了传统方法对工作室级多视角捕获系统和耗时优化的依赖，并在单目和多视角设置下均取得了显著优于现有方法的结果。", "motivation": "传统的虚拟化身方法通常需要昂贵的工作室级多视角捕获系统，并且需要耗时的优化过程来重建特定人物模型。研究者希望找到一种更灵活、更高效的方法来从任意数量的无姿态输入生成可动画的头部模型。", "method": "UIKA 提出了一种 UV 引导的虚拟化身建模策略，该策略将每个输入图像与像素级的面部对应关系关联起来。这种对应关系使得每个有效像素的颜色都可以从屏幕空间重新投影到 UV 空间，从而摆脱了相机姿态和人物表情的影响。此外，研究者设计了可学习的 UV 标记，并在屏幕和 UV 级别应用注意力机制。这些 UV 标记可以利用所有输入视图的聚合 UV 信息解码为规范的高斯属性。为了训练该模型，还准备了一个大规模、身份丰富且包含合成训练数据的数据集。", "result": "UIKA 在单目和多视角设置下都显著优于现有方法，能够生成可动画的头部模型，且对输入数据的数量和类型（单张图像、多视角、手机视频）具有很强的适应性。", "conclusion": "UIKA 是一种高效且灵活的前馈可动画高斯头部模型，能够从任意数量的无姿态输入生成高质量的头部模型，克服了传统方法的局限性，并在多个设置下展示了优越的性能。"}}
{"id": "2601.07782", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.07782", "abs": "https://arxiv.org/abs/2601.07782", "authors": ["Wei Fang", "James Glass"], "title": "Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning", "comment": null, "summary": "LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.", "AI": {"tldr": "本研究提出了一种名为TOOLQP的框架，通过将检索视为迭代查询规划来解决大型语言模型（LLM）在处理复杂工具库检索时的挑战。", "motivation": "标准的单次密集检索器在处理LLM代理操作大规模、动态工具库的复杂请求时存在困难，主要是因为用户目标与技术文档之间的语义鸿沟以及固定大小的嵌入模型难以处理工具的组合。", "method": "TOOLQP将指令分解为子任务，并动态生成查询与检索器交互。该框架通过合成查询轨迹进行训练，并利用带有可验证奖励的强化学习（RLVR）进行优化。", "result": "实验表明，TOOLQP在零样本泛化、跨检索器的鲁棒性以及下游代理执行方面取得了最先进的性能，并有显著改进。", "conclusion": "TOOLQP通过迭代查询规划有效缩小了语义鸿沟，提高了LLM代理在处理复杂工具库检索时的效率和准确性。"}}
{"id": "2601.07737", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07737", "abs": "https://arxiv.org/abs/2601.07737", "authors": ["Chen Ling", "Nai Ding"], "title": "Evaluating the encoding competence of visual language models using uncommon actions", "comment": null, "summary": "We propose UAIT (Uncommon-sense Action Image-Text) dataset, a new evaluation benchmark designed to test the semantic understanding ability of visual language models (VLMs) in uncommon-sense action scenes. Unlike previous datasets that focus on common visual scenes with statistical frequency advantages, UAIT challenges models with grammatically reasonable but semantically counter-common sense image-text pairs. Such tasks require models to go beyond superficial pattern recognition and demonstrate a deep understanding of agent-patient relationships and physical feasibility. To build UAIT, we designed a semi-automated process to synthesize high-quality uncommon-sense image-text samples using large language models, few-shot prompt engineering, and text-to-image generation. Each sample is accompanied by a carefully designed multiple-choice question to test the model's competence in fine-grained reasoning. We evaluate multiple state-of-the-art visual language models and compare them with models based on contrastive learning. Experiments show that all models perform significantly worse than humans in semantic judgment, especially in distinguishing grammatical correctness from semantic rationality. Further experiments show that even the lightweight model can improve its accuracy after fine-tuning, demonstrating the great potential of directional adaptation. This study not only reveals the key weaknesses of VLMs, but also provides diagnostic tools and research directions for the development of robust models with real visual semantic reasoning capabilities.", "AI": {"tldr": "本文提出了UAIT数据集，一个用于评估视觉语言模型（VLMs）在非常见意义场景下语义理解能力的新基准。该数据集包含语法合理但语义与常识相悖的图文对，旨在测试模型超越表面模式识别，深入理解主体-客体关系和物理可行性的能力。通过大型语言模型、少样本提示工程和文生图技术半自动生成样本，并附带多项选择题进行细粒度推理测试。实验表明，现有VLMs在语义判断上远逊于人类，尤其在区分语法正确性与语义合理性方面。轻量级模型通过微调可显著提升准确率，显示了定向适应的潜力。该研究揭示了VLMs的关键弱点，并为开发具备真实视觉语义推理能力的鲁棒模型提供了诊断工具和研究方向。", "motivation": "现有数据集侧重于常见视觉场景，VLMs在这些场景下可能仅依赖统计学优势而非深层语义理解。研究者希望挑战VLMs，测试其在非常见意义场景下的语义理解能力，特别是区分语法正确性和语义合理性。", "method": "构建UAIT数据集，通过大型语言模型、少样本提示工程和文生图技术半自动生成语法合理但语义反常识的图文对。为每个样本设计多项选择题，以测试模型在细粒度推理方面的能力。评估多个SOTA VLM模型，并与基于对比学习的模型进行比较。进行额外的微调实验以评估定向适应的潜力。", "result": "所有评估的VLMs在语义判断任务上的表现显著劣于人类，尤其在区分语法正确性和语义合理性方面。通过微调，即使是轻量级模型也能显著提高其准确性。", "conclusion": "VLMs在处理非常见意义的视觉场景时存在关键弱点。定向适应（如微调）对于提升模型的视觉语义推理能力具有巨大潜力。UAIT数据集为诊断VLMs的不足和推动更鲁棒的视觉语义模型发展提供了工具和方向。"}}
{"id": "2601.07375", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07375", "abs": "https://arxiv.org/abs/2601.07375", "authors": ["Farzad Shami", "Subhrasankha Dey", "Nico Van de Weghe", "Henrikki Tenkanen"], "title": "GROKE: Vision-Free Navigation Instruction Evaluation via Graph Reasoning on OpenStreetMap", "comment": "Under Review for ACL 2026", "summary": "The evaluation of navigation instructions remains a persistent challenge in Vision-and-Language Navigation (VLN) research. Traditional reference-based metrics such as BLEU and ROUGE fail to capture the functional utility of spatial directives, specifically whether an instruction successfully guides a navigator to the intended destination. Although existing VLN agents could serve as evaluators, their reliance on high-fidelity visual simulators introduces licensing constraints and computational costs, and perception errors further confound linguistic quality assessment. This paper introduces GROKE(Graph-based Reasoning over OSM Knowledge for instruction Evaluation), a vision-free training-free hierarchical LLM-based framework for evaluating navigation instructions using OpenStreetMap data. Through systematic ablation studies, we demonstrate that structured JSON and textual formats for spatial information substantially outperform grid-based and visual graph representations. Our hierarchical architecture combines sub-instruction planning with topological graph navigation, reducing navigation error by 68.5% compared to heuristic and sampling baselines on the Map2Seq dataset. The agent's execution success, trajectory fidelity, and decision patterns serve as proxy metrics for functional navigability given OSM-visible landmarks and topology, establishing a scalable and interpretable evaluation paradigm without visual dependencies. Code and data are available at https://anonymous.4open.science/r/groke.", "AI": {"tldr": "本文提出了一种名为GROKE的无需视觉模拟的、训练免费的LLM框架，利用OpenStreetMap数据来评估导航指令的有效性，并通过消融研究证明了结构化空间信息格式的优越性。该框架通过子指令规划和拓扑图导航相结合，显著提高了导航指令的导航成功率。", "motivation": "传统的基于参考的评估指标（如BLEU和ROUGE）无法衡量导航指令在空间上的功能效用。现有的VLN智能体作为评估者时，依赖高保真视觉模拟器，存在许可限制和计算成本高昂的问题，且感知错误会混淆语言质量评估。", "method": "提出了一种名为GROKE的基于图的、无需视觉的、无需训练的、分层的LLM框架，利用OpenStreetMap数据来评估导航指令。该框架结合了子指令规划和拓扑图导航。通过消融研究比较了JSON、文本、基于网格和视觉图等不同空间信息表示方法。", "result": "结构化JSON和文本格式的空间信息比基于网格和视觉图的表现更好。该分层架构将子指令规划与拓扑图导航相结合，与启发式和采样基线相比，在Map2Seq数据集上导航错误减少了68.5%。代理执行成功率、轨迹保真度和决策模式被用作功能导航性的代理指标。", "conclusion": "GROKE提供了一种无需视觉依赖、可扩展且可解释的导航指令评估范式，能够通过OSM可见的地标和拓扑结构来评估指令的功能导航性。"}}
{"id": "2601.07660", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07660", "abs": "https://arxiv.org/abs/2601.07660", "authors": ["Yuze He", "Yanning Zhou", "Wang Zhao", "Jingwen Ye", "Zhongkai Wu", "Ran Yi", "Yong-Jin Liu"], "title": "StdGEN++: A Comprehensive System for Semantic-Decomposed 3D Character Generation", "comment": "13 pages, 12 figures. Extended version of CVPR 2025 paper arXiv:2411.05738", "summary": "We present StdGEN++, a novel and comprehensive system for generating high-fidelity, semantically decomposed 3D characters from diverse inputs. Existing 3D generative methods often produce monolithic meshes that lack the structural flexibility required by industrial pipelines in gaming and animation. Addressing this gap, StdGEN++ is built upon a Dual-branch Semantic-aware Large Reconstruction Model (Dual-Branch S-LRM), which jointly reconstructs geometry, color, and per-component semantics in a feed-forward manner. To achieve production-level fidelity, we introduce a novel semantic surface extraction formalism compatible with hybrid implicit fields. This mechanism is accelerated by a coarse-to-fine proposal scheme, which significantly reduces memory footprint and enables high-resolution mesh generation. Furthermore, we propose a video-diffusion-based texture decomposition module that disentangles appearance into editable layers (e.g., separated iris and skin), resolving semantic confusion in facial regions. Experiments demonstrate that StdGEN++ achieves state-of-the-art performance, significantly outperforming existing methods in geometric accuracy and semantic disentanglement. Crucially, the resulting structural independence unlocks advanced downstream capabilities, including non-destructive editing, physics-compliant animation, and gaze tracking, making it a robust solution for automated character asset production.", "AI": {"tldr": "StdGEN++是一个用于从多样化输入生成高保真、语义分解的3D角色的新系统，解决了现有方法生成的整体网格不适用于工业流程的问题。它使用双分支语义感知大重建模型，能够同时重建几何、颜色和组件语义，并引入了一种新的语义表面提取方法来生成高分辨率网格，以及一个基于视频扩散的纹理分解模块来分离出可编辑的纹理层。", "motivation": "现有3D生成方法生成的整体网格缺乏工业级应用所需的结构灵活性，难以满足游戏和动画行业的下游需求。", "method": "提出了StdGEN++系统，基于双分支语义感知大重建模型（Dual-Branch S-LRM），联合重建几何、颜色和组件语义。引入了与混合隐式场兼容的语义表面提取形式，并通过粗到精提案方案加速。此外，还提出了一种基于视频扩散的纹理分解模块。", "result": "StdGEN++在几何精度和语义分解方面显著优于现有方法，实现了最先进的性能。生成的结构独立性支持非破坏性编辑、物理兼容动画和视线追踪等下游应用。", "conclusion": "StdGEN++提供了一种新颖且全面的3D角色生成解决方案，能够生成高度逼真且语义分解的角色，满足工业级应用的需求，并为自动化角色资产生产提供了强大的支持。"}}
{"id": "2601.07408", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07408", "abs": "https://arxiv.org/abs/2601.07408", "authors": ["Ziheng Li", "Liu Kang", "Feng Xiao", "Luxi Xing", "Qingyi Si", "Zhuoran Li", "Weikang Gong", "Deqing Yang", "Yanghua Xiao", "Hongcheng Guo"], "title": "Outcome-Grounded Advantage Reshaping for Fine-Grained Credit Assignment in Mathematical Reasoning", "comment": null, "summary": "Group Relative Policy Optimization (GRPO) has emerged as a promising critic-free reinforcement learning paradigm for reasoning tasks. However, standard GRPO employs a coarse-grained credit assignment mechanism that propagates group-level rewards uniformly to to every token in a sequence, neglecting the varying contribution of individual reasoning steps. We address this limitation by introducing Outcome-grounded Advantage Reshaping (OAR), a fine-grained credit assignment mechanism that redistributes advantages based on how much each token influences the model's final answer. We instantiate OAR via two complementary strategies: (1) OAR-P, which estimates outcome sensitivity through counterfactual token perturbations, serving as a high-fidelity attribution signal; (2) OAR-G, which uses an input-gradient sensitivity proxy to approximate the influence signal with a single backward pass. These importance signals are integrated with a conservative Bi-Level advantage reshaping scheme that suppresses low-impact tokens and boosts pivotal ones while preserving the overall advantage mass. Empirical results on extensive mathematical reasoning benchmarks demonstrate that while OAR-P sets the performance upper bound, OAR-G achieves comparable gains with negligible computational overhead, both significantly outperforming a strong GRPO baseline, pushing the boundaries of critic-free LLM reasoning.", "AI": {"tldr": "本文提出了一种名为Outcome-grounded Advantage Reshaping (OAR) 的新方法，用于改进Group Relative Policy Optimization (GRPO)在语言模型推理任务中的表现。OAR通过更精细的信用分配机制，根据每个token对最终答案的贡献度来调整优势，从而克服了标准GRPO奖励分配粗糙的问题。", "motivation": "现有的GRPO方法在奖励分配上过于粗糙，将群组级别的奖励平均分配给序列中的每个token，忽略了不同推理步骤的实际贡献差异。", "method": "本文提出了Outcome-grounded Advantage Reshaping (OAR)机制，并提出了两种实现策略：OAR-P通过反事实token扰动来估计结果敏感性；OAR-G使用输入-梯度敏感性代理来近似影响信号。这两种策略通过一个保守的双层优势重塑方案进行整合，以抑制低影响token并增强关键token。", "result": "在数学推理基准测试中，OAR-P设定了性能上限，而OAR-G在计算开销极小的情况下取得了可比的性能提升。两者都显著优于标准的GRPO基线。", "conclusion": "OAR是一种有效的精细化信用分配机制，能够显著提升基于GRPO的语言模型在推理任务上的性能，尤其是OAR-G在计算效率和性能之间取得了良好的平衡。"}}
{"id": "2601.07671", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07671", "abs": "https://arxiv.org/abs/2601.07671", "authors": ["Rayson Laroca", "Valter Estevam", "Gladston J. P. Moreira", "Rodrigo Minetto", "David Menotti"], "title": "Advancing Multinational License Plate Recognition Through Synthetic and Real Data Fusion: A Comprehensive Evaluation", "comment": "IET Intelligent Transport Systems, vol. 19, no. 1, p. e70086, 2025", "summary": "Automatic License Plate Recognition is a frequent research topic due to its wide-ranging practical applications. While recent studies use synthetic images to improve License Plate Recognition (LPR) results, there remain several limitations in these efforts. This work addresses these constraints by comprehensively exploring the integration of real and synthetic data to enhance LPR performance. We subject 16 Optical Character Recognition (OCR) models to a benchmarking process involving 12 public datasets acquired from various regions. Several key findings emerge from our investigation. Primarily, the massive incorporation of synthetic data substantially boosts model performance in both intra- and cross-dataset scenarios. We examine three distinct methodologies for generating synthetic data: template-based generation, character permutation, and utilizing a Generative Adversarial Network (GAN) model, each contributing significantly to performance enhancement. The combined use of these methodologies demonstrates a notable synergistic effect, leading to end-to-end results that surpass those reached by state-of-the-art methods and established commercial systems. Our experiments also underscore the efficacy of synthetic data in mitigating challenges posed by limited training data, enabling remarkable results to be achieved even with small fractions of the original training data. Finally, we investigate the trade-off between accuracy and speed among different models, identifying those that strike the optimal balance in each intra-dataset and cross-dataset settings.", "AI": {"tldr": "通过结合真实数据和多种合成数据生成方法（模板生成、字符排列、GAN），显著提升了16种OCR模型在车牌识别任务上的性能，尤其是在跨数据集和数据量有限的情况下。研究还分析了模型在准确率和速度上的权衡。", "motivation": "现有研究利用合成数据提升车牌识别（LPR）效果存在局限，研究旨在通过整合真实和合成数据来克服这些限制，进一步提高LPR性能。", "method": "对16种OCR模型在12个公共数据集上进行基准测试。研究了三种合成数据生成方法：模板生成、字符排列和GAN。比较了单一方法和组合方法的效果，并分析了不同模型在准确率和速度上的权衡。", "result": "大量合成数据的引入显著提升了模型在同数据集和跨数据集场景下的性能。三种合成数据生成方法均有效，组合使用效果最佳，超越了现有SOTA方法和商业系统。合成数据在解决训练数据不足问题上表现出色。研究识别出在不同场景下准确率和速度平衡最佳的模型。", "conclusion": "真实与合成数据的结合，特别是结合多种合成数据生成方法，是提升车牌识别模型性能的有效途径，尤其在处理数据稀疏和跨数据集挑战时。合成数据在优化LPR模型方面具有重要价值。"}}
{"id": "2601.07423", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07423", "abs": "https://arxiv.org/abs/2601.07423", "authors": ["Yongkang Liu", "Jiayang Yu", "Mingyang Wang", "Yiqun Zhang", "Ercong Nie", "Shi Feng", "Daling Wang", "Kaisong Song", "Hinrich Schütze"], "title": "SAD: A Large-Scale Strategic Argumentative Dialogue Dataset", "comment": "under review", "summary": "Argumentation generation has attracted substantial research interest due to its central role in human reasoning and decision-making. However, most existing argumentative corpora focus on non-interactive, single-turn settings, either generating arguments from a given topic or refuting an existing argument. In practice, however, argumentation is often realized as multi-turn dialogue, where speakers defend their stances and employ diverse argumentative strategies to strengthen persuasiveness. To support deeper modeling of argumentation dialogue, we present the first large-scale \\textbf{S}trategic \\textbf{A}rgumentative \\textbf{D}ialogue dataset, SAD, consisting of 392,822 examples. Grounded in argumentation theories, we annotate each utterance with five strategy types, allowing multiple strategies per utterance. Unlike prior datasets, SAD requires models to generate contextually appropriate arguments conditioned on the dialogue history, a specified stance on the topic, and targeted argumentation strategies. We further benchmark a range of pretrained generative models on SAD and present in-depth analysis of strategy usage patterns in argumentation.", "AI": {"tldr": "该研究提出了一个名为SAD的大规模、多轮、策略性论证对话数据集，包含392,822个示例，并提供了基于该数据集的预训练生成模型基准测试。", "motivation": "现有论证生成研究主要集中在单轮非交互式场景，而实际论证常常是多轮对话，涉及复杂的论证策略。为了更好地模拟和研究这种多轮论证对话，需要新的数据集。", "method": "构建了一个大规模（392,822个示例）的多轮论证对话数据集SAD。每个对话轮次都根据论证理论标注了五种论证策略类型，允许一个轮次包含多种策略。模型需要根据对话历史、特定立场和目标论证策略来生成上下文相关的论证。", "result": "创建了SAD数据集，并对一系列预训练生成模型在SAD数据集上进行了基准测试，分析了论证中的策略使用模式。", "conclusion": "SAD数据集是第一个大规模的策略性论证对话数据集，它支持对论证对话进行更深入的模型研究，并且为生成上下文相关、策略驱动的论证模型提供了新的挑战和评估平台。"}}
{"id": "2601.07692", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07692", "abs": "https://arxiv.org/abs/2601.07692", "authors": ["Nicolas Sereyjol-Garros", "Ellington Kirby", "Victor Besnier", "Nermin Samet"], "title": "Leveraging 3D Representation Alignment and RGB Pretrained Priors for LiDAR Scene Generation", "comment": null, "summary": "LiDAR scene synthesis is an emerging solution to scarcity in 3D data for robotic tasks such as autonomous driving. Recent approaches employ diffusion or flow matching models to generate realistic scenes, but 3D data remains limited compared to RGB datasets with millions of samples. We introduce R3DPA, the first LiDAR scene generation method to unlock image-pretrained priors for LiDAR point clouds, and leverage self-supervised 3D representations for state-of-the-art results. Specifically, we (i) align intermediate features of our generative model with self-supervised 3D features, which substantially improves generation quality; (ii) transfer knowledge from large-scale image-pretrained generative models to LiDAR generation, mitigating limited LiDAR datasets; and (iii) enable point cloud control at inference for object inpainting and scene mixing with solely an unconditional model. On the KITTI-360 benchmark R3DPA achieves state of the art performance. Code and pretrained models are available at https://github.com/valeoai/R3DPA.", "AI": {"tldr": "R3DPA 提出了一种新的激光雷达场景生成方法，利用图像预训练模型和自监督 3D 表示来克服激光雷达数据集的局限性，并在 KITTI-360 基准测试中取得了最先进的性能。", "motivation": "现有激光雷达场景生成方法受到 3D 数据集数量相对较少的限制。研究人员希望利用图像预训练模型中丰富的先验知识来缓解这一问题。", "method": "该研究提出 R3DPA，一种将图像预训练模型知识迁移到激光雷达场景生成的方法。具体来说，R3DPA 通过对齐生成模型的中间特征与自监督 3D 特征来提升生成质量，并利用图像预训练生成模型来弥补激光雷达数据集的不足。此外，该方法还支持在推理时对点云进行控制，实现物体修复和场景混合。", "result": "R3DPA 在 KITTI-360 基准测试中取得了最先进的性能。", "conclusion": "R3DPA 是第一个能够利用图像预训练先验的激光雷达场景生成方法，通过结合自监督 3D 表示，有效解决了数据稀缺问题，并在生成质量和控制能力上均达到了 SOTA 水平。"}}
{"id": "2601.07832", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07832", "abs": "https://arxiv.org/abs/2601.07832", "authors": ["Kewei Zhang", "Ye Huang", "Yufan Deng", "Jincheng Yu", "Junsong Chen", "Huan Ling", "Enze Xie", "Daquan Zhou"], "title": "MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head", "comment": "Code: https://github.com/DAGroup-PKU/MHLA/ Project website: https://dagroup-pku.github.io/MHLA/", "summary": "While the Transformer architecture dominates many fields, its quadratic self-attention complexity hinders its use in large-scale applications. Linear attention offers an efficient alternative, but its direct application often degrades performance, with existing fixes typically re-introducing computational overhead through extra modules (e.g., depthwise separable convolution) that defeat the original purpose. In this work, we identify a key failure mode in these methods: global context collapse, where the model loses representational diversity. To address this, we propose Multi-Head Linear Attention (MHLA), which preserves this diversity by computing attention within divided heads along the token dimension. We prove that MHLA maintains linear complexity while recovering much of the expressive power of softmax attention, and verify its effectiveness across multiple domains, achieving a 3.6\\% improvement on ImageNet classification, a 6.3\\% gain on NLP, a 12.6\\% improvement on image generation, and a 41\\% enhancement on video generation under the same time complexity.", "AI": {"tldr": "提出了一种名为多头线性注意力（MHLA）的新型Transformer变体，通过在头内沿着token维度划分计算，解决了现有线性注意力方法中全局上下文坍塌的问题，从而在保持线性复杂度的同时，显著提升了图像分类、自然语言处理、图像生成和视频生成等任务的性能。", "motivation": "Transformer模型虽然强大，但其二次自注意力复杂度限制了其在大规模应用中的使用。现有的线性注意力方法虽然高效，但性能下降，并且为了弥补性能损失而引入的额外模块又增加了计算开销，违背了线性注意力的初衷。作者发现，这些方法的一个关键失败模式是全局上下文坍塌，导致模型失去表征多样性。", "method": "提出多头线性注意力（MHLA），通过将注意力计算在划分后的头内沿着token维度进行，以保留表征多样性。理论证明MHLA可以保持线性复杂度，并恢复softmax注意力的很大一部分表达能力。", "result": "在ImageNet分类任务上取得3.6%的提升，在NLP任务上取得6.3%的提升，在图像生成任务上取得12.6%的提升，在视频生成任务上取得41%的提升。这些改进是在与现有方法相同的复杂度下实现的。", "conclusion": "MHLA是一种有效且计算效率高的Transformer模型，能够解决现有线性注意力方法的全局上下文坍塌问题，并在多个领域展现出优越的性能，是一种有前景的Transformer替代方案。"}}
{"id": "2601.07506", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07506", "abs": "https://arxiv.org/abs/2601.07506", "authors": ["Dongryeol Lee", "Yerin Hwang", "Taegwan Kang", "Minwoo Lee", "Younhyung Chae", "Kyomin Jung"], "title": "Judging Against the Reference: Uncovering Knowledge-Driven Failures in LLM-Judges on QA Evaluation", "comment": "Under review, 21 pgs, 11 figures, 7 tables", "summary": "While large language models (LLMs) are increasingly used as automatic judges for question answering (QA) and other reference-conditioned evaluation tasks, little is known about their ability to adhere to a provided reference. We identify a critical failure mode of such reference-based LLM QA evaluation: when the provided reference conflicts with the judge model's parametric knowledge, the resulting scores become unreliable, substantially degrading evaluation fidelity. To study this phenomenon systematically, we introduce a controlled swapped-reference QA framework that induces reference-belief conflicts. Specifically, we replace the reference answer with an incorrect entity and construct diverse pairings of original and swapped references with correspondingly aligned candidate answers. Surprisingly, grading reliability drops sharply under swapped references across a broad set of judge models. We empirically show that this vulnerability is driven by judges' over-reliance on parametric knowledge, leading judges to disregard the given reference under conflict. Finally, we find that this failure persists under common prompt-based mitigation strategies, highlighting a fundamental limitation of LLM-as-a-judge evaluation and motivating reference-based protocols that enforce stronger adherence to the provided reference.", "AI": {"tldr": "大型语言模型（LLMs）在作为问答（QA）等任务的自动评估者时，当参考答案与其自身知识冲突时，评估结果会变得不可靠，因为模型过度依赖其内部知识而忽略了提供的参考。", "motivation": "研究LLMs作为自动评估者时，参考答案与其内部知识冲突对评估结果的影响，以揭示LLM作为评估者时可能存在的根本性局限。", "method": "构建了一个包含“已交换参考”的QA评估框架，通过将参考答案替换为错误实体，并匹配相应的候选答案，来系统性地诱发参考-信念冲突。在多种LLM评估模型上进行了实验。", "result": "在参考答案被替换为错误信息时，LLM评估模型的评分可靠性急剧下降。实验表明，这种脆弱性源于LLM过度依赖其内部（参数化）知识，从而在冲突时忽视了提供的参考。", "conclusion": "LLM作为评估者的现有方法存在一个关键的失效模式，即当参考答案与其参数知识冲突时，评估结果不可靠。这种失效在使用常见的提示工程方法时难以解决，表明需要开发更强制参考答案遵循性的评估协议。"}}
{"id": "2601.07695", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07695", "abs": "https://arxiv.org/abs/2601.07695", "authors": ["Siwen Jiao", "Tianxiong Lv", "Kangan Qian", "Chenxu Zhao", "Xiuyuan Zhu", "Tianlun Li", "Xiaolong Cheng", "Jinyu Li", "Zhihao Liao", "Yang Cai"], "title": "Smooth Operator: Smooth Verifiable Reward Activates Spatial Reasoning Ability of Vision-Language Model", "comment": null, "summary": "Vision-Language Models (VLMs) face a critical bottleneck in achieving precise numerical prediction for 3D scene understanding. Traditional reinforcement learning (RL) approaches, primarily based on relative ranking, often suffer from severe reward sparsity and gradient instability, failing to effectively exploit the verifiable signals provided by 3D physical constraints. Notably, in standard GRPO frameworks, relative normalization causes \"near-miss\" samples (characterized by small but non-zero errors) to suffer from advantage collapse. This leads to a severe data utilization bottleneck where valuable boundary samples are discarded during optimization. To address this, we introduce the Smooth Numerical Reward Activation (SNRA) operator and the Absolute-Preserving GRPO (AP-GRPO) framework. SNRA employs a dynamically parameterized Sigmoid function to transform raw feedback into a dense, continuous reward continuum. Concurrently, AP-GRPO integrates absolute scalar gradients to mitigate the numerical information loss inherent in conventional relative-ranking mechanisms. By leveraging this approach, we constructed Numerical3D-50k, a dataset comprising 50,000 verifiable 3D subtasks. Empirical results indicate that AP-GRPO achieves performance parity with large-scale supervised methods while maintaining higher data efficiency, effectively activating latent 3D reasoning in VLMs without requiring architectural modifications.", "AI": {"tldr": "本文提出了一种名为AP-GRPO的框架，结合SNRA算子，以解决视觉语言模型（VLM）在3D场景理解中数值预测精度低的问题，克服了传统强化学习方法中的奖励稀疏性和梯度不稳定性，并在Numerical3D-50k数据集上验证了其有效性。", "motivation": "传统的强化学习方法在3D场景理解的数值预测任务中存在奖励稀疏、梯度不稳定以及“近乎命中”样本的优势折叠问题，导致数据利用效率低下。现有方法未能有效利用3D物理约束提供的可验证信号。", "method": "引入了平滑数值奖励激活（SNRA）算子，该算子使用动态参数化的Sigmoid函数将原始反馈转化为密集、连续的奖励。同时，提出了绝对保持GRPO（AP-GRPO）框架，通过集成绝对标量梯度来解决传统相对排序机制中固有的数值信息丢失问题。在此基础上构建了Numerical3D-50k数据集。", "result": "AP-GRPO框架在Numerical3D-50k数据集上实现了与大规模监督方法相当的性能，同时表现出更高的数据效率，并且无需对VLM的架构进行修改。", "conclusion": "AP-GRPO框架和SNRA算子能够有效激活VLM中潜在的3D推理能力，显著提升其在3D场景理解中的数值预测精度，并解决了现有强化学习方法在处理此类任务时面临的关键挑战。"}}
{"id": "2601.07507", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07507", "abs": "https://arxiv.org/abs/2601.07507", "authors": ["Yongkang Liu", "Xing Li", "Mengjie Zhao", "Shanru Zhang", "Zijing Wang", "Qian Li", "Shi Feng", "Feiliang Ren", "Daling Wang", "Hinrich Schütze"], "title": "High-Rank Structured Modulation for Parameter-Efficient Fine-Tuning", "comment": "under review", "summary": "As the number of model parameters increases, parameter-efficient fine-tuning (PEFT) has become the go-to choice for tailoring pre-trained large language models. Low-rank Adaptation (LoRA) uses a low-rank update method to simulate full parameter fine-tuning, which is widely used to reduce resource requirements. However, decreasing the rank encounters challenges with limited representational capacity when compared to full parameter fine-tuning. We present \\textbf{SMoA}, a high-rank \\textbf{S}tructured \\textbf{MO}dulation \\textbf{A}dapter that uses fewer trainable parameters while maintaining a higher rank, thereby improving the model's representational capacity and offering improved performance potential. The core idea is to freeze the original pretrained weights and selectively amplify or suppress important features of the original weights across multiple subspaces. The subspace mechanism provides an efficient way to increase the capacity and complexity of a model. We conduct both theoretical analyses and empirical studies on various tasks. Experiment results show that SMoA outperforms LoRA and its variants on 10 tasks, with extensive ablation studies validating its effectiveness.", "AI": {"tldr": "提出了一种名为SMoA的高秩结构化调制适配器，它使用更少的训练参数，但保持更高的秩，从而在保持模型容量的同时提高性能，优于LoRA及其变种。", "motivation": "随着模型参数量的增加，参数高效微调（PEFT）成为主流。LoRA通过低秩更新模拟全参数微调，但低秩限制了其表示能力。", "method": "SMoA冻结预训练权重，通过多子空间选择性地放大或抑制原始权重的重要特征，以增加模型容量和复杂性。", "result": "SMoA在10个任务上优于LoRA及其变种，并且通过大量消融实验验证了其有效性。", "conclusion": "SMoA是一种高效的PEFT方法，能够以更少的参数实现更高的表示能力，从而获得更好的性能。"}}
{"id": "2601.07700", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07700", "abs": "https://arxiv.org/abs/2601.07700", "authors": ["Jakob Paul Zimmermann", "Georg Loho"], "title": "Hidden Monotonicity: Explaining Deep Neural Networks via their DC Decomposition", "comment": null, "summary": "It has been demonstrated in various contexts that monotonicity leads to better explainability in neural networks. However, not every function can be well approximated by a monotone neural network. We demonstrate that monotonicity can still be used in two ways to boost explainability. First, we use an adaptation of the decomposition of a trained ReLU network into two monotone and convex parts, thereby overcoming numerical obstacles from an inherent blowup of the weights in this procedure. Our proposed saliency methods -- SplitCAM and SplitLRP -- improve on state of the art results on both VGG16 and Resnet18 networks on ImageNet-S across all Quantus saliency metric categories. Second, we exhibit that training a model as the difference between two monotone neural networks results in a system with strong self-explainability properties.", "AI": {"tldr": "本文提出了一种利用单调性来提高神经网络可解释性的方法，包括将网络分解为单调且凸的部分，以及训练两个单调神经网络的差值。提出的方法在ImageNet-S数据集上取得了SOTA结果，并增强了模型的自解释性。", "motivation": "虽然单调性已被证明能提高神经网络的可解释性，但并非所有函数都能被单调神经网络很好地近似。因此，研究如何有效利用单调性来增强可解释性是本研究的动机。", "method": "1. 将训练好的ReLU网络分解为两个单调且凸的部分，克服了数值计算上的困难。2. 提出了SplitCAM和SplitLRP两种新的显著性方法。3. 训练一个模型作为两个单调神经网络的差值。", "result": "所提出的SplitCAM和SplitLRP方法在VGG16和Resnet18网络在ImageNet-S数据集上的表现优于现有技术，并在所有Quantus显著性指标类别中均取得提升。训练为两个单调神经网络差值的模型展现出强大的自解释性。", "conclusion": "本文证明了单调性可以从两个方面提升神经网络的可解释性：通过分解和利用其差值。提出的方法不仅在显著性分析方面取得了SOTA结果，还为构建具有更强自解释性的模型提供了途径。"}}
{"id": "2601.07631", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07631", "abs": "https://arxiv.org/abs/2601.07631", "authors": ["Marija Šakota", "Dmitry Brant", "Cooltey Feng", "Shay Nowick", "Amal Ramadan", "Robin Schoenbaechler", "Joseph Seddon", "Jazmin Tanner", "Isaac Johnson", "Robert West"], "title": "Integrating Machine-Generated Short Descriptions into the Wikipedia Android App: A Pilot Deployment of Descartes", "comment": null, "summary": "Short descriptions are a key part of the Wikipedia user experience, but their coverage remains uneven across languages and topics. In previous work, we introduced Descartes, a multilingual model for generating short descriptions. In this report, we present the results of a pilot deployment of Descartes in the Wikipedia Android app, where editors were offered suggestions based on outputs from Descartes while editing short descriptions. The experiment spanned 12 languages, with over 3,900 articles and 375 editors participating. Overall, 90% of accepted Descartes descriptions were rated at least 3 out of 5 in quality, and their average ratings were comparable to human-written ones. Editors adopted machine suggestions both directly and with modifications, while the rate of reverts and reports remained low. The pilot also revealed practical considerations for deployment, including latency, language-specific gaps, and the need for safeguards around sensitive topics. These results indicate that Descartes's short descriptions can support editors in reducing content gaps, provided that technical, design, and community guardrails are in place.", "AI": {"tldr": "在维基百科安卓应用中试点部署的 Descartes 模型生成的短描述，在 12 种语言中得到了编辑者的积极采纳，质量与人工编写的描述相当，有助于减少内容差距，但仍需解决延迟、语言差异和敏感话题等实际问题。", "motivation": "维基百科的短描述在不同语言和主题上的覆盖不均衡，这影响了用户体验。之前的研究提出了 Descartes 模型来生成多语言短描述，本次研究旨在评估其在实际应用中的效果。", "method": "将 Descartes 模型部署到维基百科安卓应用中，向编辑者提供短描述的生成建议。实验涉及 12 种语言、3,900 多篇文章和 375 位编辑者，收集了用户采纳率、描述质量评分、修改情况、回退率和报告率等数据。", "result": "90% 的被接受的 Descartes 描述质量评分至少为 3/5，平均评分与人工编写的描述相当。编辑者直接或修改后采纳了机器生成的建议，回退率和报告率低。试点还发现了部署方面的挑战，包括延迟、语言特异性差距以及敏感话题的处理。", "conclusion": "Descartes 模型生成的短描述能够有效地支持编辑者，帮助弥合内容差距，但前提是必须建立健全的技术、设计和社区保障措施来解决实际部署中遇到的问题。"}}
{"id": "2601.07645", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07645", "abs": "https://arxiv.org/abs/2601.07645", "authors": ["Zijing Wang", "Yongkang Liu", "Mingyang Wang", "Ercong Nie", "Deyuan Chen", "Zhengjie Zhao", "Shi Feng", "Daling Wang", "Xiaocui Yang", "Yifei Zhang", "Hinrich Schütze"], "title": "PlaM: Training-Free Plateau-Guided Model Merging for Better Visual Grounding in MLLMs", "comment": "under review", "summary": "Multimodal Large Language Models (MLLMs) rely on strong linguistic reasoning inherited from their base language models. However, multimodal instruction fine-tuning paradoxically degrades this text's reasoning capability, undermining multimodal performance. To address this issue, we propose a training-free framework to mitigate this degradation. Through layer-wise vision token masking, we reveal a common three-stage pattern in multimodal large language models: early-modal separation, mid-modal alignment, and late-modal degradation. By analyzing the behavior of MLLMs at different stages, we propose a plateau-guided model merging method that selectively injects base language model parameters into MLLMs. Experimental results based on five MLLMs on nine benchmarks demonstrate the effectiveness of our method. Attention-based analysis further reveals that merging shifts attention from diffuse, scattered patterns to focused localization on task-relevant visual regions. Our repository is on https://github.com/wzj1718/PlaM.", "AI": {"tldr": "研究提出了一种无训练的框架PlaM，通过层级视觉token掩码揭示了多模态大模型（MLLMs）在训练中语言推理能力下降的规律，并采用基于平台期引导的模型合并方法来缓解这一问题，有效提升了MLLMs的性能。", "motivation": "多模态大模型（MLLMs）在训练过程中，其继承自基础语言模型的文本推理能力会发生退化，从而影响整体的多模态性能。作者希望解决这一问题。", "method": "通过层级视觉token掩码，分析MLLMs在不同层级的模态分离、对齐和退化模式，并提出了一种基于平台期引导的模型合并方法，选择性地将基础语言模型的参数注入到MLLMs中。", "result": "提出的PlaM方法在五个MLLMs和九个基准测试上的实验结果表明其有效性。基于注意力机制的分析显示，模型合并能够将注意力从分散模式转移到对任务相关的视觉区域的聚焦。", "conclusion": "通过分析MLLMs的训练规律并采用模型合并策略，可以有效缓解多模态指令微调导致的语言推理能力下降问题，并提升MLLMs的性能。该研究提出了一种训练自由的解决方案。"}}
{"id": "2601.07761", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07761", "abs": "https://arxiv.org/abs/2601.07761", "authors": ["Yanxiang Huang", "Guohua Gao", "Zhaoyang Wei", "Jianyuan Ni"], "title": "Video Evidence to Reasoning Efficient Video Understanding via Explicit Evidence Grounding", "comment": "6 pages", "summary": "Large Vision-Language Models (LVLMs) face a fundamental dilemma in video reasoning: they are caught between the prohibitive computational costs of verbose reasoning and the hallucination risks of efficient, ungrounded approaches. To resolve this, we introduce the Chain of Evidence (CoE), a novel framework that architecturally decouples and co-optimizes perceptual grounding and reasoning efficiency. CoE incorporates two core innovations: (1) A lightweight Evidence Grounding Module (EGM) that acts as a query-guided filter, dynamically identifying and extracting a compact set of high-fidelity visual evidence; and (2) An Evidence-Anchoring Protocol optimized via Reinforcement Learning. Crucially, we design a composite reward mechanism that enforces process alignment, compelling the model to strictly reference identified temporal anchors during deduction, thereby mitigating hallucinations. To enable this, we construct CoE-Instruct, a large-scale dataset (164k samples) featuring a novel dual-annotation schema for separate perception and reasoning supervision. Extensive experiments on five benchmarks, including Video-MME, MVBench, and VSI-Bench, demonstrate that CoE-enhanced models establish a new state-of-the-art. They significantly outperform existing methods in accuracy, proving CoE to be a powerful and practical paradigm for reliable video understanding.", "AI": {"tldr": "本文提出了链式证据（CoE）框架，通过解耦感知基础和推理效率来解决大型视觉语言模型（LVLM）在视频推理中的计算成本与幻觉风险之间的权衡问题，并在多个基准测试中取得了最先进的性能。", "motivation": "大型视觉语言模型（LVLM）在视频推理方面面临计算成本高昂和易产生幻觉的挑战，现有方法难以兼顾效率和可靠性。", "method": "提出链式证据（CoE）框架，包含两个核心创新：1. 轻量级证据基础模块（EGM），用于动态提取视觉证据；2. 通过强化学习优化的证据锚定协议，利用多重奖励机制强制模型在推理过程中引用锚定证据，减少幻觉。同时，构建了包含164k样本的CoE-Instruct数据集，用于区分感知和推理的监督。", "result": "在Video-MME、MVBench和VSI-Bench等五个基准测试中，CoE增强的模型显著优于现有方法，在准确率方面取得了新的最先进水平。", "conclusion": "CoE框架是一种有效且实用的范式，能够显著提高LVLM在视频推理中的准确性和可靠性，解决了计算成本和幻觉问题。"}}
{"id": "2601.07773", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07773", "abs": "https://arxiv.org/abs/2601.07773", "authors": ["Lingchen Sun", "Rongyuan Wu", "Zhengqiang Zhang", "Ruibin Li", "Yujing Sun", "Shuaizheng Liu", "Lei Zhang"], "title": "Beyond External Guidance: Unleashing the Semantic Richness Inside Diffusion Transformers for Improved Training", "comment": null, "summary": "Recent works such as REPA have shown that guiding diffusion models with external semantic features (e.g., DINO) can significantly accelerate the training of diffusion transformers (DiTs). However, this requires the use of pretrained external networks, introducing additional dependencies and reducing flexibility. In this work, we argue that DiTs actually have the power to guide the training of themselves, and propose \\textbf{Self-Transcendence}, a simple yet effective method that achieves fast convergence using internal feature supervision only. It is found that the slow convergence in DiT training primarily stems from the difficulty of representation learning in shallow layers. To address this, we initially train the DiT model by aligning its shallow features with the latent representations from the pretrained VAE for a short phase (e.g., 40 epochs), then apply classifier-free guidance to the intermediate features, enhancing their discriminative capability and semantic expressiveness. These enriched internal features, learned entirely within the model, are used as supervision signals to guide a new DiT training. Compared to existing self-contained methods, our approach brings a significant performance boost. It can even surpass REPA in terms of generation quality and convergence speed, but without the need for any external pretrained models. Our method is not only more flexible for different backbones but also has the potential to be adopted for a wider range of diffusion-based generative tasks. The source code of our method can be found at https://github.com/csslc/Self-Transcendence.", "AI": {"tldr": "提出了一种名为Self-Transcendence的方法，利用Diffusion Transformer（DiT）模型自身的内部特征来加速训练，无需外部预训练模型，并且在生成质量和收敛速度上优于现有方法。", "motivation": "现有的加速DiT训练的方法（如REPA）依赖于外部预训练模型，增加了依赖性并降低了灵活性。作者希望开发一种仅使用DiT内部特征就能实现快速收敛的方法。", "method": "Self-Transcendence方法包含两个阶段：1. 短期（约40个epoch）将DiT的浅层特征与预训练VAE的潜在表示对齐；2. 应用分类器自由引导（classifier-free guidance）到中间特征，增强其判别能力和语义表达能力。然后，利用这些增强的内部特征作为监督信号来指导DiT的训练。", "result": "与现有的自包含方法相比，Self-Transcendence显著提升了性能。在生成质量和收敛速度上甚至超过了REPA，同时避免了对外部预训练模型的依赖。", "conclusion": "Self-Transcendence是一种简单有效的方法，仅通过内部特征监督即可加速DiT模型的训练，具有更高的灵活性，并且有潜力应用于更广泛的扩散生成任务。"}}
{"id": "2601.07648", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07648", "abs": "https://arxiv.org/abs/2601.07648", "authors": ["Jing Yang", "Nils Feldhus", "Salar Mohtaj", "Leonhard Hennig", "Qianli Wang", "Eleni Metheniti", "Sherzod Hakimov", "Charlott Jakob", "Veronika Solopova", "Konrad Rieck", "David Schlangen", "Sebastian Möller", "Vera Schmitt"], "title": "Order in the Evaluation Court: A Critical Analysis of NLG Evaluation Trends", "comment": "8 pages", "summary": "Despite advances in Natural Language Generation (NLG), evaluation remains challenging. Although various new metrics and LLM-as-a-judge (LaaJ) methods are proposed, human judgment persists as the gold standard. To systematically review how NLG evaluation has evolved, we employ an automatic information extraction scheme to gather key information from NLG papers, focusing on different evaluation methods (metrics, LaaJ and human evaluation). With extracted metadata from 14,171 papers across four major conferences (ACL, EMNLP, NAACL, and INLG) over the past six years, we reveal several critical findings: (1) Task Divergence: While Dialogue Generation demonstrates a rapid shift toward LaaJ (>40% in 2025), Machine Translation remains locked into n-gram metrics, and Question Answering exhibits a substantial decline in the proportion of studies conducting human evaluation. (2) Metric Inertia: Despite the development of semantic metrics, general-purpose metrics (e.g., BLEU, ROUGE) continue to be widely used across tasks without empirical justification, often lacking the discriminative power to distinguish between specific quality criteria. (3) Human-LaaJ Divergence: Our association analysis challenges the assumption that LLMs act as mere proxies for humans; LaaJ and human evaluations prioritize very different signals, and explicit validation is scarce (<8% of papers comparing the two), with only moderate to low correlation. Based on these observations, we derive practical recommendations to improve the rigor of future NLG evaluation.", "AI": {"tldr": "本研究通过自动信息提取方法，分析了过去六年四大顶会（ACL, EMNLP, NAACL, INLG）的14,171篇论文，系统回顾了自然语言生成（NLG）评估方法的演变，发现不同任务在评估方法上存在显著差异（如对话生成转向LLM-as-a-judge，机器翻译仍依赖n-gram指标，问答中人工评估比例下降），通用指标（如BLEU, ROUGE）被过度使用且缺乏实证支持，并且LLM-as-a-judge与人工评估存在较大分歧，对未来NLG评估提出了改进建议。", "motivation": "尽管自然语言生成（NLG）在进步，但其评估方法仍然面临挑战。现有研究提出了新的评估指标和LLM-as-a-judge（LaaJ）方法，但人工评估仍被视为黄金标准。为了系统地审视NLG评估的演变，研究者需要了解不同评估方法的应用趋势和有效性。", "method": "研究者采用自动信息提取方案，从ACL、EMNLP、NAACL和INLG四大顶级会议过去六年的14,171篇NLG论文中提取关键信息，重点关注不同的评估方法（指标、LLM-as-a-judge和人工评估）。通过对提取的元数据进行分析，揭示了评估方法的使用趋势和相关性。", "result": "研究发现了三个关键结果：（1）任务差异：对话生成任务迅速转向LaaJ（>40%），而机器翻译仍主要使用n-gram指标，问答任务中人工评估的比例显著下降。（2）指标惰性：尽管出现了语义指标，但通用指标（如BLEU, ROUGE）在各种任务中被广泛使用，缺乏实证依据，且难以区分特定的质量标准。（3）人工-LaaJ分歧：LaaJ与人工评估优先考虑的信号不同，两者之间的相关性仅为中等到低，且进行比较验证的论文不足8%。", "conclusion": "NLG评估方法存在显著的任务差异、通用指标的过度使用以及LaaJ与人工评估之间的分歧。研究者基于这些发现，提出了改进未来NLG评估严谨性的实用建议。"}}
{"id": "2601.07696", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07696", "abs": "https://arxiv.org/abs/2601.07696", "authors": ["Nick Ferguson", "Alan Bundy", "Kwabena Nuamah"], "title": "Exploring the Meta-level Reasoning of Large Language Models via a Tool-based Multi-hop Tabular Question Answering Task", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) are increasingly focused on \"reasoning\" ability, a concept with many overlapping definitions in the LLM discourse. We take a more structured approach, distinguishing meta-level reasoning (denoting the process of reasoning about intermediate steps required to solve a task) from object-level reasoning (which concerns the low-level execution of the aforementioned steps.) We design a novel question answering task, which is based around the values of geopolitical indicators for various countries over various years. Questions require breaking down into intermediate steps, retrieval of data, and mathematical operations over that data. The meta-level reasoning ability of LLMs is analysed by examining the selection of appropriate tools for answering questions. To bring greater depth to the analysis of LLMs beyond final answer accuracy, our task contains 'essential actions' against which we can compare the tool call output of LLMs to infer the strength of reasoning ability. We find that LLMs demonstrate good meta-level reasoning on our task, yet are flawed in some aspects of task understanding. We find that n-shot prompting has little effect on accuracy; error messages encountered do not often deteriorate performance; and provide additional evidence for the poor numeracy of LLMs. Finally, we discuss the generalisation and limitation of our findings to other task domains.", "AI": {"tldr": "研究人员提出了一种新的问答任务，用于区分大型语言模型（LLM）的元层面推理（关于如何解决任务的推理）和对象层面推理（执行推理步骤）。他们的任务涉及地缘政治指标数据的检索和计算。结果表明，LLM 在元层面推理方面表现良好，但在任务理解方面存在不足，并且仍然存在计算能力差的问题。", "motivation": "区分 LLM 在推理任务中的元层面推理（如何解决问题）和对象层面推理（如何执行解决问题的步骤），并以此更深入地分析 LLM 的推理能力，超越仅关注最终答案准确性的局限性。", "method": "设计了一个新的问答任务，该任务基于各国不同年份的地缘政治指标，问题需要分解成中间步骤、数据检索和数学运算。通过检查 LLM 选择工具的能力来分析其元层面推理能力，并通过与“必需动作”进行比较来评估其推理强度。", "result": "LLM 在所设计的任务上展现出良好的元层面推理能力，但在任务理解方面存在缺陷。n-shot 提示对准确性影响不大，错误消息通常不会降低性能，并且 LLM 的计算能力较差。", "conclusion": "LLM 在处理需要选择工具的推理任务方面具有一定的潜力，但仍需改进任务理解和计算能力。研究结果为理解和评估 LLM 的推理能力提供了新的视角，并指出了其局限性。"}}
{"id": "2601.07805", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07805", "abs": "https://arxiv.org/abs/2601.07805", "authors": ["Sijun Dong", "Siming Fu", "Kaiyu Li", "Xiangyong Cao", "Xiaoliang Meng", "Bo Du"], "title": "Exchange Is All You Need for Remote Sensing Change Detection", "comment": null, "summary": "Remote sensing change detection fundamentally relies on the effective fusion and discrimination of bi-temporal features. Prevailing paradigms typically utilize Siamese encoders bridged by explicit difference computation modules, such as subtraction or concatenation, to identify changes. In this work, we challenge this complexity with SEED (Siamese Encoder-Exchange-Decoder), a streamlined paradigm that replaces explicit differencing with parameter-free feature exchange. By sharing weights across both Siamese encoders and decoders, SEED effectively operates as a single parameter set model. Theoretically, we formalize feature exchange as an orthogonal permutation operator and prove that, under pixel consistency, this mechanism preserves mutual information and Bayes optimal risk, whereas common arithmetic fusion methods often introduce information loss. Extensive experiments across five benchmarks, including SYSU-CD, LEVIR-CD, PX-CLCD, WaterCD, and CDD, and three backbones, namely SwinT, EfficientNet, and ResNet, demonstrate that SEED matches or surpasses state of the art methods despite its simplicity. Furthermore, we reveal that standard semantic segmentation models can be transformed into competitive change detectors solely by inserting this exchange mechanism, referred to as SEG2CD. The proposed paradigm offers a robust, unified, and interpretable framework for change detection, demonstrating that simple feature exchange is sufficient for high performance information fusion. Code and full training and evaluation protocols will be released at https://github.com/dyzy41/open-rscd.", "AI": {"tldr": "本文提出了一种名为SEED（Siamese Encoder-Exchange-Decoder）的简化遥感变化检测范式，通过无参数的特征交换替代显式的差分计算，并证明了其理论优势。SEED在多个基准数据集和骨干网络上取得了与现有最先进方法相当甚至更优的性能。", "motivation": "现有遥感变化检测方法通常依赖复杂的Siamese编码器和显式的差分计算模块，可能导致信息损失。作者希望提出一种更简洁、更有效的方法。", "method": "SEED范式采用共享参数的Siamese编码器和解码器，并引入一个参数免费的特征交换模块来代替显式的差分计算。作者从理论上将特征交换形式化为正交置换算子，并证明其在像素一致性下能保留互信息和贝叶斯最优风险。此外，还提出SEG2CD，将语义分割模型转化为变化检测器。", "result": "SEED在SYSU-CD、LEVIR-CD、PX-CLCD、WaterCD和CDD五个数据集上，配合SwinT、EfficientNet和ResNet三种骨干网络，均取得了与最先进方法相当或更优的性能。SEG2CD也展现出竞争力。", "conclusion": "SEED是一种强大、统一且可解释的变化检测框架，证明了简单的特征交换足以实现高性能的信息融合，并为未来的变化检测研究提供了新的方向。"}}
{"id": "2601.07698", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07698", "abs": "https://arxiv.org/abs/2601.07698", "authors": ["Chaewon Heo", "Cheyon Jin", "Yohan Jo"], "title": "Emotional Support Evaluation Framework via Controllable and Diverse Seeker Simulator", "comment": null, "summary": "As emotional support chatbots have recently gained significant traction across both research and industry, a common evaluation strategy has emerged: use help-seeker simulators to interact with supporter chatbots. However, current simulators suffer from two critical limitations: (1) they fail to capture the behavioral diversity of real-world seekers, often portraying them as overly cooperative, and (2) they lack the controllability required to simulate specific seeker profiles. To address these challenges, we present a controllable seeker simulator driven by nine psychological and linguistic features that underpin seeker behavior. Using authentic Reddit conversations, we train our model via a Mixture-of-Experts (MoE) architecture, which effectively differentiates diverse seeker behaviors into specialized parameter subspaces, thereby enhancing fine-grained controllability. Our simulator achieves superior profile adherence and behavioral diversity compared to existing approaches. Furthermore, evaluating 7 prominent supporter models with our system uncovers previously obscured performance degradations. These findings underscore the utility of our framework in providing a more faithful and stress-tested evaluation for emotional support chatbots.", "AI": {"tldr": "本文提出了一种可控的情感支持聊天机器人模拟器，用于评估聊天机器人，该模拟器通过九种心理和语言特征捕捉用户行为的多样性和可控性，并使用MoE架构训练，优于现有方法，并发现了现有评估方法未曾揭示的聊天机器人性能问题。", "motivation": "现有情感支持聊天机器人的评估方法（使用帮助寻求者模拟器）存在不足：模拟器无法捕捉真实用户的行为多样性，且缺乏模拟特定用户画像的控制能力。", "method": "提出了一种由九种心理和语言特征驱动的可控帮助寻求者模拟器。使用Reddit真实对话数据，并采用Mixture-of-Experts（MoE）架构进行模型训练，以区分和专业化处理不同的寻求者行为。", "result": "提出的模拟器在用户画像符合度和行为多样性方面优于现有方法。通过该模拟器评估7个主流支持模型，揭示了之前未被发现的性能下降问题。", "conclusion": "该框架能够提供更真实、更具挑战性的情感支持聊天机器人评估，有助于揭示现有评估方法的局限性，并促进更鲁棒的聊天机器人发展。"}}
{"id": "2601.07794", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07794", "abs": "https://arxiv.org/abs/2601.07794", "authors": ["Tianda Sun", "Dimitar Kazakov"], "title": "Kinship Data Benchmark for Multi-hop Reasoning", "comment": "11 pages, 2 figures, 9 tables", "summary": "Large language models (LLMs) are increasingly evaluated on their ability to perform multi-hop reasoning, i.e., to combine multiple pieces of information into a coherent inference. We introduce KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution of our work is a generative pipeline that produces, on demand, large-scale, realistic, and culture-specific genealogical data: collections of interconnected family trees that satisfy explicit marriage constraints associated with different kinship systems. This allows task difficulty, cultural assumptions, and relational depth to be systematically controlled and varied. From these genealogies, we derive textual inference tasks that require reasoning over implicit relational chains. We evaluate the resulting benchmark using six state-of-the-art LLMs, spanning both open-source and closed-source models, under a uniform zero-shot protocol with deterministic decoding. Performance is measured using exact-match and set-based metrics. Our results demonstrate that KinshipQA yields a wide spread of outcomes and exposes systematic differences in multi-hop reasoning across models and cultural settings.", "AI": {"tldr": "本文提出了KinshipQA数据集，用于评估大型语言模型（LLMs）的多跳推理能力，尤其是在亲属关系推理方面。该数据集通过生成大规模、真实且文化特定的家谱数据来创建，可控制任务难度、文化假设和关系深度。", "motivation": "现有的大型语言模型在多跳推理能力方面需要更深入的评估，特别是涉及到结合多条信息进行连贯推理的任务。作者希望通过一个专注于亲属关系推理的基准来探测这一能力。", "method": "研究人员开发了一个生成式流水线，可以按需生成大规模、真实且具有文化特异性的家谱数据。这些数据包含相互连接的家谱树，并满足不同亲属关系系统的婚姻约束。基于这些家谱数据，生成了需要推理隐式关系链的文本推理任务。使用六个最先进的大型语言模型（包括开源和闭源模型）在零样本设置下对基准进行评估，并使用精确匹配和基于集合的指标衡量性能。", "result": "KinshipQA基准在不同模型和文化背景下展示了广泛的性能差异，暴露了模型在多跳推理能力上的系统性区别。", "conclusion": "KinshipQA是一个有效的大规模多跳推理基准，能够通过亲属关系推理来探测和区分大型语言模型的能力，并且可以调整任务难度和文化设置。"}}
{"id": "2601.07711", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07711", "abs": "https://arxiv.org/abs/2601.07711", "authors": ["Pietro Ferrazzi", "Milica Cvjeticanin", "Alessio Piraccini", "Davide Giannuzzi"], "title": "Is Agentic RAG worth it? An experimental comparison of RAG approaches", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems are usually defined by the combination of a generator and a retrieval component that extracts textual context from a knowledge base to answer user queries. However, such basic implementations exhibit several limitations, including noisy or suboptimal retrieval, misuse of retrieval for out-of-scope queries, weak query-document matching, and variability or cost associated with the generator. These shortcomings have motivated the development of \"Enhanced\" RAG, where dedicated modules are introduced to address specific weaknesses in the workflow. More recently, the growing self-reflective capabilities of Large Language Models (LLMs) have enabled a new paradigm, which we refer to as \"Agentic\" RAG. In this approach, the LLM orchestrates the entire process-deciding which actions to perform, when to perform them, and whether to iterate-thereby reducing reliance on fixed, manually engineered modules. Despite the rapid adoption of both paradigms, it remains unclear which approach is preferable under which conditions. In this work, we conduct an extensive, empirically driven evaluation of Enhanced and Agentic RAG across multiple scenarios and dimensions. Our results provide practical insights into the trade-offs between the two paradigms, offering guidance on selecting the most effective RAG design for real-world applications, considering both costs and performance.", "AI": {"tldr": "本研究对增强型（Enhanced）RAG和代理型（Agentic）RAG进行了广泛的实证评估，旨在为不同场景下选择最有效的RAG设计提供指导，并权衡成本与性能。", "motivation": "基础RAG系统存在检索噪声、查询范围不匹配、文档匹配弱以及生成器成本等局限性。为了解决这些问题，研究人员开发了增强型RAG，并进一步利用LLM的自反思能力提出了代理型RAG。然而，在何种条件下哪种方法更优尚不明确，这促使了本研究。", "method": "通过在多个场景和维度下进行广泛的实证评估，比较了增强型RAG和代理型RAG的性能和成本。", "result": "研究结果揭示了这两种RAG范式之间的权衡，提供了实际的见解。", "conclusion": "本工作为选择最有效的RAG设计提供了指导，并考虑了实际应用中的成本和性能。"}}
{"id": "2601.07812", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07812", "abs": "https://arxiv.org/abs/2601.07812", "authors": ["Anurag Das", "Adrian Bulat", "Alberto Baldrati", "Ioannis Maniadis Metaxas", "Bernt Schiele", "Georgios Tzimiropoulos", "Brais Martinez"], "title": "More Images, More Problems? A Controlled Analysis of VLM Failure Modes", "comment": "19 pages, 16 figures", "summary": "Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities, yet their proficiency in understanding and reasoning over multiple images remains largely unexplored. While existing benchmarks have initiated the evaluation of multi-image models, a comprehensive analysis of their core weaknesses and their causes is still lacking. In this work, we introduce MIMIC (Multi-Image Model Insights and Challenges), a new benchmark designed to rigorously evaluate the multi-image capabilities of LVLMs. Using MIMIC, we conduct a series of diagnostic experiments that reveal pervasive issues: LVLMs often fail to aggregate information across images and struggle to track or attend to multiple concepts simultaneously. To address these failures, we propose two novel complementary remedies. On the data side, we present a procedural data-generation strategy that composes single-image annotations into rich, targeted multi-image training examples. On the optimization side, we analyze layer-wise attention patterns and derive an attention-masking scheme tailored for multi-image inputs. Experiments substantially improved cross-image aggregation, while also enhancing performance on existing multi-image benchmarks, outperforming prior state of the art across tasks. Data and code will be made available at https://github.com/anurag-198/MIMIC.", "AI": {"tldr": "本文提出了一个名为 MIMIC 的新基准测试，用于评估大型视觉语言模型（LVLM）在理解和推理多张图像方面的能力。研究发现，现有的 LVLM 在整合跨图像信息和同时关注多个概念方面存在困难。为了解决这些问题，作者提出了一种新的数据生成策略和一种注意力掩码方案，并在实验中取得了显著的性能提升。", "motivation": "现有的大型视觉语言模型在理解和推理多张图像方面的能力尚未得到充分探索和评估，缺乏对其核心弱点及其原因的全面分析。", "method": "作者引入了一个名为 MIMIC 的新基准测试，并使用该基准进行了一系列诊断实验，揭示了 LVLM 在整合跨图像信息和同时关注多个概念方面的普遍性问题。为了解决这些问题，提出了两种新的补救措施：一种程序化数据生成策略，用于创建更丰富的多图像训练样本；以及一种基于层级注意力模式分析的注意力掩码方案。", "result": "通过提出的方法，实验显著改善了模型跨图像信息的聚合能力，并提升了在现有 MUlti-Image 基准测试上的性能，超越了先前在该领域的最高水平。", "conclusion": "大型视觉语言模型在处理多张图像时存在信息整合和多概念关注的挑战。通过专门的数据生成策略和优化的注意力机制，可以显著提高模型在多图像理解和推理任务上的表现。"}}
{"id": "2601.07754", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07754", "abs": "https://arxiv.org/abs/2601.07754", "authors": ["Aryan Mishra", "Akash Anil"], "title": "Structure First, Reason Next: Enhancing a Large Language Model using Knowledge Graph for Numerical Reasoning in Financial Documents", "comment": null, "summary": "Numerical reasoning is an important task in the analysis of financial documents. It helps in understanding and performing numerical predictions with logical conclusions for the given query seeking answers from financial texts. Recently, Large Language Models (LLMs) have shown promising results in multiple Question-Answering (Q-A) systems with the capability of logical reasoning. As documents related to finance often consist of long and complex financial contexts, LLMs appear well-suited for building high-quality automated financial question-answering systems. However, LLMs often face challenges in accurately processing the various numbers within financial reports. Extracting numerical data from unstructured text and semi-structured tables, and reliably performing accurate calculations, remains a significant bottleneck for numerical reasoning in most state-of-the-art LLMs. Recent studies have shown that structured data augmentations, such as Knowledge Graphs (KGs), have notably improved the predictions of LLMs along with logical explanations. Thus, it is an important requirement to consider inherent structured information in financial reports while using LLMs for various financial analytics. This paper proposes a framework to incorporate structured information using KGs along with LLM predictions for numerical reasoning tasks. The KGs are extracted using a proposed schema inherently from the document under processing. We evaluated our proposed framework over the benchmark data FinQA, using an open-source LLM, namely Llama 3.1 8B Instruct. We observed that the proposed framework improved execution accuracy by approximately 12% relative to the vanilla LLM.", "AI": {"tldr": "该研究提出了一种结合知识图谱（KG）和大型语言模型（LLM）的框架，用于提升金融领域的数值推理能力，并在FinQA数据集上通过Llama 3.1 8B Instruct模型验证，将准确率提升了约12%。", "motivation": "大型语言模型在金融问答领域显示出潜力，但目前在准确处理金融报告中的数值数据，特别是从非结构化文本和半结构化表格中提取数值并进行精确计算方面存在挑战。现有的研究表明，知识图谱等结构化数据增强可以提升LLM的预测能力，因此需要考虑金融报告中固有的结构化信息来解决这一问题。", "method": "提出一个框架，利用从金融文档中提取的知识图谱来增强大型语言模型的数值推理能力。该框架首先根据一个预定义的模式从文档中提取知识图谱，然后将其与LLM的预测相结合。", "result": "在FinQA基准数据集上，使用Llama 3.1 8B Instruct模型对提出的框架进行了评估，结果显示，与单独使用LLM相比，该框架将数值推理的执行准确率相对提高了约12%。", "conclusion": "将知识图谱与大型语言模型相结合的框架能够有效提升金融领域的数值推理能力，克服了LLM在处理金融报告中的数值数据时遇到的瓶颈，并在实验中取得了显著的准确率提升。"}}
{"id": "2601.07795", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07795", "abs": "https://arxiv.org/abs/2601.07795", "authors": ["Patrick Bauer", "Marius Schwinning", "Florian Renk", "Andreas Weinmann", "Hichem Snoussi"], "title": "Vision-Language Model for Accurate Crater Detection", "comment": null, "summary": "The European Space Agency (ESA), driven by its ambitions on planned lunar missions with the Argonaut lander, has a profound interest in reliable crater detection, since craters pose a risk to safe lunar landings. This task is usually addressed with automated crater detection algorithms (CDA) based on deep learning techniques. It is non-trivial due to the vast amount of craters of various sizes and shapes, as well as challenging conditions such as varying illumination and rugged terrain. Therefore, we propose a deep-learning CDA based on the OWLv2 model, which is built on a Vision Transformer, that has proven highly effective in various computer vision tasks. For fine-tuning, we utilize a manually labeled dataset fom the IMPACT project, that provides crater annotations on high-resolution Lunar Reconnaissance Orbiter Camera Calibrated Data Record images. We insert trainable parameters using a parameter-efficient fine-tuning strategy with Low-Rank Adaptation, and optimize a combined loss function consisting of Complete Intersection over Union (CIoU) for localization and a contrastive loss for classification. We achieve satisfactory visual results, along with a maximum recall of 94.0% and a maximum precision of 73.1% on a test dataset from IMPACT. Our method achieves reliable crater detection across challenging lunar imaging conditions, paving the way for robust crater analysis in future lunar exploration.", "AI": {"tldr": "本文提出了一种基于OWLv2模型的深度学习月球陨石坑探测算法（CDA），使用LoRA进行参数高效微调，并结合CIoU和对比损失进行优化，在IMPACT数据集上取得了94.0%的最大召回率和73.1%的最大精确率，为未来的月球探测提供了可靠的陨石坑分析能力。", "motivation": "欧洲空间局（ESA）在规划月球任务时，需要可靠的陨石坑探测技术，因为陨石坑会给安全着陆带来风险。现有的自动化陨石坑探测算法（CDA）面临着陨石坑多样性、光照变化和地形复杂等挑战。", "method": "作者提出了一种基于OWLv2（一种基于Vision Transformer的模型）的深度学习CDA。使用IMPACT项目的手动标注数据集进行微调，并采用低秩适配（LoRA）进行参数高效微调。优化了包含完整交并比（CIoU）损失用于定位和对比损失用于分类的组合损失函数。", "result": "在IMPACT测试数据集上，该方法实现了令人满意的视觉效果，最大召回率为94.0%，最大精确率为73.1%。", "conclusion": "该方法能够在具有挑战性的月球成像条件下实现可靠的陨石坑探测，为未来月球探测中的鲁棒陨石坑分析铺平了道路。"}}
{"id": "2601.07833", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07833", "abs": "https://arxiv.org/abs/2601.07833", "authors": ["Maxwell Jones", "Rameen Abdal", "Or Patashnik", "Ruslan Salakhutdinov", "Sergey Tulyakov", "Jun-Yan Zhu", "Kuan-Chieh Jackson Wang"], "title": "Tuning-free Visual Effect Transfer across Videos", "comment": "Project Page: $\\href{https://tuningfreevisualeffects-maker.github.io/Tuning-free-Visual-Effect-Transfer-across-Videos-Project-Page/}{this\\ URL}$", "summary": "We present RefVFX, a new framework that transfers complex temporal effects from a reference video onto a target video or image in a feed-forward manner. While existing methods excel at prompt-based or keyframe-conditioned editing, they struggle with dynamic temporal effects such as dynamic lighting changes or character transformations, which are difficult to describe via text or static conditions. Transferring a video effect is challenging, as the model must integrate the new temporal dynamics with the input video's existing motion and appearance. % To address this, we introduce a large-scale dataset of triplets, where each triplet consists of a reference effect video, an input image or video, and a corresponding output video depicting the transferred effect. Creating this data is non-trivial, especially the video-to-video effect triplets, which do not exist naturally. To generate these, we propose a scalable automated pipeline that creates high-quality paired videos designed to preserve the input's motion and structure while transforming it based on some fixed, repeatable effect. We then augment this data with image-to-video effects derived from LoRA adapters and code-based temporal effects generated through programmatic composition. Building on our new dataset, we train our reference-conditioned model using recent text-to-video backbones. Experimental results demonstrate that RefVFX produces visually consistent and temporally coherent edits, generalizes across unseen effect categories, and outperforms prompt-only baselines in both quantitative metrics and human preference. See our website $\\href{https://tuningfreevisualeffects-maker.github.io/Tuning-free-Visual-Effect-Transfer-across-Videos-Project-Page/}{at\\ this\\ URL}$.", "AI": {"tldr": "RefVFX 提出了一种新的框架，可以将参考视频中的复杂时间效果以前馈方式转移到目标视频或图像上，解决了现有方法在处理动态时间效果方面的局限性。", "motivation": "现有方法在处理动态时间效果（如动态光照变化或角色变换）时存在困难，因为这些效果难以通过文本或静态条件来描述。将视频效果转移到另一个视频或图像上，需要模型能够将新的时间动态与输入视频的现有运动和外观相结合，这是一个挑战。", "method": "研究人员提出了一个大规模的三元组数据集，包含参考效果视频、输入图像/视频和转移效果后的输出视频。他们设计了一个自动流水线来生成高质量的视频对，以保持输入视频的运动和结构，同时根据固定、可重复的效果进行转换。此外，还通过 LoRA 适配器和基于代码的时间效果生成来增强数据。在此基础上，他们使用一个参考条件模型，并基于最新的文本到视频骨干网络进行训练。", "result": "RefVFX 能够生成视觉上一致且时间上连贯的编辑，能够泛化到未见过的效果类别，并且在定量指标和人类偏好方面均优于仅使用提示词的基线方法。", "conclusion": "RefVFX 框架成功实现了复杂时间视觉效果的转移，克服了现有方法的不足，并在保持视频的原始运动和外观的同时，引入了新的动态时间效果。"}}
{"id": "2601.07796", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.07796", "abs": "https://arxiv.org/abs/2601.07796", "authors": ["Shaz Furniturewala", "Gerard Christopher Yeo", "Kokil Jaidka"], "title": "Learning Through Dialogue: Unpacking the Dynamics of Human-LLM Conversations on Political Issues", "comment": null, "summary": "Large language models (LLMs) are increasingly used as conversational partners for learning, yet the interactional dynamics supporting users' learning and engagement are understudied. We analyze the linguistic and interactional features from both LLM and participant chats across 397 human-LLM conversations about socio-political issues to identify the mechanisms and conditions under which LLM explanations shape changes in political knowledge and confidence. Mediation analyses reveal that LLM explanatory richness partially supports confidence by fostering users' reflective insight, whereas its effect on knowledge gain operates entirely through users' cognitive engagement. Moderation analyses show that these effects are highly conditional and vary by political efficacy. Confidence gains depend on how high-efficacy users experience and resolve uncertainty. Knowledge gains depend on high-efficacy users' ability to leverage extended interaction, with longer conversations benefiting primarily reflective users. In summary, we find that learning from LLMs is an interactional achievement, not a uniform outcome of better explanations. The findings underscore the importance of aligning LLM explanatory behavior with users' engagement states to support effective learning in designing Human-AI interactive systems.", "AI": {"tldr": "LLM 学习中的知识和信心增长是用户与 LLM 互动的结果，并且受到用户政治效能感的影响。", "motivation": "LLM 已被广泛用作学习的对话伙伴，但支撑用户学习和参与的互动动态仍未得到充分研究。", "method": "分析了 397 次人类-LLM 对话的语言和互动特征，以识别 LLM 解释塑造政治知识和信心变化的机制和条件。", "result": "LLM 的解释丰富度通过培养用户的反思性洞察力来部分支持信心，而其对知识获取的影响完全通过用户的认知参与来实现。这些影响高度依赖于政治效能感，信心增长取决于高政治效能感用户如何体验和解决不确定性，知识增长则取决于高政治效能感用户利用扩展互动（较长的对话）的能力。", "conclusion": "从 LLM 学习是一种互动成就，而不是解释质量的统一结果。设计人类-AI 交互系统时，应使 LLM 的解释行为与用户的参与状态保持一致，以支持有效的学习。"}}
{"id": "2601.07780", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07780", "abs": "https://arxiv.org/abs/2601.07780", "authors": ["Mariana Costa", "Alberlucia Rafael Soarez", "Daniel Kim", "Camila Ferreira"], "title": "Enhancing Self-Correction in Large Language Models through Multi-Perspective Reflection", "comment": null, "summary": "While Chain-of-Thought (CoT) prompting advances LLM reasoning, challenges persist in consistency, accuracy, and self-correction, especially for complex or ethically sensitive tasks. Existing single-dimensional reflection methods offer insufficient improvements. We propose MyGO Poly-Reflective Chain-of-Thought (PR-CoT), a novel methodology employing structured multi-perspective reflection. After initial CoT, PR-CoT guides the LLM to self-assess its reasoning across multiple predefined angles: logical consistency, information completeness, biases/ethics, and alternative solutions. Implemented purely via prompt engineering, this process refines the initial CoT into a more robust and accurate final answer without model retraining. Experiments across arithmetic, commonsense, ethical decision-making, and logical puzzles, using GPT-three point five and GPT-four models, demonstrate PR-CoT's superior performance. It significantly outperforms traditional CoT and existing reflection methods in logical consistency and error correction, with notable gains in nuanced domains like ethical decision-making. Ablation studies, human evaluations, and qualitative analyses further validate the contribution of each reflection perspective and the overall efficacy of our poly-reflective paradigm in fostering more reliable LLM reasoning.", "AI": {"tldr": "本文提出了一种名为 MyGO Poly-Reflective Chain-of-Thought (PR-CoT) 的新型方法，通过多角度的结构化反思来提高大型语言模型（LLM）的推理能力，无需重新训练模型。", "motivation": "现有的 Chain-of-Thought (CoT) 提示在一致性、准确性和自我纠正方面存在挑战，尤其是在处理复杂或伦理敏感任务时。单一维度的反思方法改进不足。", "method": "PR-CoT 在初步 CoT 后，引导 LLM 从逻辑一致性、信息完整性、偏见/伦理和替代方案等多个预定义角度进行自我评估和反思，以优化推理过程，生成更可靠的最终答案。", "result": "在算术、常识、伦理决策和逻辑谜题等任务上，PR-CoT 显著优于传统 CoT 和现有反思方法，尤其在逻辑一致性和错误纠正方面表现突出，并在伦理决策等领域取得显著进展。消融研究、人类评估和定性分析均验证了其有效性。", "conclusion": "PR-CoT 是一种通过结构化多视角反思来增强 LLM 推理能力、提高其可靠性和准确性的有效方法，无需模型再训练。"}}
{"id": "2601.07765", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07765", "abs": "https://arxiv.org/abs/2601.07765", "authors": ["Igor Sterner", "Alex Lascarides", "Frank Keller"], "title": "Contrastive Learning with Narrative Twins for Modeling Story Salience", "comment": "EACL 2026", "summary": "Understanding narratives requires identifying which events are most salient for a story's progression. We present a contrastive learning framework for modeling narrative salience that learns story embeddings from narrative twins: stories that share the same plot but differ in surface form. Our model is trained to distinguish a story from both its narrative twin and a distractor with similar surface features but different plot. Using the resulting embeddings, we evaluate four narratologically motivated operations for inferring salience (deletion, shifting, disruption, and summarization). Experiments on short narratives from the ROCStories corpus and longer Wikipedia plot summaries show that contrastively learned story embeddings outperform a masked-language-model baseline, and that summarization is the most reliable operation for identifying salient sentences. If narrative twins are not available, random dropout can be used to generate the twins from a single story. Effective distractors can be obtained either by prompting LLMs or, in long-form narratives, by using different parts of the same story.", "AI": {"tldr": "本文提出了一种对比学习框架，用于通过生成“叙事双胞胎”（情节相同但表述不同的故事）来学习故事嵌入，以识别故事中的关键事件。研究发现，对比学习效果优于基线模型，并且摘要操作是识别关键句最有效的方法。如果叙事双胞胎不可用，可以通过随机丢弃或利用大型语言模型生成。", "motivation": "理解叙事需要识别对故事发展最突出的事件。现有方法在捕捉叙事中的核心事件方面存在不足。", "method": "提出一种对比学习框架，通过构建“叙事双胞胎”（共享相同情节但表面形式不同的故事）来训练模型，学习故事嵌入。模型被训练用来区分一个故事与其叙事双胞胎以及一个具有相似表面特征但情节不同的干扰项。在此基础上，评估了四种基于叙事学的方法（删除、移位、扰乱和摘要）来推断事件的突出性。", "result": "在ROCStories语料库的短篇叙事和维基百科情节摘要的较长叙事上的实验表明，对比学习生成的故事嵌入效果优于掩码语言模型基线。摘要操作被证明是识别突出句子的最可靠方法。", "conclusion": "对比学习框架能够有效地学习故事嵌入，用于识别叙事中的关键事件。当无法获得叙事双胞胎时，可以通过随机丢弃或利用大型语言模型来生成。摘要操作是判断句子突出性的有效策略。"}}
{"id": "2601.07806", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07806", "abs": "https://arxiv.org/abs/2601.07806", "authors": ["Ahmed Sabir", "Markus Kängsepp", "Rajesh Sharma"], "title": "The Confidence Trap: Gender Bias and Predictive Certainty in LLMs", "comment": "AAAI 2026 (AISI Track), Oral. Project page: https://bit.ly/4p8OKQD", "summary": "The increased use of Large Language Models (LLMs) in sensitive domains leads to growing interest in how their confidence scores correspond to fairness and bias. This study examines the alignment between LLM-predicted confidence and human-annotated bias judgments. Focusing on gender bias, the research investigates probability confidence calibration in contexts involving gendered pronoun resolution. The goal is to evaluate if calibration metrics based on predicted confidence scores effectively capture fairness-related disparities in LLMs. The results show that, among the six state-of-the-art models, Gemma-2 demonstrates the worst calibration according to the gender bias benchmark. The primary contribution of this work is a fairness-aware evaluation of LLMs' confidence calibration, offering guidance for ethical deployment. In addition, we introduce a new calibration metric, Gender-ECE, designed to measure gender disparities in resolution tasks.", "AI": {"tldr": "本研究评估了大型语言模型（LLM）的置信度分数与其预测的性别偏见分数之间的关系，并提出了一种新的性别偏见评估指标 Gender-ECE。", "motivation": "随着LLM在敏感领域的应用日益广泛，研究其置信度分数与公平性和偏见之间的一致性变得至关重要。", "method": "研究通过分析LLM在处理涉及性别代词消歧任务时的概率置信度校准，并与人类标注的偏见判断进行对比。实验评估了六种最先进的模型，并引入了Gender-ECE指标。", "result": "在接受评估的六种模型中，Gemma-2在性别偏见基准测试中表现出最差的校准性能。", "conclusion": "本研究提出了一个面向公平性的LLM置信度校准评估方法，并引入了Gender-ECE指标，为LLM的伦理部署提供了指导，并表明LLM的置信度校准可能无法有效捕捉公平性相关的差异。"}}
{"id": "2601.07820", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.07820", "abs": "https://arxiv.org/abs/2601.07820", "authors": ["Manar Ali", "Judith Sieker", "Sina Zarrieß", "Hendrik Buschmeier"], "title": "Reference Games as a Testbed for the Alignment of Model Uncertainty and Clarification Requests", "comment": null, "summary": "In human conversation, both interlocutors play an active role in maintaining mutual understanding. When addressees are uncertain about what speakers mean, for example, they can request clarification. It is an open question for language models whether they can assume a similar addressee role, recognizing and expressing their own uncertainty through clarification. We argue that reference games are a good testbed to approach this question as they are controlled, self-contained, and make clarification needs explicit and measurable. To test this, we evaluate three vision-language models comparing a baseline reference resolution task to an experiment where the models are instructed to request clarification when uncertain. The results suggest that even in such simple tasks, models often struggle to recognize internal uncertainty and translate it into adequate clarification behavior. This demonstrates the value of reference games as testbeds for interaction qualities of (vision and) language models.", "AI": {"tldr": "本研究利用参考游戏测试语言模型能否像人类一样识别自身不确定性并主动请求澄清。结果表明，即使在简单任务中，模型也难以识别不确定性并转化为有效的澄清行为，突显了参考游戏作为评估模型交互能力的价值。", "motivation": "当前语言模型在多大程度上能够扮演对话中的被听者角色，识别自身理解的不确定性并主动请求澄清，这是一个未解决的问题。作者希望通过一个可控的测试场景来探索这个问题。", "method": "研究者设计了一个参考游戏（reference game）实验。他们比较了三种视觉-语言模型在一个标准的参考解析任务和一个要求模型在不确定时请求澄清的实验中的表现。通过对比两种设置下的表现来评估模型识别和表达不确定性的能力。", "result": "研究结果表明，即使在参考游戏这样相对简单的任务中，被测试的三个视觉-语言模型在识别内部不确定性并将其转化为恰当的澄清行为方面仍然存在困难。", "conclusion": "参考游戏是一个有价值的测试平台，可以用来评估（视觉）语言模型的交互能力，特别是其识别和表达自身不确定性的能力。现有模型在执行此类交互任务时仍有待改进。"}}
{"id": "2601.07749", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.07749", "abs": "https://arxiv.org/abs/2601.07749", "authors": ["Agnieszka Kaliszewska", "Monika Syga"], "title": "On the application of the Wasserstein metric to 2D curves classification", "comment": null, "summary": "In this work we analyse a number of variants of the Wasserstein distance which allow to focus the classification on the prescribed parts (fragments) of classified 2D curves. These variants are based on the use of a number of discrete probability measures which reflect the importance of given fragments of curves. The performance of this approach is tested through a series of experiments related to the clustering analysis of 2D curves performed on data coming from the field of archaeology.", "AI": {"tldr": "本文提出了一种基于离散概率测度的Wasserstein距离变体，用于重点关注二维曲线分类的指定片段，并通过考古学数据的聚类分析进行了实验验证。", "motivation": "为了改进二维曲线分类，使其能够侧重于曲线的特定重要部分（片段）。", "method": "使用离散概率测度来量化曲线片段的重要性，并基于此提出Wasserstein距离的变体，用于曲线分类。", "result": "提出的Wasserstein距离变体在考古学二维曲线聚类分析的实验中表现出了良好的性能。", "conclusion": "基于Wasserstein距离变体并结合离散概率测度的方法，能够有效地实现对二维曲线指定片段的分类关注，并在实际应用中（如考古学数据分析）证明了其有效性。"}}
{"id": "2509.07820", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.07820", "abs": "https://arxiv.org/abs/2509.07820", "authors": ["João Paulo Nogueira", "Wentao Sun", "Alonso Silva", "Laith Zumot"], "title": "Certainty-Guided Reasoning in Large Language Models: A Dynamic Thinking Budget Approach", "comment": null, "summary": "The rise of large reasoning language models (LRLMs) has unlocked new potential for solving complex tasks. These models operate with a thinking budget, that is, a predefined number of reasoning tokens used to arrive at a solution. We propose a novel approach, inspired by the generator/discriminator framework in generative adversarial networks, in which a critic model periodically probes its own reasoning to assess whether it has reached a confident conclusion. If not, reasoning continues until a target certainty threshold is met. This mechanism adaptively balances efficiency and reliability by allowing early termination when confidence is high, while encouraging further reasoning when uncertainty persists. Through experiments on the AIME2024 and AIME2025 datasets, we show that Certainty-Guided Reasoning (CGR) improves baseline accuracy while reducing token usage. Importantly, extended multi-seed evaluations over 64 runs demonstrate that CGR is stable, reducing variance across seeds and improving exam-like performance under penalty-based grading. Additionally, our token savings analysis shows that CGR can eliminate millions of tokens in aggregate, with tunable trade-offs between certainty thresholds and efficiency. Together, these findings highlight certainty as a powerful signal for reasoning sufficiency. By integrating confidence into the reasoning process, CGR makes large reasoning language models more adaptive, trustworthy, and resource efficient, paving the way for practical deployment in domains where both accuracy and computational cost matter.", "AI": {"tldr": "本文提出了一种名为“确定性引导推理”（CGR）的新方法，模仿生成对抗网络的生成器/判别器框架，让语言模型在推理过程中自我评估确定性，从而在保证准确性的同时减少不必要的计算资源消耗。", "motivation": "现有的大型推理语言模型（LRLMs）虽然能力强大，但其推理过程需要消耗预设的“思考预算”（即推理token数量）。研究者希望在保证模型解决复杂任务的准确性的前提下，提高其资源利用效率，使其更加适合实际部署。", "method": "该方法借鉴了生成对抗网络的生成器/判别器框架。引入一个“批评者”模型，该模型会周期性地评估自身推理过程的确定性。当模型认为已达到足够高的确定性阈值时，推理过程会提前终止；否则，推理将继续进行，直到满足目标确定性阈值。", "result": "在AIME2024和AIME2025数据集上的实验表明，CGR方法在提高基线准确率的同时，显著减少了token的使用量。此外，通过64次多种子实验评估，CGR显示出良好的稳定性，降低了不同种子之间的方差，并且在模拟考试场景下（带有惩罚机制的评分）表现更优。token节省分析也显示，CGR在聚合层面上能够节省数百万token，并且可以通过调整确定性阈值来平衡准确性和效率。", "conclusion": "研究表明，确定性可以作为衡量推理充分性的一个有效信号。通过将模型自身的信心度量整合到推理过程中，CGR使大型推理语言模型更加自适应、可信赖且资源高效，为在需要兼顾准确性和计算成本的领域进行实际部署开辟了道路。"}}
